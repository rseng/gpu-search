# https://github.com/elwinter/nnde

```console
paper.md:Development of the `nnde` package began before the widespread adoption of modern neural network software frameworks. In the Python ecosystem, the most popular packages are TensorFlow (`https://tensorflow.org`) and PyTorch (`https://pytorch.org`). These frameworks are designed to be application-neutral - they can be used to develop neural networks with arbitrary architectures for arbitrary learning objectives. The primary advantages of these frameworks are autodifferentiation and distributed computing. By recording the sequence of mathematical operations performed in the forward pass through the network, autodifferentiation can automatically compute the gradients of the loss function with respect to each of the network parameters, as well as the network inputs. The latter capability is central to solving differential equations. Autodifferentiation also greatly reduces the volume of code that must be developed to solve a given problem. The distributed computing capability allows a network to take advantage of GPU-enabled hardware, and multiple compute nodes, to speed the calculation, with little or no code changes required. The `nnde` package uses a more direct method - precomputed derivative functions for the components of the differential equations of interest and the trial solution. This code is typically faster than TensorFlow or PyTorch, but requires more hand-crafted code to solve a given problem.

```
