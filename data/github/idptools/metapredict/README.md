# https://github.com/idptools/metapredict

```console
docs/getting_started.rst:#. **Easier batch predictions**\ : V2 previously required you to use ``predict_disorder_batch()`` to take advantage of the 10-100x improvement in prediction speed on CPUs and GPUs. However, you can now use a single function - ``predict_disorder()`` - on individual sequences, lists of sequences, and dictionaries of sequences, and metapredict will automatically take care of the rest for you including running batch predictions if you input more than 1 sequence. 
docs/getting_started.rst:#. **More device selection**\ : Newer versions of Torch (>2.0) support MacOS GPU utilization through the Metal Performance Shaders (MPS) framework, so you can now choose to use *mps* on MacOS. 
docs/getting_started.rst:#. **More clear device selection**\ : Metapredict used to fall back to using CPU for predictions if it failed to use GPU for whatever reason. This had good intentions but made troubleshooting GPU usage very tricky. Now if you specify using a specific device and it does not work, metapredict will not automatically fall back to CPU.
docs/getting_started.rst:WARNING: Problems with installing Torch with propert CUDA version (November 2024).
docs/getting_started.rst:**This is only relevent if you are trying to run metapredict on a CUDA-enabled GPU!**
docs/getting_started.rst:If you are on an older version of CUDA, a torch version that *does not have the correct CUDA version* will be installed. This can cause a segfault when running metapredict. To fix this, you need to install torch for your specific CUDA version. For example, to install PyTorch on Linux using pip with a CUDA version of 12.1, you would run:
docs/getting_started.rst:To figure out which version of CUDA you currently have (assuming you have a CUDA-enabled GPU that is set up correctly), you need to run:
docs/getting_started.rst:   nvidia-smi
docs/getting_started.rst:Which should return information about your GPU, NVIDIA driver version, and your CUDA version at the top.
docs/getting_started.rst:metapredict V2 and V2-FF are identical in terms of predictions and features, with the major difference being that metapredict V2-FF offers batched predictions. Batched predictions are automatically parallelized on either the CPU or GPU. In addition, we rewrote the metapredict domain decomposition algorithm in C to provide a 10-20x improvement in performance for this step.
docs/getting_started.rst:2. It's incredibly fast; on CPUs one can predict every IDR in the human proteome in ~2.5 minutes. On modest GPUs one can predict every IDR in the human proteome in under 5 seconds. This stands in stark contrast to other predictors which place length caps on sequences and can take hours per sequence.
docs/usage/using-in-python.rst:In November 2024 we upated the default version of metapredict updated to be V3. V3 introduces a few new changes including increased speed for all disorder and pLDDT predictions on CPU or GPU **and new networks for pLDDT and disorder prediction**. The new default network for disorder prediction is V3. The new default network for pLDDT prediction is V2. Furthermore, V3 introduces simplification to our Python functionality in that :code:`predict_disorder()` now offers functionality for individual predictions and batch predictions for all metapredict networks. In addition, the same functionality now applies to :code:`predict_pLDDT()`, enabling massive increases in pLDDT prediction. 
docs/usage/using-in-python.rst:If a CUDA-enabled GPU is available, batch prediction will automatically use it. If not, batch prediction will fallback to CPU. While all the original functionality is preserved, :code:`predict_disorder()`, offers a 5-10x speedup on CPUs and 30-40x speedup on GPUs. In addition, Apple Silicon machines can now use the MPS framework for GPU predictions. 
docs/usage/using-in-python.rst:If you are predicting a single IDR, metapredict will just use the CPU. However, if you input a list or dictionary of sequences, metapredict will see if a CUDA-enabled GPU is available to use and *if one is available*, metapredict will use that GPU to increase the speed of disorder prediction. However, you can 'force' metapredict to use one or the other if you'd like. You can also specify a GPU if you have multiple available. In addition, if you are using MacOS and an Apple Silicon computer, you can use a Mac GPU using the MPS framework. Metapredict will not do this automatically because mps is still under development.
docs/usage/using-in-python.rst:**Example - predicting on CUDA-enabled GPU:** 
docs/usage/using-in-python.rst:    meta.predict_disorder(sequences, device='cuda')
docs/usage/using-in-python.rst:**Example - predicting on first CUDA-enabled GPU:** 
docs/usage/using-in-python.rst:**Example - predicting on MacOS GPU (MPS):** 
docs/usage/using-in-python.rst:If you are predicting a single pLDDT score, metapredict will just use the CPU. However, if you input a list or dictionary of sequences, metapredict will see if a CUDA-enabled GPU is available to use and *if one is available*, metapredict will use that GPU to increase the speed of pLDDT prediction. However, you can 'force' metapredict to use one or the other if you'd like. You can also specify a GPU if you have multiple available. In addition, if you are using MacOS and an Apple Silicon computer, you can use a Mac GPU using the MPS framework. Metapredict will not do this automatically because mps is still under development.
docs/usage/using-in-python.rst:**Example - predicting on CUDA-enabled GPU:** 
docs/usage/using-in-python.rst:    meta.predict_pLDDT(sequences, device='cuda')
docs/usage/using-in-python.rst:**Example - predicting on first CUDA-enabled GPU:** 
docs/usage/using-in-python.rst:**Example - predicting on MacOS GPU (MPS):** 
docs/usage/using-in-python.rst:As of metapredict V2-FF (V2.6), metapredict enables GPU or CPU enabled batch prediction using ``predict_disorder_batch()``, though you can now use ``predict_disorder()``.
docs/usage/command-line.rst:By default, the results are saved to a ``disorder_scores.csv`` file in the current working directory. Additionally, a progress bar is displayed, and predictions will automatically use a GPU if one is available.
docs/usage/command-line.rst:Note that as of metapredict V3, all three networks can be submitted in batch for massive increases in prediction speed. Further, metapredict will automatically use a CUDA GPU if available. A progress bar will also be generated in the terminal.
docs/usage/command-line.rst:You can manually specify the device for prediction with the ``-d`` or ``--device`` flag. Available options are ``cpu``, ``mps`` (for Apple Silicon), ``cuda`` (for GPUs), or ``cuda:int`` to specify a specific GPU by its index.
docs/usage/command-line.rst:By default, ``metapredict`` will use a CUDA-enabled GPU if available, otherwise it defaults to the CPU.
docs/usage/command-line.rst:    $ metapredict-predict-disorder interestingProteins.fasta -d cuda:0
docs/usage/command-line.rst:As of metapredict V3, you can automatically parallelize any metapredict network on a GPU or CPU if available.
docs/usage/command-line.rst:Use the ``-d`` or ``--device`` flag to choose the device for prediction. Available options include ``cpu``, ``mps`` (for Apple Silicon), ``cuda`` (for GPUs), or ``cuda:int`` to specify a specific GPU by its index.
docs/usage/command-line.rst:By default, ``metapredict-predict-idrs`` will use a CUDA-enabled GPU if available, otherwise it defaults to the CPU.
docs/usage/command-line.rst:    $ metapredict-predict-idrs interestingProteins.fasta -d cuda:0
docs/usage/command-line.rst:To specify the device to run the prediction on (CPU, MPS, CUDA), use the ``-d`` or ``--device`` flag.
docs/usage/command-line.rst:    $ metapredict-predict-pLDDT input_sequences.fasta -d cuda:0
README.md:3. **Easier batch predictions**: V2 previously required you to use ``predict_disorder_batch()`` to take advantage of the 10-100x improvement in prediction speed on CPUs and GPUs. However, you can now use a single function - ``predict_disorder()`` - on individual sequences, lists of sequences, and dictionaries of sequences, and metapredict will automatically take care of the rest for you including running batch predictions if you input more than 1 sequence. 
README.md:7. **More device selection**: Newer versions of Torch (>2.0) support MacOS GPU utilization through the Metal Performance Shaders (MPS) framework, so you can now choose to use *mps* on MacOS. 
README.md:8. **More clear device selection**: Metapredict used to fall back to using CPU for predictions if it failed to use GPU for whatever reason. This had good intentions but made troubleshooting GPU usage very tricky. Now if you specify using a specific device and it does not work, metapredict will not automatically fall back to CPU.
README.md:#### WARNING: Problems with installing Torch with propert CUDA version (November 2024).
README.md:**This is only relevent if you are trying to run metapredict on a CUDA-enabled GPU!**
README.md:If you are on an older version of CUDA, a torch version that *does not have the correct CUDA version* will be installed. This can cause a segfault when running metapredict. To fix this, you need to install torch for your specific CUDA version. For example, to install PyTorch on Linux using pip with a CUDA version of 12.1, you would run:
README.md:To figure out which version of CUDA you currently have (assuming you have a CUDA-enabled GPU that is set up correctly), you need to run:
README.md:nvidia-smi
README.md:Which should return information about your GPU, NVIDIA driver version, and your CUDA version at the top.
README.md:4. *NEW as of August 2022:* as a Google Colab notebook for batch-predicting disorder scores for larger numbers of sequences: [**LINK HERE**](https://colab.research.google.com/drive/1UOrOxun9i23XDE8lFo_4I89Tw8P3Z1D-?usp=sharing). Performance-wise, batch mode can predict the entire yeast proteome in ~1.5 min using the Colab Notebook and much faster if using a local GPU.
metapredict/meta.py:    (a specific CUDA enabled GPU, MPS on Mac GPUs, or CPU).
metapredict/meta.py:        Possible inputs: 'cpu', 'mps', 'cuda', or an int that corresponds to
metapredict/meta.py:        the index of a specific cuda-enabled GPU. If 'cuda' is specified and
metapredict/meta.py:        cuda.is_available() returns False, instead of falling back to CPU, 
metapredict/meta.py:        using CUDA as you were expecting. 
metapredict/meta.py:            When set to None, we will check if there is a cuda-enabled
metapredict/meta.py:            GPU. If there is, we will try to use that GPU. 
metapredict/meta.py:            If you set the value to be an int, we will use cuda:int as the device
metapredict/meta.py:            where int is the int you specify. The GPU numbering is 0 indexed, so 0 
metapredict/meta.py:            corresponds to the first GPU and so on. Only specify this if you
metapredict/meta.py:            know which GPU you want to use. 
metapredict/meta.py:    parallelization such that whether it's on a GPU or a 
metapredict/meta.py:        Possible inputs: 'cpu', 'mps', 'cuda', or an int that corresponds to
metapredict/meta.py:        the index of a specific cuda-enabled GPU. If 'cuda' is specified and
metapredict/meta.py:        cuda.is_available() returns False, instead of falling back to CPU, 
metapredict/meta.py:        using CUDA as you were expecting. 
metapredict/meta.py:            When set to None, we will check if there is a cuda-enabled
metapredict/meta.py:            GPU. If there is, we will try to use that GPU. 
metapredict/meta.py:            If you set the value to be an int, we will use cuda:int as the device
metapredict/meta.py:            where int is the int you specify. The GPU numbering is 0 indexed, so 0 
metapredict/meta.py:            corresponds to the first GPU and so on. Only specify this if you
metapredict/meta.py:            know which GPU you want to use. 
metapredict/meta.py:        Possible inputs: 'cpu', 'mps', 'cuda', or an int that corresponds to
metapredict/meta.py:        the index of a specific cuda-enabled GPU. If 'cuda' is specified and
metapredict/meta.py:        cuda.is_available() returns False, instead of falling back to CPU, 
metapredict/meta.py:        using CUDA as you were expecting. 
metapredict/meta.py:            When set to None, we will check if there is a cuda-enabled
metapredict/meta.py:            GPU. If there is, we will try to use that GPU. 
metapredict/meta.py:            If you set the value to be an int, we will use cuda:int as the device
metapredict/meta.py:            where int is the int you specify. The GPU numbering is 0 indexed, so 0 
metapredict/meta.py:            corresponds to the first GPU and so on. Only specify this if you
metapredict/meta.py:            know which GPU you want to use. 
metapredict/meta.py:        the function will try to use a GPU if one is available. 
metapredict/meta.py:        Options include 'cpu', 'cuda', 'mps', or an int that corresponds
metapredict/meta.py:        to the index of a specific cuda-enabled GPU. To specify by index, 
metapredict/meta.py:        use 'cuda:int' where int is the index of the GPU you want to use.
metapredict/meta.py:        For example, 'cuda:0' would use the first GPU. If 'cuda' is specified
metapredict/meta.py:        and cuda.is_available() returns False, instead of falling back to
metapredict/meta.py:        not using CUDA as you were expecting.
metapredict/meta.py:        the function will try to use a GPU if one is available. 
metapredict/meta.py:        Options include 'cpu', 'cuda', 'mps', or an int that corresponds
metapredict/meta.py:        to the index of a specific cuda-enabled GPU. To specify by index, 
metapredict/meta.py:        use 'cuda:int' where int is the index of the GPU you want to use.
metapredict/meta.py:        For example, 'cuda:0' would use the first GPU. If 'cuda' is specified
metapredict/meta.py:        and cuda.is_available() returns False, instead of falling back to
metapredict/meta.py:        not using CUDA as you were expecting.
metapredict/backend/architectures.py:        Should be either 'cpu' or 'cuda' (GPU).
metapredict/backend/architectures.py:            Should be either 'cpu' or 'cuda' (GPU).
metapredict/backend/predictor.py:def check_device(use_device, default_device='cuda'):
metapredict/backend/predictor.py:        Possible inputs: 'cpu', 'mps', 'cuda', 'cuda:int', or an int that corresponds to
metapredict/backend/predictor.py:        the index of a specific cuda-enabled GPU. If 'cuda' is specified and
metapredict/backend/predictor.py:        cuda.is_available() returns False, instead of falling back to CPU, 
metapredict/backend/predictor.py:        using CUDA as you were expecting. 
metapredict/backend/predictor.py:        For example, we could make default device 'gpu' where it will check for 
metapredict/backend/predictor.py:        cuda or mps and use either if available and then otherwise fall back to CPU. 
metapredict/backend/predictor.py:    # if use_device is None, check for cuda. 
metapredict/backend/predictor.py:        elif default_device=='cuda':
metapredict/backend/predictor.py:            if torch.cuda.is_available():
metapredict/backend/predictor.py:                return 'cuda'
metapredict/backend/predictor.py:            raise MetapredictError("Default device can only be set to 'cpu', 'mps', or 'cuda'")
metapredict/backend/predictor.py:            use_device=f'cuda:{use_device}'
metapredict/backend/predictor.py:                    raise MetapredictError('mps was specified, but mps is not available. Be sure you are running a Mac with mps-supported GPUs and a Pytorch version with mps support (>=2.1)')
metapredict/backend/predictor.py:            elif 'cuda' in use_device:
metapredict/backend/predictor.py:                # make sure cuda is available.
metapredict/backend/predictor.py:                if torch.cuda.is_available()==False:
metapredict/backend/predictor.py:                    error_message = f'{use_device} was specified as the device, but torch.cuda.is_available() returned False.'
metapredict/backend/predictor.py:                if use_device == 'cuda':
metapredict/backend/predictor.py:                    pattern = r"^cuda(:\d+)?$"
metapredict/backend/predictor.py:                        error_message = f'{use_device} was specified as the device, but it does not match the pattern of cuda:int where int is a positive integer.'
metapredict/backend/predictor.py:                        num_devices = torch.cuda.device_count()
metapredict/backend/predictor.py:                            error_message = f'{use_device} was specified as the device, but there are only {num_devices} cuda-enabled GPUs available.\nRemember, GPU indices are 0-indexed, so cuda:0 is for the first GPU and so on.\nThe max device index you can use based on torch.cuda.device_count() is {num_devices-1}.'
metapredict/backend/predictor.py:            raise MetapredictError("Device can only be set to: None, a string equal to 'cpu', 'mps', 'cuda', 'cuda:int' where int is some positive integer, or an int that is equal to the index of a specific CUDA-enabled GPU")
metapredict/backend/predictor.py:            default_to_device = 'cuda'):
metapredict/backend/predictor.py:    parallelization such that whether it's on a GPU or a 
metapredict/backend/predictor.py:        Possible inputs: 'cpu', 'mps', 'cuda', or an int that corresponds to
metapredict/backend/predictor.py:        the index of a specific cuda-enabled GPU. If 'cuda' is specified and
metapredict/backend/predictor.py:        cuda.is_available() returns False, instead of falling back to CPU, 
metapredict/backend/predictor.py:        using CUDA as you were expecting. 
metapredict/backend/predictor.py:            When set to None, we will check if there is a cuda-enabled
metapredict/backend/predictor.py:            GPU. If there is, we will try to use that GPU. 
metapredict/backend/predictor.py:            If you set the value to be an int, we will use cuda:int as the device
metapredict/backend/predictor.py:            where int is the int you specify. The GPU numbering is 0 indexed, so 0 
metapredict/backend/predictor.py:            corresponds to the first GPU and so on. Only specify this if you
metapredict/backend/predictor.py:            know which GPU you want to use. 
metapredict/backend/predictor.py:        For example, we could make default device 'gpu' where it will check for 
metapredict/backend/predictor.py:        cuda or mps and use either if available and then otherwise fall back to CPU.
metapredict/backend/predictor.py:    # if a single sequence, just use cpu. Using GPU for a single sequence would be silly.
metapredict/backend/predictor.py:            default_to_device = 'cuda'):
metapredict/backend/predictor.py:    parallelization such that whether it's on a GPU or a 
metapredict/backend/predictor.py:        Possible inputs: 'cpu', 'mps', 'cuda', or an int that corresponds to
metapredict/backend/predictor.py:        the index of a specific cuda-enabled GPU. If 'cuda' is specified and
metapredict/backend/predictor.py:        cuda.is_available() returns False, instead of falling back to CPU, 
metapredict/backend/predictor.py:        using CUDA as you were expecting. 
metapredict/backend/predictor.py:            When set to None, we will check if there is a cuda-enabled
metapredict/backend/predictor.py:            GPU. If there is, we will try to use that GPU. 
metapredict/backend/predictor.py:            If you set the value to be an int, we will use cuda:int as the device
metapredict/backend/predictor.py:            where int is the int you specify. The GPU numbering is 0 indexed, so 0 
metapredict/backend/predictor.py:            corresponds to the first GPU and so on. Only specify this if you
metapredict/backend/predictor.py:            know which GPU you want to use. 
metapredict/backend/predictor.py:        For example, we could make default device 'gpu' where it will check for 
metapredict/backend/predictor.py:        cuda or mps and use either if available and then otherwise fall back to CPU.
metapredict/backend/predictor.py:    # if a single sequence, just use cpu. Using GPU for a single sequence would be silly.
metapredict/tests/test_metapredict_CPU_GPU.py:Testing to make sure that metapredict can use the GPU and the CPU
metapredict/tests/test_metapredict_CPU_GPU.py:prediction and pLDDT prediction on CPU and GPU. It also makes sure results
metapredict/tests/test_metapredict_CPU_GPU.py:on CPU match those from GPU. 
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disorder_v1_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disorder_v2_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disorder_v3_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_pLDDT_v1_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_pLDDT_v2_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_force_disable_batch_disorder_v1_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_force_disable_batch_disorder_v2_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_force_disable_batch_disorder_v3_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_force_disable_batch_pLDDT_v1_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_force_disable_batch_pLDDT_v2_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disable_pack_n_pad_disorder_v1_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disable_pack_n_pad_disorder_v2_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disable_pack_n_pad_disorder_v3_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disable_pack_n_pad_pLDDT_v1_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disable_pack_n_pad_pLDDT_v2_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disorder_v1_cpu_vs_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    print(f'Running metapredict version {version}, comparing CPU vs GPU scores.\n')
metapredict/tests/test_metapredict_CPU_GPU.py:    gpu_scores=meta.predict_disorder(sequences, version=version, device='cuda', round_values=False)
metapredict/tests/test_metapredict_CPU_GPU.py:        cur_gpu_scores = gpu_scores[seq_name][1]
metapredict/tests/test_metapredict_CPU_GPU.py:            assert close_enough(cur_cpu_scores[i], cur_gpu_scores[i])==True
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disorder_v2_cpu_vs_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    print(f'Running metapredict version {version}, comparing CPU vs GPU scores.\n')
metapredict/tests/test_metapredict_CPU_GPU.py:    gpu_scores=meta.predict_disorder(sequences, version=version, device='cuda', round_values=False)
metapredict/tests/test_metapredict_CPU_GPU.py:        cur_gpu_scores = gpu_scores[seq_name][1]
metapredict/tests/test_metapredict_CPU_GPU.py:            assert close_enough(cur_cpu_scores[i], cur_gpu_scores[i])==True
metapredict/tests/test_metapredict_CPU_GPU.py:def test_disorder_v3_cpu_vs_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    print(f'Running metapredict version {version}, comparing CPU vs GPU scores.\n')
metapredict/tests/test_metapredict_CPU_GPU.py:    gpu_scores=meta.predict_disorder(sequences, version=version, device='cuda', round_values=False)
metapredict/tests/test_metapredict_CPU_GPU.py:        cur_gpu_scores = gpu_scores[seq_name][1]
metapredict/tests/test_metapredict_CPU_GPU.py:            assert close_enough(cur_cpu_scores[i], cur_gpu_scores[i])==True
metapredict/tests/test_metapredict_CPU_GPU.py:def test_pLDDT_v1_cpu_vs_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    print(f'Running pLDDT prediction version {version}, comparing CPU vs GPU scores.\n')
metapredict/tests/test_metapredict_CPU_GPU.py:    gpu_scores=meta.predict_pLDDT(sequences, pLDDT_version=version, device='cuda', round_values=False)
metapredict/tests/test_metapredict_CPU_GPU.py:        cur_gpu_scores = gpu_scores[seq_name][1]
metapredict/tests/test_metapredict_CPU_GPU.py:            assert close_enough(cur_cpu_scores[i], cur_gpu_scores[i], allowed_error=0.1)==True
metapredict/tests/test_metapredict_CPU_GPU.py:def test_pLDDT_v2_cpu_vs_gpu(sequences=sequences):
metapredict/tests/test_metapredict_CPU_GPU.py:    print(f'Running pLDDT prediction version {version}, comparing CPU vs GPU scores.\n')
metapredict/tests/test_metapredict_CPU_GPU.py:    gpu_scores=meta.predict_pLDDT(sequences, pLDDT_version=version, device='cuda', round_values=False)
metapredict/tests/test_metapredict_CPU_GPU.py:        cur_gpu_scores = gpu_scores[seq_name][1]
metapredict/tests/test_metapredict_CPU_GPU.py:            assert close_enough(cur_cpu_scores[i], cur_gpu_scores[i])==True
metapredict/tests/test_metapredict_CPU_GPU.py:def test_single_sequence_disorder_v1_gpu(sequences='GSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGS'):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_single_sequence_disorder_v2_gpu(sequences='GSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGS'):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_single_sequence_disorder_v3_gpu(sequences='GSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGS'):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_single_sequence_pLDDT_v1_gpu(sequences='GSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGS'):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:def test_single_sequence_pLDDT_v2_gpu(sequences='GSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGSGS'):
metapredict/tests/test_metapredict_CPU_GPU.py:    device='cuda'
metapredict/tests/test_metapredict_CPU_GPU.py:test_single_sequence_disorder_v3_gpu()
metapredict/analysis/caid2_disorder_pdb.fasta:MEIDQCLLESLPLGQRQRLVRRMRCEQIKAYYEREKVFQKQEGLLKRIKPGKSQKVRFGLADMIQDAIIHHHDKEVLQLLKEGADPHTLVSSGGSLLHLCARYDNVFIAEVLIDRGVNVNHQDEDFWAPMHIACACDNPDIVLLLILAGANVLLQDVNGNIPLDYAVEGTESSAILLAYLDENGVDLNSLRQIKLQRPLSMLTDVRHFLSSGGDVNEKNDDGVTLLHMACASGYKEVVLLLLEHGGDLNGMDDGYWTPLHLAAKYGQTTLVKLLLAHQANPHLVNCNGEKPSDIAASESIEEMLLKAEIAWEERMKESPSVPSLAQEELYEEILHDLPELSSKLSPLVLPIAKQDSLLEKDIMFKDTTKGLCNQESQDGPPETSMVSSSSKPEQVQLTPPAPSDDLATLSELNDSSLLYEIQKRFGNDQIHTFIGDIFLLVNPFKELPIYSTVVSQMYLSPTGQRSPSLPPHLFSCAERAFHRLFQERRPQNIILSGERGSGKTQASKQIMKHLTSRASSSCTMFDSRFKHAICILEAFGHAKTTLNNVSSCLIQYWELQFCQRRKHVTGARISTYMLEKPRLVAQPPGQGSFLIFSWLMDGLSAEEKCGLHLSNFCAHRYVSQGMREDVSTAERSLNKERLADLKHALNVIGFSALEVENLFAILSAILHIGDIQFTALTEADSAFVSDLQLLEQVADMLQVSTDELASALTTDIQYFKGDVIIRRHTTQIAAFYRDLLAKSLYSRLFGFLINTVNCCLQSQDEYKSLQTLDIGILDIFGFEEFQKNEFEQLCVNLTNEKMHHYIQEVLFLQEQTECVQEGVAMETACSPGNQAGVLDFFFQKPSGFFSLLDEESQAIWSVEPNLPRKLQGLLESSNTNAVYSPMKDGNGNVAFKGQGAAFTVMHYAGRVTYEIRGAVERNKDSLSQNLLFVMKTSENVVISHLFQSKLSPTGSLISSYPSFKFGGHKSSLLSKRIASSMVGVNKNYLELSKLLKKKGTCTFLQRLERGDPATTASQLTKSLADITAKLQKGSPHFILCVKPNTSQLPGVFDHFYVSAQLQYLGVLGLVRLFRYGYPVRPSFEDFLSRYEPLASVLLGEKKGQPAEERCRLVLQRCKLQGWQMGVHKVFLKYWQVDQLGDLWLQMQRKIVTCQKVIRGFLARQHLLQRMSIKQQEVTSIKSFLQSTEDMALKTYDALVIQNASDIAREHDRLRKEVHAAYHRNRQEEGTKRAEDQGGCRHAHSNSVPVPMAVDSLAQALAGPSSRSPSLHSVFSMDDSTGLPSPRKQPPPKPKRDPNTRLSASYEAVSACLSATKDAASEALTRPRPHSDDYSTMKKIPPRKPKRSPHTKLSGSYEEIWGPRPSGTMGQVGKHHAPGTLGVQWASPDSMPQCTPQLPLHLPLPQGDYDDDGEPVYIEMVGNAARAGGSETDSPDQGESVYEEMKYVLPEEGCGPGMLTFLPASPPLFLETRKAIILEAGEGSCQPLKDTCDIPPPFPNLLPHRPPLLVFPPTPVTCSPASDESPLTPLEVKKLPVLETNLKYPVQSEGSSPLSPQYSKAQKGENDQLTSPGFPVFNGPSRISPPATPPPPPGPPPAPCGPPSAPCGPPPAPCGPPPVPCGPPPAPCGPPPAPCGAAPAPCRPPTHFAFPPDSVLVTAAKALTNSDLPRTQPKPSSAPVLGPCSPFVKAPYSPGRTARADLRKASSTFSPPSPYSPPNSRPLSSPLDELASLFNSGRSVLRRSAVGRRIREAEGFETNMNLSSRDEPSSSEMASETQDRNANNHGTQLSSSLSSVVAAENGNPVTNGLAEDDGCSRLCLSGMGTSSFQRHRESHTTQVIHQLRLSENESVALQELLDWRRKLCESREGWQEAMQHPEPRAPPPPPCKKPTLLKKPEGGSCTRLSSQLWDSSI
metapredict/analysis/seq_caid_plddt.tsv:GPSFCKADEKPCEYHADCCNCCLSGICAPSTNWILPGCSTSSFFKI	0000000000000000000000000000000000011111111111	0.364 0.482 0.541 0.677 0.754 0.777 0.775 0.804 0.827 0.845 0.858 0.821 0.842 0.771 0.79 0.751 0.785 0.778 0.759 0.766 0.759 0.799 0.795 0.823 0.844 0.848 0.843 0.788 0.724 0.652 0.585 0.539 0.522 0.557 0.525 0.562 0.557 0.564 0.516 0.519 0.439 0.468 0.495 0.428 0.366 0.383 
metapredict/analysis/seq_caid_plddt.tsv:MNEDLPKEYFELIRKALNEKEAEKAPLSRRRRVRRKNQPLPDAKKKFKTGLNELPRESVVTVNLDSSDDGVVTVPTDDSVEEIQSSEEDYDSEEFEDVTDGNEVAGVEDISVEIKPSSKRNSDARRTSRNVCSNEERKRRKYFHMLYLVCLMVHGFIRNEWINSKRLSRKLSNLVPEKVFELLHPQKDEELPLRSTRKLLDGLKKCMELWQKHWKITKKYDNVGLYMRTWKEIEMSANNKRKFKTLKRSDFLRAVSKGHGDPDISVQGFVAMLRACNVNARLIMSCQPPDFTNMKIDTSLNGNNAYKDMVKYPIFWCEVWDKFSKKWITVDPVNLKTIEQVRLHSKLAPKGVACCERNMLRYVIAYDRKYGCRDVTRRYAQWMNSKVRKRRITKDDFGEKWFRKVITALHHRKRTKIDDYEDQYFFQRDESEGIPDSVQDLKNHPYYVLEQDIKQTQIVKPGCKECGYLKVHGKVGKVLKVYAKRDIADLKSARQWYMNGRILKTGSRCKKVIKRTVGRPKGEAEEEDERLYSFEDTELYIPPLASASGEITKNTFGNIEVFAPTMIPGNCCLVENPVAIKAARFLGVEFAPAVTSFKFERGSTVKPVLSGIVVAKWLREAIETAIDGIEFIQEDDNRKEHLLGALESWNTLLLKLRIRSKLNSTYGKIAEEEPNVTKEQNIADNHDNTETFMGGGFLPGIANHEARPYSEPSEPEDSLDYVSVDKAEESATDDDVGEDYSDFMKELEMSEESD	11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111110000------------------00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000-------00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111	0.362 0.345 0.479 0.625 0.711 0.771 0.766 0.788 0.767 0.77 0.802 0.776 0.77 0.76 0.801 0.75 0.76 0.722 0.73 0.671 0.647 0.654 0.603 0.515 0.45 0.455 0.442 0.412 0.379 0.368 0.377 0.381 0.357 0.37 0.35 0.392 0.382 0.424 0.409 0.43 0.421 0.392 0.401 0.403 0.391 0.401 0.369 0.397 0.37 0.371 0.384 0.372 0.372 0.425 0.43 0.353 0.377 0.368 0.325 0.325 0.302 0.325 0.305 0.379 0.331 0.378 0.383 0.376 0.399 0.357 0.313 0.33 0.303 0.339 0.337 0.286 0.316 0.321 0.31 0.359 0.297 0.33 0.328 0.341 0.333 0.356 0.335 0.298 0.353 0.368 0.388 0.38 0.408 0.44 0.381 0.401 0.373 0.402 0.328 0.366 0.312 0.342 0.354 0.376 0.388 0.378 0.398 0.417 0.404 0.476 0.423 0.445 0.481 0.597 0.494 0.488 0.453 0.458 0.522 0.503 0.548 0.573 0.617 0.624 0.632 0.605 0.616 0.648 0.792 0.857 0.91 0.915 0.937 0.939 0.957 0.947 0.958 0.963 0.973 0.977 0.978 0.979 0.98 0.984 0.983 0.984 0.983 0.985 0.986 0.985 0.985 0.986 0.986 0.984 0.982 0.984 0.983 0.978 0.981 0.975 0.978 0.975 0.962 0.959 0.948 0.944 0.942 0.948 0.948 0.944 0.95 0.941 0.945 0.948 0.956 0.962 0.955 0.96 0.967 0.969 0.961 0.963 0.965 0.963 0.952 0.933 0.912 0.921 0.902 0.918 0.922 0.927 0.942 0.944 0.95 0.961 0.965 0.966 0.975 0.975 0.973 0.973 0.977 0.977 0.974 0.975 0.97 0.963 0.958 0.972 0.95 0.956 0.954 0.962 0.937 0.953 0.948 0.947 0.949 0.946 0.892 0.901 0.922 0.939 0.967 0.975 0.973 0.959 0.959 0.954 0.928 0.934 0.94 0.92 0.908 0.895 0.86 0.861 0.832 0.827 0.853 0.881 0.889 0.913 0.94 0.946 0.963 0.962 0.955 0.964 0.968 0.961 0.958 0.962 0.969 0.951 0.954 0.957 0.96 0.95 0.961 0.965 0.972 0.973 0.977 0.978 0.979 0.973 0.979 0.983 0.979 0.976 0.978 0.978 0.968 0.965 0.962 0.965 0.973 0.982 0.985 0.986 0.987 0.986 0.985 0.984 0.982 0.981 0.978 0.975 0.972 0.951 0.946 0.938 0.931 0.894 0.895 0.898 0.88 0.875 0.797 0.777 0.8 0.794 0.878 0.928 0.932 0.941 0.946 0.958 0.963 0.977 0.976 0.982 0.985 0.986 0.986 0.986 0.985 0.984 0.973 0.956 0.951 0.944 0.965 0.97 0.984 0.984 0.986 0.985 0.982 0.967 0.96 0.958 0.964 0.971 0.972 0.978 0.971 0.963 0.962 0.93 0.913 0.928 0.967 0.966 0.971 0.967 0.967 0.938 0.92 0.921 0.929 0.936 0.946 0.935 0.954 0.966 0.971 0.981 0.978 0.985 0.987 0.987 0.988 0.986 0.975 0.962 0.97 0.974 0.973 0.984 0.983 0.984 0.984 0.983 0.982 0.98 0.98 0.973 0.956 0.962 0.967 0.963 0.948 0.955 0.97 0.96 0.95 0.963 0.98 0.973 0.967 0.946 0.942 0.952 0.961 0.964 0.959 0.975 0.984 0.982 0.979 0.982 0.982 0.981 0.98 0.982 0.976 0.978 0.976 0.966 0.967 0.972 0.973 0.975 0.979 0.979 0.982 0.981 0.982 0.982 0.979 0.977 0.98 0.966 0.965 0.969 0.954 0.929 0.941 0.954 0.937 0.953 0.947 0.922 0.934 0.947 0.932 0.945 0.946 0.922 0.909 0.956 0.95 0.958 0.97 0.97 0.967 0.96 0.94 0.952 0.954 0.952 0.942 0.957 0.965 0.962 0.973 0.967 0.942 0.952 0.961 0.957 0.961 0.955 0.953 0.961 0.95 0.938 0.93 0.88 0.893 0.885 0.872 0.853 0.925 0.942 0.952 0.97 0.976 0.978 0.973 0.96 0.962 0.97 0.97 0.965 0.966 0.973 0.972 0.961 0.958 0.942 0.954 0.974 0.963 0.946 0.95 0.954 0.978 0.969 0.973 0.97 0.943 0.931 0.938 0.945 0.954 0.949 0.952 0.954 0.93 0.905 0.841 0.779 0.693 0.591 0.536 0.543 0.569 0.582 0.592 0.616 0.708 0.795 0.854 0.908 0.922 0.96 0.972 0.975 0.969 0.966 0.957 0.962 0.969 0.966 0.969 0.962 0.954 0.957 0.958 0.964 0.962 0.958 0.927 0.92 0.928 0.954 0.957 0.95 0.946 0.943 0.961 0.938 0.943 0.962 0.962 0.965 0.965 0.951 0.946 0.951 0.95 0.957 0.967 0.969 0.957 0.969 0.975 0.97 0.973 0.966 0.959 0.942 0.937 0.946 0.962 0.952 0.943 0.954 0.956 0.953 0.936 0.947 0.94 0.945 0.952 0.964 0.97 0.974 0.972 0.969 0.943 0.934 0.932 0.915 0.869 0.829 0.783 0.744 0.702 0.824 0.881 0.913 0.937 0.946 0.952 0.947 0.953 0.974 0.979 0.972 0.976 0.973 0.962 0.958 0.964 0.962 0.957 0.966 0.959 0.958 0.954 0.958 0.95 0.938 0.924 0.903 0.916 0.916 0.89 0.891 0.916 0.92 0.914 0.913 0.923 0.918 0.901 0.934 0.942 0.932 0.934 0.948 0.936 0.923 0.957 0.943 0.929 0.943 0.945 0.927 0.925 0.926 0.915 0.881 0.872 0.87 0.872 0.823 0.847 0.825 0.81 0.746 0.678 0.633 0.625 0.551 0.561 0.482 0.442 0.439 0.414 0.402 0.392 0.39 0.34 0.39 0.389 0.411 0.393 0.391 0.404 0.393 0.37 0.385 0.355 0.353 0.372 0.343 0.374 0.441 0.38 0.49 0.376 0.433 0.368 0.346 0.379 0.374 0.318 0.378 0.357 0.338 0.369 0.358 0.327 0.39 0.363 0.407 0.402 0.426 0.422 0.42 0.381 0.392 0.39 0.416 0.414 0.39 0.36 0.406 0.44 0.362 0.37 0.389 0.341 0.359 0.357 0.392 0.368 0.366 0.372 0.424 0.383 0.463 0.554 0.556 0.532 0.621 0.533 0.594 0.599 0.559 0.475 0.495 0.425 0.443 0.39 0.38 0.412 0.378 
metapredict/analysis/seq_caid_plddt.tsv:MEIDQCLLESLPLGQRQRLVRRMRCEQIKAYYEREKVFQKQEGLLKRIKPGKSQKVRFGLADMIQDAIIHHHDKEVLQLLKEGADPHTLVSSGGSLLHLCARYDNVFIAEVLIDRGVNVNHQDEDFWAPMHIACACDNPDIVLLLILAGANVLLQDVNGNIPLDYAVEGTESSAILLAYLDENGVDLNSLRQIKLQRPLSMLTDVRHFLSSGGDVNEKNDDGVTLLHMACASGYKEVVLLLLEHGGDLNGMDDGYWTPLHLAAKYGQTTLVKLLLAHQANPHLVNCNGEKPSDIAASESIEEMLLKAEIAWEERMKESPSVPSLAQEELYEEILHDLPELSSKLSPLVLPIAKQDSLLEKDIMFKDTTKGLCNQESQDGPPETSMVSSSSKPEQVQLTPPAPSDDLATLSELNDSSLLYEIQKRFGNDQIHTFIGDIFLLVNPFKELPIYSTVVSQMYLSPTGQRSPSLPPHLFSCAERAFHRLFQERRPQNIILSGERGSGKTQASKQIMKHLTSRASSSCTMFDSRFKHAICILEAFGHAKTTLNNVSSCLIQYWELQFCQRRKHVTGARISTYMLEKPRLVAQPPGQGSFLIFSWLMDGLSAEEKCGLHLSNFCAHRYVSQGMREDVSTAERSLNKERLADLKHALNVIGFSALEVENLFAILSAILHIGDIQFTALTEADSAFVSDLQLLEQVADMLQVSTDELASALTTDIQYFKGDVIIRRHTTQIAAFYRDLLAKSLYSRLFGFLINTVNCCLQSQDEYKSLQTLDIGILDIFGFEEFQKNEFEQLCVNLTNEKMHHYIQEVLFLQEQTECVQEGVAMETACSPGNQAGVLDFFFQKPSGFFSLLDEESQAIWSVEPNLPRKLQGLLESSNTNAVYSPMKDGNGNVAFKGQGAAFTVMHYAGRVTYEIRGAVERNKDSLSQNLLFVMKTSENVVISHLFQSKLSPTGSLISSYPSFKFGGHKSSLLSKRIASSMVGVNKNYLELSKLLKKKGTCTFLQRLERGDPATTASQLTKSLADITAKLQKGSPHFILCVKPNTSQLPGVFDHFYVSAQLQYLGVLGLVRLFRYGYPVRPSFEDFLSRYEPLASVLLGEKKGQPAEERCRLVLQRCKLQGWQMGVHKVFLKYWQVDQLGDLWLQMQRKIVTCQKVIRGFLARQHLLQRMSIKQQEVTSIKSFLQSTEDMALKTYDALVIQNASDIAREHDRLRKEVHAAYHRNRQEEGTKRAEDQGGCRHAHSNSVPVPMAVDSLAQALAGPSSRSPSLHSVFSMDDSTGLPSPRKQPPPKPKRDPNTRLSASYEAVSACLSATKDAASEALTRPRPHSDDYSTMKKIPPRKPKRSPHTKLSGSYEEIWGPRPSGTMGQVGKHHAPGTLGVQWASPDSMPQCTPQLPLHLPLPQGDYDDDGEPVYIEMVGNAARAGGSETDSPDQGESVYEEMKYVLPEEGCGPGMLTFLPASPPLFLETRKAIILEAGEGSCQPLKDTCDIPPPFPNLLPHRPPLLVFPPTPVTCSPASDESPLTPLEVKKLPVLETNLKYPVQSEGSSPLSPQYSKAQKGENDQLTSPGFPVFNGPSRISPPATPPPPPGPPPAPCGPPSAPCGPPPAPCGPPPVPCGPPPAPCGPPPAPCGAAPAPCRPPTHFAFPPDSVLVTAAKALTNSDLPRTQPKPSSAPVLGPCSPFVKAPYSPGRTARADLRKASSTFSPPSPYSPPNSRPLSSPLDELASLFNSGRSVLRRSAVGRRIREAEGFETNMNLSSRDEPSSSEMASETQDRNANNHGTQLSSSLSSVVAAENGNPVTNGLAEDDGCSRLCLSGMGTSSFQRHRESHTTQVIHQLRLSENESVALQELLDWRRKLCESREGWQEAMQHPEPRAPPPPPCKKPTLLKKPEGGSCTRLSSQLWDSSI	-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111	0.445 0.505 0.625 0.663 0.727 0.727 0.734 0.72 0.782 0.79 0.785 0.782 0.727 0.743 0.796 0.804 0.751 0.749 0.78 0.76 0.725 0.771 0.734 0.72 0.722 0.747 0.719 0.716 0.755 0.746 0.736 0.706 0.771 0.744 0.714 0.727 0.734 0.65 0.635 0.623 0.562 0.531 0.486 0.463 0.424 0.413 0.395 0.41 0.393 0.357 0.385 0.39 0.368 0.388 0.421 0.467 0.522 0.705 0.8 0.847 0.843 0.854 0.88 0.907 0.896 0.88 0.908 0.902 0.869 0.861 0.858 0.876 0.868 0.859 0.876 0.855 0.883 0.869 0.879 0.862 0.868 0.85 0.832 0.856 0.864 0.87 0.876 0.86 0.875 0.858 0.82 0.799 0.845 0.871 0.924 0.934 0.934 0.939 0.925 0.928 0.924 0.915 0.897 0.885 0.885 0.876 0.866 0.897 0.901 0.865 0.875 0.902 0.89 0.88 0.87 0.85 0.896 0.909 0.919 0.925 0.929 0.917 0.909 0.856 0.84 0.866 0.921 0.931 0.946 0.946 0.935 0.919 0.925 0.916 0.889 0.87 0.872 0.882 0.867 0.846 0.893 0.904 0.867 0.886 0.917 0.886 0.854 0.875 0.87 0.896 0.889 0.889 0.879 0.877 0.835 0.83 0.761 0.676 0.71 0.804 0.877 0.894 0.887 0.858 0.878 0.838 0.77 0.732 0.709 0.785 0.757 0.839 0.875 0.814 0.821 0.844 0.839 0.812 0.832 0.844 0.789 0.785 0.786 0.695 0.709 0.66 0.645 0.658 0.696 0.7 0.653 0.665 0.692 0.649 0.675 0.7 0.702 0.698 0.772 0.82 0.825 0.85 0.868 0.858 0.856 0.881 0.866 0.867 0.866 0.852 0.854 0.822 0.822 0.866 0.866 0.878 0.876 0.897 0.87 0.879 0.849 0.868 0.897 0.917 0.902 0.932 0.929 0.891 0.9 0.908 0.868 0.828 0.826 0.879 0.87 0.866 0.878 0.902 0.907 0.898 0.903 0.895 0.878 0.874 0.853 0.857 0.883 0.872 0.888 0.867 0.908 0.911 0.903 0.881 0.9 0.921 0.931 0.939 0.947 0.943 0.922 0.921 0.922 0.907 0.861 0.84 0.878 0.862 0.877 0.908 0.912 0.895 0.907 0.907 0.902 0.88 0.873 0.863 0.882 0.904 0.903 0.895 0.903 0.915 0.907 0.891 0.85 0.859 0.905 0.919 0.912 0.923 0.911 0.904 0.886 0.833 0.847 0.813 0.829 0.86 0.889 0.878 0.878 0.905 0.898 0.878 0.875 0.888 0.853 0.841 0.832 0.78 0.768 0.698 0.64 0.627 0.433 0.348 0.353 0.315 0.326 0.3 0.285 0.297 0.274 0.267 0.253 0.266 0.27 0.274 0.295 0.312 0.318 0.28 0.319 0.307 0.303 0.336 0.274 0.292 0.309 0.28 0.343 0.309 0.316 0.327 0.303 0.348 0.365 0.362 0.42 0.449 0.47 0.504 0.441 0.557 0.498 0.482 0.471 0.453 0.425 0.502 0.427 0.428 0.356 0.321 0.297 0.293 0.282 0.275 0.281 0.275 0.295 0.338 0.28 0.304 0.32 0.291 0.322 0.347 0.385 0.277 0.264 0.263 0.27 0.345 0.225 0.3 0.272 0.299 0.298 0.33 0.355 0.475 0.593 0.638 0.767 0.801 0.807 0.81 0.839 0.767 0.846 0.895 0.9 0.919 0.872 0.873 0.884 0.855 0.856 0.854 0.883 0.883 0.908 0.915 0.919 0.933 0.932 0.928 0.938 0.94 0.926 0.931 0.933 0.913 0.905 0.911 0.907 0.933 0.947 0.946 0.924 0.914 0.849 0.849 0.909 0.938 0.955 0.957 0.955 0.938 0.93 0.895 0.906 0.869 0.888 0.878 0.89 0.897 0.877 0.855 0.879 0.892 0.87 0.864 0.879 0.896 0.871 0.743 0.703 0.684 0.682 0.674 0.719 0.674 0.711 0.777 0.867 0.9 0.918 0.932 0.934 0.934 0.912 0.918 0.931 0.922 0.899 0.927 0.923 0.894 0.874 0.911 0.886 0.832 0.835 0.866 0.877 0.924 0.954 0.958 0.966 0.952 0.938 0.905 0.874 0.871 0.847 0.814 0.875 0.872 0.904 0.886 0.894 0.931 0.921 0.906 0.921 0.933 0.903 0.881 0.907 0.899 0.846 0.823 0.818 0.726 0.596 0.536 0.512 0.54 0.59 0.619 0.725 0.74 0.772 0.828 0.842 0.862 0.9 0.909 0.908 0.925 0.936 0.92 0.912 0.936 0.948 0.905 0.908 0.886 0.841 0.772 0.729 0.682 0.735 0.747 0.81 0.812 0.863 0.873 0.905 0.911 0.925 0.946 0.943 0.936 0.921 0.904 0.885 0.837 0.815 0.778 0.769 0.836 0.808 0.835 0.825 0.866 0.902 0.915 0.928 0.925 0.924 0.91 0.871 0.892 0.872 0.886 0.872 0.871 0.897 0.886 0.816 0.759 0.703 0.694 0.697 0.771 0.785 0.884 0.922 0.922 0.94 0.921 0.879 0.911 0.91 0.858 0.874 0.869 0.887 0.877 0.849 0.85 0.867 0.859 0.845 0.842 0.875 0.849 0.837 0.698 0.706 0.683 0.658 0.766 0.867 0.88 0.885 0.819 0.664 0.591 0.535 0.528 0.521 0.494 0.521 0.589 0.647 0.733 0.755 0.764 0.809 0.852 0.866 0.878 0.901 0.918 0.924 0.935 0.932 0.926 0.944 0.938 0.926 0.927 0.925 0.904 0.862 0.842 0.828 0.863 0.882 0.88 0.87 0.878 0.903 0.885 0.888 0.926 0.937 0.926 0.944 0.948 0.937 0.948 0.955 0.932 0.937 0.952 0.922 0.928 0.942 0.935 0.941 0.911 0.881 0.692 0.664 0.632 0.671 0.762 0.849 0.902 0.893 0.926 0.909 0.898 0.914 0.923 0.927 0.937 0.943 0.924 0.949 0.952 0.93 0.924 0.939 0.931 0.945 0.939 0.944 0.926 0.923 0.943 0.939 0.922 0.921 0.938 0.926 0.894 0.823 0.799 0.711 0.69 0.648 0.695 0.682 0.727 0.754 0.776 0.839 0.831 0.868 0.884 0.891 0.91 0.877 0.892 0.921 0.923 0.909 0.923 0.946 0.939 0.924 0.949 0.954 0.936 0.928 0.948 0.955 0.928 0.93 0.938 0.943 0.917 0.91 0.925 0.92 0.904 0.898 0.904 0.913 0.866 0.854 0.854 0.792 0.651 0.56 0.521 0.436 0.453 0.466 0.496 0.551 0.666 0.776 0.886 0.924 0.957 0.954 0.961 0.956 0.927 0.893 0.836 0.823 0.861 0.831 0.825 0.795 0.792 0.819 0.858 0.877 0.883 0.86 0.881 0.916 0.912 0.89 0.914 0.925 0.919 0.909 0.913 0.91 0.902 0.889 0.893 0.901 0.888 0.854 0.867 0.865 0.841 0.825 0.819 0.812 0.806 0.823 0.848 0.853 0.861 0.867 0.882 0.913 0.865 0.864 0.778 0.718 0.621 0.592 0.544 0.552 0.536 0.533 0.543 0.541 0.617 0.762 0.823 0.885 0.898 0.881 0.909 0.922 0.899 0.85 0.802 0.76 0.784 0.86 0.909 0.911 0.87 0.877 0.89 0.878 0.843 0.846 0.846 0.759 0.687 0.601 0.642 0.529 0.533 0.558 0.638 0.777 0.824 0.816 0.814 0.844 0.842 0.823 0.823 0.838 0.844 0.813 0.792 0.723 0.651 0.663 0.724 0.81 0.844 0.838 0.775 0.68 0.564 0.5 0.49 0.514 0.487 0.418 0.437 0.452 0.41 0.43 0.38 0.49 0.495 0.577 0.731 0.845 0.891 0.901 0.909 0.894 0.899 0.86 0.86 0.857 0.892 0.899 0.915 0.915 0.885 0.853 0.816 0.808 0.864 0.866 0.841 0.861 0.896 0.876 0.862 0.838 0.856 0.844 0.827 0.86 0.899 0.882 0.876 0.916 0.928 0.901 0.896 0.92 0.907 0.871 0.857 0.858 0.906 0.882 0.848 0.893 0.889 0.851 0.818 0.822 0.826 0.831 0.817 0.829 0.8 0.83 0.857 0.808 0.648 0.525 0.441 0.351 0.304 0.301 0.306 0.35 0.262 0.264 0.275 0.294 0.266 0.285 0.296 0.287 0.27 0.269 0.278 0.297 0.251 0.262 0.261 0.276 0.276 0.308 0.314 0.366 0.338 0.366 0.335 0.375 0.362 0.323 0.362 0.418 0.354 0.385 0.404 0.401 0.34 0.313 0.325 0.322 0.428 0.323 0.372 0.371 0.325 0.333 0.388 0.348 0.398 0.473 0.501 0.695 0.868 0.882 0.896 0.879 0.896 0.907 0.911 0.906 0.918 0.92 0.917 0.922 0.926 0.918 0.924 0.913 0.92 0.909 0.887 0.884 0.901 0.926 0.94 0.94 0.95 0.946 0.946 0.942 0.923 0.941 0.914 0.867 0.838 0.849 0.87 0.897 0.873 0.924 0.942 0.942 0.932 0.922 0.917 0.939 0.928 0.908 0.927 0.922 0.888 0.852 0.877 0.857 0.905 0.892 0.851 0.878 0.896 0.873 0.843 0.848 0.845 0.842 0.842 0.872 0.813 0.854 0.893 0.897 0.926 0.935 0.901 0.88 0.911 0.896 0.853 0.814 0.843 0.848 0.796 0.842 0.844 0.82 0.801 0.805 0.78 0.644 0.609 0.583 0.58 0.691 0.76 0.865 0.873 0.913 0.889 0.9 0.913 0.915 0.896 0.901 0.91 0.897 0.876 0.868 0.867 0.852 0.836 0.836 0.904 0.911 0.917 0.914 0.911 0.918 0.938 0.934 0.924 0.907 0.883 0.82 0.82 0.876 0.828 0.793 0.848 0.871 0.81 0.818 0.852 0.821 0.771 0.806 0.771 0.75 0.782 0.795 0.814 0.82 0.848 0.832 0.86 0.898 0.887 0.881 0.886 0.893 0.897 0.877 0.89 0.912 0.828 0.836 0.887 0.887 0.847 0.864 0.855 0.861 0.873 0.859 0.853 0.847 0.873 0.877 0.873 0.852 0.877 0.861 0.858 0.891 0.886 0.88 0.857 0.862 0.858 0.878 0.856 0.807 0.878 0.861 0.856 0.856 0.866 0.85 0.866 0.871 0.87 0.84 0.856 0.857 0.84 0.832 0.842 0.814 0.815 0.795 0.794 0.78 0.79 0.754 0.745 0.696 0.658 0.659 0.583 0.526 0.511 0.452 0.407 0.328 0.438 0.419 0.403 0.368 0.358 0.295 0.319 0.319 0.292 0.366 0.294 0.314 0.346 0.309 0.298 0.279 0.28 0.292 0.301 0.309 0.295 0.279 0.267 0.273 0.28 0.403 0.386 0.355 0.351 0.367 0.313 0.307 0.277 0.247 0.338 0.307 0.309 0.323 0.322 0.339 0.29 0.265 0.252 0.268 0.355 0.328 0.28 0.294 0.266 0.263 0.283 0.288 0.304 0.295 0.309 0.306 0.286 0.308 0.364 0.369 0.435 0.383 0.33 0.328 0.311 0.372 0.422 0.379 0.338 0.395 0.315 0.338 0.33 0.37 0.313 0.359 0.329 0.289 0.288 0.299 0.33 0.374 0.402 0.414 0.376 0.404 0.359 0.365 0.34 0.335 0.296 0.308 0.278 0.288 0.304 0.265 0.256 0.298 0.294 0.253 0.253 0.33 0.28 0.354 0.317 0.277 0.309 0.312 0.319 0.336 0.327 0.351 0.287 0.358 0.294 0.328 0.341 0.393 0.298 0.278 0.405 0.29 0.284 0.31 0.389 0.303 0.325 0.3 0.294 0.285 0.263 0.267 0.264 0.275 0.282 0.309 0.249 0.366 0.33 0.324 0.319 0.284 0.261 0.254 0.245 0.27 0.28 0.266 0.284 0.281 0.299 0.297 0.324 0.358 0.306 0.297 0.264 0.269 0.252 0.222 0.223 0.238 0.279 0.324 0.229 0.239 0.309 0.278 0.229 0.217 0.291 0.29 0.242 0.307 0.273 0.233 0.248 0.266 0.284 0.325 0.292 0.251 0.257 0.265 0.282 0.283 0.277 0.28 0.333 0.348 0.33 0.292 0.305 0.301 0.321 0.265 0.293 0.297 0.285 0.276 0.271 0.271 0.259 0.304 0.264 0.26 0.274 0.274 0.317 0.32 0.376 0.296 0.298 0.327 0.315 0.328 0.305 0.348 0.35 0.357 0.329 0.309 0.325 0.301 0.275 0.362 0.285 0.281 0.284 0.252 0.286 0.338 0.282 0.266 0.251 0.243 0.26 0.227 0.353 0.276 0.242 0.366 0.342 0.255 0.255 0.272 0.289 0.298 0.271 0.302 0.284 0.311 0.302 0.305 0.296 0.273 0.291 0.252 0.294 0.258 0.244 0.272 0.284 0.254 0.266 0.312 0.311 0.306 0.34 0.328 0.358 0.336 0.384 0.323 0.342 0.343 0.355 0.372 0.397 0.333 0.336 0.373 0.351 0.336 0.322 0.325 0.307 0.339 0.332 0.34 0.314 0.295 0.351 0.287 0.316 0.391 0.328 0.382 0.364 0.377 0.376 0.407 0.369 0.372 0.378 0.374 0.374 0.323 0.366 0.349 0.298 0.355 0.298 0.339 0.276 0.302 0.279 0.337 0.288 0.294 0.33 0.278 0.324 0.321 0.328 0.32 0.33 0.329 0.37 0.313 0.301 0.384 0.306 0.307 0.297 0.287 0.29 0.333 0.328 0.305 0.297 0.297 0.299 0.29 0.259 0.295 0.291 0.371 0.321 0.304 0.357 0.321 0.311 0.33 0.304 0.406 0.352 0.302 0.38 0.353 0.432 0.388 0.371 0.412 0.491 0.539 0.485 0.567 0.553 0.444 0.473 0.529 0.42 0.376 0.425 0.352 0.358 0.402 0.478 0.348 0.367 0.402 0.314 0.399 0.427 0.487 0.447 0.376 0.422 0.322 0.372 0.518 0.46 0.413 0.431 0.484 0.372 0.414 0.504 0.518 0.457 0.454 0.46 0.34 0.387 0.414 0.491 0.41 0.358 0.39 0.296 0.347 0.342 0.31 0.38 0.32 0.378 0.309 0.302 0.445 0.391 0.343 0.327 0.312 0.291 0.291 0.334 0.315 0.312 0.312 0.28 0.286 0.293 0.282 0.308 0.314 0.29 0.287 0.292 0.273 0.277 0.316 0.327 0.278 0.374 0.303 0.342 0.327 0.391 0.339 0.376 0.312 0.334 0.313 0.379 0.308 0.336 0.284 0.363 0.292 0.359 0.395 0.308 0.321 0.322 0.348 0.398 0.338 0.37 0.409 0.363 0.347 0.356 0.344 0.33 0.342 0.311 0.309 0.319 0.299 0.297 0.308 0.289 0.293 0.292 0.275 0.345 0.367 0.3 0.292 0.288 0.279 0.307 0.306 0.257 0.291 0.262 0.312 0.306 0.294 0.291 0.319 0.324 0.328 0.331 0.326 0.325 0.33 0.316 0.332 0.324 0.35 0.307 0.301 0.301 0.29 0.275 0.276 0.28 0.281 0.297 0.312 0.284 0.291 0.27 0.294 0.292 0.255 0.301 0.273 0.284 0.281 0.28 0.264 0.303 0.271 0.31 0.318 0.283 0.334 0.307 0.35 0.325 0.362 0.28 0.331 0.3 0.332 0.329 0.321 0.334 0.312 0.356 0.324 0.369 0.362 0.336 0.36 0.356 0.292 0.341 0.278 0.296 0.276 0.253 0.258 0.244 0.283 0.265 0.249 0.233 0.253 0.266 0.297 0.275 0.313 0.295 0.335 0.266 0.354 0.3 0.312 0.313 0.284 0.289 0.295 0.301 0.305 0.311 0.283 0.246 0.254 0.238 0.246 0.249 0.247 0.252 0.272 0.275 0.283 0.274 0.282 0.262 0.251 0.267 0.284 0.298 0.272 0.278 0.307 0.312 0.271 0.298 0.344 0.34 0.353 0.359 0.381 0.328 0.339 0.41 0.518 0.529 0.546 0.564 0.543 0.676 0.63 0.573 0.639 0.708 0.632 0.601 0.676 0.67 0.57 0.594 0.645 0.559 0.451 0.464 0.437 0.392 0.364 0.353 0.341 0.34 0.343 0.373 0.293 0.308 0.313 0.331 0.32 0.317 0.323 0.325 0.335 0.384 0.331 0.299 0.326 0.297 0.315 0.297 0.285 0.345 0.333 0.334 0.325 0.321 0.36 0.331 0.33 0.331 0.328 0.284 0.298 0.29 0.287 0.265 0.282 0.27 0.275 0.275 0.3 0.27 0.246 0.344 
metapredict/analysis/caid1_disorder_pdb.fasta:GPSFCKADEKPCEYHADCCNCCLSGICAPSTNWILPGCSTSSFFKI
metapredict/analysis/caid1_disorder_pdb.fasta:MNEDLPKEYFELIRKALNEKEAEKAPLSRRRRVRRKNQPLPDAKKKFKTGLNELPRESVVTVNLDSSDDGVVTVPTDDSVEEIQSSEEDYDSEEFEDVTDGNEVAGVEDISVEIKPSSKRNSDARRTSRNVCSNEERKRRKYFHMLYLVCLMVHGFIRNEWINSKRLSRKLSNLVPEKVFELLHPQKDEELPLRSTRKLLDGLKKCMELWQKHWKITKKYDNVGLYMRTWKEIEMSANNKRKFKTLKRSDFLRAVSKGHGDPDISVQGFVAMLRACNVNARLIMSCQPPDFTNMKIDTSLNGNNAYKDMVKYPIFWCEVWDKFSKKWITVDPVNLKTIEQVRLHSKLAPKGVACCERNMLRYVIAYDRKYGCRDVTRRYAQWMNSKVRKRRITKDDFGEKWFRKVITALHHRKRTKIDDYEDQYFFQRDESEGIPDSVQDLKNHPYYVLEQDIKQTQIVKPGCKECGYLKVHGKVGKVLKVYAKRDIADLKSARQWYMNGRILKTGSRCKKVIKRTVGRPKGEAEEEDERLYSFEDTELYIPPLASASGEITKNTFGNIEVFAPTMIPGNCCLVENPVAIKAARFLGVEFAPAVTSFKFERGSTVKPVLSGIVVAKWLREAIETAIDGIEFIQEDDNRKEHLLGALESWNTLLLKLRIRSKLNSTYGKIAEEEPNVTKEQNIADNHDNTETFMGGGFLPGIANHEARPYSEPSEPEDSLDYVSVDKAEESATDDDVGEDYSDFMKELEMSEESD
metapredict/analysis/caid1_and_2_disorder_pdb.fasta:GPSFCKADEKPCEYHADCCNCCLSGICAPSTNWILPGCSTSSFFKI
metapredict/analysis/caid1_and_2_disorder_pdb.fasta:MNEDLPKEYFELIRKALNEKEAEKAPLSRRRRVRRKNQPLPDAKKKFKTGLNELPRESVVTVNLDSSDDGVVTVPTDDSVEEIQSSEEDYDSEEFEDVTDGNEVAGVEDISVEIKPSSKRNSDARRTSRNVCSNEERKRRKYFHMLYLVCLMVHGFIRNEWINSKRLSRKLSNLVPEKVFELLHPQKDEELPLRSTRKLLDGLKKCMELWQKHWKITKKYDNVGLYMRTWKEIEMSANNKRKFKTLKRSDFLRAVSKGHGDPDISVQGFVAMLRACNVNARLIMSCQPPDFTNMKIDTSLNGNNAYKDMVKYPIFWCEVWDKFSKKWITVDPVNLKTIEQVRLHSKLAPKGVACCERNMLRYVIAYDRKYGCRDVTRRYAQWMNSKVRKRRITKDDFGEKWFRKVITALHHRKRTKIDDYEDQYFFQRDESEGIPDSVQDLKNHPYYVLEQDIKQTQIVKPGCKECGYLKVHGKVGKVLKVYAKRDIADLKSARQWYMNGRILKTGSRCKKVIKRTVGRPKGEAEEEDERLYSFEDTELYIPPLASASGEITKNTFGNIEVFAPTMIPGNCCLVENPVAIKAARFLGVEFAPAVTSFKFERGSTVKPVLSGIVVAKWLREAIETAIDGIEFIQEDDNRKEHLLGALESWNTLLLKLRIRSKLNSTYGKIAEEEPNVTKEQNIADNHDNTETFMGGGFLPGIANHEARPYSEPSEPEDSLDYVSVDKAEESATDDDVGEDYSDFMKELEMSEESD
metapredict/analysis/caid1_and_2_disorder_pdb.fasta:MEIDQCLLESLPLGQRQRLVRRMRCEQIKAYYEREKVFQKQEGLLKRIKPGKSQKVRFGLADMIQDAIIHHHDKEVLQLLKEGADPHTLVSSGGSLLHLCARYDNVFIAEVLIDRGVNVNHQDEDFWAPMHIACACDNPDIVLLLILAGANVLLQDVNGNIPLDYAVEGTESSAILLAYLDENGVDLNSLRQIKLQRPLSMLTDVRHFLSSGGDVNEKNDDGVTLLHMACASGYKEVVLLLLEHGGDLNGMDDGYWTPLHLAAKYGQTTLVKLLLAHQANPHLVNCNGEKPSDIAASESIEEMLLKAEIAWEERMKESPSVPSLAQEELYEEILHDLPELSSKLSPLVLPIAKQDSLLEKDIMFKDTTKGLCNQESQDGPPETSMVSSSSKPEQVQLTPPAPSDDLATLSELNDSSLLYEIQKRFGNDQIHTFIGDIFLLVNPFKELPIYSTVVSQMYLSPTGQRSPSLPPHLFSCAERAFHRLFQERRPQNIILSGERGSGKTQASKQIMKHLTSRASSSCTMFDSRFKHAICILEAFGHAKTTLNNVSSCLIQYWELQFCQRRKHVTGARISTYMLEKPRLVAQPPGQGSFLIFSWLMDGLSAEEKCGLHLSNFCAHRYVSQGMREDVSTAERSLNKERLADLKHALNVIGFSALEVENLFAILSAILHIGDIQFTALTEADSAFVSDLQLLEQVADMLQVSTDELASALTTDIQYFKGDVIIRRHTTQIAAFYRDLLAKSLYSRLFGFLINTVNCCLQSQDEYKSLQTLDIGILDIFGFEEFQKNEFEQLCVNLTNEKMHHYIQEVLFLQEQTECVQEGVAMETACSPGNQAGVLDFFFQKPSGFFSLLDEESQAIWSVEPNLPRKLQGLLESSNTNAVYSPMKDGNGNVAFKGQGAAFTVMHYAGRVTYEIRGAVERNKDSLSQNLLFVMKTSENVVISHLFQSKLSPTGSLISSYPSFKFGGHKSSLLSKRIASSMVGVNKNYLELSKLLKKKGTCTFLQRLERGDPATTASQLTKSLADITAKLQKGSPHFILCVKPNTSQLPGVFDHFYVSAQLQYLGVLGLVRLFRYGYPVRPSFEDFLSRYEPLASVLLGEKKGQPAEERCRLVLQRCKLQGWQMGVHKVFLKYWQVDQLGDLWLQMQRKIVTCQKVIRGFLARQHLLQRMSIKQQEVTSIKSFLQSTEDMALKTYDALVIQNASDIAREHDRLRKEVHAAYHRNRQEEGTKRAEDQGGCRHAHSNSVPVPMAVDSLAQALAGPSSRSPSLHSVFSMDDSTGLPSPRKQPPPKPKRDPNTRLSASYEAVSACLSATKDAASEALTRPRPHSDDYSTMKKIPPRKPKRSPHTKLSGSYEEIWGPRPSGTMGQVGKHHAPGTLGVQWASPDSMPQCTPQLPLHLPLPQGDYDDDGEPVYIEMVGNAARAGGSETDSPDQGESVYEEMKYVLPEEGCGPGMLTFLPASPPLFLETRKAIILEAGEGSCQPLKDTCDIPPPFPNLLPHRPPLLVFPPTPVTCSPASDESPLTPLEVKKLPVLETNLKYPVQSEGSSPLSPQYSKAQKGENDQLTSPGFPVFNGPSRISPPATPPPPPGPPPAPCGPPSAPCGPPPAPCGPPPVPCGPPPAPCGPPPAPCGAAPAPCRPPTHFAFPPDSVLVTAAKALTNSDLPRTQPKPSSAPVLGPCSPFVKAPYSPGRTARADLRKASSTFSPPSPYSPPNSRPLSSPLDELASLFNSGRSVLRRSAVGRRIREAEGFETNMNLSSRDEPSSSEMASETQDRNANNHGTQLSSSLSSVVAAENGNPVTNGLAEDDGCSRLCLSGMGTSSFQRHRESHTTQVIHQLRLSENESVALQELLDWRRKLCESREGWQEAMQHPEPRAPPPPPCKKPTLLKKPEGGSCTRLSSQLWDSSI
metapredict/scripts/metapredict_predict_pLDDT.py:    parser.add_argument('-d', '--device', default=None, help='Optional. Use this flag to specify device to use. Options are cpu, mps, cuda, or cuda:int, or an int specifying the index of a CUDA-enabled GPU.')
metapredict/scripts/metapredict_predict_disorder.py:    parser.add_argument('-d', '--device', default=None, help='Optional. Use this flag to specify device to use. Options are cpu, mps, cuda, or cuda:int, or an int specifying the index of a CUDA-enabled GPU.')
metapredict/scripts/metapredict_predict_idrs.py:    parser.add_argument('-d', '--device', default=None, help='Optional. Use this flag to specify device to use. Options are cpu, mps, cuda, or cuda:int, or an int specifying the index of a CUDA-enabled GPU.')
metapredict/__init__.py:        the a cuda GPU if available and a CPU if not.
metapredict/__init__.py:        the a cuda GPU if available and a CPU if not.
changelog.md:* Massive change to how predictor is implemented. You can now do batch prediction on CPU, GPU (CUDA), or Mac GPU (MPS) for V1 (legacy), V2, and V3. 
changelog.md:* V2.6 represents an update of metapredict to a version we refer to as metapredict V2-FF. V2-F22 provides a dramatic improvement in prediction performance when `batch_mode()` is used. On CPUs, this provides a 5-20x improvement in performance. On GPUs, this enables proteome-wide prediction in seconds. 

```
