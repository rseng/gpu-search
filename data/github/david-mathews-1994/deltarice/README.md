# https://github.com/david-mathews-1994/deltarice

```console
docs/Performance.md:## GPU Performance Testing
docs/Performance.md:For testing GPU performance a different computer was used and its specifications are below. 
docs/Performance.md: - GPU: Nvidia A100 80GB
docs/Performance.md:The most straightforward way of implementing this routine on GPU is by compressing/decompressing one chunk of data in parallel, similar to how it is performed on CPU. While it is possible to handle multiple chunks at once, this was not done during testing to keep the configuration as similar as possible to the CPU tests. For a chunk that is $2000\times7000$ as for the Nab dataset testing before, that would require $2000$ independent threads operating in parallel on a GPU for both the compression and decompression operations. Depending on the GPU in particular being used, that may be either too many or too few depending on the number of compute units available in the system. Tuning will need to be performed on a per-GPU basis to optimize the chunk size for throughput. 
docs/Performance.md:| GPU With Compression | RAM                  | File            | 1210 MB/s  |
docs/Performance.md:| GPU With Compression | File                 | RAM             | 2150 MB/s  |
docs/Performance.md:| GPU With Compression | VRAM                 | File            | 2550 MB/s  |
docs/Performance.md:| GPU With Compression | File                 | VRAM            | 3375 MB/s  |
docs/Performance.md:In this particular set of tests, the GPU compression/decompression performance was roughly the same when the data source or destination were not on the GPU. These cases require an additional data transfer which reduces throughput. The highest throughput case was when the data is read compressed from the file, decompressed on the GPU, and remains on the GPU. This is because the total amount of data transfered to and from VRAM is the smallest of all cases. Increasing the chunk size to $20000\times7000$ improved performance of the compression routine across the board due to allowing for more parallel instances at once as shown below.
docs/Performance.md:| GPU With Compression | RAM                  | File            | 1300 MB/s  |
docs/Performance.md:| GPU With Compression | File                 | RAM             | 2450 MB/s  |
docs/Performance.md:| GPU With Compression | VRAM                 | File            | 2800 MB/s  |
docs/Performance.md:| GPU With Compression | File                 | VRAM            | 5900 MB/s  |
docs/Performance.md:The GPU compression and decompression performance truly shines when the data originates or has its final destination on the GPU. When the situation requires transfers to and from the GPU, the performance is significantly lower, and in general the multi-threaded CPU implementation is a better choice. However, if a user is in a situation where they are reading data from a file with the intent of processing on GPU, this routine can significantly improve the read performance to nearly the full throughput of an uncompressed data file. 
docs/Performance.md:Unlike the CPU and GPU, FPGAs are deterministic devices that will perform a fixed set of operations every clock cycle. As such, the clock frequency of the compression or decompression function will determine throughput of the routine. For example, if the algorithm is compiled to run at 125 MHz, then the throughput of the code will be $\approx 238$ MB/s as every clock cycle will compress a single $16$ bit number. This compression routine, using the delta encoding filter, was synthesized for a single channel of the NI PXIe 5171 Oscilloscope Modules used in the Nab experiment at a rate of $250$ MHz, or $\approx 480$MB/s. By having the FPGA compress data from multiple channels simultaneously, it is possible for this rate to be improved even further, but the number of simultaneous streams and maximum frequency will depend on the FPGA. 
paper/paper.md:  - GPU
paper/paper.md:Delta-Rice is an HDF5 [@hdf5] filter plugin that was developed to compress digitized detector signals recorded by the Nab experiment [@Fry2019], a fundamental neutron physics experiment. This is a two-step process where incoming data is passed through a pre-processing filter and then compressed with Rice coding. A routine for determining the optimal pre-processing filter for a dataset is provided along with an example GPU deployment. When applied to data collected by the Nab data acquisition system, this method produced output files 29% their initial size, and was able to do so with an average read/write throughput in excess of 2 GB/s on a single CPU. Compared to the widely used Gzip compression routine, Delta-Rice reduces the file size by 33% more with over an order of magnitude increase in read/write throughput. Delta-Rice is available on CPU to users through the HDF5 library.
paper/paper.md:Delta-Rice is accessible to users through the HDF5 library [@hdf5] as filter ID $32025$. The user can specify $m$, the encoding filter, and the length of the smallest axis of the data being stored $l$. If $l$ is specified and OpenMP [@openmp] is available, then the algorithm will utilize multiple threads to compress/decompress the data. Note that datasets written in parallel can be read by either serial or parallel decoding operations, but a dataset written serially will be read serially unless $l$ was specified. For performance information and a discussion of using this routine on GPUs and FPGAs, see [Performance](https://github.com/david-mathews-1994/deltarice/blob/master/docs/Performance.md). 

```
