# https://github.com/NLeSC/litstudy

```console
tests/resources/ieee.csv:"Tracking Performance Portability on the Yellow Brick Road to Exascale","T. Deakin; A. Poenaru; T. Lin; S. McIntosh-Smith","University of Bristol,Department of Computer Science,UK; University of Bristol,Department of Computer Science,UK; University of Bristol,Department of Computer Science,UK; University of Bristol,Department of Computer Science,UK","2020 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","1 Jan 2021","2020","","","1","13","With Exascale machines on our immediate horizon, there is a pressing need for applications to be made ready to best exploit these systems. However, there will be multiple paths to Exascale, with each system relying on processor and accelerator technologies from different vendors. As such, applications will be required to be portable between these different architectures, but it is also critical that they are efficient too. These double requirements for portability and efficiency begets the need for performance portability. In this study we survey the performance portability of different programming models, including the open standards OpenMP and SYCL, across the diverse landscape of Exascale and pre-Exascale processors from Intel, AMD, NVIDIA, Fujitsu, Marvell, and Amazon, together encompassing GPUs and CPUs based on both x86 and Arm architectures. We also take a historical view and analyse how performance portability has changed over the last year.","","978-1-6654-2287-1","10.1109/P3HPC51967.2020.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309052","performance portability;programming models","Graphics processing units;Kernel;Biological system modeling;Computer architecture;Bandwidth;Parallel programming;Performance evaluation","application program interfaces;coprocessors;graphics processing units;library automation;microprocessor chips;multiprocessing systems;parallel architectures;parallel processing;parallel programming;power aware computing","performance portability;different programming models;pre-Exascale processors;yellow brick road;Exascale machines;processor;accelerator technologies","","5","","18","","1 Jan 2021","","","IEEE","IEEE Conferences"
tests/resources/ieee.csv:"Predicting the Energy Consumption of CUDA Kernels using SimGrid","D. Boughzala; L. Lefèvre; A. -C. Orgerie","Univ Lyon, EnsL, UCBL, CNRS, Inria, LIP; Univ Lyon, EnsL, UCBL, CNRS, Inria, LIP; CNRS, IRISA","2020 IEEE 32nd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)","22 Oct 2020","2020","","","191","198","Building a sustainable Exascale machine is a very promising target in High Performance Computing (HPC). To tackle the energy consumption challenge while continuing to provide tremendous performance, the HPC community have rapidly adopted GPU-based systems. Today, GPUs have became the most prevailing components in the massively parallel HPC landscape thanks to their high computational power and energy efficiency. Modeling the energy consumption of applications running on GPUs has gained a lot of attention for the last years. Alas, the HPC community lacks simple yet accurate simulators to predict the energy consumption of general purpose GPU applications. In this work, we address the prediction of the energy consumption of CUDA kernels via simulation. We propose in this paper a simple and lightweight energy model that we implemented using the open-source framework SimGrid. Our proposed model is validated across a diverse set of CUDA kernels and on two different NVIDIA GPUs (Tesla M2075 and Kepler K20Xm). As our modeling approach is not based on performance counters or detailed-architecture parameters, we believe that our model can be easily approved by users who take care of the energy consumption of their GPGPU applications.","2643-3001","978-1-7281-9924-5","10.1109/SBAC-PAD49847.2020.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9235065","GPGPU computing, CUDA kernels, Energy modeling, Simulation","Graphics processing units;Kernel;Energy consumption;Computational modeling;Instruction sets;Computer architecture;Scheduling","application program interfaces;coprocessors;graphics processing units;grid computing;parallel architectures;parallel processing;power aware computing;public domain software","high performance computing;energy consumption challenge;CUDA kernels;lightweight energy model;massively parallel HPC;GPU-based system;SimGrid;NVIDIA GPU;Tesla M2075 GPU;Kepler K20Xm GPU;GPGPU applications;exascale machine","","","","33","","22 Oct 2020","","","IEEE","IEEE Conferences"
tests/resources/ieee.csv:"Parallel Dynamic Data Driven Approaches for Synthetic Aperture Radar","A. Wijayasiri; T. Banerjee; S. Ranka; S. Sahni; M. Schmalz","Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA; Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA; Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA; Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA; Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA","2017 IEEE 24th International Conference on High Performance Computing (HiPC)","8 Feb 2018","2017","","","193","202","Hybrid multicore processors (HMPs) are poised to dominate the landscape of the next generation of computing on the desktop as well as on exascale systems. HMPs consist of general purpose CPU cores along with specialized co-processors and can provide high performance for a wide spectrum of applications at significantly lower energy requirements per FLOP. In this paper, we develop parallel algorithms and software for constructing multi-resolution SAR images on HMPs. We develop several load balancing algorithms for optimizing time performance and energy on HMPs. We also present a systematic approach for deriving the energy-time performance trade-offs on HMPs in the presence of Dynamic Voltage Frequency Scaling. Pareto-optimal curves are presented on a system consisting of 24 traditional cores and a GPU.","","978-1-5386-2293-3","10.1109/HiPC.2017.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8287750","Synthetic Aperture Radar;MultiResolution images;HMP;GPU;Load Balancing;List Assignment;DVFS;Power and Energy Evaluation","Graphics processing units;Synthetic aperture radar;Image reconstruction;Image resolution;Multicore processing;Partitioning algorithms;Load management","coprocessors;multiprocessing systems;parallel algorithms;radar computing;radar imaging;resource allocation;synthetic aperture radar","multiresolution SAR images;HMPs;energy-time performance trade-offs;Dynamic Voltage Frequency Scaling;parallel Dynamic data driven approaches;synthetic aperture radar;hybrid multicore processors;exascale systems;specialized co-processors;parallel algorithms;load balancing algorithms;Pareto-optimal curves;GPU;general purpose CPU cores","","3","","22","","8 Feb 2018","","","IEEE","IEEE Conferences"
tests/resources/ieee.csv:"Pre-exascale accelerated application development: The ORNL Summit experience","L. Luo; T. P. Straatsma; L. E. A. Suarez; R. Broer; D. Bykov; E. F. D'Azevedo; S. S. Faraji; K. C. Gottiparthi; C. De Graaf; J. A. Harris; R. W. A. Havenith; H. J. A. Jensen; W. Joubert; R. K. Kathir; J. Larkin; Y. W. Li; D. I. Lyakh; O. E. B. Messer; M. R. Norman; J. C. Oefelein; R. Sankaran; A. F. Tillack; A. L. Barnes; L. Visscher; J. C. Wells; M. Wibowo",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,"IBM Journal of Research and Development","13 May 2020","2020","64","3/4","11:1","11:21","High-performance computing (HPC) increasingly relies on heterogeneous architectures to achieve higher performance. In the Oak Ridge Leadership Facility (OLCF), Oak Ridge, TN, USA, this trend continues as its latest supercomputer, Summit, entered production in early 2019. The combination of IBM POWER9 CPU and NVIDIA V100 GPU, along with a fast NVLink2 interconnect and other latest technologies, pushes system performance to a new height and breaks the exascale barrier by certain measures. Due to Summit's powerful GPUs and much higher GPU–CPU ratio, offloading to accelerators becomes a requirement for any application, which intends to effectively use the system. To facilitate navigating a complex landscape of competing heterogeneous architectures, a collection of applications from a wide spectrum of scientific domains is selected for early adoption on Summit. In this article, the experience and lessons learned are summarized, in the hope of providing useful guidance to address new programming challenges, such as scalability, performance portability, and software maintainability, for future application development efforts on heterogeneous HPC systems.","0018-8646","","10.1147/JRD.2020.2965881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960361","","Graphics processing units;Supercomputers;Memory management;Task analysis;Kernel","","","","","","59","IBM","15 Jan 2020","","","IBM","IBM Journals"
tests/resources/ieee.csv:"Multiobjective Optimization of SAR Reconstruction on Hybrid Multicore Systems","A. Wijayasiri; T. Banerjee; S. Ranka; S. Sahni; M. Schmalz","Department of Computer, and Information Science, and Engineering, University of Florida, Gainesville, FL, USA; Department of Computer, and Information Science, and Engineering, University of Florida, Gainesville, FL, USA; Department of Computer, and Information Science, and Engineering, University of Florida, Gainesville, FL, USA; Department of Computer, and Information Science, and Engineering, University of Florida, Gainesville, FL, USA; Department of Computer, and Information Science, and Engineering, University of Florida, Gainesville, FL, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","27 Aug 2020","2020","13","","4674","4688","Hybrid multicore processors (HMPs) are poised to dominate the landscape of the next generation of computing on the desktop as well as on exascale systems. HMPs consist of general purpose CPU cores along with specialized coprocessors and can provide high performance for a wide spectrum of applications at significantly lower energy requirements per floating-point operations per second (FLOP). In this article, we develop parallel algorithms and software for constructing multiresolution synthetic aperture radar images on HMPs. We develop several load balancing algorithms for optimizing time performance and energy on HMPs. We also present a systematic approach for deriving the energy-time performance tradeoffs on HMPs in the presence of dynamic voltage frequency scaling. Pareto-optimal curves are presented on a system consisting of 24 traditional cores and a GPU.","2151-1535","","10.1109/JSTARS.2020.3014531","Air Force Office of Scientific Research(grant numbers:FA9550-15-1-0047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159855","Dynamic voltage frequency scaling (DVFS);GPU;hybrid multicore processors (HMP);load balancing;list assignment;multiresolution images;power and energy evaluation;synthetic aperture radar","Graphics processing units;Synthetic aperture radar;Image reconstruction;Image resolution;Multicore processing;Partitioning algorithms;Load management","image reconstruction;multiprocessing systems;optimisation;parallel algorithms;power aware computing;radar imaging;resource allocation;synthetic aperture radar","multiobjective optimization;SAR reconstruction;hybrid multicore systems;hybrid multicore processors;HMPs;exascale systems;floating-point operations;parallel algorithms;multiresolution synthetic aperture radar images;energy-time performance tradeoffs;Pareto-optimal curves;load balancing algorithms","","","","30","CCBY","5 Aug 2020","","","IEEE","IEEE Journals"
tests/resources/example.ris:AB  - This article provides an overview of AMD's vision for exascale computing, and in particular, how heterogeneity will play a central role in realizing this vision. Exascale computing requires high levels of performance capabilities while staying within stringent power budgets. Using hardware optimized for specific functions is much more energy efficient than implementing those functions with general-purpose cores. However, there is a strong desire for supercomputer customers not to have to pay for custom components designed only for high-end high-performance computing systems. Therefore, high-volume GPU technology becomes a natural choice for energy-efficient data-parallel computing. To fully realize the GPU's capabilities, the authors envision exascale computing nodes that compose integrated CPUs and GPUs (that is, accelerated processing units), along with the hardware and software support to enable scientists to effectively run their scientific experiments on an exascale system. The authors discuss the hardware and software challenges in building a heterogeneous exascale system and describe ongoing research efforts at AMD to realize their exascale vision.
tests/resources/springer.csv:"Comparative Study of Directive-based Programming Models on CPUs and GPUs for Scientific Applications","Emerging Research in Computing, Information, Communication and Applications","","","","10.1007/978-981-16-1342-5_61","C. NavyaH. A. SanjaySanket Salvi","2022","http://link.springer.com/chapter/10.1007/978-981-16-1342-5_61","Chapter"
notebooks/data/ieee_2.csv:"Experiences with OpenMP, PGI, HMPP and OpenACC Directives on ISO/TTI Kernels","S. Ghosh; T. Liao; H. Calandra; B. M. Chapman","Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; TOTAL E&P R&T USA, LLC, Houston, TX, USA; TOTAL E&P, Pau, France; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA","2012 SC Companion: High Performance Computing, Networking Storage and Analysis","11 Apr 2013","2012","","","691","700","GPUs are slowly becoming ubiquitous devices in High Performance Computing, as their capabilities to enhance the performance per watt of compute intensive algorithms as compared to multicore CPUs have been identified. The primary shortcoming of a GPU is usability, since vendor specific APIs are quite different from existing programming languages, and it requires a substantial knowledge of the device and programming interface to optimize applications. Hence, lately a growing number of higher level programming models are targeting GPUs to alleviate this problem. The ultimate goal for a high-level model is to expose an easy-to-use interface for the user to offload compute intensive portions of code (kernels) to the GPU, and tune the code according to the target accelerator to maximize overall performance with a reduced development effort. In this paper, we share our experiences of three of the notable high-level directive based GPU programming models - PGI, CAPS and OpenACC (from CAPS and PGI) on an Nvidia M2090 GPU. We analyze their performance and programmability against Isotropic (ISO)/Tilted Transversely Isotropic (TTI) finite difference kernels, which are primary components in the Reverse Time Migration (RTM) application used by oil and gas exploration for seismic imaging of the sub-surface. When ported to a single GPU using the mentioned directives, we observe an average 1.5-1.8x improvement in performance for both ISO and TTI kernels, when compared with optimized multi-threaded CPU implementations using OpenMP.","","978-0-7695-4956-9","10.1109/SC.Companion.2012.95","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6495877","GPGPU;OpenMP;OpenACC;PGI;CAPS;HMPP;ISO;TTI;Finite Difference Stencils;RTM","","finite difference methods;graphics processing units;multiprocessing systems;parallel processing;user interfaces","OpenMP directive;PGI directive;HMPP directive;OpenACC directive;GPU;graphics processing unit;high performance computing;compute intensive algorithm;multicore CPU;vendor specific API;application program interface;programming language;programming interface;easy-to-use user interface;Nvidia M2090 GPU;GPU programming model;isotropic kernel;tilted transversely isotropic kernel;ISO-TTI finite difference kernel;reverse time migration;RTM application","","6","","11","","11 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Evaluating Multi-core and Many-Core Architectures through Parallelizing a High-Order WENO Solver","L. Deng; H. Bai; D. Zhao; F. Wang","China Aerodynamics R&D Center, Comput. Aerodynamics Inst., Mianyang, China; China Aerodynamics R&D Center, Comput. Aerodynamics Inst., Mianyang, China; China Aerodynamics R&D Center, Comput. Aerodynamics Inst., Mianyang, China; Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2016 IEEE Trustcom/BigDataSE/ISPA","9 Feb 2017","2016","","","2167","2174","This paper studies the implementation and optimization of a high-order weighted essentially non-oscillatory (WENO) solver to the solution of the Euler equations on the multi-core and many-core architectures (Intel Ivy Bridge CPU, Intel Xeon Phi 7110P coprocessor and NVIDIA Kepler K20c GPU). The implementation of up to ninth-order accurate WENO schemes is used in the solver. For the GPU platform, both the OpenACC-based and CUDA-based versions of different WENO schemes are developed. To achieve high performance, various optimizatin techniques are used. For Ivy Bridge CPU and MIC, we focus on three categories of optimization techniques: thread parallelism for multi-/many-core scaling, data parallelism to exploit the SIMD mechanism and improving on-chip data reuse, to maximize the performance. Also, we provide an in-depth analysis on the performance differences between Ivy Bridge and MIC. The numerical experiments show that the OpenACC performance can reach up to 84% in contrast to CUDA performance with careful manual optimizations, and the proposed CUDA-based version can achieve a speedup of 9.0 on a Kepler GPU in comparison with the sequential run. We also notice that the speedups of different WENO schemes roughly reach 15.9 and 192.2 on the two Ivy Bridge CPUs and the MIC, respectively. Besides, we conduct a systematic comparison of the three platforms in three aspects: performance, programmability, and power efficiency. Our insights facilitate the programmers to select the right platform with a suitable programming model according to their target applications.","2324-9013","978-1-5090-3205-1","10.1109/TrustCom.2016.0333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847216","high-order;WENO solver;Euler equations;performance;programmability;optimization techniques;power efficiency;Ivy Bridge;MIC;GPU;CUDA;OpenACC","Graphics processing units;Mathematical model;Optimization;Programming;Bridges;Microwave integrated circuits;Computer architecture","differential equations;graphics processing units;multiprocessing systems;optimisation;parallel architectures","multicore architecture evaluation;many-core architecture evaluation;high-order WENO solver;high-order weighted essentially nonscillatory solver;Euler equations;Intel Ivy Bridge CPU;Intel Xeon Phi 7110P coprocessor;NVIDIA Kepler K20c GPU;OpenACC-based version;CUDA-based version;optimization techniques;thread parallelism;data parallelism;multicore scaling;many-core scaling;SIMD mechanism;on-chip data reuse improvement;programming model","","1","","22","","9 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A customizable MapReduce framework for complex data-intensive workflows on GPUs","Z. Qiao; Shuwen Liang; H. Jiang; Song Fu","Department of Computer Science and Engineering, University of North Texas, United States of America; Department of Computer Science and Engineering, University of North Texas, United States of America; Department of Computer Science, Arkansas State University, United States of America; Department of Computer Science and Engineering, University of North Texas, United States of America","2015 IEEE 34th International Performance Computing and Communications Conference (IPCCC)","18 Feb 2016","2015","","","1","8","The MapReduce programming model has been widely used in big data and cloud applications. Criticism on its inflexibility when being applied to complicated scientific applications recently emerges. Several techniques have been proposed to enhance its flexibility. However, some of them exert special requirements on applications, while others fail to support the increasingly popular coprocessors, such as Graphics Processing Unit (GPU). In this paper, we propose MR-Graph, a customizable and unified framework for GPU-based MapReduce, which aims to improve the flexibility and performance of MapReduce. MR-Graph addresses the limitations and restrictions of the traditional MapReduce execution paradigm. The three execution modes integrated in MR-Graph facilitates users to write their applications in a more flexible fashion by defining a Map and Reduce function call graph. MR-Graph efficiently explores the memory hierarchy in GPUs to reduce the data transfer overhead between execution stages and accommodate big data applications.We have implemented a prototype of MR-Graph and experimental results show the effectiveness of using MR-Graph for flexible and scalable GPU-based MapReduce computing.","2374-9628","978-1-4673-8590-9","10.1109/PCCC.2015.7410298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410298","MapReduce;GPU;Customizable;Data Intensive;Iterative;Recursive","Graphics processing units;Programming;Computational modeling;Data models;Parallel processing;Big data;Computer architecture","Big Data;cloud computing;graph theory;graphics processing units;parallel processing","customizable MapReduce framework;complex data-intensive workflows;MapReduce programming model;big data applications;cloud applications;graphics processing unit;MR-Graph;MapReduce execution paradigm;map and reduce function call graph;memory hierarchy;data transfer overhead;big data applications;GPU-based MapReduce computing","","2","","18","","18 Feb 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Human Skin Colour Detection Algorithm Optimization with CUDA","D. Ghorpade; A. D. Thakare","Dept. of Computer Engineering Pimpri Chinchwad College of Engineering, Pune, India; Dept. of Computer Engineering Pimpri Chinchwad College of Engineering, Pune, India","2017 International Conference on Computing, Communication, Control and Automation (ICCUBEA)","13 Sep 2018","2017","","","1","6","This Human Skin Colour detection is analyzed to be a most suitable and strong cue for face detection and face recognition which finds various application in domain like surveillance, face biometrics, gesture recognition, interactive game application and many other. These applications require fast image processing in real time and demands enormously high performance with respect to time and processing speed. Earlier work done on sequential architecture does not provide required capability and can be achieved by parallel programming. As Image processing applications shows high degree of parallelism, they prove excellent source for multi-core platform. We can use GPU multithreaded parallel computing techniques to improve the speed of image processing. The paper proposes a data parallelism programming model for Human Skin Colour Detection algorithm. The objective is to increase the computational speed of the algorithm through data parallelism using CUDA framework. The framework is supported by OpenCV libraries and implemented by GPU (Graphics Processing Unit). The evaluation is done on basis of comparative analysis of serial and parallel programming computing. The pixel based Explicitly Defined Region skin classifier is used and RGB colour space is chosen due to its wider use in storing and processing of digital image data. To gain substantial acceleration in image computations, skin classifier code is off-loaded to GPU having compute capacity of 3.5 and rest of code is executed on CPU. We have tested module on static images, as well as on live camera captured images. SFA standard dataset is utilized to evaluate performance. Speedup of 23.45% was achieved using parallel programming.","","978-1-5386-4008-1","10.1109/ICCUBEA.2017.8464010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464010","Human skin colour;GPU;Image processing;CUDA;Parallel processing;Colour space;RGB colour space;Skin classifier","Graphics processing units;Image color analysis;Skin;Instruction sets;Parallel processing;Computational modeling;Kernel","face recognition;graphics processing units;image classification;image colour analysis;multiprocessing systems;multi-threading;object detection","image processing applications;graphics processing unit;OpenCV libraries;pixel based explicitly defined region skin classifier;digital image data storage;SFA standard dataset;live camera captured images;static images;skin classifier code;image computations;RGB colour space;CUDA framework;computational speed;data parallelism programming model;GPU multithreaded parallel computing techniques;multicore platform;parallel programming;processing speed;fast image processing;interactive game application;gesture recognition;face biometrics;face recognition;face detection","","","","20","","13 Sep 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A way for accelerating DNA sequences reconstruction problem based on CUDA","Y. Zhong; J. Lin; B. Wang; C. Tao; X. Wen; C. Nian","Computer Science and Engineering Department, Sichuan University Jinjiang College, Penshan 620860, China; Computer Science and Engineering Department, Sichuan University Jinjiang College, Penshan 620860, China; Computer Science and Engineering Department, Sichuan University Jinjiang College, Penshan 620860, China; Computer Science and Engineering Department, Sichuan University Jinjiang College, Penshan 620860, China; Computer Science and Engineering Department, Sichuan University Jinjiang College, Penshan 620860, China; Computer Science and Engineering Department, Sichuan University Jinjiang College, Penshan 620860, China","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","1 Dec 2014","2014","","","151","157","Traditionally, shotgun for DNA sequences alignment is one of the main method of bioinformatics. It is used to break a long DNA sequence into small fragments. This paper introduces a new method to improve the efficiency of DNA sequence reconstruction after shotgun method using construction suffix array based on CUDA programming model. The experimental results show the construction of suffix array using GPU is an more efficient approach on Intel(R) Core(TM) i3-3110K quad-core and NVIDIA GeForce 610M GPU. Consequently, The experiment presents the efficiency of GPU performance compared with CPU performance, and study shows the method is more than 20 times speedup than that of CPU serial implementation.","","978-1-4799-3080-7","10.1109/ICACCI.2014.6968196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968196","CUDA;GPU;shotgun method;superstring;DNA sequence reassemble;suffix array;radix sort","DNA;Graphics processing units;Arrays","bioinformatics;DNA;graphics processing units;parallel architectures","DNA sequences reconstruction problem;DNA sequences alignment;bioinformatics;long DNA sequence;DNA sequence reconstruction;shotgun method;construction suffix array;CUDA programming model;Intel Core i3-3110K quadcore;NVIDIA GeForce 610M GPU","","","","13","","1 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Accelerating data clustering on GPU-based clusters under shared memory abstraction","K. I. Karantasis; E. D. Polychronopoulos; G. N. Dimitrakopoulos","High Performance Information Systems Lab, School of Computer Engineering and Informatics, University of Patras, Rio, Greece 26500; High Performance Information Systems Lab, School of Computer Engineering and Informatics, University of Patras, Rio, Greece 26500; High Performance Information Systems Lab, School of Computer Engineering and Informatics, University of Patras, Rio, Greece 26500","2010 IEEE International Conference On Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS)","28 Oct 2010","2010","","","1","5","Many-core graphics processors are playing today an important role in the advancements of modern highly concurrent processors. Their ability to accelerate computation is being explored under several scientific fields. In the current paper we present the acceleration of a widely used data clustering algorithm, K-means, in the context of high performance GPU clusters. As opposed to most related implementation efforts that use MPI to port their target applications on a GPU cluster, our implementation follows the Software Distributed Shared Memory (SDSM) paradigm in order to distribute information and computation across the accelerator cluster. In order to investigate the efficiency of a programming model that offers shared memory abstraction on GPU clusters we present two implementations, one that is based on a SDSM implementation of OpenMP and another that utilizes the Pleiad cluster middleware on top of the Java platform. The first results show that such an implementation is feasible in order to accelerate a broad category of large scale, data intensive applications, among which K-means is a characteristic case.","","978-1-4244-8396-9","10.1109/CLUSTERWKSP.2010.5613079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613079","","Graphics processing unit;Clustering algorithms;Programming;Middleware;Acceleration;Graphics","data handling;distributed shared memory systems;message passing;multiprocessing programs;pattern clustering","data clustering;GPU-based clusters;shared memory abstraction;many-core graphics processors;concurrent processors;K-means algorithm;MPI;software distributed shared memory;OpenMP","","6","","24","","28 Oct 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Design and evaluation of a parallel k-nearest neighbor algorithm on CUDA-enabled GPU","S. Liang; Y. Liu; C. Wang; L. Jian","Graduate University of Chinese Academy of Sciences, Beijing, 100190, China; Graduate University of Chinese Academy of Sciences, Beijing, 100190, China; Agilent Technologies, Beijing, 100102, China; Graduate University of Chinese Academy of Sciences, Beijing, 100190, China","2010 IEEE 2nd Symposium on Web Society","21 Oct 2010","2010","","","53","60","Recent developments in Graphics Processing Units (GPUs) have enabled inexpensive high performance computing for general-purpose applications. Due to GPU's tremendous computing capability, it has emerged as the co-processor of CPU to achieve a high overall throughput. CUDA programming model provides the programmers adequate C language like APIs to better exploit the parallel power of the GPU. K-nearest neighbor (KNN) is a widely used classification technique and has significant applications in various domains, especially in text classification. The computational-intensive nature of KNN requires a high performance implementation. In this paper, we propose CUKNN, a CUDA-based parallel implementation of KNN. It launches two CUDA kernels, distance calculation kernel and selecting kernel. In the distance calculation kernel, a great number of concurrent CUDA threads are issued, where each thread performs the calculation between the query object and a reference object; in the selecting kernel, threads in a block find the local-k nearest neighbors of the query object concurrently, and then a thread is invoked to find the global-k nearest neighbors out of the queues of local-k neighbors. Various CUDA optimization techniques are applied to maximize the utilization of GPU. We evaluate our implementation by using synthetic dataseis and a real physical simulation dataset. The experimental results demonstrate that CUKNN outperforms the serial KNN on an HP xw8600 workstation significantly, achieving up to 46.7IX speedup on the synthetic dataseis and 42.49X on the physical simulation dataset including I/O cost. It also shows good scalability when varying the number of dimensions of the reference dataset, the number of objects in the reference dataset, and the number of objects in the query dataset.","2158-6993","978-1-4244-6359-6","10.1109/SWS.2010.5607480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607480","","Graphics processing unit;Instruction sets;Kernel;Nearest neighbor searches;Computational modeling;Programming;Classification algorithms","C language;computer graphic equipment;coprocessors;optimisation;pattern classification","parallel k-nearest neighbor algorithm;CUDA-enabled GPU;graphics processing units;coprocessor;C language;KNN;classification technique;text classification;parallel implementation;CUDA optimization techniques;query dataset","","12","1","18","","21 Oct 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Iterative tensor tracking using GPU for textile fabric defect detection","K. L. Mak; X. W. Tian","Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, China; Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, China","The 2010 International Conference on Green Circuits and Systems","9 Aug 2010","2010","","","375","380","This paper presents an efficient real-time implementation of an unsupervised textile fabric defect detection algorithm called ITT using the concept of iterative tensor tracking on graphics processing unit (GPU). The algorithm adopts a new local image descriptor, Spatial Histograms of Oriented Gradients (S-HOG), which is shift-invariant, light insensitive and space scalable. For a given textile fabric image, ITT iteratively updates and then analyzes S-HOG using tensor operations, in particular tensor decomposition to detect textile defects. To speedup the calculation required, ITT is implemented on the GPU using the Compute Unified Device Architecture (CUDA) programming model. The respective computational efficiencies of implementing ITT on the GPU and on the CPU are compared by using experiments. The results demonstrate that the computation speed of the former is on average thirty times and ten times faster than that of the later for updating the S-HOG and for detecting defects respectively because of its parallel processing nature.","","978-1-4244-6878-2","10.1109/ICGCS.2010.5543036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5543036","","Tensile stress;Textiles;Fabrics;Detection algorithms;Graphics;Iterative algorithms;Histograms;Image analysis;Computer architecture;Computational efficiency","computer graphic equipment;coprocessors;fabrics;iterative methods;parallel architectures;production engineering computing;tensors;textiles;tracking","iterative tensor tracking;GPU;textile fabric defect detection;real-time implementation;graphics processing unit;local image descriptor;spatial histograms of oriented gradients;textile fabric image;tensor operations;tensor decomposition;compute unified device architecture programming;computation speed;parallel processing","","1","","9","","9 Aug 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"An Evaluation of Unified Memory Technology on NVIDIA GPUs","W. Li; G. Jin; X. Cui; S. See","Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China; Tokyo Inst. of Technol., Tokyo, Japan; Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China; Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","9 Jul 2015","2015","","","1092","1098","Unified Memory is an emerging technology which is supported by CUDA 6.X. Before CUDA 6.X, the existing CUDA programming model relies on programmers to explicitly manage data between CPU and GPU and hence increases programming complexity. CUDA 6.X provides a new technology which is called as Unified Memory to provide a new programming model that defines CPU and GPU memory space as a single coherent memory (imaging as a same common address space). The system manages data access between CPU and GPU without explicit memory copy functions. This paper is to evaluate the Unified Memory technology through different applications on different GPUs to show the users how to use the Unified Memory technology of CUDA 6.X efficiently. The applications include Diffusion3D Benchmark, Parboil Benchmark Suite, and Matrix Multiplication from the CUDA SDK Samples. We changed those applications to corresponding Unified Memory versions and compare those with the original ones. We selected the NVIDIA Keller K40 and the Jetson TK1, which can represent the latest GPUs with Keller architecture and the first mobile platform of NVIDIA series with Keller GPU. This paper shows that Unified Memory versions cause 10% performance loss on average. Furthermore, we used the NVIDIA Visual Profiler to dig the reason of the performance loss by the Unified Memory technology.","","978-1-4799-8006-2","10.1109/CCGrid.2015.105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152596","Unified Memory;Heterogeneous Computing;CUDA programming model","Graphics processing units;Benchmark testing;Kernel;Programming;Computational modeling;Memory management;Random access memory","graphics processing units;parallel architectures;storage management","unified memory technology;NVIDIA GPUs;CUDA 6.X;CUDA programming model;data management;CPU;programming complexity;single coherent memory;Diffusion3D benchmark;parboil benchmark suite;matrix multiplication;CUDA SDK samples;NVIDIA Keller K40;Jetson TK1;Keller architecture;mobile platform;NVIDIA visual profiler","","27","","21","","9 Jul 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Improving Application Performance by Efficiently Utilizing Heterogeneous Many-core Platforms","J. Shen; A. L. Varbanescu; H. Sips","Parallel & Distrib. Syst. Group, Delft Univ. of Technol., Delft, Netherlands; Inf. Inst., Univ. of Amsterdam, Amsterdam, Netherlands; Parallel & Distrib. Syst. Group, Delft Univ. of Technol., Delft, Netherlands","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","9 Jul 2015","2015","","","709","712","Heterogeneous platforms integrating different types of processing units (such as multi-core CPUs and GPUs) are in high demand in high performance computing. Existing studies have shown that using heterogeneous platforms can improve application performance and hardware utilization. However, systematic methods to design, implement, and map applications to efficiently use heterogeneous computing resources are only very few. The goal of my PhD research is therefore to study such heterogeneous systems and propose systematic methods to allow many (classes of) applications to efficiently use them. After 3.5 years of PhD study, my contributions are (1) a thorough evaluation of a suitable programming model for heterogeneous computing, (2) a workload partitioning framework to accelerate parallel applications on heterogeneous platforms, (3) a modelling-based prediction method to determine the optimal workload partitioning, (4) a systematic approach to decide the best mapping between the application and the platform by choosing the best performing hardware configuration (Only-CPU, Only-GPU, or CPU+GPU with the workload partitioning). In the near future, I plan to apply my approach to large-scale applications and platforms to expand its usability and applicability.","","978-1-4799-8006-2","10.1109/CCGrid.2015.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152538","Heterogeneous platforms;Workload partitioning;Hardware configuration;Multi-core CPUs;GPUs;Accelerators","Hardware;Systematics;Computational modeling;Kernel;Graphics processing units;Programming;Predictive models","graphics processing units;multiprocessing systems;performance evaluation","application performance improvement;heterogeneous many-core platforms;multicore CPU;multicore GPU;high-performance computing;hardware utilization improvement;heterogeneous computing resource usage;programming model;parallel applications;modeling-based prediction method;optimal workload partitioning;only-CPU hardware configuration;only-GPU hardware configuration;CPU-plus-GPU hardware configuration;large-scale applications","","1","3","10","","9 Jul 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Singular value decomposition on GPU using CUDA","S. Lahabar; P. J. Narayanan","Center for Visual Information Technology, International Institute of Information Technology, Hyderabad, India; Center for Visual Information Technology, International Institute of Information Technology, Hyderabad, India","2009 IEEE International Symposium on Parallel & Distributed Processing","10 Jul 2009","2009","","","1","10","Linear algebra algorithms are fundamental to many computing applications. Modern GPUs are suited for many general purpose processing tasks and have emerged as inexpensive high performance co-processors due to their tremendous computing power. In this paper, we present the implementation of singular value decomposition (SVD) of a dense matrix on GPU using the CUDA programming model. SVD is implemented using the twin steps of bidiagonalization followed by diagonalization. It has not been implemented on the GPU before. Bidiagonalization is implemented using a series of householder transformations which map well to BLAS operations. Diagonalization is performed by applying the implicitly shifted QR algorithm. Our complete SVD implementation outperforms the Matlab and Intel regMath kernel library (MKL) LAPACK implementation significantly on the CPU. We show a speedup of upto 60 over the MATLAB implementation and upto 8 over the Intel MKL implementation on a Intel Dual Core 2.66 GHz PC on NVIDIA GTX 280 for large matrices. We also give results for very large matrices on NVIDIA Tesla S1070.","1530-2075","978-1-4244-3751-1","10.1109/IPDPS.2009.5161058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5161058","","Singular value decomposition;Linear algebra;Computer applications;Coprocessors;High performance computing;Matrix decomposition;Mathematical model;Kernel;Libraries;MATLAB","computer graphic equipment;linear algebra;matrix algebra;parallel processing;programming languages;singular value decomposition","singular value decomposition;graphics processing unit;high performance coprocessor;CUDA programming model;householder transformation;Intel Math kernel library;Matlab;Intel Dual Core PC;linear algebra algorithm;parallel coprocessor;frequency 2.66 GHz","","61","","25","","10 Jul 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"CUDA-enabled Hadoop cluster for Sparse Matrix Vector Multiplication","M. Reza; A. Sinha; R. Nag; P. Mohanty","High Performance Computing Lab, School of Computer Science and Engineering, National Institute of Science & Technology, Berhampur-761008, India; High Performance Computing Lab, School of Computer Science and Engineering, National Institute of Science & Technology, Berhampur-761008, India; High Performance Computing Lab, School of Computer Science and Engineering, National Institute of Science & Technology, Berhampur-761008, India; High Performance Computing Lab, School of Computer Science and Engineering, National Institute of Science & Technology, Berhampur-761008, India","2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS)","3 Sep 2015","2015","","","169","172","Compute Unified Device Architecture (CUDA) is an architecture and programming model that allows leveraging the high compute-intensive processing power of the Graphical Processing Units (GPUs) to perform general, non-graphical tasks in a massively parallel manner. Hadoop is an open-source software framework that has its own file system, the Hadoop Distributed File System (HDFS), and its own programming model, the Map Reduce, in order to accomplish the tasks of storage of very large amount of data and their fast processing in a distributed manner in a cluster of inexpensive hardware. This paper presents a model and implementation of a Hadoop-CUDA Hybrid approach to perform Sparse Matrix Vector Multiplication (SpMV) of very large matrices in a very high performing manner. Hadoop is used for splitting the input matrix into smaller sub-matrices, storing them on individual data nodes and then invoking the required CUDA kernels on the individual GPU-possessing cluster nodes. The original SpMV is done using CUDA. Such an implementation has been seen to improve the performance of the SpMV operation over very large matrices by speedup of around 1.4 in comparison to non-Hadoop, single-GPU CUDA implementation.","","978-1-4799-8349-0","10.1109/ReTIS.2015.7232872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7232872","Hadoop;MapReduce;SpMV;CUDA;SCOO;GPGPU","Graphics processing units;Sparse matrices;Kernel;Instruction sets;Java;Programming;File systems","data handling;graphics processing units;parallel architectures","CUDA-enabled Hadoop cluster;sparse matrix vector multiplication;compute unified device architecture;programming model;high compute-intensive processing power;graphical processing units;massively parallel manner;open-source software framework;Hadoop distributed file system;Map Reduce;distributed manner;Hadoop-CUDA hybrid approach;input matrix;smaller sub-matrices;data nodes;GPU-possessing cluster nodes","","2","","11","","3 Sep 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"GREEN Cache: Exploiting the Disciplined Memory Model of OpenCL on GPUs","J. Lee; D. H. Woo; H. Kim; M. Azimi","Intel Corporation, Hillsboro, OR; Google, Inc., Mountain View, CA; School of Computer Science, Georgia Institute of Technology, Atlanta, GA; Platform Architecture Research team in the Microprocessor and Programming Research group","IEEE Transactions on Computers","6 Oct 2015","2015","64","11","3167","3180","As various graphics processing unit architectures are deployed across broad computing spectrum from a hand-held or embedded device to a high-performance computing server, OpenCL becomes the de facto standard programming environment for general-purpose computing on graphics processing units. Unlike its CPU counterpart, OpenCL has several distinct features such as its disciplined memory model, which is partially inherited from conventional 3D graphics programming models. On the other hand, due to ever increasing memory bandwidth pressure and low power requirement, the capacity of on-chip caches in GPUs keeps increasing overtime. Given such trends, we believe that we have interesting programming model/architecture co-optimization opportunities, in particular, how to energy-efficiently utilize large on-chip caches for GPUs. In this paper, as a showcase, we study the characteristics of the OpenCL memory model and propose a technique called GPU Region-aware energy-efficient non-inclusive cache hierarchy, or GREEN cache hierarchy. With the GREEN cache, our simulation results show that we can save 56 percent of dynamic energy in the L1 cache, 39 percent of dynamic energy in the L2 cache, and 50 percent of leakage energy in the L2 cache with practically no performance degradation and off-chip access increases.","1557-9956","","10.1109/TC.2015.2395435","US National Science Foundation(grant numbers:1054830); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7018047","OpenCL;GPU;Cache;OpenCL;GPU;cache","Graphics processing units;Kernel;Computational modeling;Programming;Memory management;Hardware;Training","cache storage;energy conservation;graphics processing units;low-power electronics;power aware computing","disciplined memory model;graphics processing unit architectures;hand-held device;embedded device;high-performance computing server;de facto standard programming environment;general-purpose computing;3D graphics programming models;memory bandwidth;low power requirement;programming architecture;energy efficiency;large on-chip caches;GPU;OpenCL memory model;region-aware energy-efficient noninclusive cache hierarchy;GREEN cache hierarchy;dynamic energy;L1 cache;L2 cache;leakage energy;off-chip access","","7","","40","IEEE","22 Jan 2015","","","IEEE","IEEE Journals"
notebooks/data/ieee_2.csv:"Fast CUDA-based codec for height fields","Đ. M. Đurđević; I. I. Tartalja","School of Electrical Engineering, University of Belgrade, Bul. kralja Aleksandra 73, 11120, Serbia; School of Electrical Engineering, University of Belgrade, Bul. kralja Aleksandra 73, 11120, Serbia","2013 21st Telecommunications Forum Telfor (TELFOR)","20 Jan 2014","2013","","","947","954","Following the advances in remote sensing technology in the last decade, the horizontal and vertical scan resolutions for digital terrains have reached the order of a meter and decimeter, respectively. At these resolutions, descriptions of real terrains require very large storage spaces. Efficient storage, transfer, retrieval, and manipulation of such large amounts of data require an efficient compression method. This paper presents a method for fast lossy and lossless compression of regular height fields, which are a commonly used solution for representing surfaces scanned at regular intervals along two axes. The method is suitable for SIMD parallel implementation and thus inherently suitable for modern GPU architectures, which significantly outperform modern CPUs in computation speed, and are already present in home computers. The method allows independent decompression of individual data points, as well as progressive decompression. Even in the case of lossy decompression, the decompressed surface is inherently seamless. The method's efficiency was confirmed through a CUDA implementation of compression and decompression algorithms, and application in a terrain visualization system.","","978-1-4799-1420-3","10.1109/TELFOR.2013.6716388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716388","height field;lossy and lossless compression;progressive decompression;SIMD parallelism;GPU friendly algorithm;CUDA programming model;terrain visualization","Graphics processing units;Image coding;Approximation methods;Parallel processing;Data visualization;Vegetation;Educational institutions","codecs;data compression;geophysical image processing;graphics processing units;parallel architectures;remote sensing","CUDA based codec;height fields;horizontal scan resolution;vertical scan resolution;digital terrains;regular height field lossy compression;regular height field lossless compression;SIMD parallel implementation;GPU architecture;terrain visualization system","","","","31","","20 Jan 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Unified Cross-Platform Profiling of Parallel C++ Applications","V. Kucher; F. Fey; S. Gorlatch","University of Muenster, Einsteinstr. 62, Muenster, Germany; University of Muenster, Einsteinstr. 62, Muenster, Germany; University of Muenster, Einsteinstr. 62, Muenster, Germany","2018 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)","14 Feb 2019","2018","","","57","62","To address the great variety of available parallel hardware architectures (CPUs, GPUs, etc.), high-performance applications increasingly demand cross-platform portability. While unified programming models like OpenCL or SYCL provide the ultimate portability of code, the profiling of applications in the development process is still done by using different platform-specific tools of the corresponding hardware vendors. We design and implement a unified, cross-platform profiling interface by extending the PACXX framework for unified programming in C++. With our profiling interface, a single tool is used to profile parallel C++ applications across different target platforms. We illustrate and evaluate our uniform profiler using an example application of matrix multiplication for CPU and GPU architectures.","","978-1-7281-0182-8","10.1109/PMBS.2018.8641652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8641652","C++;parallelism;many-cores;GPU programming;cross-platform;unified programming model;profiling","Kernel;Computer architecture;Hardware;Graphics processing units;Measurement;Tools;C++ languages","C++ language;graphics processing units;matrix multiplication;multiprocessing systems;parallel architectures;parallel programming","unified cross-platform profiling;parallel C++ applications;high-performance applications;parallel hardware architectures;hardware vendors;OpenCL;SYCL;platform-specific tools;PACXX;matrix multiplication;GPU architectures;CPU architectures","","","","16","","14 Feb 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Exploiting GPUs to Simulate Complex Systems","F. Messina; G. Pappalardo; C. Santoro","Dipt. di Mat. e Inf., Univ. di Catania, Catania, Italy; Dipt. di Mat. e Inf., Univ. di Catania, Catania, Italy; Dipt. di Mat. e Inf., Univ. di Catania, Catania, Italy","2013 Seventh International Conference on Complex, Intelligent, and Software Intensive Systems","19 Sep 2013","2013","","","535","540","This paper describes GCS (GPU-aware ComplexSim), a simulation framework for complex systems which is capable of executing on GPUs exploiting the CUDA programming model. GCS is based on an architecture similar to a previous work, ComplexSim, which provides simulation functionalities on symmetric multiprocessing (SMP) systems. With the current architecture of GCS, the simulation of the complex system run on GPUs, while tasks related to graph analysis still run on the host, by exploiting the embedded multi-thread engine of ComplexSim. The user code can be provided as a behaviour function, without taking into account issues related to task parallelisation, which are managed by the engine of GCS. In GCS, network data -"" as links and mailboxes -"" are organised as SoA (Structure of Array) to deal with the constraints and optimisation issues related to GPU architecture and the CUDA programming model. Moreover nodes attributes are defined by the user as in the case of ComplexSim, but GCS automatically organises them into SoA. GCS exhibits a significant improvement, in terms of simulation times, if compared to ComplexSim running on a SMP system.","","978-0-7695-4992-7","10.1109/CISIS.2013.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603946","","Graphics processing units;Message systems;Arrays;Instruction sets;Engines;Data models","digital simulation;embedded systems;graphics processing units;large-scale systems;multiprocessing systems;multi-threading;parallel architectures","complex systems;GCS;GPU-aware ComplexSim;simulation framework;CUDA programming model;symmetric multiprocessing;SMP systems;graph analysis;embedded multithread engine;user code;network data;SoA;structure of array;GPU architecture","","12","","29","","19 Sep 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Parallelizing the cellular potts model on GPU and multi-core CPU: An OpenCL cross-platform study","C. Yu; B. Yang","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2014 11th International Joint Conference on Computer Science and Software Engineering (JCSSE)","26 Jun 2014","2014","","","117","122","In this paper, we present the analysis and development of a cross-platform OpenCL parallelization of the Cellular Potts Model (CPM). In general, the evolution of the CPM is time-consuming. Using data-parallel programming model such as CUDA can accelerate the process, but it is highly dependent on the hardware type and manufacturer. Recently, OpenCL has attracted a lot of attention and been widely used by researchers. OpenCL provides a flexible solution, which allows us to come up with an implementation that can execute on both GPUs and multi-core CPUs regardless of the hardware type and manufacturer. Some optimizations are also made for both GPU and multi-core CPU implementations of the CPM, and we also propose a resource management method, MLBBRM. Experimental results show that the developed optimized algorithms for both GPU and multi-core CPU have an average speedup of about 30× and 8× respectively compared with the single threaded CPU implementation.","","978-1-4799-5822-1","10.1109/JCSSE.2014.6841853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6841853","Cellular Potts Model;OpenCL;Parallel computing;Cross-platform","Computer science;Software engineering","biology computing;cellular biophysics;graphics processing units;multiprocessing systems;parallel processing;resource allocation","cross-platform OpenCL parallelization;cellular Potts model;CPM;GPU;optimizations;multicore CPU implementations;resource management method;MLBBRM","","3","","17","","26 Jun 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Tradeoffs and Considerations in the Design of Accelerators for Database Applications","R. Moussalli","T.J. Watson Res. Center, Accel. Platforms Group, IBM, Yorktown Heights, NY, USA","2017 IEEE 33rd International Conference on Data Engineering (ICDE)","18 May 2017","2017","","","1615","1615","General purpose processors have traditionally been favored over application-specific architectures due to the provided flexibility, standardized and simpler programming model, as well as significant reduction in development time. Fueled by the steady advances in transistor scaling, general purpose CPUs satisfied the performance needs of most applications. While CPUs were becoming ubiquitous, advances in digital storage technologies and sensing devices (cameras, microphones, etc) led to massive and sky-rocketing amounts of data being generated by devices of all scales. Extracting insights out of this Big Data introduces significant opportunities for business intelligence, though the growth of data volumes and complexity of query patterns has been increasing at a startling rate. With Moore's law ending, transistors' shrinking coming to a halt and CPU performance saturating, accelerator technologies are increasingly embraced to augment general purpose CPUs and to address performance concerns. Accelerators diverge from traditional CPU architectures in the way they utilize the available silicon resources. In particular, accelerators maximize the resources available for raw computing (ALUs, Floating Point Units) and push back the burden of correct program semantics and control to higher levels of the stack including the compiler and programming models, while focusing on a selected subset of applications. Accelerators include Application Specific Integrated Circuits (ASICs), Field Programmable Gate Arrays (FPGAs) and General Purpose Graphics Processing Units (GPGPUs), each with their programming model, advantages and challenges. FPGAs enable the deployment of deep custom pipelines, whereas GPGPUs provide hundreds of small processors executing in a massively parallel fashion. Compared to CPUs, accelerators attain higher performance out of the available transistors for a wide range of applications. This talk covers tradeoffs of accelerators (FPGA and GPGPU) specific to a set of database applications, namely XML filtering, spatiotemporal analytics in the context of the Internet of Things, and relational database querying. Tradeoff metrics include programmability, performance, accuracy and energy consumption. While accelerators achieve high speedups for ""hot"" code paths, the attach point of accelerators in a system significantly impacts the end-to-end application performance. As such, system and deployment-level considerations must be made. To this end, I will go over IBM's efforts to facilitate the inclusion and increase the adoption of accelerators. These include (1) the Coherent Accelerator Processor Interface (CAPI), reducing software refactoring from the CPU side as well as CPU-accelerator latency, (2) the ConTutto research platform for acceleration innovation in the memory subsystem, providing very high bandwidth to accelerators, and (3) NVLink<sup>®</sup>-enabled IBM POWER<sup>®</sup> processors.","2375-026X","978-1-5090-6543-1","10.1109/ICDE.2017.238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7930135","accelerator;acceleration;hardware;FPGA;GPU;database;ConTutto;CAPI;NVLink","Program processors;Field programmable gate arrays;Integrated circuit modeling;Trademarks;Databases;Programming;Transistors","Internet of Things;query processing;relational databases;software maintenance;XML","database applications;programming models;application specific integrated circuits;ASIC;field programmable gate arrays;FPGA;general purpose graphics processing units;GPGPU;deep custom pipelines;XML filtering;spatiotemporal analytics;Internet of Things;relational database querying;programmability;energy consumption;deployment-level considerations;coherent accelerator processor interface;CAPI;software refactoring;CPU-accelerator latency;ConTutto research platform;acceleration innovation;memory subsystem;NVLink-enabled IBM POWER processors;compiler;program semantics;floating point units;ALU;raw computing;accelerators;silicon resources;CPU architectures;accelerator technologies;CPU performance saturating;Moore law ending;query patterns;Big Data;sky-rocketing amounts;sensing devices;digital storage technologies;general purpose CPU;transistor scaling;development time;simpler programming model;standardized;flexibility;application-specific architectures;general purpose processors","","2","","","","18 May 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Achieving Portability and Performance through OpenACC","J. A. Herdman; W. P. Gaudin; O. Perks; D. A. Beckingsale; A. C. Mallinson; S. A. Jarvis","High Performance Comput., AWE plc, Aldermaston, UK; High Performance Comput., AWE plc, Aldermaston, UK; High Performance Comput., AWE plc, Aldermaston, UK; Dept. of Comput. Sci., Univ. of Warwick, Warwick, UK; Dept. of Comput. Sci., Univ. of Warwick, Warwick, UK; Dept. of Comput. Sci., Univ. of Warwick, Warwick, UK","2014 First Workshop on Accelerator Programming using Directives","9 Apr 2015","2014","","","19","26","OpenACC is a directive-based programming model designed to allow easy access to emerging advanced architecture systems for existing production codes based on Fortran, C and C++. It also provides an approach to coding contemporary technologies without the need to learn complex vendor-specific languages, or understand the hardware at the deepest level. Portability and performance are the key features of this programming model, which are essential to productivity in real scientific applications. OpenACC support is provided by a number of vendors and is defined by an open standard. However the standard is relatively new, and the implementations are relatively immature. This paper experimentally evaluates the currently available compilers by assessing two approaches to the OpenACC programming model: the ""parallel"" and ""kernels"" constructs. The implementation of both of these construct is compared, for each vendor, showing performance differences of up to 84%. Additionally, we observe performance differences of up to 13% between the best vendor implementations. OpenACC features which appear to cause performance issues in certain compilers are identified and linked to differing default vector length clauses between vendors. These studies are carried out over a range of hardware including GPU, APU, Xeon and Xeon Phi based architectures. Finally, OpenACC performance, and productivity, are compared against the alternative native programming approaches on each targeted platform, including CUDA, OpenCL, OpenMP 4.0 and Intel Offload, in addition to MPI and OpenMP.","","978-1-4673-6753-0","10.1109/WACCPD.2014.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081674","","Kernel;Graphics processing units;Computer architecture;Programming;Acceleration;Hardware;Microprocessors","application program interfaces;software performance evaluation;software portability;software standards","OpenMP;Intel Offload;MPI;OpenCL;CUDA;native programming approaches;Xeon Phi based architectures;APU;GPU;OpenACC features;kernels constructs;parallel constructs;OpenACC programming model;open standard;real scientific applications;C++ language;C language;Fortran;production codes;advanced architecture systems;directive-based programming model;portability","","8","","20","","9 Apr 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Fast parallel interpolation algorithm using CUDA","Y. Zhao; Q. Qiu; J. Fang; L. Li","Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China","2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS","27 Jan 2014","2013","","","3662","3665","Interpolation is one time consuming and serial operation in the fields of spatial information processing. While fast processing speed is often required in some real-time interactive scenarios. With the development of Purpose computing on Graphics Processing Units (GPGPU), it provides an opportunity to accelerate some traditional inefficient algorithms with low-cost and low-power compared to clusters. In this paper, we mapped the Inverse distance weighted (IDW) interpolation method to Compute Unified Device Architecture (CUDA) parallel programming model. Taking the advantage of Graphics Processing Unit (GPU) parallel computing, we build two-level indexes on GPU, then clever blocking schemes are used to assign computing task among different threads. After illustrate the parallel interpolation process, we conduct several experiments, the result shows the correctness and high efficiency of our optimized implementation. With larger influence radius and massive data, the performance can obtain dozens of times speedups over a very similar single-threaded CPU implementation.","2153-7003","978-1-4799-1114-1","10.1109/IGARSS.2013.6723624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6723624","parallel interpolation;GPGPU;CUDA;Inverse distance weighted interpolation","Graphics processing units;Interpolation;Indexes;Tiles;Instruction sets;Binary codes;Real-time systems","graphics processing units;interpolation;mathematics computing;multi-threading;parallel architectures","parallel interpolation algorithm;spatial information processing;processing speed;real-time interactive scenarios;GPGPU;inverse distance weighted interpolation method;IDW interpolation method;compute unified device architecture;CUDA parallel programming model;graphics processing unit parallel computing;GPU parallel computing;two-level indexes;blocking schemes;computing task assignment;multithreading;performance improvement","","","1","9","","27 Jan 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Evaluating cache coherent shared virtual memory for heterogeneous multicore chips","B. A. Hechtman; D. J. Sorin","Department of Electrical and Computer Engineering, Duke University, USA; Department of Electrical and Computer Engineering, Duke University, USA","2013 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)","15 Jul 2013","2013","","","118","119","Although current homogeneous chips tightly couple the cores with cache-coherent shared virtual memory (CCSVM), this is not the communication paradigm used by any current heterogeneous chip. In this paper, we present a CCSVM design for a CPU/GPU chip, as well as an extension of the pthreads programming model for programming this HMC. We experimentally compare CCSVM/xthreads to a state-of-the-art CPU/GPU chip from AMD that runs OpenCL software. CCSVM's more efficient communication enables far better performance and far fewer DRAM accesses.","","978-1-4673-5779-1","10.1109/ISPASS.2013.6557152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6557152","","Graphics processing units;Multicore processing;Instruction sets;Programming;Random access memory;Couplings","graphics processing units;integrated circuit design;multi-threading;virtual storage","cache coherent shared virtual memory evaluation;CCSVM design;heterogeneous multicore chips;homogeneous chips;GPU chip;CPU chip;pthreads programming model;HMC;AMD;OpenCL software;DRAM accesses;xthreads","","9","","6","","15 Jul 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Fine-Granular Parallel EBCOT and Optimization with CUDA for Digital Cinema Image Compression","F. Wei; Q. Cui; Y. Li","Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China; Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China; Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","2012 IEEE International Conference on Multimedia and Expo","13 Sep 2012","2012","","","1051","1054","JPEG2000 has been accepted by The Society of Motion Picture and Television Engineers (SMPTE) as the image compression standard for the digital distribution of motion pictures. In JPEG2000, the biggest contribution to the coding performance comes from the Embedded Block Coding with Optimized Truncation (EBCOT), which is also the most time-consuming module by occupying almost 37% of the encoding time. There have been many research activities in the optimization of EBCOT on platforms like FPGA and VLSI, but on Graphics Processing Unit (GPU), a currently popular parallel computing platform in post-production of motion pictures, still few works have been done. This paper proposes a fine-granular parallel EBCOT by re-designing the highly serialized bit-plane coding to a parallel structure where the coding of all bits in a bit-plane could be performed in parallel, then the bit coding tasks can be distributed to the stream processors in GPU by taking advantage of the programming and memory model of CUDA. Experimental results show that our algorithms reveal 3 to 4 times computational speed improvement on an ordinary GPU compared to that on CPU.","1945-788X","978-1-4673-1659-0","10.1109/ICME.2012.115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298542","EBCOT;GPU;CUDA;JPEG2000;DCI","Graphics processing unit;Encoding;Image coding;Transform coding;Motion pictures;Instruction sets;Strips","block codes;cinematography;graphics processing units;image coding;image motion analysis;parallel architectures","fine-granular parallel EBCOT;digital cinema image compression;JPEG2000;Society of Motion Picture and Television Engineers;image compression standard;digital distribution;coding performance;embedded block coding with optimized truncation;EBCOT optimization;graphics processing unit;GPU;parallel computing platform;motion picture post-production;bit-plane coding;parallel structure;stream processors;CUDA programming model;CUDA memory model;computational speed improvement","","6","","12","","13 Sep 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A real time Breast Microwave Radar imaging reconstruction technique using simt based interpolation","D. Flores-Tapia; S. Pistorius","Division of Medical Physics, CancerCare Manitoba, USA; Division of Medical Physics, CancerCare Manitoba, USA","2010 IEEE International Conference on Image Processing","3 Dec 2010","2010","","","1389","1392","Breast Microwave Radar(BMR) is a novel imaging modality that is capable of producing high contrast images and can detect tumors of at least 4mm. To properly visualize the responses from the breast structures, BMR data sets must be reconstructed. In this paper, a real time BMR image formation technique is proposed. This approach is based on the use of a Single Instruction Multiple Thread(SIMT) interpolation method. By using this programming model, the proposed approach can be implemented on General Purpose Graphic Processing Unit (GPGPU) platform to speed up the reconstruction process. The proposed method yielded promising results when applied to simulated data sets obtained using anatomically accurate numeric phantoms. In average, the proposed approach yielded speed increases of one order of magnitude compared to its CPU counterpart, and two orders of magnitude with respect to current BMR reconstruction techniques.","2381-8549","978-1-4244-7994-8","10.1109/ICIP.2010.5652126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5652126","Breast microwave radar;GPU;real time image processing","Image reconstruction;Interpolation;Breast;Microwave imaging;Radar imaging;Microwave theory and techniques;Computational modeling","biological organs;computer graphic equipment;coprocessors;image reconstruction;interpolation;medical image processing;microwave imaging;multi-threading;radar imaging;tumours","real time breast microwave radar imaging reconstruction technique;high contrast images;tumors;BMR data sets;BMR image formation technique;single instruction multiple thread interpolation method;programming model;general purpose graphic processing unit platform;simulated data sets;numeric phantoms;CPU;BMR reconstruction techniques;SIMT","","2","","10","","3 Dec 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Leveraging Data-Flow Task Parallelism for Locality-Aware Dynamic Scheduling on Heterogeneous Platforms","O. S. Simsek; A. Drebes; A. Pop","Sch. of Comput. Sci., Univ. of Manchester, Manchester, UK; Sch. of Comput. Sci., Univ. of Manchester, Manchester, UK; Sch. of Comput. Sci., Univ. of Manchester, Manchester, UK","2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","6 Aug 2018","2018","","","540","549","Writing programs for heterogeneous platforms is challenging, since programmers must deal with multiple programming models, partition work for CPUs and accelerators with different compute capabilities, and manage memory in multiple distinct address spaces. We show that using a task-parallel data-flow programming model, in which parallelism is specified in a platform-neutral description that abstracts in particular from the heterogeneity of the hardware, efficient execution can be carried out by a run-time system at execution time using an appropriate task scheduling and memory allocation scheme. This is achieved through dynamic scheduling of tasks by reducing the dependence exchanges between devices, interleaved execution of tasks and transfer between host and device memory, and load balancing across CPUs and GPUs. Our results show our technique increases the number of tasks offloaded to the GPU and improves data locality of GPU tasks leading to a significant reduction of GPU idle time and thus to substantial improvements of performance.","","978-1-5386-5555-9","10.1109/IPDPSW.2018.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425460","Task-parallelism;heterogeneous systems;scheduling;memory allocation","Task analysis;Graphics processing units;Dynamic scheduling;Memory management;Processor scheduling;Data transfer","graphics processing units;multiprocessing systems;parallel processing;parallel programming;processor scheduling;resource allocation","locality-aware dynamic scheduling;heterogeneous platforms;multiple programming models;partition work;CPUs;multiple distinct address;task-parallel data-flow programming model;platform-neutral description;run-time system;execution time;appropriate task scheduling;device memory;data locality;GPU tasks;GPU idle time;compute capabilities;data-flow task parallelism","","1","","20","","6 Aug 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"An Enhanced Profiling Framework for the Analysis and Development of Parallel Primitives for GPUs","N. Bombieri; F. Busato; F. Fummi","Dept. of Comput. Sci., Univ. of Verona, Verona, Italy; Dept. of Comput. Sci., Univ. of Verona, Verona, Italy; Dept. of Comput. Sci., Univ. of Verona, Verona, Italy","2015 IEEE 9th International Symposium on Embedded Multicore/Many-core Systems-on-Chip","12 Nov 2015","2015","","","1","8","Parallelizing software applications through the use of existing optimized % target-oriented primitives is a common trend that mediates the complexity of manual parallelization and the use of less efficient directive-based programming models. Parallel primitive libraries allow software engineers to map any sequential code to a target many-core architecture by identifying the most computational intensive code sections and mapping them into one ore more existing primitives. On the other hand, the spreading of such a primitive-based programming model and the different GPU architectures have led to a large and increasing number of third-party libraries, which often provide different implementations of the same primitive, each one optimized for a specific architecture. From the developer point of view, this moves the actual problem of parallelizing the software application to selecting, among the several implementations, the most efficient primitives for the target platform. This paper presents a profiling framework for GPU primitives, which allows measuring the implementation quality of a given primitive by considering the target architecture characteristics. The framework collects the information provided by a standard GPU profiler and combines them into optimization criteria. The criteria evaluations are weighed to distinguish the impact of each optimization on the overall quality of the primitive implementation. The paper shows how the tuning of the different weights has been conducted through the analysis of five of the most widespread existing primitive libraries and how the framework has been eventually applied to improve the implementation performance of a standard primitive.","","978-1-4799-8670-5","10.1109/MCSoC.2015.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328180","","Graphics processing units;Kernel;Instruction sets;Optimization;Libraries;Synchronization","graphics processing units;parallel programming","profiling framework;software applications parallelization;parallel primitives;GPU;graphics processing unit;directive-based programming models;many-core architecture;primitive-based programming model;GPU profiler","","1","","18","","12 Nov 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"ST-Accel: A High-Level Programming Platform for Streaming Applications on FPGA","Z. Ruan; T. He; B. Li; P. Zhou; J. Cong","Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Microsoft Res. Univ. of Sci. & Technol. of China, China; Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA","2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)","11 Sep 2018","2018","","","9","16","In recent years we have witnessed the emergence of the FPGA in many high-performance systems. This is due to FPGA's high reconfigurability and improved user-friendly programming environment. OpenCL, supported by major FPGA vendors, is a high-level programming platform that liberates hardware developers from having to deal with the complex and error-prone HDL development. While OpenCL exposes a GPU-like programming model, which is well-suited for compute-intensive tasks, in many state-of-art systems that deploy FPGA, we observe that the workloads are streaming-like, which is communication-intensive. This mismatch leads to low throughput and high end-to-end latency. In this paper, we propose ST-Accel, a new high-level programming platform for streaming applications on FPGA. It has the following advantages: (i) ST-Accel adopts the multiprocessing programming model to capture the inherent pipeline-level parallelism of streaming applications while reducing the end-to-end latency. (ii) A message-passing-based host/FPGA communication model is used to avoid the coherency issue of shared memory, thus enabling host/FPGA communication during kernel execution. (iii) ST-Accel provides a high-level abstraction for I/O devices to support direct I/O device access that eliminates the overhead of host CPU and reduces the I/O latency. (iv) ST-Accel enables the decoupled access/execute architecture to maximize the utilization of I/O devices. (v) The host/FPGA communication interface is redesigned to cater to the demands of both latency-critical and throughput-critical scenarios. The experimental results on the Amazon AWS cloud and local machine show that ST-Accel can achieve 1.6X-166X throughput and 1/3 latency for typical streaming workloads when compared to OpenCL.","2576-2621","978-1-5386-5522-1","10.1109/FCCM.2018.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457626","FPGA;OpenCL;Programming Platform;Streaming","Field programmable gate arrays;Kernel;Programming;Random access memory;Hardware design languages;Acceleration;Throughput","field programmable gate arrays;message passing;multiprocessing programs;parallel programming","high-performance systems;improved user-friendly programming environment;OpenCL;high-level programming platform;GPU-like programming model;ST-Accel;multiprocessing programming model;high-level abstraction;pipeline-level parallelism;message-passing-based host-FPGA communication model;host-FPGA communication interface;error-prone HDL development;streaming applications;end-to-end latency reduction;kernel execution;direct I/O device access;decoupled access-execute architecture;throughput-critical scenarios;Amazon AWS cloud;I/O latency reduction","","11","","28","","11 Sep 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Distributed-memory multi-GPU block-sparse tensor contraction for electronic structure","T. Herault; Y. Robert; G. Bosilca; R. J. Harrison; C. A. Lewis; E. F. Valeev; J. J. Dongarra","University of Tennessee,ICL,TN,USA; University of Tennessee,ICL,TN,USA; Stony Brook University,IACS,NY,USA; Stony Brook University,IACS,NY,USA; Sandia Ntl. Lab.,CA,USA; Virignia Tech,Dept. of Chemistry,VA,USA; University of Tennessee,ICL,TN,USA","2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","28 Jun 2021","2021","","","537","546","Many domains of scientific simulation (chemistry, condensed matter physics, data science) increasingly eschew dense tensors for block-sparse tensors, sometimes with additional structure (recursive hierarchy, rank sparsity, etc.). Distributed-memory parallel computation with block-sparse tensorial data is paramount to minimize the time-to-solution (e.g., to study dynamical problems or for real-time analysis) and to accommodate problems of realistic size that are too large to fit into the host/device memory of a single node equipped with accelerators. Unfortunately, computation with such irregular data structures is a poor match to the dominant imperative, bulk-synchronous parallel programming model. In this paper, we focus on the critical element of block-sparse tensor algebra, namely binary tensor contraction, and report on an efficient and scalable implementation using the task-focused PaRSEC runtime. High performance of the block-sparse tensor contraction on the Summit supercomputer is demonstrated for synthetic data as well as for real data involved in electronic structure simulations of unprecedented size.","1530-2075","978-1-6654-4066-0","10.1109/IPDPS49936.2021.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460455","electronic structure;tensor contraction;block-sparse matrix multiplication;distributed memory;multi-GPU nodes;PaRSEC","Tensors;Runtime;Computational modeling;Tools;Data models;Supercomputers;Real-time systems","distributed memory systems;graphics processing units;parallel programming;tensors","dense tensors;distributed-memory parallel computation;block-sparse tensorial data;irregular data structures;block-sparse tensor algebra;binary tensor contraction;electronic structure simulations;distributed-memory multiGPU block-sparse tensor contraction","","","","32","","28 Jun 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Hybrid CPU/GPU tasks optimized for concurrency in OpenMP","A. E. Eichenberger; G. . -T. Bercea; A. Bataev; L. Grinberg; J. K. O'Brien",NA; NA; NA; NA; NA,"IBM Journal of Research and Development","13 May 2020","2020","64","3/4","13:1","13:14","Sierra and Summit supercomputers exhibit a significant amount of intranode parallelism between the host POWER9 CPUs and their attached GPU devices. In this article, we show that exploiting device-level parallelism is key to achieving high performance by reducing overheads typically associated with CPU and GPU task execution. Moreover, manually exploiting this type of parallelism in large-scale applications is nontrivial and error-prone. We hide the complexity of exploiting this hybrid intranode parallelism using the OpenMP programming model abstraction. The implementation leverages the semantics of OpenMP tasks to express asynchronous task computations and their associated dependences. Launching tasks on the CPU threads requires a careful design of work-stealing algorithms to provide efficient load balancing among CPU threads. We propose a novel algorithm that removes locks from all task queueing operations that are on the critical path. Tasks assigned to GPU devices require additional steps such as copying input data to GPU devices, launching the computation kernels, and copying data back to the host CPU memory. We perform key optimizations to reduce the cost of these additional steps by tightly integrating data transfers and GPU computations into streams of asynchronous GPU operations. We further map high-level dependences between GPU tasks to the same asynchronous GPU streams to further avoid unnecessary synchronization. Results validate our approach.","0018-8646","","10.1147/JRD.2019.2960245","U.S. Department of Energy(grant numbers:B604142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935508","","Task analysis;Graphics processing units;Instruction sets;Parallel processing;Runtime;Scheduling;Delays","","","","","","14","IBM","17 Dec 2019","","","IBM","IBM Journals"
notebooks/data/ieee_2.csv:"GPU Accelerated Lanczos Algorithm with Applications","K. K. Matam; K. Kothapalli","Int. Inst. of Inf. Technol., Hyderabad Gachibowli, Hyderabad, India; Int. Inst. of Inf. Technol., Hyderabad Gachibowli, Hyderabad, India","2011 IEEE Workshops of International Conference on Advanced Information Networking and Applications","5 May 2011","2011","","","71","76","Graphics Processing Units provide a large computational power at a very low price which position them as an ubiquitous accelerator. GPGPU is accelerating general purpose computations using GPU's. GPU's have been used to accelerate many Linear Algebra routines and Numerical Methods. Lanczos is an iterative method well suited for finding the extreme eigenvalues and the corresponding eigenvectors of large sparse symmetric matrices. In this paper, we present an implementation of Lanczos Algorithm on GPU using the CUDA programming model and apply it to two important problems : graph bisection using spectral methods, and image segmentation. Our GPU implementation of spectral bisection performs better when compared to both an Intel Math Kernel Library implementation and a Matlab implementation. Our GPU implementation shows a speedup up to 97.3 times over Matlab Implementation and 2.89 times over the Intel Math Kernel Library implementation on a Intel Core i7 920 Processor, which is a quad-core CPU. Similarly, our image segmentation implementation achieves a speed up of 3.27 compared to a multicore CPU based implementation using Intel Math Kernel Library and OpenMP. Through this work, we therefore wish to establish that the GPU may still be a better platform for also highly irregular and computationally intensive applications.","","978-1-61284-829-7","10.1109/WAINA.2011.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763440","GPGPU;Lanczos;graph partitioning;image segmentation;spectral methods","Graphics processing unit;Eigenvalues and eigenfunctions;Image segmentation;Sparse matrices;Kernel;Instruction sets;Symmetric matrices","coprocessors;eigenvalues and eigenfunctions;graph theory;image segmentation;iterative methods;ubiquitous computing","accelerated Lanczos algorithm;graphics processing units;ubiquitous accelerator;GPGPU;general purpose computations;linear algebra;iterative method;eigenvalues;eigenvectors;CUDA programming;graph bisection;image segmentation;multicore CPU;Intel Math Kernel Library;OpenMP","","3","","18","","5 May 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Improved Bilinear Interpolation Method for Image Fast Processing","Y. Sa","Guangdong Univ. of Educ., Guangzhou, China","2014 7th International Conference on Intelligent Computation Technology and Automation","8 Jan 2015","2014","","","308","311","Bilinear interpolation algorithm is broadly applied in digital image processing but its calculation speed is very slow. In order to improve its performance in calculation, this paper proposes a graphic processing unit acceleration-based bilinear interpolation parallel It mainly utilizes Wallis transforming independence among various blocks in bilinear interpolation, which is adaptable to characteristics of GPU parallel processing structure. It maps traditional serial bilinear interpolation algorithm to CUDA parallel programming model and optimize thread allocation, memory usage, hardware resources division, etc, to make full use of huge calculation ability. The experiment results show bilinear interpolation parallel algorithm can greatly improve calculation speed with increasing image resolution.","","978-1-4799-6636-3","10.1109/ICICTA.2014.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7003545","bilinear interpolation;image processing;GPU;CUDA","Graphics processing units;Interpolation;Instruction sets;Parallel algorithms;Acceleration;Computers","graphics processing units;image resolution;interpolation;parallel algorithms;parallel architectures;parallel programming","digital image processing;performance improvement;graphic processing unit acceleration;Wallis transforming independence;GPU parallel processing structure;serial bilinear interpolation algorithm;CUDA parallel programming model;thread allocation optimization;memory usage optimization;hardware resource division optimization;calculation ability;bilinear interpolation parallel algorithm;calculation speed improvement;image resolution improvement","","7","","11","","8 Jan 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Generalizing the Utility of GPUs in Large-Scale Heterogeneous Computing Systems","S. Xiao; W. Feng","Dept. of Electr. & Comput. Eng., Virginia Tech, Blacksburg, VA, USA; Dept. of Electr. & Comput. Eng., Virginia Tech, Blacksburg, VA, USA","2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum","20 Aug 2012","2012","","","2554","2557","Graphics Processing Units (GPUs) have been widely used as accelerators in large-scale heterogeneous computing systems. However, current programming models can only support the utilization of local GPUs. When using non-local GPUs, programmers need to explicitly call API functions for data communication across computing nodes. As such, programming GPUs in large-scale computing systems is more challenging than local GPUs since local and remote GPUs have to be dealt with separately. In this work, we propose a virtual OpenCL (VOCL) framework to support the transparent virtualization of GPUs. This framework, based on the OpenCL programming model, exposes physical GPUs as decoupled virtual resources that can be transparently managed independent of the application execution. To reduce the virtualization overhead, we optimize the GPU memory accesses and kernel launches. We also extend the VOCL framework to support live task migration across physical GPUs to achieve load balance and/or quick system maintenance. Our experiment results indicate that VOCL can greatly simplify the task of programming cluster-based GPUs at a reasonable virtualization cost.","","978-1-4673-0974-5","10.1109/IPDPSW.2012.325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6270892","graphics processing unit (GPU);virtual OpenCL;task migration","Graphics processing unit;Kernel;Optimization;Libraries;Bandwidth;Programming","application program interfaces;graphics processing units","GPU utility;large scale heterogeneous computing systems;graphics processing units;current programming models;API functions;data communication;virtual OpenCL;VOCL;OpenCL programming model;decoupled virtual resources","","2","","14","","20 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"VOCL: An optimized environment for transparent virtualization of graphics processing units","S. Xiao; P. Balaji; Q. Zhu; R. Thakur; S. Coghlan; H. Lin; G. Wen; J. Hong; W. -c. Feng","Dept. of Computer Science, Virginia Tech., USA; Math. and Comp. Sci. Div., Argonne National Lab., USA; Accenture Technology Labs, USA; Math. and Comp. Sci. Div., Argonne National Lab., USA; Leadership Comp. Facility, Argonne National Lab., USA; Dept. of Computer Science, Virginia Tech., USA; Shenzhen Inst. of Adv. Tech., Chinese Academy of Sciences, China; Shenzhen Inst. of Adv. Tech., Chinese Academy of Sciences, China; Dept. of Computer Science, Virginia Tech., USA","2012 Innovative Parallel Computing (InPar)","25 Oct 2012","2012","","","1","12","Graphics processing units (GPUs) have been widely used for general-purpose computation acceleration. However, current programming models such as CUDA and OpenCL can support GPUs only on the local computing node, where the application execution is tightly coupled to the physical GPU hardware. In this work, we propose a virtual OpenCL (VOCL) framework to support the transparent utilization of local or remote GPUs. This framework, based on the OpenCL programming model, exposes physical GPUs as decoupled virtual resources that can be transparently managed independent of the application execution. The proposed framework requires no source code modifications. We also propose various strategies for reducing the overhead caused by data communication and kernel launching and demonstrate about 85% of the data write bandwidth and 90% of the data read bandwidth compared to data write and read, respectively, in a native nonvirtualized environment. We evaluate the performance of VOCL using four real-world applications with various computation and memory access intensities and demonstrate that compute-intensive applications can execute with negligible overhead in the VOCL environment.","","978-1-4673-2633-9","10.1109/InPar.2012.6339609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6339609","Graphics Processing Unit (GPU);Transparent Virtualization;OpenCL","Graphics processing unit;Kernel;Libraries;Programming;Computational modeling","graphics processing units;virtualisation","VOCL;transparent virtualization;graphics processing units;general-purpose computation acceleration;CUDA;local computing node;physical GPU hardware;virtual OpenCL framework;VOCL framework;OpenCL programming model;virtual resources;application execution;data communication;kernel launching;data write bandwidth;data read bandwidth;memory access intensity","","37","1","27","","25 Oct 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"CUDA-Based Parallel Implementation of IBM Word Alignment Algorithm for Statistical Machine Translation","S. Jing; G. Yan; X. Chen; P. Jin; Z. Guo","Sch. of Comput. Sci., Leshan Normal Univ., Leshan, China; Sch. of Foreign Language, Leshan Normal Univ., Leshan, China; Sch. of Comput. Sci., Leshan Normal Univ., Leshan, China; Sch. of Comput. Sci., Leshan Normal Univ., Leshan, China; Sch. of Comput. Sci., Leshan Normal Univ., Leshan, China","2016 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)","8 Jun 2017","2016","","","189","194","Word alignment is a basic task in natural language processing and it usually serves as the starting point when building a modern statistical machine translation system. However, the state-of-art parallel algorithm for word alignment is still time-consuming. In this work, we explore a parallel implementation of word alignment algorithm on Graphics Processor Unit (GPU), which has been widely available in the field of high performance computing. We use the Compute Unified Device Architecture (CUDA) programming model to re-implement a state-of-the-art word alignment algorithm, called IBM Expectation-Maximization (EM) algorithm. A Tesla K40M card with 2880 cores is used for experiments and execution times obtained with the proposed algorithm are compared with a sequential algorithm and a multi-threads algorithm on an IBM X3850 server, which has two Intel Xeon E7 CPUs (2.0GHz * 10 cores). The best experimental results show a 16.8-fold speedup compared to the multi-threads algorithm and a 234.7-fold speedup compared to the sequential algorithm.","","978-1-5090-5081-9","10.1109/PDCAT.2016.050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7943355","Word Alignment;GPU;Parallel Computation;Expectation-Maximization Algorithm;CUDA","Graphics processing units;Algorithm design and analysis;Instruction sets;Hidden Markov models;Computational modeling;Kernel;Programming","graphics processing units;language translation;microprocessor chips;multiprocessing systems;natural language processing;optimisation;parallel algorithms;parallel architectures;statistical analysis;word processing","CUDA-based parallel implementation;IBM word alignment algorithm;statistical machine translation;natural language processing;parallel algorithm;graphics processor unit;GPU;high performance computing;compute unified device architecture;CUDA programming model;IBM expectation-maximization;EM algorithm;Tesla K40M card;2880 cores;sequential algorithm;multithreads algorithm;IBM X3850 server;Intel Xeon E7 CPUs","","1","","15","","8 Jun 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A new parallel video understanding and retrieval system","K. Liu; T. Zhang; L. Wang","HP Labs China; HP Labs, Palo Alto; HP Labs China","2010 IEEE International Conference on Multimedia and Expo","23 Sep 2010","2010","","","679","684","In this paper, a hybrid parallel computing framework is proposed for video understanding and retrieval. It is a unified computing architecture based on the Map-Reduce programming model, which supports multi-core and GPU architectures. A key task scheduler is designed for the parallelization of computation tasks. The SVM method is used to train models for video understanding purposes. To effectively shorten the training and processing time, the hybrid computing framework is used to train large scale SVM models. The TRECVID database is used as the basic experimental content for video understanding and retrieval. Experiments were conducted on two 8-core servers, each equipped with NVIDIA Quadro FX 4600 graphics card. Results proved that the proposed parallel computing framework works well for the video understanding and retrieval system by speeding up system development and providing better performances.","1945-788X","978-1-4244-7493-6","10.1109/ICME.2010.5583873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583873","Parallel computing;map-reduce;multi-core CPU;general purpose GPU;video understanding and retrieval","Support vector machines;Training;Graphics processing unit;Feature extraction;Classification algorithms;Computational modeling;Computer architecture","computer graphic equipment;coprocessors;parallel processing;support vector machines;video retrieval;video signal processing;visual databases","parallel video understanding;video retrieval system;hybrid parallel computing framework;Map-Reduce programming model;GPU architectures;key task scheduler;SVM method;TRECVID database;NVIDIA Quadro FX 4600 graphics card","","5","1","14","","23 Sep 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"An Efficient Numerical Solution Technique for VLSI Interconnect Equations on Many-Core Processors","G. Doménech-Asensi; T. J. Kazmierski","Dpto. de Electrónica, Tec. de Computadoras y Proyectos, Universidad Politécnica de Cartagena, Cartagena, Spain; Dpt. of Electronics and Computers Science, University of Southampton, Southampton, UK","2019 IEEE International Symposium on Circuits and Systems (ISCAS)","1 May 2019","2019","","","1","5","This paper presents a technique to accelerate transient simulations of analog circuits using an explicit integration method parallelised on a many-core computer. Usual methods used by SPICE-type simulators are based on Newton-Raphson iterations, which are reliable and numerically stable, but require long CPU processing times. However, although the integration time step in explicit methods is smaller than that used in implicit methods, this technique avoids the calculation of time-consuming computations due to the Jacobian matrix inversion. The proposed method uses an explicit integration scheme based on the fourth order Adams-Bashforth formula. The algorithm has been parallelised on a NVIDIA general purpose GPU using the CUDA programming model. As a case study, the RC ladder model of a VLSI interconnect is simulated on a general purpose graphic processing unit and the achieved performance is then evaluated against that of a multiprocessor CPU. The results show that the proposed technique achieves a speedup of one order of magnitude in comparison with implicit integration techniques executed on a CPU.","2158-1525","978-1-7281-0397-6","10.1109/ISCAS.2019.8702085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8702085","simulation acceleration;state-space technique;GPU;VLSI interconnect","Instruction sets;Mathematical model;Graphics processing units;Computational modeling;Integrated circuit interconnections;Jacobian matrices;Transient analysis","coprocessors;graphics processing units;integration;multiprocessing systems;Newton-Raphson method;parallel architectures;SPICE;VLSI","implicit methods;time-consuming computations;Jacobian matrix inversion;explicit integration scheme;fourth order Adams-Bashforth formula;NVIDIA general purpose GPU;CUDA programming model;RC ladder model;multiprocessor CPU;implicit integration techniques;VLSI interconnect equations;many-core processors;transient simulations;many-core computer;SPICE-type simulators;Newton-Raphson iterations;integration time step;numerical solution technique;integration method;CPU processing times","","2","","17","","1 May 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Three-dimensional particle beam simulation using high performance graphics processing hardware","S. J. Cooke","Naval Research Laboratory, Washington DC 20375, USA","2009 IEEE International Conference on Plasma Science - Abstracts","28 Aug 2009","2009","","","1","1","In this paper, a new three- dimensional particle beam simulation using a high performance hardware is introduced. The graphics processing unit (GPU) hardware is highly parallel and has low-cost computational capabilities. The code uses NVIDIA CUDA programming model and a particle trajectory integration steps on the graphics hardware, in a standard 4th-order Runge-Kutta scheme. The model uses mesh less representations for electromagnetic fields, based on either analytic formulas or field expansion techniques, to achieve a high degree of parallelism in the calculations. The author describe potential applications of the code for 3D simulation of vacuum electronic devices, and present details of both the algorithms used and simulation performance results.","0730-9244","978-1-4244-2617-1","10.1109/PLASMA.2009.5227556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5227556","","Particle beams;Graphics;Hardware;Computational modeling;Concurrent computing;Code standards;Electromagnetic modeling;Electromagnetic fields;Electromagnetic analysis;Parallel processing","electromagnetic fields;microprocessor chips;parallel programming;particle beams;Runge-Kutta methods;solid modelling;three-dimensional displays","three-dimensional particle beam simulation;graphics processing unit hardware;GPU hardware;NVIDIA CUDA programming model;Runge-Kutta scheme;electromagnetic fields;vacuum electronic devices","","","","1","","28 Aug 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Evaluation of Medical Imaging Applications using SYCL","Z. Jin; H. Finkel","Argonne National Laboratory,Leadership Computing Facility,Lemont,IL,USA; Argonne National Laboratory,Leadership Computing Facility,Lemont,IL,USA","2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","6 Feb 2020","2019","","","2259","2264","As opposed to the Open Computing Language (OpenCL) programming model in which host and device codes are written in different languages, the SYCL programming model can combine host and device codes for an application in a type-safe way to improve development productivity. In this paper, we chose two medical imaging applications (Heart Wall and Particle Filter) in the Rodinia benchmark suite to study the performance and programming productivity of the SYCL programming model. More specifically, we introduced the SYCL programming model, shared our experience of implementing the applications using SYCL, and compared the performance and programming portability of the SYCL implementations with the OpenCL implementations on an Intel® Xeon® CPU and an Iris® Pro integrated GPU. The results are promising. For the Heart Wall application, the SYCL implementation is on average 15% faster than the OpenCL implementation on the GPU. For the Particle Filter application, the SYCL implementation is 3% slower than the OpenCL implementation on the GPU, but it is 75% faster on the CPU. Using lines of code as an indicator of programming productivity, the SYCL host program reduces the lines of code of the OpenCL host program by 52% and 38% for the Heart Wall and Particle Filter applications, respectively.","","978-1-7281-1867-3","10.1109/BIBM47256.2019.8982983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982983","","","biomedical imaging;graphics processing units;multiprocessing systems;parallel architectures;particle filtering (numerical methods);program compilers;software portability","OpenCL implementation;Heart Wall application;SYCL implementation;programming productivity;SYCL host program;OpenCL host program;medical imaging applications;device codes;SYCL programming model;programming portability;open computing language programming model;particle filter application","","3","","19","","6 Feb 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Parallel Algorithms for Approximate String Matching with k Mismatches on CUDA","Y. Liu; L. Guo; J. Li; M. Ren; K. Li","Sch. of Comput. Sci. & Technol., Heilongjiang Univ., Harbin, China; Sch. of Comput. Sci. & Technol., Heilongjiang Univ., Harbin, China; Sch. of Comput. Sci. & Technol., Heilongjiang Univ., Harbin, China; Sch. of Comput. Sci. & Technol., Heilongjiang Univ., Harbin, China; Dept. of Comput. Sci., State Univ. of New York, New Paltz, NY, USA","2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum","20 Aug 2012","2012","","","2414","2422","Approximate string matching using the k-mismatch technique has been widely applied to many fields such as virus detection and computational biology. The traditional parallel algorithms are all based on multiple processors, which have high costs of computing and communication. GPU has high parallel processing capability, low cost of computing, and less time of communication. To the best of our knowledge, there is no any parallel algorithm for approximate string matching with k mismatches on GPU. With a new parallel programming model based on CUDA, we present three parallel algorithms and their implementations on GPU, namely, the thread parallel algorithm, the block-thread parallel algorithm, and the OPT-block-thread parallel algorithm. The OPT-block thread parallel algorithm can take full advantage of the powerful parallel capability of GPU. Furthermore, it balances the load among the threads and optimizes the execution time with the memory model of GPU. Experimental results show that compared with the traditional sequential algorithm on CPU, our best parallel algorithm on GPU in this paper achieves speedup of 40-80.","","978-1-4673-0974-5","10.1109/IPDPSW.2012.298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6270613","Approximate string matching;CUDA;GPU;Hamming distance;parallel algorithm","Instruction sets;Graphics processing unit;Parallel algorithms;Hamming distance;Kernel;Complexity theory","graphics processing units;multiprocessing systems;parallel architectures;string matching","approximate string matching;CUDA;k-mismatch technique;multiple processors;GPU;parallel processing;OPT-block-thread parallel algorithm","","13","","12","","20 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"ValuePack: Value-based scheduling framework for CPU-GPU clusters","V. T. Ravi; M. Becchi; G. Agrawal; S. Chakradhar","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Electr. & Comput. Eng., Univ. of Missouri, Columbia, MO, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; NEC Labs. America, Princeton, NJ, USA","SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis","25 Feb 2013","2012","","","1","12","Heterogeneous computing nodes are becoming commonplace today, and recent trends strongly indicate that clusters, supercomputers, and cloud environments will increasingly host more heterogeneous resources, with some being massively parallel (e.g., GPU). With such heterogeneous environments becoming common, it is important to revisit scheduling problems for clusters and cloud environments. In this paper, we formulate and address the problem of value-driven scheduling of independent jobs on heterogeneous clusters, which captures both the urgency and relative priority of jobs. Our overall scheduling goal is to maximize the aggregate value or yield of all jobs. Exploiting the portability available from the underlying programming model, we propose four novel scheduling schemes that can automatically and dynamically map jobs onto heterogeneous resources. Additionally, to improve the utilization of massively parallel resources, we also propose heuristics to automatically decide when and which jobs can share a single resource.","2167-4337","978-1-4673-0806-9","10.1109/SC.2012.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6468477","","Graphics processing units;Processor scheduling;Delay;Multicore processing;Aggregates;Supercomputers;Torque","cloud computing;graphics processing units;processor scheduling","value-based scheduling framework;ValuePack;CPU-GPU clusters;heterogeneous computing nodes;supercomputers;cloud environments;value-driven scheduling;heterogeneous clusters;parallel resources","","5","","48","","25 Feb 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"G-Storm: GPU-enabled high-throughput online data processing in Storm","Z. Chen; J. Xu; J. Tang; K. Kwiat; C. Kamhoua","Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13244; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13244; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13244; US Air Force Research Lab (AFRL), Rome, NY; US Air Force Research Lab (AFRL), Rome, NY","2015 IEEE International Conference on Big Data (Big Data)","28 Dec 2015","2015","","","307","312","The Single Instruction Multiple Data (SIMD) architecture of Graphic Processing Units (GPUs) makes them perfect for parallel processing of big data. In this paper, we present the design, implementation and evaluation of G-Storm, a GPU-enabled parallel system based on Storm, which harnesses the massively parallel computing power of GPUs for high-throughput online stream data processing. G-Storm has the following desirable features: 1) G-Storm is designed to be a general data processing platform as Storm, which can handle various applications and data types. 2) G-Storm exposes GPUs to Storm applications while preserving its easy-to-use programming model. 3) G-Storm achieves high-throughput and low-overhead data processing with GPUs. We implemented G-Storm based on Storm 0.9.2 and tested it using two different applications: continuous query and matrix multiplication. Extensive experimental results show that compared to Storm, G-Storm achieves over 7x improvement on throughput for continuous query, while maintaining reasonable average tuple processing time. It also leads to 2.3x throughput improvement for the matrix multiplication application.","","978-1-4799-9926-2","10.1109/BigData.2015.7363769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363769","","Graphics processing units;Storms;Kernel;Data processing;Programming;Fasteners;Indexes","Big Data;graphics processing units;matrix multiplication;parallel processing","matrix multiplication;continuous query;parallel processing;graphic processing units;SIMD architecture;single instruction multiple data;high-throughput online data processing;GPU;G-Storm","","18","","21","","28 Dec 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Iterative Solution on GPU of Linear Systems Arising from the A-V Edge-FEA of Time-Harmonic Electromagnetic Phenomena","A. F. P. Camargos; V. C. Silva; J. Guichon; G. Meunier","Inst. Fed. de Minas Gerais, Formiga, Brazil; Escola Politec., Univ. de Sao Paulo, São Paulo, Brazil; Grenoble Genie Electr. Lab., St. Martin d'Hères, France; Grenoble Genie Electr. Lab., St. Martin d'Hères, France","2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing","14 Apr 2014","2014","","","365","371","We present a performance analysis of a parallel implementation to both preconditioned Conjugate Gradient and preconditioned Bi-conjugate Gradient solvers using graphic processing units with CUDA programming model. The solvers were optimized for the solution of sparse systems of equations arising from Finite Element Analysis of electromagnetic phenomena involved in the diffusion of underground currents under time-harmonic current excitation. We used a shifted Incomplete Cholesky factorization as preconditioner. Results show a significant speedup by using the GPU compared to a serial CPU implementation.","2377-5750","978-1-4799-2729-6","10.1109/PDP.2014.95","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787300","Finite Elements;Graphic Processing Unit;Preconditioner;Incomplete Factorization","Graphics processing units;Linear systems;Mathematical model;Equations;Iterative methods;Finite element analysis;Sparse matrices","computational electromagnetics;conjugate gradient methods;eddy currents;finite element analysis;graphics processing units;iterative methods;linear systems;parallel architectures","iterative solution;GPU;linear systems;A-V edge-FEA;time-harmonic electromagnetic phenomena;preconditioned biconjugate gradient solver;preconditioned conjugate gradient solver;finite element analysis;underground currents;time-harmonic current excitation;shifted incomplete Cholesky factorization;graphic processing unit;sparse systems;eddy currents","","5","","23","","14 Apr 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Toward a Portable Programming Environment for Distributed High Performance Accelerators","S. Hirasawa; H. Honda","Japan Sci. & Technol. Agency, Univ. of Electro-Commun., Chofu, Japan; Japan Sci. & Technol. Agency, Univ. of Electro-Commun., Chofu, Japan","2009 Software Technologies for Future Dependable Distributed Systems","13 Jan 2011","2009","","","189","194","Accelerators with little power consumption per computation performance are beginning to widely spread for High Performance Computing use, instead of general-purpose CPUs with much power consumption. They are GPUs, processors of Cell architecture, and FPGA accelerators. While these processors have much higher computation performance than general-purpose CPUs, they need specific programming environment respectively when using them as distributed memory accelerators. We discuss a portable programming environment which can be used in common with distributed memory accelerators in this paper.","","978-0-7695-3572-2","10.1109/STFSSD.2009.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804597","Heterogeneous Programming Model;Distributed Memory;SIMD Accelerator","Probability density function;Data mining;Software","coprocessors;distributed memory systems;field programmable gate arrays;programming environments","portable programming environment;distributed high performance accelerators;power consumption;computation performance;high performance computing;general-purpose CPU;GPU;cell architecture processors;FPGA accelerators;distributed memory accelerators","","1","1","12","","13 Jan 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Software technologies coping with memory hierarchy of GPGPU clusters for stencil computations","T. Endo; G. Jin","Global Science Information and Computing Center, Tokyo Institute of Technology/JST-CREST, Japan; Global Science Information and Computing Center, Tokyo Institute of Technology/JST-CREST, Japan","2014 IEEE International Conference on Cluster Computing (CLUSTER)","1 Dec 2014","2014","","","132","139","Stencil computations, which are important kernels for CFD simulations, have been highly successful on GPGPU clusters, due to high memory bandwidth and computation speed of GPU accelerators. However, sizes of the computed domains are limited by small capacity of GPU device memory. In order to support larger domain sizes, we utilize the memory hierarchy of GPGPU clusters; larger host memory is used for maintain large domains. However, it is challenging to achieve all of larger domain sizes, high performance and easiness of program development. Towards this goal, we combine two software technologies. From the aspect of algorithm, we adopt a locality improvement technique called temporal blocking. From the aspect of system software, we developed a MPI/CUDA wrapper library named HHRT, which supports memory swapping and finer grained programming model. With this combination, we demonstrate that our goal is achieved through evaluations on TSUBAME2.5, a petascale GPGPU supercomputer.","2168-9253","978-1-4799-5548-0","10.1109/CLUSTER.2014.6968747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968747","","Graphics processing units;Arrays;Performance evaluation;Libraries;Programming;Bandwidth;Supercomputers","application program interfaces;computational fluid dynamics;graphics processing units;message passing;parallel architectures","software technologies;memory hierarchy;GPGPU clusters;stencil computations;kernels;CFD simulations;memory bandwidth;computation speed;GPU accelerators;GPU device memory;program development;locality improvement technique;temporal blocking;MPI/CUDA wrapper library;HHRT;memory swapping;grained programming model;TSUBAME2.5;petascale GPGPU supercomputer","","12","","19","","1 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"An Automatic Host and Device Memory Allocation Method for OpenMPC","H. Uchiyama; T. Tsumura; H. Matsuo","Nagoya Inst. of Technol., Nagoya, Japan; Nagoya Inst. of Technol., Nagoya, Japan; Nagoya Inst. of Technol., Nagoya, Japan","2012 Third International Conference on Networking and Computing","31 Jan 2013","2012","","","208","214","The CUDA programming model provides better abstraction for GPU programming. However, it is still hard to write programs with CUDA because both some specific techniques and knowledge about GPU architecture are required. Hence, many programming frameworks for CUDA have been developed. OpenMPC is one of them based on OpenMP. OpenMPC is an easy-to-write framework for programmers familiar with traditional OpenMP, but still requires programmers to use the special directives for utilizing fast device memories. To solve this problem, this paper proposes a method for allocating appropriate device memories automatically. This paper also proposes a method for automatically allocating page locked memory for the data which are transferred between host and device. The evaluation results with several programs show that proposed methods can reduce 52% execution time in maximum.","","978-1-4673-4624-5","10.1109/ICNC.2012.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424565","GPGPU;CUDA;OpenMPC;memory allocation","Graphics processing units;Kernel;Instruction sets;Programming;Resource management;Data transfer;Arrays","graphics processing units;paged storage;parallel architectures;parallel programming;program compilers;program diagnostics;storage allocation","OpenMPC;CUDA programming model;GPU programming abstraction;GPU architecture;programming frameworks;automatic device memory allocation method;automatic page locked memory allocation method;automatic host allocation method;graphics processing unit","","2","","10","","31 Jan 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Record Setting Software Implementation of DES Using CUDA","G. Agosta; A. Barenghi; F. De Santis; G. Pelosi","Dipt. di Elettron. e Inf., Politec. di Milano, Milan, Italy; Dipt. di Elettron. e Inf., Politec. di Milano, Milan, Italy; Politec. di Milano, Milan, Italy; Dipt. di Ing. dell'Inf. e Metodi Matematici, Univ. of Bergamo, Dalmine, Italy","2010 Seventh International Conference on Information Technology: New Generations","1 Jul 2010","2010","","","748","755","The increase in computational power of off-the-shelf hardware offers more and more advantageous tradeoffs among efficiency, cost and availability, thus enhancing the feasibility of of cryptanalytic attacks aiming to lower the security of widely used cryptosystems. In this paper we illustrate an GPU-based software implementation of the most efficent variant of Data Encryption Standard (DES), showing the performance of a software breaker which effectively exploits the multi-core Nvidia GT200 graphic architecture. The key point is to assess how well the structure of a symmetric key cipher can fit the GPU programming model and the single instruction multiple data architectural parallelism. The proposed breaker outperforms the fastest general purpose CPU-based implementations by an order of magnitude, and, due to the vast availability of GPUs on the market, the speedup translates into a sound improvement in the cost efficiency of the attack. As opposed to solutions based either on application specific or reconfigurable hardware, the proposed implementation does not require any specific technical knowledge from the attacker in order to be successfully built, once our implementation is available. This turns out in a better cost-availability tradeoff and minimizes the required setup time for such an attack to be mounted.","","978-1-4244-6271-1","10.1109/ITNG.2010.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5501641","Brute-force Attacks;DES;GPGPU","Hardware;Costs;Cryptography;Software performance;Availability;Data security;Software standards;Graphics;Computer architecture;Parallel programming","computer graphic equipment;coprocessors;cryptography;parallel architectures","record setting software implementation;DES;data encryption standard;CUDA;off-the-shelf hardware;cryptanalytic attacks;cryptosystems;GPU-based software implementation;software breaker;multicore Nvidia GT200 graphic architecture;symmetric key cipher;GPU programming model;cost-availability tradeoff;single instruction multiple data architectural parallelism","","16","","14","","1 Jul 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Optimal loop unrolling for GPGPU programs","G. S. Murthy; M. Ravishankar; M. M. Baskaran; P. Sadayappan","Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA","2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)","24 May 2010","2010","","","1","11","Graphics Processing Units (GPUs) are massively parallel, many-core processors with tremendous computational power and very high memory bandwidth. With the advent of general purpose programming models such as NVIDIA's CUDA and the new standard OpenCL, general purpose programming using GPUs (GPGPU) has become very popular. However, the GPU architecture and programming model have brought along with it many new challenges and opportunities for compiler optimizations. One such classical optimization is loop unrolling. Current GPU compilers perform limited loop unrolling. In this paper, we attempt to understand the impact of loop unrolling on GPGPU programs. We develop a semi-automatic, compile-time approach for identifying optimal unroll factors for suitable loops in GPGPU programs. In addition, we propose techniques for reducing the number of unroll factors evaluated, based on the characteristics of the program being compiled and the device being compiled to. We use these techniques to evaluate the effect of loop unrolling on a range of GPGPU programs and show that we correctly identify the optimal unroll factors. The optimized versions run up to 70 percent faster than the unoptimized versions.","1530-2075","978-1-4244-6443-2","10.1109/IPDPS.2010.5470423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470423","Compiler optimizations;Loop Unrolling;GPGPU","Central Processing Unit;Program processors;Optimizing compilers;Concurrent computing;Registers;Computer graphics;Linear programming;Computer science;Power engineering and energy;Power engineering computing","computer graphic equipment;coprocessors;parallel programming;program compilers","optimal loop unrolling;GPGPU programs;graphics processing units;massively parallel many-core processors;programming model;NVIDIA CUDA;OpenCL;general purpose programming;GPU architecture;compiler optimization;GPU compilers","","34","","15","","24 May 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Code generation for embedded heterogeneous architectures on android","R. Membarth; O. Reiche; F. Hannig; J. Teich","Department of Computer Science, University of Erlangen-Nuremberg, Germany; Department of Computer Science, University of Erlangen-Nuremberg, Germany; Department of Computer Science, University of Erlangen-Nuremberg, Germany; Department of Computer Science, University of Erlangen-Nuremberg, Germany","2014 Design, Automation & Test in Europe Conference & Exhibition (DATE)","21 Apr 2014","2014","","","1","6","The success of Android is based on its unified Java programming model that allows to write platform-independent programs for a variety of different target platforms. However, this comes at the cost of performance. As a consequence, Google introduced APIs that allow to write native applications and to exploit multiple cores as well as embedded GPUs for compute-intensive parts. This paper proposes code generation techniques in order to target the Renderscript and Filterscript APIs. Renderscript harnesses multi-core CPUs and unified shader GPUs, while the more restricted Filterscript also supports GPUs with earlier shader models. Our techniques focus on image processing applications and allow to target these APIs and OpenCL from a common description. We further supersede memory transfers by sharing the same memory region among different processing elements on HSA platforms. As reference, we use an embedded platform hosting a multi-core ARM CPU and an ARM Mali GPU. We show that our generated source code is faster than native implementations in OpenCV as well as the pre-implemented script intrinsics provided by Google for acceleration on the embedded GPU.","1558-1101","978-3-9815370-2-4","10.7873/DATE.2014.099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6800300","","Graphics processing units;Kernel;Androids;Humanoid robots;Computer architecture;DSL;Optimization","Android (operating system);application program interfaces;embedded systems;graphics processing units;Java;multiprocessing systems;source code (software)","code generation;embedded heterogeneous architectures;unified Java programming model;platform independent programs;multiple cores;embedded GPU;API;image processing applications;embedded platform;multicore ARM CPU;ARM Mali GPU;generated source code","","1","","11","","21 Apr 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Portable and Fast Stochastic Volatility Model Calibration Using Multi and Many-Core Processors","M. Dixon; J. Lotze; M. Zubair","Dept. of Analytics, Univ. of San Francisco, San Francisco, CA, USA; Xcelerit, Dublin, Ireland; Dept. of Comput. Sci., Old Dominion Univ., Norfolk, VA, USA","2014 Seventh Workshop on High Performance Computational Finance","26 Jan 2015","2014","","","23","28","Financial markets change precipitously and on-demand pricing and risk models must be constantly recalibrated to reduce risk. However, certain classes of models are computationally intensive to robustly calibrate to intraday pricesstochastic volatility models being an archetypal example due to the non-convexity of the objective function. In order to accelerate this procedure through parallel implementation,nancial application developers are faced with an ever growing plethora of low-level high-performance computing frameworks such as OpenMP, OpenCL, CUDA, or SIMD intrinsics, and forced to make a trade-off between performance versus the portability,exibility and modularity of the code required to facilitate rapid in-house model development and productionization.This paper describes the acceleration of stochastic volatility model calibration on multi-core CPUs and GPUs using the Xcelerit platform. By adopting a simple dataow programming model, the Xcelerit platform enables the application developer to write sequential, high-level C++ code, without concern for low-level high-performance computing frameworks. This platform provides the portability,exibility and modularity required by application developers. Speedups of up to 30x and 293x are respectively achieved on an Intel Xeon CPU and NVIDIA Tesla K40 GPU, compared to a sequential CPU implementation. The Xcelerit platform implementation is further shown to be equivalent in performance to a low-level CUDA version. Overall, we are able to reduce the entire calibration process time of the sequential implementation from 6; 189 seconds to 183:8 and 17:8 seconds on the CPU and GPU respectively without requiring the developer to reimplement in low-level high performance computing frameworks.","","978-1-4799-7027-8","10.1109/WHPCF.2014.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016370","Calibration; Stochastic Volatility; GPGPU; C++","Graphics processing units;Calibration;Computational modeling;Stochastic processes;Mathematical model;Optimization;Data models","C++ language;data flow computing;financial data processing;graphics processing units;multiprocessing systems;parallel architectures;pricing;risk management;stock markets","fast stochastic volatility model calibration;multicore processors;many-core processors;financial markets;on-demand pricing model;risk model;risk reduction;objective function nonconvexity;low-level high-performance computing frameworks;OpenMP intrinsic;OpenCL intrinsic;CUDA intrinsic;SIMD intrinsic;multicore CPU;multicore GPU;Xcelerit platform;dataflow programming model;high-level C++ code;sequential code;NVIDIA Tesla K40 GPU;Intel Xeon CPU","","","","16","","26 Jan 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"On the characterization of OpenCL dwarfs on fixed and reconfigurable platforms","K. Krommydas; W. -c. Feng; M. Owaida; C. D. Antonopoulos; N. Bellas","Department of Computer Science, Virginia Tech, USA; Department of Computer Science, Virginia Tech, USA; Department of Electrical and Computer Engineering, University of Thessaly, Greece; Department of Electrical and Computer Engineering, University of Thessaly, Greece; Department of Electrical and Computer Engineering, University of Thessaly, Greece","2014 IEEE 25th International Conference on Application-Specific Systems, Architectures and Processors","31 Jul 2014","2014","","","153","160","The proliferation of heterogeneous computing platforms presents the parallel computing community with new challenges. One such challenge entails evaluating the efficacy of such parallel architectures and identifying the architectural innovations that ultimately benefit applications. To address this challenge, we need benchmarks that capture the execution patterns (i.e., dwarfs or motifs) of applications, both present and future, in order to guide future hardware design. Furthermore, we desire a common programming model for the benchmarks that facilitates code portability across a wide variety of different processors (e.g., CPU, APU, GPU, FPGA, DSP) and computing environments (e.g., embedded, mobile, desktop, server). As such, we present the latest release of OpenDwarfs, a benchmark suite that currently realizes the Berkeley dwarfs in OpenCL, a vendor-agnostic and open-standard computing language for parallel computing. Using OpenDwarfs, we characterize a diverse set of fixed and reconfigurable parallel platforms: multicore CPUs, discrete and integrated GPUs, Intel Xeon Phi coprocessor, as well as a FPGA. We describe the computation and communication patterns exposed by a representative set of dwarfs, obtain relevant profiling data and execution information, and draw conclusions that highlight the complex interplay between dwarfs' patterns and the underlying hardware architecture of modern parallel platforms.","2160-052X","978-1-4799-3609-0","10.1109/ASAP.2014.6868650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6868650","OpenDwarfs;benchmarking;evaluation;dwarfs;performance characterization;CPU;FPGA;GPU;OpenCL","Benchmark testing;Field programmable gate arrays;Graphics processing units;Hardware;Computer architecture;Kernel;High definition video","field programmable gate arrays;graphics processing units;multiprocessing systems;parallel architectures;reconfigurable architectures","OpenCL Dwarfs;fixed platforms;reconfigurable platforms;heterogeneous computing platforms;parallel computing community;parallel architectures;future hardware design;OpenDwarfs;Berkeley dwarfs;vendor-agnostic computing language;open-standard computing language;multicore CPU;integrated GPU;discrete GPU;Intel Xeon Phi coprocessor;FPGA;execution information;profiling data;hardware architecture","","14","","14","","31 Jul 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Heterogeneous work-stealing across CPU and DSP cores","V. Kumar; A. Sbîrlea; A. Jayaraj; Z. Budimlić; D. Majeti; V. Sarkar","Rice University, Houston, Texas 77005, United States; Rice University, Houston, Texas 77005, United States; Texas Instruments, Dallas, United States; Rice University, Houston, Texas 77005, United States; Rice University, Houston, Texas 77005, United States; Rice University, Houston, Texas 77005, United States","2015 IEEE High Performance Extreme Computing Conference (HPEC)","12 Nov 2015","2015","","","1","6","Due to the increasing power constraints and higher and higher performance demands, many vendors have shifted their focus from designing high-performance computer nodes using powerful multicore general-purpose CPUs, to nodes containing a smaller number of general-purpose CPUs aided by a larger number of more power-efficient special purpose processing units, such as GPUs, FPGAs or DSPs. While offering a lower power-to-performance ratio, unfortunately, such heterogeneous systems are notoriously hard to program, forcing the users to resort to lower-level direct programming of the special purpose processors and manually managing data transfer and synchronization between the parts of the program running on general-purpose CPUs and on special-purpose processors. In this paper, we present HC-K2H, a programming model and runtime system for the Texas Instruments Keystone II Hawking platform, consisting of 4 ARM CPUs and 8 TI DSP processors. This System-on-a-Chip (SoC) offers high floating-point performance with lower power requirements than other processors with comparable performance. We present the design and implementation of a hybrid programming model and work-stealing runtime that allows tasks to be created and executed on both the ARM and DSP, and enables the seamless execution and synchronization of tasks regardless of whether they are running on the ARM or DSP. The design of our programming model and runtime is based on an extension of the Habanero-C programming system. We evaluate our implementation using task-parallel benchmarks on a Hawking board, and demonstrate excellent scaling compared to sequential implementations on a single ARM processor.","","978-1-4673-9286-0","10.1109/HPEC.2015.7322452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7322452","Habanero;Keystone-II;load balancing;scheduling;work-stealing","Digital signal processing;Runtime;Programming;Program processors;Hardware;Benchmark testing;Multicore processing","digital signal processing chips;low-power electronics;multiprocessing systems;parallel programming;synchronisation;system-on-chip","heterogeneous work-stealing;DSP cores;power constraints;high-performance computer nodes;multicore general-purpose CPU;power-efficient special purpose processing units;GPU;FPGAs;power-to-performance ratio;heterogeneous systems;lower-level direct programming;special purpose processors;data transfer;synchronization;HC-K2H;runtime system;Texas Instruments Keystone II Hawking platform;ARM CPU;DSP processors;system-on-a-chip;SoC;floating-point performance;lower power requirements;hybrid programming model;work-stealing runtime;Habanero-C programming system;parallel programming model","","6","","23","","12 Nov 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Efficient Mapping of Graphic Software on DSP","M. Mody; A. Jayaraj; H. Hariyani; A. Balagopalakrishnan; J. Jones; E. Narvaez; S. Govindarajan; P. Shankar; H. Garud","Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc; Embedded Processor Business, Texas Instruments Inc","2021 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","7 Dec 2021","2021","","","1","4","High Performance GPU is critical to render sophisticated user interfaces and general-purpose compute for image and vision processing in the Automotive and Industrial applications. The paper provides an overview of methods that can be used for offloading of part of GPU software (namely shaders) on DSP keeping traditional GPU software programming model intact to improve overall performance in the system. The methods allow efficient and transparent mapping of GPU shaders to DSP without alterations to existing software model. The proposed solution is prototyped in Jacinoto6 Platform of Texas Instruments. Experiments indicate that multiple shader primitives can be efficiently mapped to DSP achieving performance similar to GPU, with exception of trigonometric primitives. This allows DSP to be used as co-processor for graphics rendering applications. Leveraging compute capabilities of dual core C66x DSP in J acinto6 Platform using proposed solution can improve overall GPU Shader performance by up-to 41 % for different shaders corresponding to different use-cases.","2766-2101","978-1-6654-2849-1","10.1109/CONECCT52877.2021.9622613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622613","GPu;DSP;GLOPS;Shader;LLVM;OpenGL;Vulkan;Compute Primitives;Jacinto","Computational modeling;Conferences;Graphics processing units;User interfaces;Programming;Rendering (computer graphics);Software","","","","","","12","","7 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"An investigation of Unified Memory Access performance in CUDA","R. Landaverde; Tiansheng Zhang; A. K. Coskun; M. Herbordt","Electrical and Computer Engineering Department, Boston University, MA, USA; Electrical and Computer Engineering Department, Boston University, MA, USA; Electrical and Computer Engineering Department, Boston University, MA, USA; Electrical and Computer Engineering Department, Boston University, MA, USA","2014 IEEE High Performance Extreme Computing Conference (HPEC)","12 Feb 2015","2014","","","1","6","Managing memory between the CPU and GPU is a major challenge in GPU computing. A programming model, Unified Memory Access (UMA), has been recently introduced by Nvidia to simplify the complexities of memory management while claiming good overall performance. In this paper, we investigate this programming model and evaluate its performance and programming model simplifications based on our experimental results. We find that beyond on-demand data transfers to the CPU, the GPU is also able to request subsets of data it requires on demand. This feature allows UMA to outperform full data transfer methods for certain parallel applications and small data sizes. We also find, however, that for the majority of applications and memory access patterns, the performance overheads associated with UMA are significant, while the simplifications to the programming model restrict flexibility for adding future optimizations.","","978-1-4799-6233-4","10.1109/HPEC.2014.7040988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7040988","","Graphics processing units;Benchmark testing;Kernel;Data transfer;Programming;Runtime;Acceleration","electronic data interchange;graphics processing units;parallel architectures;performance evaluation;shared memory systems;storage management","unified memory access performance;CUDA;memory management;CPU;GPU computing;UMA;Nvidia;performance evaluation;programming model simplification;on-demand data transfer;data transfer method;memory access pattern","","46","","10","","12 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Measurement and Analysis of GPU-Accelerated OpenCL Computations on Intel GPUs","A. T. Cherian; K. Zhou; D. Grubisic; X. Meng; J. Mellor-Crummey","Rice University,Dept. of Computer Science; Rice University,Dept. of Computer Science; Rice University,Dept. of Computer Science; Rice University,Dept. of Computer Science; Rice University,Dept. of Computer Science","2021 IEEE/ACM International Workshop on Programming and Performance Visualization Tools (ProTools)","22 Dec 2021","2021","","","26","35","Graphics Processing Units (GPUs) have become a key technology for accelerating node performance in supercomputers, including the US Department of Energy’s forthcoming exascale systems. Since the execution model for GPUs differs from that for conventional processors, applications need to be rewritten to exploit GPU parallelism. Performance tools are needed for such GPU-accelerated systems to help developers assess how well applications offload computation onto GPUs.In this paper, we describe extensions to Rice University’s HPC-Toolkit performance tools that support measurement and analysis of Intel’s DPC++ programming model for GPU-accelerated systems atop an implementation of the industry-standard OpenCL framework for heterogeneous parallelism on Intel GPUs. HPCToolkit supports three techniques for performance analysis of programs atop OpenCL on Intel GPUs. First, HPC-Toolkit supports profiling and tracing of OpenCL kernels. Second, HPCToolkit supports CPU-GPU blame shifting for OpenCL kernel executions—a profiling technique that can identify code that executes on one or more CPUs while GPUs are idle. Third, HPCToolkit supports fine-grained measurement, analysis, and attribution of performance metrics to OpenCL GPU kernels, including instruction counts, execution latency, and SIMD waste. The paper describes these capabilities and then illustrates their application in case studies with two applications that offload computations onto Intel GPUs.","","978-1-6654-1110-3","10.1109/ProTools54808.2021.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651230","Supercomputers;High performance computing;Performance analysis;Parallel programming","Measurement;Visualization;Parallel programming;Computational modeling;High performance computing;Graphics processing units;Parallel processing","","","","","","25","","22 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"X<sup>e</sup><inf>HPC</inf> Ponte Vecchio","D. Blythe","Chief GPU Architect,Intel","2021 IEEE Hot Chips 33 Symposium (HCS)","20 Oct 2021","2021","","","1","34","500X Increase In Compute Performance Scalable Compute & Memory Packaging & Interconnect For Density & Scale Full Software Stack/Programming Model","2573-2048","978-1-6654-1397-8","10.1109/HCS52781.2021.9567038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9567038","","Computational modeling;Packaging;Software","","","","","","0","","20 Oct 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Case Study of k-means Clustering using SYCL","Z. Jin; H. Finkel","Leadership Computing Facility Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility Argonne National Laboratory,Lemont,IL,USA","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","4466","4471","As opposed to the OpenCL programming model in which host and device codes are written in two programming languages, the SYCL programming model combines them for an application in a type-safe way to improve development productivity. As a popular cluster analysis algorithm, k-means has been implemented using programming models such as OpenMP, OpenCL, and CUDA. Developing a SYCL implementation of k-means as a case study allows us to have a better understanding of performance portability and programming productivity of the SYCL programming model. Specifically, we explained the k-means benchmark in Rodinia, described our efforts of porting the OpenCL k-means benchmark, and evaluated the performance of the OpenCL and SYCL implementations on the Intel<sup>®</sup> Haswell, Broadwell, and Skylake processors. We summarized the migration steps from OpenCL to SYCL, compiled the SYCL program using Codeplay and Intel<sup>®</sup> SYCL compilers, analyzed the SYCL and OpenCL programs using an open-source profiling tool which can intercept OpenCL runtime calls, and compared the performance of the implementations on Intel<sup>®</sup> CPUs and integrated GPU. The experimental results show that the SYCL version in which the kernels run on the GPU is 2% and 8% faster than the OpenCL version for the two large datasets. However, the OpenCL version is still much faster than the SYCL version on the CPUs. Compared to the Intel<sup>®</sup> Haswell and Skylake CPUs, running the k-means benchmark on the Intel<sup>®</sup> Broadwell low-power processor with a CPU and an integrated GPU can achieve the lowest energy consumption. In terms of programming productivity, the lines of code of the SYCL program are 51% fewer than those of the OpenCL program.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005555","","Kernel;Graphics processing units;Programming;Benchmark testing;C++ languages;Productivity","application program interfaces;graphics processing units;parallel programming;pattern clustering;program compilers;programming languages","OpenCL programming model;programming languages;SYCL programming model;cluster analysis algorithm;SYCL program;SYCL compilers;OpenCL runtime calls","","3","","14","","24 Feb 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Validation Testsuite for OpenACC 1.0","C. Wang; R. Xu; S. Chandrasekaran; B. Chapman; O. Hernandez","Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Comput. Sci. & Math. Div., Oak Ridge Nat. Lab., Oak Ridge, TN, USA","2014 IEEE International Parallel & Distributed Processing Symposium Workshops","4 Dec 2014","2014","","","1407","1416","Directive-based programming models provide high-level of abstraction thus hiding complex low-level details of the underlying hardware from the programmer. One such model is OpenACC that is also a portable programming model allowing programmers to write applications that offload portions of work from a host CPU to an attached accelerator (GPU or a similar device). The model is gaining popularity and being used for accelerating many types of applications, ranging from molecular dynamics codes to particle physics models. It is critical to evaluate the correctness of the OpenACC implementations and determine its conformance to the specification. In this paper, we present a robust and scalable testing infrastructure that serves this purpose. We worked very closely with three main vendors that offer compiler support for OpenACC and assisted them in identifying and resolving compiler bugs helping them improve the quality of their compilers. The testsuite also aims to identify and resolve ambiguities within the OpenACC specification. This testsuite has been integrated into the harness infrastructure of the TITAN machine at Oak Ridge National Lab and is being used for production. The testsuite consists of test cases for all the directives and clauses of OpenACC, both for C and Fortran languages. The testsuite discussed in this paper focuses on the OpenACC 1.0 feature set. The framework of the testsuite is robust enough to create test cases for 2.0 and future releases. This work is in progress.","","978-1-4799-4116-2","10.1109/IPDPSW.2014.158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969543","Validation;OpenACC;Compiler","Arrays;Programming;Computer bugs;Vectors;Performance evaluation;Standards;Graphics processing units","C language;formal specification;FORTRAN;graphics processing units;molecular dynamics method;program compilers;program debugging","validation testsuite;OpenACC 1.0;directive-based programming model;high-level of abstraction;programmer;portable programming model;attached accelerator;GPU;molecular dynamics codes;particle physics model;OpenACC implementation;testing infrastructure;compiler support;compiler bugs;OpenACC specification;harness infrastructure;TITAN machine;Oak Ridge National Lab;C language;Fortran language","","7","1","12","","4 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Accelerating the reconstruction of magnetic resonance imaging by three-dimensional dual-dictionary learning using CUDA","J. Li; J. Sun; Y. Song; Y. Xu; J. Zhao","School of Biomedical Engineering, Shanghai Jiao Tong University, China; School of Biomedical Engineering, Shanghai Jiao Tong University, China; School of Biomedical Engineering, Shanghai Jiao Tong University, China; School of Biomedical Engineering, Shanghai Jiao Tong University, China; School of Biomedical Engineering, Shanghai Jiao Tong University, China","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","6 Nov 2014","2014","","","2412","2415","An effective way to improve the data acquisition speed of magnetic resonance imaging (MRI) is using under-sampled k-space data, and dictionary learning method can be used to maintain the reconstruction quality. Three-dimensional dictionary trains the atoms in dictionary in the form of blocks, which can utilize the spatial correlation among slices. Dual-dictionary learning method includes a low-resolution dictionary and a high-resolution dictionary, for sparse coding and image updating respectively. However, the amount of data is huge for three-dimensional reconstruction, especially when the number of slices is large. Thus, the procedure is time-consuming. In this paper, we first utilize the NVIDIA Corporation's compute unified device architecture (CUDA) programming model to design the parallel algorithms on graphics processing unit (GPU) to accelerate the reconstruction procedure. The main optimizations operate in the dictionary learning algorithm and the image updating part, such as the orthogonal matching pursuit (OMP) algorithm and the k-singular value decomposition (K-SVD) algorithm. Then we develop another version of CUDA code with algorithmic optimization. Experimental results show that more than 324 times of speedup is achieved compared with the CPU-only codes when the number of MRI slices is 24.","1558-4615","978-1-4244-7929-0","10.1109/EMBC.2014.6944108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6944108","","Graphics processing units;Dictionaries;Image reconstruction;Matching pursuit algorithms;Acceleration;Magnetic resonance imaging;Instruction sets","biomedical MRI;data acquisition;graphics processing units;image coding;image matching;image reconstruction;iterative methods;learning (artificial intelligence);medical image processing;optimisation;parallel algorithms;singular value decomposition;time-frequency analysis","three-dimensional dual-dictionary learning;data acquisition;magnetic resonance imaging;sampled k-space data;spatial correlation;low-resolution dictionary;high-resolution dictionary;sparse coding;image updating;image reconstruction quality;three-dimensional image reconstruction;Corporation compute unified device architecture programming model;NVIDIA-CUDA programming model;parallel algorithms;graphics processing unit;GPU;orthogonal matching pursuit algorithm;OMP algorithm;k-singular value decomposition;K-SVD algorithm;algorithmic optimization;CPU-only codes;MRI slices","Algorithms;Computer Graphics;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Models, Theoretical;Signal-To-Noise Ratio","","","12","","6 Nov 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Many-Core Accelerated LIBOR Swaption Portfolio Pricing","J. Lotze; P. D. Sutton; H. Lahlou","Xcelerit, Dublin, Ireland; Xcelerit, Dublin, Ireland; Xcelerit, Dublin, Ireland","2012 SC Companion: High Performance Computing, Networking Storage and Analysis","11 Apr 2013","2012","","","1185","1192","This paper describes the acceleration of a MonteCarlo algorithm for pricing a LIBOR swaption portfolio using multi-core CPUs and GPUs. Speedups of up to 305x are achieved on two Nvidia Tesla M2050 GPUs and up to 20.8x on two Intel Xeon E5620 CPUs, compared to a sequential CPU implementation. This performance is achieved by using the Xcelerit platform - writing sequential, high-level C++ code and adopting a simple dataflow programming model. It avoids the complexity involved when using low-level high-performance computing frameworks such as OpenMP, OpenCL, CUDA, or SIMD intrinsics. The paper provides an overview of the Xcelerit platform, details how high performance is achieved through various automatic optimisation and parallelisation techniques, and shows how the tool can be used to implement portable accelerated Monte-Carlo algorithms in finance. It illustrates the implementation of the Monte-Carlo LIBOR swaption portfolio pricer and gives performance results. A comparison of the Xcelerit platform implementation with an equivalent low-level CUDA version shows that the overhead introduced is less than 1.5% in all scenarios.","","978-0-7695-4956-9","10.1109/SC.Companion.2012.143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6495925","finance;swaption;GPU;GPGPU;derivatives pricing;HPC;CUDA","","C++ language;financial data processing;graphics processing units;investment;Monte Carlo methods;optimisation;parallel programming;pricing","Monte Carlo algorithm;optimisation technique;parallelisation technique;high performance computing framework;dataflow programming model;C++ code;Xcelerit platform;sequential CPU implementation;Intel Xeon E5620 CPU;Nvidia Tesla M2050 GPU;graphics processing unit;multicore CPU;portfolio pricing;many-core accelerated LIBOR swaption portfolio","","6","","15","","11 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Stream Processing on Multi-cores with GPUs: Parallel Programming Models' Challenges","D. A. Rockenbach; C. M. Stein; D. Griebler; G. Mencagli; M. Torquati; M. Danelutto; L. G. Fernandes","School of Technology, Pontifical Catholic University of Rio Grande do Sul (PUCRS) / Laboratory of Advanced Research on Cloud Computing (LARCC), Três de Maio Faculty (SETREM); Laboratory of Advanced Research on Cloud Computing (LARCC), Três de Maio Faculty (SETREM); School of Technology, Pontifical Catholic University of Rio Grande do Sul (PUCRS) / Laboratory of Advanced Research on Cloud Computing (LARCC), Três de Maio Faculty (SETREM); Computer Science Department, University of Pisa (UNIPI); Computer Science Department, University of Pisa (UNIPI); Computer Science Department, University of Pisa (UNIPI); School of Technology, Pontifical Catholic University of Rio Grande do Sul (PUCRS)","2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","29 Jul 2019","2019","","","834","841","The stream processing paradigm is used in several scientific and enterprise applications in order to continuously compute results out of data items coming from data sources such as sensors. The full exploitation of the potential parallelism offered by current heterogeneous multi-cores equipped with one or more GPUs is still a challenge in the context of stream processing applications. In this work, our main goal is to present the parallel programming challenges that the programmer has to face when exploiting CPUs and GPUs' parallelism at the same time using traditional programming models. We highlight the parallelization methodology in two use-cases (the Mandelbrot Streaming benchmark and the PARSEC's Dedup application) to demonstrate the issues and benefits of using heterogeneous parallel hardware. The experiments conducted demonstrate how a high-level parallel programming model targeting stream processing like the one offered by SPar can be used to reduce the programming effort still offering a good level of performance if compared with state-of-the-art programming models.","","978-1-7281-3510-6","10.1109/IPDPSW.2019.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778359","Parallel Programming;GPU;multi core;high performance computing;stream processing;structured parallel programming","Graphics processing units;Parallel processing;Parallel programming;Kernel;Instruction sets;Computational modeling","graphics processing units;multiprocessing systems;parallel programming","programming effort;state-of-the-art programming models;parallel programming models;stream processing paradigm;scientific enterprise applications;data items;data sources;potential parallelism;current heterogeneous multicores;stream processing applications;parallel programming challenges;traditional programming models;parallelization methodology;Mandelbrot Streaming benchmark;heterogeneous parallel hardware;high-level parallel programming model targeting stream processing;CPU;GPU parallelism;PARSEC Dedup application","","1","","24","","29 Jul 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Statistical-Feature ML Approach to IP Traffic Classification Based on CUDA","Z. Chen; R. Chen; Y. Zhang; J. Zhang; J. Xu","Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China","2016 IEEE Trustcom/BigDataSE/ISPA","9 Feb 2017","2016","","","2235","2239","In modern networks, there exist different applications which generate various different types of network traffic. In order to improve the performance of network management, it is important to identify and classify the internet traffic. The machine learning (ML) technique based on per-flow statistics has been widely used in traffic classification. Different from traditional classification methods, it is insensitive to port number and payload on application level. Our approach in this work is also based on a machine learning method kNN. kNN is a special case of a variable-bandwidth, kernel density ""balloon"" estimator with a uniform kernel [1]. Although there is no time taken for the construction of the classification model using kNN, it is computationally intensive since it relies on searching neighbor among large sets of d-dimensional vectors. The kNN algorithm may have quite expensive classification steps. CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model invented by NVIDIA. It enables dramatic increases in computing performance by harnessing the power of the graphics processing unit (GPU) [2]. This paper puts forward a CUDA-based kNN algorithm to classify internet traffic. The experimental results show that the peek speed of traffic classification based on GPU improves greatly compared with that based on CPU. Our approach presents a significant speed improvement through GPU, meanwhile, the results demonstrate the potential applicability of GPU in the field of traffic classification.","2324-9013","978-1-5090-3205-1","10.1109/TrustCom.2016.0344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847227","Traffic Classification;CUDA;k-Nearest Neighbor;GPU","Graphics processing units;Classification algorithms;Kernel;Training;IP networks;Ports (Computers);Internet","graphics processing units;Internet;learning (artificial intelligence);parallel architectures;pattern classification;telecommunication traffic","statistical-feature ML approach;IP traffic classification;machine learning method;compute unified device architecture;parallel computing platform;NVIDIA;graphics processing unit;CUDA-based kNN algorithm;Internet traffic;GPU","","1","","12","","9 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Image registration techniques using parallel computing in multicore environment and its applications in medical imaging: An overview","S. Saxena; S. Sharma; N. Sharma","School of Biomedical engineering, Indian Institute of Technology (BHU), Varanasi, UP, India; School of Biomedical engineering, Indian Institute of Technology (BHU), Varanasi, UP, India; School of Biomedical engineering, Indian Institute of Technology (BHU), Varanasi, UP, India","2014 International Conference on Computer and Communication Technology (ICCCT)","8 Jan 2015","2014","","","97","104","Image Registration is the key step of Image Processing as it is the process to locate most accurate relative orientation among two or more images, captured at the same or different times by distinguishable or indistinguishable sensors to increase the information content. For speed optimization of Image Registration, There have been developed numerous approaches till now based on CPU platforms, GPU, CUDA Programming Models etc. Purpose of this paper is to provide a comprehensive review of the existing literature available on Image registration methods based on parallel computing in Multi core architecture. Another considerable intention of this paper is to describe the various applications of image registration using parallel computing in Medical imaging as it can be applied for different modalities of medical images.","","978-1-4799-6758-2","10.1109/ICCCT.2014.7001475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001475","Image Registration;GPU;CUDA;Parallel Computing;CPU","Image registration;Graphics processing units;Biomedical imaging;Parallel processing;Computational modeling;Histograms;MATLAB","graphics processing units;image registration;medical image processing;parallel architectures","image registration techniques;parallel computing;multicore environment;medical imaging;image processing;information content;speed optimization;CPU platform;GPU;CUDA programming model;multicore architecture;medical images","","3","","70","","8 Jan 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Towards Achieving Performance Portability Using Directives for Accelerators","M. G. Lopez; V. V. Larrea; W. Joubert; O. Hernandez; A. Haidar; S. Tomov; J. Dongarra","Comput. Sci. & Math. Div., Oak Ridge Nat. Lab., Oak Ridge, TN, USA; Nat. Center for Comput. Sci., Oak Ridge Nat. Lab., Oak Ridge, TN, USA; Comput. Sci. & Math. Div., Oak Ridge Nat. Lab., Oak Ridge, TN, USA; Comput. Sci. & Math. Div., Oak Ridge Nat. Lab., Oak Ridge, TN, USA; Innovative Comput. Lab., Univ. of Tennessee, Knoxville, TN, USA; Innovative Comput. Lab., Univ. of Tennessee, Knoxville, TN, USA; Innovative Comput. Lab., Univ. of Tennessee, Knoxville, TN, USA","2016 Third Workshop on Accelerator Programming Using Directives (WACCPD)","2 Feb 2017","2016","","","13","24","In this paper we explore the performance portability of directives provided by OpenMP 4 and OpenACC to program various types of node architectures with attached accelerators, both self-hosted multicore and offload multicore/GPU. Our goal is to examine how successful OpenACC and the newer offload features of OpenMP 4.5 are for moving codes between architectures, how much tuning might be required and what lessons we can learn from this experience. To do this, we use examples of algorithms with varying computational intensities for our evaluation, as both compute and data access efficiency are important considerations for overall application performance. We implement these kernels using various methods provided by newer OpenACC and OpenMP implementations, and we evaluate their performance on various platforms including both X86_64 with attached NVIDIA GPUs, self-hosted Intel Xeon Phi KNL, as well as an X86_64 host system with Intel Xeon Phi coprocessors. In this paper, we explain what factors affected the performance portability such as how to pick the right programming model, its programming style, its availability on different platforms, and how well compilers can optimize and target to multiple platforms.","","978-1-5090-6152-5","10.1109/WACCPD.2016.006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836577","","Programming;Computer architecture;Computational modeling;Kernel;Writing;Government;Graphics processing units","graphics processing units;multiprocessing systems;parallel architectures;performance evaluation;program compilers","performance portability;OpenMP 4;OpenACC;node architectures;offload multicore-GPU;self-hosted multicore;computational intensities;data access efficiency;X86_64;NVIDIA GPU;KNL;self-hosted Intel Xeon Phi KNL;Intel Xeon Phi coprocessors;programming model;compilers","","16","","29","","2 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Map-reduce as a Programming Model for Custom Computing Machines","J. H. C. Yeung; C. C. Tsang; K. H. Tsoi; B. S. H. Kwan; C. C. C. Cheung; A. P. C. Chan; P. H. W. Leong","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China; Hong Kong Sci. & Technol. Park, Cluster Technol. Ltd., Hong Kong, China; Hong Kong Sci. & Technol. Park, Cluster Technol. Ltd., Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China","2008 16th International Symposium on Field-Programmable Custom Computing Machines","22 Dec 2008","2008","","","149","159","The map-reduce model requires users to express their problem in terms of a map function that processes single records in a stream, and a reduce function that merges all mapped outputs to produce a final result. By exposing structural similarity in this way, a number of key issues associated with the design of custom computing machines including parallelisation; design complexity; software-hardware partitioning; hardware-dependency, portability and scalability can be easily addressed. We present an implementation of a map-reduce library supporting parallel field programmable gate arrays (FPGAs) and graphics processing units (GPUs). Parallelisation due to pipelining, multiple data paths and concurrent execution of FPGA/GPU hardware is automatically achieved. Users first specify the map and reduce steps for the problem in ANSI Cand no knowledge of the underlying hardware or parallelisation is needed. The source code is then manually translated into a pipelined data path which, along with the map-reduce library, is compiled into appropriate binary configurations for the processing units. We describe our experience in developing a number of benchmark problems in signal processing, Monte Carlo simulation and scientific computing as well as report on the performance of FPGA, GPU and heterogeneous systems.","","978-0-7695-3307-0","10.1109/FCCM.2008.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724898","reconfigurable computing;map reduce;hardware/software codesign","Field programmable gate arrays;Hardware;Concurrent computing;Parallel processing;Graphics;Signal processing;Computer science;Scalability;Software libraries;Pipeline processing","computer graphics;field programmable gate arrays;functional languages;Monte Carlo methods;parallel machines","custom computing machines;map-reduce model;map function;parallelisation;design complexity;software-hardware partitioning;hardware-dependency;field programmable gate arrays;graphics processing units;ANSI C;source code;map-reduce library;Monte Carlo simulation","","50","","17","","22 Dec 2008","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"On the Design of a Demo for Exhibiting rCUDA","C. Reaño; F. Pérez; F. Silla","Univ. Politec. de Valencia, Valencia, Spain; Univ. Politec. de Valencia, Valencia, Spain; Univ. Politec. de Valencia, Valencia, Spain","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","9 Jul 2015","2015","","","1169","1172","CUDA is a technology developed by NVIDIA which provides a parallel computing platform and programming model for NVIDIA GPUs and compatible ones. It takes benefit from the enormous parallel processing power of GPUs in order to accelerate a wide range of applications, thus reducing their execution time. rCUDA (remote CUDA) is a middleware which grants applications concurrent access to CUDA-compatible devices installed in other nodes of the cluster in a transparent way so that applications are not aware of being accessing a remote device. In this paper we present a demo which shows, in real time, the overhead introduced by rCUDA in comparison to CUDA when running image filtering applications. The approach followed in this work is to develop a graphical demo which contains both an appealing design and technical contents.","","978-1-4799-8006-2","10.1109/CCGrid.2015.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152613","GPGPU;CUDA;HPC;virtualization","Graphics processing units;Gray-scale;Servers;Parallel processing;Acceleration;Middleware;Color","graphics processing units;image filtering;middleware;parallel architectures;parallel programming","rCUDA;demo design;NVIDIA;parallel computing platform;programming model;NVIDIA GPU;parallel processing power;remote CUDA;middleware;concurrent access;CUDA-compatible devices;image filtering applications","","","","4","","9 Jul 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Heterogeneous tasking on SMP/FPGA SoCs: The case of OmpSs and the Zynq","A. Filgueras; E. Gil; C. Alvarez; D. Jimenez; X. Martorell; J. Langer; J. Noguera","Barcelona Supercomputing Center, Barcelona; Universitat Politecnica de Catalunya, Barcelona; Barcelona Supercomputing Center, Barcelona; Barcelona Supercomputing Center, Barcelona; Barcelona Supercomputing Center, Barcelona; Xilinx Research Lab, Dublin; Xilinx Research Lab, Dublin","2013 IFIP/IEEE 21st International Conference on Very Large Scale Integration (VLSI-SoC)","25 Nov 2013","2013","","","290","291","OmpSs is a directive-based programming model that uses OpenMP-like directives, that allow to execute the tasks annotated on both the SMPs and as FPGA kernels on modern SoC processors, like the Xilinx Zynq platform. OmpSs includes the support for accelerators (MIC, GPUs, FPGAs) and task dependencies, like OpenMP 4.0 will support. In this paper we present our approach for the support of FPGAs and the Zynq SoC, the current status of the implementation, its analysis and performance evaluation.","2324-8440","978-1-4799-0524-9","10.1109/VLSI-SoC.2013.6673293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6673293","","Field programmable gate arrays;Hardware;Runtime;System-on-chip;Ecosystems;Programming;Software","field programmable gate arrays;system-on-chip","heterogeneous tasking;SMP-FPGA SoC;OmpS;directive-based programming model;OpenMP-like directives;FPGA kernels;SoC processors;Xilinx Zynq platform;MIC;GPU;OpenMP 4.0","","3","","1","","25 Nov 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Compiler-assisted Runtime-prefetching Scheme for Heterogenous Platforms","B. Shou; X. Hou; L. Chen","ICT, Beijing, China; ICT, Beijing, China; ICT, Beijing, China","2011 International Conference on Parallel Architectures and Compilation Techniques","29 Dec 2011","2011","","","215","215","GPGPU has been widely adopted by industry and academia. For real applications on industry, however, the data communications between CPUs and GPUs often dramatically slow down the overall performance. Another difficulty raised by GPGPU is the programming productivity. OpenMP is a high-level programming model widely accepted by industry. A software distributed shared memory system (DSM) is implemented to provide a logic shared memory space and to manage data communications between CPUs and GPUs. The DSM is block-based, and the block size is adjustable based on loop partitioning parameters. In this work, we optimize the DSM system using a compiler-assisted data-prefetching scheme. There is a prefetching thread and a prefetching worker for each sepa rated memory. The prefetching thread looks into the future, applies inter-thread use-def analysis to judge which part of the USE region has already been generated by computing threads and produces prefetching requests. The prefetching worker carries out the prefetching operations.","1089-795X","978-1-4577-1794-9","10.1109/PACT.2011.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113825","","Prefetching;Runtime;Data communication;Kernel;Industries;Programming","distributed shared memory systems;graphics processing units;multiprocessing systems;parallel architectures;program compilers;program control structures;storage management","compiler assisted runtime prefetching scheme;heterogenous platforms;OpenMP;high level programming model;Pthreads;CUDA code;software distributed shared memory system;logic shared memory space;data communications manage;CPU;GPU;DSM;loop partitioning parameters;prefetching thread;prefetching worker;interthread use-def analysis;USE region","","","","","","29 Dec 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Scheduling and Runtime Framework for a Cluster of Heterogeneous Machines with Multiple Accelerators","T. Beri; S. Bansal; S. Kumar","Indian Inst. of Technol. Delhi, New Delhi, India; Indian Inst. of Technol. Delhi, New Delhi, India; Indian Inst. of Technol. Delhi, New Delhi, India","2015 IEEE International Parallel and Distributed Processing Symposium","20 Jul 2015","2015","","","146","155","We present a runtime system for simple and efficient programming of CPU+GPU clusters. The programmer focuses on core logic, while the system undertakes task allocation, load balancing, scheduling, data transfer, etc. Our programming model is based on a shared global address space, made efficient by transaction style bulk-synchronous semantics. This model broadly targets coarse-grained data parallel computation particularly suited to multi-GPU heterogeneous clusters. We describe our computation and communication scheduling system and report its performance ona few prototype applications. For example, parallelization of matrix multiplication or 2D FFT using our system requires the regular CPU/GPU implementations and about 30 lines of additional C code to set up the runtime. Our runtime system achieves a performance of 5.61 TFlop/s while multiplying two square matrices of 1.56 billion elements each over a 10-nodecluster with 20 GPUs. This performance is possible due toa number of critical optimizations working in concert. These include perfecting, pipelining, maximizing overlap between computation and communication, and scheduling efficiently across heterogeneous devices of vastly different capacities.","1530-2075","978-1-4799-8649-1","10.1109/IPDPS.2015.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7161504","High Performance Computing;Heterogeneous Architectures;Hybrid CPU-GPU Clusters;Work Stealing;Multi Scheduling","Graphics processing units;Runtime;Kernel;Programming;Message systems;Data transfer;Subscriptions","graphics processing units;parallel processing;resource allocation;scheduling","scheduling framework;runtime framework;heterogeneous machine;accelerator;CPU+GPU cluster programming;graphics processing unit;task allocation;load balancing;data transfer;transaction style bulk-synchronous semantics;high-performance computing","","7","","47","","20 Jul 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Evaluating Multi-core and Many-Core Architectures through Accelerating an Alternating Direction Implicit CFD Solver","L. Deng; J. Fang; F. Wang; H. Bai","Comput. Aerodynamics Inst., China Aerodynamics R&D Center, Mianyang, China; Software Institue, Nat. Univ. of Defense Technol., Changsha, China; Software Institue, Nat. Univ. of Defense Technol., Changsha, China; Comput. Aerodynamics Inst., China Aerodynamics R&D Center, Mianyang, China","2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)","24 Apr 2017","2016","","","1","10","In this paper, we accelerate a double-precision alternating direction implicit (ADI) solver for three-dimensional compressible Navier-Stokes equations from our in-house computational fluid dynamics (CFD) software on the latest multi-core and many-core architectures (Intel Ivy Bridge CPU, Intel Xeon Phi 7110P coprocessor and NVIDIA Kepler K20c GPU). For the GPU platform, both the OpenACC-based and the CUDA-based versions of the ADI solver are developed. To achieve high performance, we use a series of optimization techniques. For the Ivy Bridge CPU and Xeon Phi, we focus on three categories of optimization techniques: thread parallelism for multi-/many-core scaling, data parallelism to exploit the SIMD mechanism and improving on-chip data reuse, to maximize the performance. Also, we provide an in-depth analysis on the performance differences between Ivy Bridge and Xeon Phi. Our numerical experiments show that the proposed CUDA-based ADI solver can achieve a speedup of 9.7 on a Kepler GPU in contrast to a single naive serial version and our optimization techniques can improve the performance of the ADI solver by 2.5x on two Ivy Bridge CPUs and 1.7x on the Intel Xeon Phi coprocessor. We also notice that the OpenACC-based version runs around 29% slower than the CUDA-based one with careful manual optimizations. Besides, we systematically evaluate the programmability of the three platforms. Our insights facilitate the programmers to select a right platform with a suitable programming model according to their target applications.","","978-1-5090-4152-7","10.1109/ISPDC.2016.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7904262","performance;programmability;optimization techniques;alternating direction implicit;CFD solver;Ivy Bridge;Xeon Phi;GPU;CUDA;OpenACC","Graphics processing units;Mathematical model;Optimization;Instruction sets;Programming;Computer architecture;Bridges","computational fluid dynamics;graphics processing units;microprocessor chips;multiprocessing systems;multi-threading;Navier-Stokes equations;parallel architectures","multicore architectures;many-core architectures;alternating direction implicit CFD solver;double-precision alternating direction implicit solver;ADI solver;three-dimensional compressible Navier-Stokes equations;computational fluid dynamics software;CFD software;Intel Ivy Bridge CPU;Intel Xeon Phi 7110P coprocessor;NVIDIA Kepler K20c GPU;OpenACC;CUDA;optimization techniques;thread parallelism;data parallelism;on-chip data reuse","","","","26","","24 Apr 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Characteristic mode analysis of arbitrary electromagnetic structures using FEKO","D. J. Ludick; E. Lezar; U. Jakobus","EM Software & Systems - S.A. (Pty) Ltd, 32 Techno Avenue, Technopark, Stellenbosch, 7600, South Africa; EM Software & Systems - S.A. (Pty) Ltd, 32 Techno Avenue, Technopark, Stellenbosch, 7600, South Africa; EM Software & Systems - S.A. (Pty) Ltd, 32 Techno Avenue, Technopark, Stellenbosch, 7600, South Africa","2012 International Conference on Electromagnetics in Advanced Applications","11 Oct 2012","2012","","","208","211","This paper considers the characteristic mode analysis (CMA) of arbitrary electromagnetic structures using the comprehensive 3D electromagnetic field solver, FEKO [1]. The theory of characteristic modes, as presented in [2], is used to derive the real orthogonal current modes. These modes are obtained by solving a generalised symmetric eigenvalue problem defined by the real and imaginary parts of the Method-of-Moments (MoM) impedance matrix. The research presented in this article discusses the techniques used in FEKO to solve this generalised eigenproblem. Furthermore, paralleli-sation using both distributed and shared memory programming models, as well as GPU computation is considered within the FEKO framework to accelerate the CMA.","","978-1-4673-0335-4","10.1109/ICEAA.2012.6328622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6328622","","Eigenvalues and eigenfunctions;Moment methods;Runtime;Graphics processing unit;Impedance;Symmetric matrices;Equations","distributed memory systems;eigenvalues and eigenfunctions;electromagnetic field theory;matrix algebra;method of moments;shared memory systems","characteristic mode analysis;arbitrary electromagnetic structures;CMA;comprehensive 3D electromagnetic field solver;real orthogonal current modes;generalised symmetric eigenvalue problem;method-of-moments impedance matrix;MoM impedance matrix;GPU computation;FEKO framework;shared memory programming model","","14","","10","","11 Oct 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Efficient parallel CKY parsing using GPUs","Y. Yi; C. Lai; S. Petrov",NA; NA; NA,"Journal of Logic and Computation","18 Jan 2018","2014","24","2","375","393","Low-latency solutions for syntactic parsing are needed if parsing is to become an integral part of user-facing natural language applications. Unfortunately, most state-of-the-art constituency parsers employ large probabilistic context-free grammars for disambiguation, which renders them impractical for real-time use. Meanwhile, Graphics Processor Units (GPUs) have become widely available, offering the opportunity to alleviate this bottleneck by exploiting the fine-grained data parallelism found in the Cocke–Kasami–Younger (CKY) algorithm. In this article, we explore the design space of parallelizing the dynamic programming computations carried out by the CKY algorithm. We use the Compute Unified Device Architecture (CUDA) programming model to reimplement a state-of-the-art parser, and compare its performance on three recent GPUs with different architectural features. Our best results show a 33-fold speedup for the CUDAparser compared to a sequential C implementation.","1465-363X","","10.1093/logcom/exs078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8200101","CKY parsing;Viterbi parsing;parallel parsing;GPU;CUDA","","","","","","","","","18 Jan 2018","","","OUP","OUP Journals"
notebooks/data/ieee_2.csv:"Performance and Portability Studies with OpenACC Accelerated Version of GTC-P","Y. Wei; Y. Wang; L. Cai; W. Tang; B. Wang; S. Ethier; S. See; J. Lin","Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China; Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China; Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China; Princeton Inst. of Comput. Sci. & Eng., Princeton Univ., Princeton, NJ, USA; Princeton Inst. of Comput. Sci. & Eng., Princeton Univ., Princeton, NJ, USA; Princeton Plasma Phys. Lab., Princeton, NJ, USA; Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China; Center for High Performance Comput., Shanghai Jiao Tong Univ., Shanghai, China","2016 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)","8 Jun 2017","2016","","","13","18","Accelerator-based heterogeneous computing is of paramount importance to High Performance Computing. The increasing complexity of the cluster architectures requires more generic, high-level programming models. OpenACC is a directive-based parallel programming model, which provides performance on and portability across a wide variety of platforms, including GPU, multicore CPU, and many-core processors. GTC-P is a discovery-science-capable real-world application code based on the Particle-In-Cell (PIC) algorithm that is well-established in the HPC area. Several native versions of GTC-P have been developed for supercomputers on TOP500 with different architectures, including Titan, Mira, etc. Motivated by the state-of-art portability, we implemented the first OpenACC version of GTC-P and evaluated its performance portability across NVIDIA GPUs, Intel x86 and OpenPOWER CPUs. In this paper, we also proposed two key optimization methods for OpenACC implementation of PIC algorithm on multicore CPU and GPU including removing atomic operation and taking advantage of shared memory. OpenACC shows both impressive productivity and performance in a perspective of portability and scalability. The OpenACC version achieves more than 90% performance compared with the native versions with only about 300 LOC.","","978-1-5090-5081-9","10.1109/PDCAT.2016.019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7943324","Gyrokinetic PIC code;GTC-P;OpenACC;CUDA;GPU;OpenPOWER","Graphics processing units;Multicore processing;Instruction sets;Optimization;Acceleration;Scalability","computational complexity;graphics processing units;multiprocessing systems;parallel processing;performance evaluation","GTC-P;accelerator-based heterogeneous computing;high performance computing;cluster architecture complexity;directive-based parallel programming model;multicore CPU;many-core processors;discovery-science-capable real-world application code;particle-in-cell algorithm;PIC algorithm;performance portability;NVIDIA GPUs;Intel x86;OpenPOWER CPUs;optimization methods;OpenACC implementation","","1","","10","","8 Jun 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"HSAemu - A full system emulator for HSA platforms","J. -H. Ding; W. Hsu; BaiCheng Jeng; S. Hung; Y. Chung","National Tsing Hua University, Hsinchu, 30013, Taiwan; National Taiwan University, Taipei, 10617, Taiwan; National Tsing Hua University, Hsinchu, 30013, Taiwan; National Taiwan University, Taipei, 10617, Taiwan; National Tsing Hua University, Hsinchu, 30013, Taiwan","2014 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)","4 Dec 2014","2014","","","1","10","Heterogeneous System Architecture (HSA) is an open industry standard designed to support a large variety of data-parallel and task-parallel programming models. Currently, most of HSA hardware and software components are still in development. It is helpful to provide various heterogeneous simulation environments for HSA developers in developing HSA software stacks. This paper presents the design of HSAemu, a full system emulator for the HSA platform, and illustrates how those HSA features are implemented in the simulator. HSAemu provides an infrastructure of heterogeneous simulation environments by supporting required HSA features, including hUMA, hQ and HSAIL. Based on the infrastructure, HSAemu provide two simulation models, FastSim and DeepSim, for high-speed functional emulation and slow cycle-accurate simulation, respectively. In our preliminary experiments, HSAemu helps test a complete HSA software stack and profile system performance. Our case studies show that HSAemu is very useful as a hardware/software co-design tool for heterogeneous systems.","","978-1-4503-3051-0","10.1145/2656075.2656088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971842","HSA;GPU simulation;parallel simulation","Graphics processing units;Computational modeling;Kernel;Hardware;Computer architecture;Synchronization","digital simulation;graphics processing units","HSAemu;full-system emulator;HSA platforms;heterogeneous system architecture;open industry standard;data-parallel programming model;task-parallel programming model;HSA hardware components;HSA software components;heterogeneous simulation environments;HSA software stacks;hUMA;hQ;HSAIL;FastSim simulation model;DeepSim simulation model;high-speed functional emulation;slow-cycle-accurate simulation;profile system performance;hardware/software co-design tool","","3","","27","","4 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Evaluation of Performance Portability of Applications and Mini-Apps across AMD, Intel and NVIDIA GPUs","J. Kwack; J. Tramm; C. Bertoni; Y. Ghadar; B. Homerding; E. Rangel; C. Knight; S. Parker","Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA; Leadership Computing Facility / Computational Science Division, Argonne National Laboratory,Lemont,IL,USA","2021 International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","28 Dec 2021","2021","","","45","56","This paper will evaluate the progress being made on achieving performance portability by a sub-set of ECP applications, or their related mini-apps, across a diverse spectrum of applications domains and approaches to achieving performance portability. The applications or mini-apps evaluated are AMR-Wind, HACC, SW4, GAMESS RI-MP2, XSBench, and TestSNAP. These codes are being redeveloped using the SYCL, OpenMP, RAJA, or Kokkos programming models, or the AMReX framework and in this paper we assess their performance portability across the AMD MI100, Intel Gen9, and NVIDIA A100 GPUs. Since each GPU has different performance characteristics we have utilized the roofline performance model to compute the performance efficiency and evaluate performance portability across the three platforms. The merits of different metrics for quantifying performance portability are considered and a metric based on the standard deviation of roofline efficiencies is proposed as a preferred metric. Finally, observations on developer productivity are made based on the experience gained working with these applications.","","978-1-6654-2439-4","10.1109/P3HPC54578.2021.00008","DOE Office of Science User Facility(grant numbers:DE-AC02-06CHl1357); National Nuclear Security Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652861","high performance computing;performance portability;performance efficiency;roofline performance analysis;GPU;portable programming model;software framework","Measurement;Productivity;Analytical models;Codes;Computational modeling;Conferences;Graphics processing units","","","","","","40","","28 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"A Compiler-Based Tool for Array Analysis in HPC Applications","A. Qawasmeh; B. Chapman; A. Banerjee","Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Pet. Geo-Services, Houston, TX, USA","2012 41st International Conference on Parallel Processing Workshops","25 Oct 2012","2012","","","454","463","Array region analysis plays a significant role in various optimizations at compile time. Displaying array access information efficiently in HPC applications has been a vital challenge for scientists and developers for the past few years. Dragon array region analysis tool is a powerful and interactive tool that was built on top of the Open UH compiler, an open source C/C++/Fortran compiler, that supports OpenMP and CAF programming models. We have extended the linear-based Region analysis method and the high level IR (WHIRL) of Open UH to visualize the static and interprocedural array region accesses, the frequency of these accesses per access mode, the access mode in which the array is processed, the number of dimensions, the size of each dimension, the total size in bytes allocated to this array statically, and the memory location. We have also defined the access density term which illustrates the frequency of accesses per bytes allocated to these arrays. The information provided enables users to efficiently develop and optimize HPC applications by understanding procedure side effects and finding inefficiencies in defining arrays, which guides to a better memory allocation and cache usage. Moreover, we demonstrate the access density of the portions of arrays that have been accessed, which is crucial to reduce data transfers between host and device when using directive-based GPU programming models.","2332-5690","978-1-4673-2509-7","10.1109/ICPPW.2012.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337513","Analysis tool;Linear-based techniques;Compiler-based tool;Array Region Analysis","Arrays;Optimization;Programming;Data mining;Indexes;Graphics processing unit","application program interfaces;C++ language;cache storage;data visualisation;FORTRAN;graphics processing units;multi-threading;program compilers;public domain software;shared memory systems","compiler-based tool;Dragon array region analysis tool;HPC applications;interactive tool;Open UH compiler;open source C compiler;open source C++ compiler;open source Fortran compiler;OpenMP programming model;CAF programming model;linear-based region analysis method;high level IR;WHIRL;static array region access visualization;interprocedural array region access visualization;memory location;memory allocation;cache usage;data transfer reduction;directive-based GPU programming models;multithreaded programming API","","3","","28","","25 Oct 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Exploration of OpenCL for FPGAs using SDAccel and comparison to GPUs and multicore CPUs","L. Kalms; D. Göhringer","Technische Universität Dresden, Dresden, Germany; Technische Universität Dresden, Dresden, Germany","2017 27th International Conference on Field Programmable Logic and Applications (FPL)","5 Oct 2017","2017","","","1","4","Due to energy efficiency, heterogeneous computing is gaining more and more attention. Since FPGA implementations are time consuming, high-level synthesis (HLS) is used to close the productivity gap. OpenCL has become accepted as a good programming model for HLS, due to its portability, good capability of design verification and rich instruction set. This work implements different optimization strategies using OpenCL for a heterogeneous system containing CPU, integrated GPU, GPU and FPGA. Energy efficiency and performance of the architectures are compared using a feature detection algorithm. It is shown how to maximize performance while hitting the maximum memory bandwidth and keeping the resource utilization low for the SDAccel tool from Xilinx. The evaluation shows the great streaming capability of OpenCL for FPGAs. The FPGA achieves a speed up of 62.8 and consumes 49 times less energy for the application in comparison to an optimized single threaded CPU implementation in full HD.","1946-1488","978-9-0903-0428-1","10.23919/FPL.2017.8056847","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8056847","OpenCL;SDAccel;GPU;CPU;FPGA;Energy Efficiency;Performance;Image Processing;Accelerators","Kernel;Field programmable gate arrays;Graphics processing units;Bandwidth;Optimization;Resource management","electronic engineering computing;energy conservation;feature extraction;field programmable gate arrays;graphics processing units;high level synthesis;microprocessor chips;multiprocessing systems;optimisation;power aware computing;public domain software","optimization strategies;integrated GPU;Xilinx;HLS;high-level synthesis;FPGA implementations;heterogeneous computing;SDAccel tool;feature detection algorithm;energy efficiency;heterogeneous system;OpenCL;multicore CPU","","7","","18","","5 Oct 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Resource Centered Computing Delivering High Parallel Performance","J. Gustedt; S. Vialle; P. Mercier","INRIA Nancy - Grand Est, Nancy, France; SUPELEC, Metz, France; SUPELEC, Metz, France","2014 IEEE International Parallel & Distributed Processing Symposium Workshops","4 Dec 2014","2014","","","77","88","Modern parallel programming requires a combination of different paradigms, expertise and tuning, that correspond to the different levels in today's hierarchical architectures. To cope with the inherent difficulty, ORWL (ordered read-write locks) presents a new paradigm and toolbox centered around local or remote resources, such as data, processors or accelerators. ORWL programmers describe their computation in terms of access to these resources during critical sections. Exclusive or shared access to the resources is granted through FIFOs and with read-write semantic. ORWL partially replaces a classical runtime and offers a new API for resource centric parallel programming. We successfully ran an ORWL benchmark application on different parallel architectures (a multicore CPU cluster, a NUMA machine, a CPU+GPU cluster). When processing large data we achieved scalability and performance similar to a reference code built on top of MPI+OpenMP+CUDA. The integration of optimized kernels of scientific computing libraries (ATLAS and cuBLAS) has been almost effortless, and we were able to increase performance using both CPU and GPU cores on our hybrid hierarchical cluster simultaneously. We aim to make ORWL a new easy-to-use and efficient programming model and toolbox for parallel developers.","","978-1-4799-4116-2","10.1109/IPDPSW.2014.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969373","resource centered computing;read-write locks;clusters;accelerators;GPU;experiments;performance","Computational modeling;Graphics processing units;Kernel;Computer architecture;Parallel processing;Parallel programming","application program interfaces;graphics processing units;natural sciences computing;parallel architectures;parallel programming","resource centered computing;high parallel performance;ordered read-write locks;ORWL programmers;remote resources;local resources;critical sections;read-write semantic;API;resource centric parallel programming;parallel architectures;MPI+OpenMP+CUDA;scientific computing libraries;CPU cores;GPU cores;hybrid hierarchical cluster;parallel developers","","","","26","","4 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Implementation and Evaluation of One-Sided PGAS Communication in XcalableACC for Accelerated Clusters","A. Tabuchi; M. Nakao; H. Murai; T. Boku; M. Sato","Grad. Sch. of Syst. & Inf. Eng., Univ. of Tsukuba, Tsukuba, Japan; RIKEN Adv. Inst. for Comput. Sci., Kobe, Japan; RIKEN Adv. Inst. for Comput. Sci., Kobe, Japan; Center for Comput. Sci., Univ. of Tsukuba, Tsukuba, Japan; RIKEN Adv. Inst. for Comput. Sci., Kobe, Japan","2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)","13 Jul 2017","2017","","","625","634","Clusters equipped with accelerators such as graphics processing unit (GPU) and Many Integrated Core (MIC) are widely used. For such clusters, programmers write programs for their applications by combining MPI with one of the available accelerator programming models. In particular, OpenACC enables programmers to develop their applications easily, but with lower productivity owing to complex MPI programming. XcalableACC (XACC) is a new programming model, which is an ""orthogonal"" integration of a partitioned global address space (PGAS) language XcalableMP (XMP) and OpenACC. While XMP enables distributed-memory programming on both global-view and local-view models, OpenACC allows operations to be offloaded to a set of accelerators. In the local-view model, programmers can describe communication with the coarray features adopted from Fortran 2008, and we extend them to communication between accelerators. We have designed and implemented an XACC compiler for NVIDIA GPU and evaluated its performance and productivity by using two benchmarks, Himeno benchmark and NAS Parallel Benchmarks CG (NPB-CG). The performance of the XACC version with the Himeno benchmark and NPB-CG are over 85% and 97% in the local-view model against the MPI+OpenACC version, respectively. Moreover, using non-blocking communication makes the performance of local-view version over 89% with the Himeno benchmark. From the viewpoint of productivity, the local-view model provides an intuitive form of array assignment statement for communication.","","978-1-5090-6611-7","10.1109/CCGRID.2017.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973750","Accelerator;GPU;Cluster;PGAS;Coarray;OpenACC","Graphics processing units;Programming;Synchronization;Electronics packaging;Syntactics;Benchmark testing;Productivity","distributed memory systems;distributed programming;FORTRAN;graphics processing units;message passing;parallel processing","one-sided PGAS communication;XcalableACC;accelerated clusters;graphics processing unit;many integrated core;MIC;accelerator programming models;OpenACC;complex MPI programming;partitioned global address space;PGAS language XcalableMP;distributed-memory programming;global-view models;local-view models;coarray features;Fortran 2008;XACC compiler;NVIDIA GPU;Himeno benchmark;NAS Parallel Benchmarks CG;NPB-CG;nonblocking communication;array assignment statement","","3","","25","","13 Jul 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Complete solution of eight puzzle problem using BFS in CUDA environment","M. Sultana; R. N. Dutta; S. K. Setua","Dept. of CSE, University of Calcutta, Kolkata, India; Dept. of CSE, University of Calcutta, Kolkata, India; Dept. of CSE, University of Calcutta, Kolkata, India","2015 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE)","31 Mar 2016","2015","","","333","337","The eight puzzle problem is the largest completely solvable problem of n×n sliding puzzle problems. It is combinatorial in nature, but there is a large problem space of 9! /2. Objective of this work is to find the complete solution of eight puzzle problem i.e. examining all the permutations for solvability. Using Breadth First search (BFS) graph traversal we can reach the solution for a definite goal. The parallel algorithm is capable of providing us with much more faster solution using Compute Unified Device Architecture (CUDA). CUDA facility enables us to use best possible available computation power of GPU (Graphics Processing Unit). In this paper, we present fast implementation of common graph operation like breadth-first search to find out complete solution of eight puzzle problem on the GPU using the CUDA programming model. Our implementations exhibit better performance. The availability and spread of GPUs to desktops and laptops make them ideal candidates to accelerate graph operations over the CPU-only implementations.","","978-1-4673-8786-6","10.1109/WIECON-ECE.2015.7443931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443931","Eight puzzle problem;Complete Solution;Breadth-first search;GPU;CUDA","Graphics processing units;Arrays;Indexes;Instruction sets;Search problems;Computational modeling","computability;graph theory;graphics processing units;parallel algorithms;parallel architectures;tree searching","eight puzzle problem;sliding puzzle problems;permutations;solvability;breadth first search graph traversal;BFS graph traversal;parallel algorithm;compute unified device architecture;GPU;graphics processing unit;CUDA programming","","","","12","","31 Mar 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"On the Programmability and Performance of Heterogeneous Platforms","K. Krommydas; T. R. W. Scogland; W. -C. Feng","Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA","2013 International Conference on Parallel and Distributed Systems","1 May 2014","2013","","","224","231","General-purpose computing on an ever-broadening array of parallel devices has led to an increasingly complex and multi-dimensional landscape with respect to programmability and performance optimization. The growing diversity of parallel architectures presents many challenges to the domain scientist, including device selection, programming model, and level of investment in optimization. All of these choices influence the balance between programmability and performance. In this paper, we characterize the performance achievable across a range of optimizations, along with their programmability, for multi- and many-core platforms - specifically, an Intel Sandy Bridge CPU, Intel Xeon Phi co-processor, and NVIDIA Kepler K20 GPU - in the context of an n-body, molecular-modeling application called GEM. Our systematic approach to optimization delivers implementations with speed-ups of 194.98×, 885.18×, and 1020.88× on the CPU, Xeon Phi, and GPU, respectively, over the naive serial version. Beyond the speed-ups, we characterize the incremental optimization of the code from naive serial to fully hand-tuned on each platform through four distinct phases of increasing complexity to expose the strengths and weaknesses of the programming models offered by each platform.","1521-9097","978-1-4799-2081-5","10.1109/ICPADS.2013.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808178","performance;programmability;optimization;AVX;GPU;Intel MIC;NVIDIA Kepler K20;Xeon Phi;CUDA;OpenACC","Optimization;Graphics processing units;Vectors;Computer architecture;Programming;Performance evaluation;Mathematical model","coprocessors;general purpose computers;multiprocessing systems;optimisation;parallel architectures;performance evaluation","programmability;heterogeneous platform performance;general-purpose computing;parallel devices;performance optimization;parallel architectures;device selection;optimization investment level;multicore platform;many-core platforms;Intel Sandy Bridge CPU;Intel Xeon Phi coprocessor;NVIDIA Kepler K20 GPU;n-body molecular-modeling application;GEM;incremental optimization;naive serial;programming models","","6","","12","","1 May 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Compute Intensive Algorithm on Heterogeneous System: A Case Study about Fourier Transform","A. Galizia; E. Danovaro; G. Ripepi; A. Clematis","Inst. for Appl. Math. & Inf. Technol., Genoa, Italy; Inst. for Appl. Math. & Inf. Technol., Genoa, Italy; Inst. for Appl. Math. & Inf. Technol., Genoa, Italy; Inst. for Appl. Math. & Inf. Technol., Genoa, Italy","2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing","14 Apr 2014","2014","","","223","227","Current workstations can offer really amazing raw computational power: up to 10 TFlops on a single machine equipped with multiple CPUs and accelerators as the Intel Xeon Phi or GPU devices. Such results can only be achieved with a massive parallelism of computational devices, thus the actual barrier posed by the exploitation of modern heterogeneous HPC resources is the difficulty in development and/or (performance) efficient porting of software on such architectures. In this paper, we present an experimental study about achievable performance of a widely used, computational intensive application the Fourier Transform, i.e. Discrete Fourier Transform (DFT) and Fast Fourier Transform. We propose an evaluation of the benefits obtained exploiting such resources in terms of performance and programming efforts in the development of the code with a emphasis on the programming approach adopted for code parallelization. With the exception of the interesting performance achieved exploiting GPU for the DFT algorithm, the use state-ofthe- art software libraries provide the best solution since they represent a good compromise to balance programming efforts and performance achievements.","2377-5750","978-1-4799-2729-6","10.1109/PDP.2014.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787277","Complex Heterogeneous System;Parallel Programming Model;Fourier Transform","Graphics processing units;Discrete Fourier transforms;Computer architecture;Programming;Libraries;Hardware","discrete Fourier transforms;fast Fourier transforms;graphics processing units;multiprocessing systems","compute intensive algorithm;heterogeneous system;multiple CPU;multiple accelerators;GPU device;Intel Xeon Phi device;heterogeneous HPC resources;discrete Fourier transform;fast Fourier transform;code parallelization;DFT algorithm;software libraries","","","","10","","14 Apr 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"VComputeBench: A Vulkan Benchmark Suite for GPGPU on Mobile and Embedded GPUs","N. Mammeri; B. Juurlink",Technische Universität Berlin; Technische Universität Berlin,"2018 IEEE International Symposium on Workload Characterization (IISWC)","13 Dec 2018","2018","","","25","35","GPUs have become immensely important computational units on embedded and mobile devices. However, GPGPU developers are often not able to exploit the compute power offered by GPUs on these devices mainly due to the lack of support of traditional programming models such as CUDA and OpenCL. The recent introduction of the Vulkan API provides a new programming model that could be explored for GPGPU computing on these devices, as it supports compute and promises to be portable across different architectures. In this paper we propose VComputeBench, a set of benchmarks that help developers understand the differences in performance and portability of Vulkan. We also evaluate the suitability of Vulkan as an emerging cross-platform GPGPU framework by conducting a thorough analysis of its performance compared to CUDA and OpenCL on mobile as well as on desktop platforms. Our experiments show that Vulkan provides better platform support on mobile devices and can be regarded as a good cross-platform GPGPU framework. It offers comparable performance and with some low-level optimizations it can offer average speedups of 1.53× and 1.66× compared to CUDA and OpenCL respectively on desktop platforms and 1.59× average speedup compared to OpenCL on mobile platforms. However, while Vulkan's low-level control can enhance performance, it requires a significantly higher programming effort.","","978-1-5386-6780-4","10.1109/IISWC.2018.8573477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573477","VComputeBench;Vulkan;SPIR-V;GPGPU;CUDA;OpenCL;Rodinia;Mobile","Graphics processing units;Benchmark testing;Programming;Computational modeling;Performance evaluation;Mobile handsets;Computer architecture","application program interfaces;electronic engineering computing;graphics processing units;optimisation","VComputeBench;Vulkan benchmark suite;computational units;mobile devices;GPGPU developers;traditional programming models;Vulkan API;programming model;GPGPU computing;desktop platforms;platform support;mobile platforms;embedded GPU;cross-platform GPGPU framework;Vulkan low-level control;mobile GPU;low-level optimizations","","2","","34","","13 Dec 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Using Graphics Processor Units (GPUs) for Automatic Video Structuring","P. Kehoe; A. F. Smeaton","Dublin City University, Glasnevin, Dublin 9, Ireland.; Dublin City University, Glasnevin, Dublin 9, Ireland.","Eighth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS '07)","30 Jul 2007","2007","","","18","18","The rapid pace of development of graphic processor units (GPUs) in recent years in terms of performance and programmability has attracted the attention of those seeking to leverage alternative architectures for better performance than that which commodity CPUs can provide. In this paper, the potential of the GPU in automatically structuring video is examined, specifically in shot boundary detection and representative keyframe selection techniques. We first introduce the programming model of the GPU and outline the implementation of techniques for shot boundary detection and representative keyframe selection on both the CPU and GPU, using histogram comparisons. We compare the approaches and present performance results for both the CPU and GPU. Overall these results demonstrate the significant potential for the GPU in this domain.","","0-7695-2818-X","10.1109/WIAMIS.2007.85","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4279126","","Graphics;Gunshot detection systems;Rendering (computer graphics);Bandwidth;Random access memory;Read-write memory;Histograms;Video compression;Programming profession;Acceleration","digital signal processing chips;image representation;video signal processing","graphics processor units;automatic video structuring;programmability h;alternative architectures;shot boundary detection;representative keyframe selection;programming model;histogram comparisons","","2","","4","","30 Jul 2007","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Streaming FFT Asynchronously on Graphics Processor Units","L. Zhao; Z. Shengbing; Z. Meng; Z. Yi","NA; Eng. Res. Center of Embedded Syst. Integration, Northwestern Polytech. Univ. (NWPU), Xi'an, China; Eng. Res. Center of Embedded Syst. Integration, Northwestern Polytech. Univ. (NWPU), Xi'an, China; Sch. of Comput., Northwestern Polytech. Univ. (NWPU), Xi'an, China","2010 International Forum on Information Technology and Applications","11 Nov 2010","2010","1","","308","312","The Fast Fourier Transform (FFT), which charactered in memory-access-intensive, follows a divide-and-conquer strategy, is one of the most important and heavily used kernel in scientific computing. The newest generation of Graphics Processor Units (GPUs) implement a stream architecture besides acting as powerful massively parallel coprocessor. Fouthermore, the intruduction of APIs for general-purpose computation on GPUs mades GPUs an attractive choice for high-performance numerical and scientific computing. In this work we deal with the implementation of the FFT on a novel NVIDIA GPU, using the CUDA programming model. By optimizing the organiztion of signal data, exploiting the memory hierairchy, and associating the stream to different operations, we efficiently overlap kernel execution and data transfer. Our results indicate a significant performance improvement over GPU-based and CPU-based FFT algorithms. The speedup is 18 percent higher than the original GPU-based on average.","","978-1-4244-7622-0","10.1109/IFITA.2010.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635067","FFT;GPUs;stream;asynchronous communication","Graphics processing unit;Instruction sets;Kernel;Graphics;Programming;Memory management","application program interfaces;computer graphic equipment;coprocessors;fast Fourier transforms;general purpose computers;parallel programming","graphics processor units;streaming;FFT;fast Fourier Transform;divide and conquer strategy;stream architecture;parallel coprocessor;API;general purpose computation;GPU;CUDA programming model","","1","","17","","11 Nov 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Accelerating SVMs by integrating GPUs into MapReduce clusters","S. Herrero-Lopez","Intelligent Engineering Systems Laboratory, Massachusetts Institute of Technology, Cambridge, 02139, USA","2011 IEEE International Conference on Systems, Man, and Cybernetics","21 Nov 2011","2011","","","1298","1305","The uninterrupted growth of information repositories has progressively lead data-intensive applications, such as MapReduce-based systems, to the mainstream. The MapReduce paradigm has frequently proven to be a simple yet flexible and scalable technique to distribute algorithms across thousands of nodes and petabytes of information. Under these circumstances, classic data mining algorithms have been adapted to this model, in order to run in production environments. Unfortunately, the high latency nature of this architecture has relegated the applicability of these algorithms to batch-processing scenarios. In spite of this shortcoming, the emergence of massively threaded shared-memory multiprocessors, such as Graphics Processing Units (GPU), on the commodity computing market has enabled these algorithms to be executed orders of magnitude faster, while keeping the same MapReduce based model. In this paper, we propose the integration of massively threaded shared-memory multiprocessors into MapReduce-based clusters creating a unified heterogeneous architecture that enables executing Map and Reduce operators on thousands of threads across multiple GPU devices and nodes, while maintaining the built-in reliability of the baseline system. For this purpose, we created a programming model that facilitates the collaboration of multiple CPU cores and multiple GPU devices towards the resolution of a data intensive problem. In order to prove the potential of this hybrid system, we take a popular NP-Hard supervised learning algorithm, the Support Vector Machine (SVM) and show that a 36x - 192x speedup can be achieved on large datasets without changing the model or leaving the commodity hardware paradigm.","1062-922X","978-1-4577-0653-0","10.1109/ICSMC.2011.6083839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083839","Multiprocessing;Parallel Algorithms;Pattern Classification","Message systems;Graphics processing unit;Support vector machines;Computer architecture;Parallel processing;Computational modeling;Instruction sets","computational complexity;coprocessors;data mining;learning (artificial intelligence);shared memory systems;support vector machines","SVM;GPU;MapReduce clusters;information repositories;data-intensive applications;MapReduce-based systems;MapReduce paradigm;data mining;massively threaded shared-memory multiprocessors;graphics processing units;programming model;NP-hard supervised learning;support vector machine","","11","","22","","21 Nov 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Exploiting bit-level parallelism in GPGPUs: A case study on KeeLoq exhaustive key search attack","G. Agosta; A. Barenghi; G. Pelosi","Dipartimento di Elettronica e Informazione (DEI) Politecnico di Milano, 20133 Milano (MI), Italy; Dipartimento di Elettronica e Informazione (DEI) Politecnico di Milano, 20133 Milano (MI), Italy; Dipartimento di Elettronica e Informazione (DEI) Politecnico di Milano, 20133 Milano (MI), Italy","ARCS 2012","21 Jun 2012","2012","","","1","7","Graphic Processing Units (GPU) are increasingly popular in the field of high-performance computing for their ability to provide computational power for massively parallel problems at a reduced cost. However, the programming model exposed by the GPGPU software development tools is often insufficient to achieve full performance, and a major rethinking of algorithmic choices is needed. In this paper, we showcase such an effect on a case study drawn from the cryptography application domain. The pervasive use of cryptographic primitives in modern embedded systems is a growing trend. Small, efficient cryptosystems have been effectively employed to design and implement keyless password-based access control systems in various wireless authentication applications. The security margin provided by these lightweight ciphers should be accurately examined in light of the speed and area constraints imposed by the target environment. We present a re-design of the ASIC-oriented KEELOQ implementation to perform efficient exhaustive key search attacks while fitting tightly the parallel programming model exposed by modern GPUs. Indeed, the bitslicing technique allows the intrinsic parallelism offered by word-oriented SIMD computations to be effectively exploited. Through proper adaptation of the algorithm implementation to a platform radically different from the one it was designed for, we achieved a ×40 speedup in the computation time with respect to a single-core CPU bruteforce attack, employing only consumer grade hardware. The outstanding speedup obtainable points to a significant weakening of the cipher security margin, since it proves that anyone with off-the-shelf hardware is able to circumvent the security measures in place.","","978-3-00-037922-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6222213","","Graphics processing unit;Parallel processing;Registers;Programming;Instruction sets;Computer architecture;Hardware","authorisation;cryptography;embedded systems;graphics processing units;message authentication;parallel programming","bit-level parallelism;KEELOQ exhaustive key search attack;general purpose computing on graphics processing units;high-performance computing;massively parallel problems;programming model;GPGPU software development tools;algorithmic choice thinking;cryptography;cryptographic primitives;embedded systems;cryptosystems;keyless password-based access control systems;wireless authentication applications;lightweight ciphers;ASIC-oriented KEELOQ implementation redesign;parallel programming model;bitslicing technique;word-oriented SIMD computations;single-core CPU bruteforce attack;consumer grade hardware;cipher security margin;off-the-shelf hardware","","","","17","","21 Jun 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Study of BDRM Asynchronous Parallel Computing Model Based on Multiple CUDA Streams","X. Sun; L. Da; Y. Li","Navy Underwater Battlefield Environ. Instn., Navy Submarine Acad., Qingdao, China; Navy Underwater Battlefield Environ. Instn., Navy Submarine Acad., Qingdao, China; Navy Underwater Battlefield Environ. Instn., Navy Submarine Acad., Qingdao, China","2014 Seventh International Symposium on Computational Intelligence and Design","9 Apr 2015","2014","1","","181","184","In order to improve the computing speed of ocean acoustic field using the Beam-Displacement Ray-Mode (BDRM) theory, a BDRM parallel computing model based on Compute Unified Device Architecture (CUDA) is designed by virtue of the powerful parallel computing ability of GPU and the character of BDRM theory. The emphasis is how to implement parallel computing of eigen value and eigen function in CUDA programming model. The results of simulation experiment show that the CPU elapsed time increases fast but the GPU elapsed time increases slow with the frequency of the sound source reaching higher. The speedup in blue-water is bigger than that in shallow-water under the same frequency of the sound source. The speedups are 7.84× and 33.36× respectively in shallow-water and blue-water when the frequency of the sound source is 1000Hz. The BDRM parallel computing model based on CUDA has higher computing efficiency than the BDRM serial computing model based on CPU under large scale operations. It could achieve the requirement of fast forecast of ocean acoustic field and engineering application.","","978-1-4799-7005-6","10.1109/ISCID.2014.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064168","CUDA;BDRM;eigenvalue;eigenfunction;acoustic field;parallel computing","Graphics processing units;Computational modeling;Parallel processing;Acoustics;Eigenvalues and eigenfunctions;Oceans;Instruction sets","eigenvalues and eigenfunctions;graphics processing units;parallel architectures;parallel programming","BDRM asynchronous parallel computing model;multiple CUDA stream;beam-displacement ray-mode theory;Compute Unified Device Architecture;GPU parallel computing ability;graphics processing unit;CUDA programming;eigenvalue;eigenfunction;CPU elapsed time;GPU elapsed time;sound source frequency;ocean acoustic field;engineering application;BDRM serial computing model","","2","","11","","9 Apr 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Numerical Simulation of Transit-Time Ultrasonic Flowmeters by a Direct Approach","A. Luca; R. Marchiano; J. Chassaing","Ultraflux, Éragny, France; Institut Jean Le Rond d’Alembert, 4 place Jussieu, Sorbonne Universités, UPMC Univ Paris 06, CNRS, UMR 7190, Paris, France; Institut Jean Le Rond d’Alembert, 4 place Jussieu, Sorbonne Universités, UPMC Univ Paris 06, CNRS, UMR 7190, Paris, France","IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control","23 May 2016","2016","63","6","886","897","This paper deals with the development of a computational code for the numerical simulation of wave propagation through domains with a complex geometry consisting in both solids and moving fluids. The emphasis is on the numerical simulation of ultrasonic flowmeters (UFMs) by modeling the wave propagation in solids with the equations of linear elasticity (ELE) and in fluids with the linearized Euler equations (LEEs). This approach requires high performance computing because of the high number of degrees of freedom and the long propagation distances. Therefore, the numerical method should be chosen with care. In order to minimize the numerical dissipation which may occur in this kind of configuration, the numerical method employed here is the nodal discontinuous Galerkin (DG) method. Also, this method is well suited for parallel computing. To speed up the code, almost all the computational stages have been implemented to run on graphical processing unit (GPU) by using the compute unified device architecture (CUDA) programming model from NVIDIA. This approach has been validated and then used for the two-dimensional simulation of gas UFMs. The large contrast of acoustic impedance characteristic to gas UFMs makes their simulation a real challenge.","1525-8955","","10.1109/TUFFC.2016.2545714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439838","Numerical simulation;transit-time flowmeters;linear elasticity;Euler equations;discontinuous Galerkin methods;GPU computing;Discontinuous Galerkin methods;Euler equations;graphical processing unit computing;linear elasticity;numerical simulation;transit-time flowmeters","Mathematical model;Acoustics;Solids;Numerical simulation;Propagation;Computational modeling;Transducers","elasticity;flowmeters;Galerkin method;ultrasonic measurement;wave propagation","numerical simulation;transit-time ultrasonic flowmeters;computational code;wave propagation;complex geometry;solids;moving fluids;linear elasticity;linearized Euler equations;nodal discontinuous Galerkin method;graphical processing unit;compute unified device architecture programming model;NVIDIA;acoustic impedance characteristic","Computer Simulation;Image Processing, Computer-Assisted;Rheology;Ultrasonics","21","","51","IEEE","23 Mar 2016","","","IEEE","IEEE Journals"
notebooks/data/ieee_2.csv:"GPGPU implementation of fractal image coding","O. Alvarado-Nava; H. M. Chablé Martínez; E. Rodríguez-Martínez","Departamento de Electrónica, Divisi ón de Ciencias Básicas e Ingeniería, Universidad Autónoma Metropolitana, Unidad Azcapotzalco, México D.F., México; Departamento de Electrónica, Divisi ón de Ciencias Básicas e Ingeniería, Universidad Autónoma Metropolitana, Unidad Azcapotzalco, México D.F., México; Departamento de Electrónica, Divisi ón de Ciencias Básicas e Ingeniería, Universidad Autónoma Metropolitana, Unidad Azcapotzalco, México D.F., México","3rd IEEE International Work-Conference on Bioinspired Intelligence","2 Oct 2014","2014","","","106","110","The programming model of general propose computing on graphic processing units (GPGPU) offers great efficiency for applications acceleration. This feature is granted by the ability of partitioning a sequential application into smaller subproblems with high computing requirements; those subproblems can be executed in parallel by a graphics processing unit (GPU) and partial results can be transferred to main memory where the central processing unit (CPU) collects and presents them. On the other hand, Fractal Image Coding (FIC) is a lossy compression technique with promising features, however it has been relegated due to its large coding time. The present article propose a parallel implementation of FIC on a GPGPU system which achieves an acceleration on coding time of about 129 times.","","978-1-4799-6174-0","10.1109/IWOBI.2014.6913947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913947","Fractal Image Compression;GPGPU;GPU;Parallel Computing","Graphics processing units;Image coding;Instruction sets;Fractals;Image resolution;Central Processing Unit;Acceleration","fractals;graphics processing units;image coding","GPGPU implementation;fractal image coding;programming model;applications acceleration;partitioning;sequential application;high computing requirements;central processing unit;CPU;FIC;lossy compression technique;parallel implementation;graphic processing units","","2","","15","","2 Oct 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Self-Adaptive OmpSs Tasks in Heterogeneous Environments","J. Planas; R. M. Badia; E. Ayguadé; J. Labarta","Barcelona Supercomput. Center, Univ. Politec. de Catalunya, Barcelona, Spain; Artificial Intell. Res. Inst. (IIIA), Barcelona Supercomput. Center, Barcelona, Spain; Barcelona Supercomput. Center, Univ. Politec. de Catalunya, Barcelona, Spain; Barcelona Supercomput. Center, Univ. Politec. de Catalunya, Barcelona, Spain","2013 IEEE 27th International Symposium on Parallel and Distributed Processing","29 Jul 2013","2013","","","138","149","As new heterogeneous systems and hardware accelerators appear, high performance computers can reach a higher level of computational power. Nevertheless, this does not come for free: the more heterogeneity the system presents, the more complex becomes the programming task in terms of resource management. OmpSs is a task-based programming model and framework focused on the runtime exploitation of parallelism from annotated sequential applications. This paper presents a set of extensions to this framework: we show how the application programmer can expose different specialized versions of tasks (i.e. pieces of specific code targeted and optimized for a particular architecture) and how the system can choose between these versions at runtime to obtain the best performance achievable for the given application. From the results obtained in a multi-GPU system, we prove that our proposal gives flexibility to application's source code and can potentially increase application's performance.","1530-2075","978-1-4673-6066-1","10.1109/IPDPS.2013.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6569807","multi-gpu management;heterogeneous architectures;parallel programming models;scheduling techniques","Runtime;Graphics processing units;Programming;Computer architecture;Reliability;Proposals;Kernel","graphics processing units;parallel programming;resource allocation;scheduling;source coding","self-adaptive OmpSs tasks;heterogeneous environments;heterogeneous systems;hardware accelerators;high performance computers;task-based programming model;resource management;computational power;runtime parallelism exploitation;sequential applications;application programmer;multiGPU system;application source code;application performance","","34","","25","","29 Jul 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Design and Performance Evaluation of Image Processing Algorithms on GPUs","I. K. Park; N. Singhal; M. H. Lee; S. Cho; C. Kim","Inha University, Incheon; Samsung Electronics Co., Ltd., Suwon; Inha University, Incheon; Samsung Electronics Co., Ltd., Suwon; NVIDIA Corporation, Seoul","IEEE Transactions on Parallel and Distributed Systems","29 Nov 2010","2011","22","1","91","104","We construe key factors in design and evaluation of image processing algorithms on the massive parallel graphics processing units (GPUs) using the compute unified device architecture (CUDA) programming model. A set of metrics, customized for image processing, is proposed to quantitatively evaluate algorithm characteristics. In addition, we show that a range of image processing algorithms map readily to CUDA using multiview stereo matching, linear feature extraction, JPEG2000 image encoding, and nonphotorealistic rendering (NPR) as our example applications. The algorithms are carefully selected from major domains of image processing, so they inherently contain a variety of subalgorithms with diverse characteristics when implemented on the GPU. Performance is evaluated in terms of execution time and is compared to the fastest host-only version implemented using OpenMP. It is shown that the observed speedup varies extensively depending on the characteristics of each algorithm. Intensive analysis is conducted to show the appropriateness of the proposed metrics in predicting the effectiveness of an application for parallel implementation.","1558-2183","","10.1109/TPDS.2010.115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477417","GPU;CUDA;image processing;parallel implementation;GPGPU.","Algorithm design and analysis;Image processing;Concurrent computing;Computer architecture;Graphics processing unit;Parallel programming;Computer vision;Scattering;Parallel processing","computer graphic equipment;coprocessors;feature extraction;image coding;performance evaluation","image processing algorithms;massive parallel graphics processing units;compute unified device architecture programming model;performance evaluation;multiview stereo matching;linear feature extraction;JPEG2000 image encoding;nonphotorealistic rendering;OpenMP;execution time","","90","2","38","IEEE","3 Jun 2010","","","IEEE","IEEE Journals"
notebooks/data/ieee_2.csv:"Software Pipelined Execution of Stream Programs on GPUs","A. Udupa; R. Govindarajan; M. J. Thazhuthaveetil","Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore; Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore; Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore","2009 International Symposium on Code Generation and Optimization","5 May 2009","2009","","","200","209","The StreamIt programming model has been proposed to exploit parallelism in streaming applications on general purpose multi-core architectures. This model allows programmers to specify the structure of a program as a set of filters that act upon data, and a set of communication channels between them. The StreamIt graphs describe task, data and pipeline parallelism which can be exploited on modern graphics processing units (GPUs), as they support abundant parallelism in hardware. In this paper, we describe the challenges in mapping StreamIt to GPUs and propose an efficient technique to software pipeline the execution of stream programs on GPUs. We formulate this problem - both scheduling and assignment of filters to processors - as an efficient integer linear program (ILP), which is then solved using ILP solvers. We also describe a novel buffer layout technique for GPUs which facilitates exploiting the high memory bandwidth available in GPUs. The proposed scheduling utilizes both the scalar units in GPU, to exploit data parallelism, and multiprocessors, to exploit task and pipeline parallelism. Further it takes into consideration the synchronization and bandwidth limitations of GPUs, and yields speedups between 1.87X and 36.83X over a single threaded CPU.","","978-0-7695-3576-0","10.1109/CGO.2009.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907664","CUDA;GPU Programming;Software Pipelining;Stream Programming","Pipelines;Filters;Processor scheduling;Bandwidth;Parallel programming;Application software;Computer architecture;Programming profession;Communication channels;Graphics","linear programming;parallel programming;pipeline processing","software pipelined execution;stream programs;StreamIt programming model;multi-core architectures;StreamIt graphs;graphics processing units;integer linear program;high memory bandwidth","","60","2","23","","5 May 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Exploring Memory Persistency Models for GPUs","Z. Lin; M. Alshboul; Y. Solihin; H. Zhou",North Carolina State University; North Carolina State University; University of Central Florida; North Carolina State University,"2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)","7 Nov 2019","2019","","","311","323","Given its high integration density, high speed, byte addressability, and low standby power, non-volatile or persistent memory is expected to supplement/replace DRAM as main memory. Through persistency programming model (which defines durability ordering of stores) and durable transaction constructs, the programmer can provide recoverable data structure (RDS) which allows programs to recover to a consistent state after a failure. While persistency models have been well studied for CPUs, they have been neglected for graphics processing units (GPUs). Considering the importance of GPUs as a dominant accelerator for high performance computing, we investigate persistency models for GPUs. GPU applications exhibit substantial differences with CPUs applications, hence in this paper we adapt, re-architect, and optimize CPU persistency models for GPUs. We design a pragma-based compiler scheme for expressing persistency model for GPUs. We identify that the thread hierarchy in GPUs offers intuitive scopes to form epochs and durable transactions. We find that undo logging produces significant performance overheads. We propose to use idempotency analysis to reduce both logging frequency and the size of logs. Through both real-system and simulation evaluations, we show low overheads of our proposed architecture support.","2641-7936","978-1-7281-3613-4","10.1109/PACT.2019.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891613","GPU;Memory Persistency","Graphics processing units;Instruction sets;Adaptation models;Nonvolatile memory;Kernel;Bandwidth;Random access memory","data structures;DRAM chips;graphics processing units;microprocessor chips;parallel processing;program compilers","memory persistency models;GPUs;high integration density;low standby power;persistent memory;persistency programming model;persistency model;high performance computing;CPU persistency models;durable transactions;byte addressability;nonvolatile memory;recoverable data structure;graphics processing units;DRAM;pragma-based compiler scheme","","4","","28","","7 Nov 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"HadoopCL2: Motivating the Design of a Distributed, Heterogeneous Programming System With Machine-Learning Applications","M. Grossman; M. Breternitz; V. Sarkar","Department of Computer Science, 6100 Main St., Rice University, Houston, TX; AMD Research, 7171 Southwest Parkway, Austin, TX; Department of Computer Science, 6100 Main St., Rice University, Houston, TX","IEEE Transactions on Parallel and Distributed Systems","11 Feb 2016","2016","27","3","762","775","Machine learning (ML) algorithms have garnered increased interest as they demonstrate improved ability to extract meaningful trends from large, diverse, and noisy data sets. While research is advancing the state-of-the-art in ML algorithms, it is difficult to drastically improve the real-world performance of these algorithms. Porting new and existing algorithms from single-node systems to multi-node clusters, or from architecturally homogeneous systems to heterogeneous systems, is a promising optimization technique. However, performing optimized ports is challenging for domain experts who may lack experience in distributed and heterogeneous software development. This work explores how challenges in ML application development on heterogeneous, distributed systems shaped the development of the HadoopCL2 (HCL2) programming system. ML applications guide this work because they exhibit features that make application development difficult: large & diverse datasets, complex algorithms, and the need for domain-specific knowledge. The goal of this work is a general, MapReduce programming system that outperforms existing programming systems. This work evaluates the performance and portability of HCL2 against five ML applications from the Mahout ML framework on two hardware platforms. HCL2 demonstrates speedups of greater than 20x relative to Mahout for three computationally heavy algorithms and maintains minor performance improvements for two I/O bound algorithms.","1558-2183","","10.1109/TPDS.2015.2414943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064791","MapReduce;heterogeneous;distributed;programming model;GPU;auto-scheduling","Programming;Performance evaluation;Vectors;Java;Kernel;Object oriented modeling;Computational modeling","data handling;distributed programming;learning (artificial intelligence);optimisation;parallel processing;software engineering","distributed programming system;heterogeneous programming system;machine-learning applications;optimization technique;distributed software development;heterogeneous software development;ML application development;HadoopCL2 programming system;HCL2 programming system;domain-specific knowledge;MapReduce programming system;Mahout ML framework;I/O bound algorithms","","6","","16","IEEE","20 Mar 2015","","","IEEE","IEEE Journals"
notebooks/data/ieee_2.csv:"Running High Performance Linpack on CPUGPU clusters","D. Tomić; D. Ogrizović","Hewlett-Packard Croatia, Zagreb, Croatia; Center for advanced computing and modeling / Faculty of Maritime Studies, Rijeka, Croatia","2012 Proceedings of the 35th International Convention MIPRO","16 Jul 2012","2012","","","400","404","A trend is developing in High-Performance Computing with cluster nodes built of general purpose CPUs and GPU accelerators. The common name of these systems is CPUGPU clusters. High Performance Linpack (HPL) benchmarking of High Performance Clusters consisting of nodes with both CPUs and GPUs is still a challenging task and deserves a high attention. In order to make HPL on such clusters more efficient, a multi-layered programming model consisting of at least Message Passing Interface (MPI), Multiprocessing (MP) and Streams Programming (Streams) needs to be utilized. Besides multi-layered programming model, it is crucial to deploy a right load-balancing scheme if someone wants to run HPL efficiently on CPUGPU systems. That means, besides the highest possible utilization rate, both fast and slow processors needs to receive appropriate portion of load, in order to avoid faster resources waiting on slower to finish their jobs. Moreover, in HPC clusters on Cloud, one has to take into account not only computing nodes of different processing power, but also a communication links of different speed between nodes as well. For this reasons we propose a load balancing method based on a semidefinite optimization. We hope that this method, coupled with a multi-layered programming, can perform a HPL benchmark on CPUGPU clusters and HPC Cloud systems more efficiently than methods used today.","","978-953-233-068-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240677","","Benchmark testing;Graphics processing unit;Programming;Symmetric matrices;Load management;Optimization;Clustering algorithms","application program interfaces;benchmark testing;graphics processing units;message passing;multiprocessing systems;parallel programming;performance evaluation;resource allocation","high performance Linpack;CPUGPU clusters;high-performance computing;general purpose CPU;GPU accelerators;HPL benchmarking;multilayered programming model;least message passing interface;multiprocessing;stream programming;load-balancing scheme;processing power;load balancing method;semidefinite optimization","","2","","10","","16 Jul 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"OpenMP 4.5 compiler optimization for GPU offloading","E. Tiotto; B. Mahjour; W. Tsang; X. Xue; T. Islam; W. Chen",NA; NA; NA; NA; NA; NA,"IBM Journal of Research and Development","15 May 2020","2020","64","3/4","14:1","14:11","Ability to efficiently offload computational workloads to graphic processing units (GPUs) is critical for the success of hybrid CPU–GPU architectures, such as the Summit and Sierra supercomputing systems. OpenMP 4.5 is a high-level programming model that enables the development of architecture- and accelerator-independent applications. This article describes aspects of the OpenMP implementation in the IBM XL C/C++ and XL Fortran OpenMP compilers that aid programmers to achieve performance objectives. This includes an interprocedural static analysis the XL optimizer uses to specialize code generation of the OpenMP <italic>distribute parallel do</italic> loop within the dynamic context of a target region, and other compiler optimizations designed to reduce the overhead of data transferred to an offloaded target region. We introduce the heuristic used at runtime to select optimal grid sizes for offloaded target team constructs. These tuned heuristics lead to an average improvement of 2× in the runtime of several target regions in the SPEC ACCEL V1.2 benchmark suite. In addition to performance enhancement, this article also presents an advanced diagnostic feature implemented in the XL Fortran compiler to aid in debugging OpenMP applications offloaded to accelerators.","0018-8646","","10.1147/JRD.2019.2962428","CORAL; U.S. Department of Energy(grant numbers:B604142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943339","","Graphics processing units;Runtime;Programming;Context;Computer architecture;Optimization","","","","","","11","IBM","25 Dec 2019","","","IBM","IBM Journals"
notebooks/data/ieee_2.csv:"A Runtime Library for Platform-Independent Task Parallelism","P. E. Hadjidoukas; E. Lappas; V. V. Dimakopoulos","Dept. of Comput. Sci., Univ. of Ioannina, Ioannina, Greece; Dept. of Comput. Sci., Univ. of Ioannina, Ioannina, Greece; Dept. of Comput. Sci., Univ. of Ioannina, Ioannina, Greece","2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing","15 Mar 2012","2012","","","229","236","With the increasing diversity of computing systems and the rapid performance improvement of commodity hardware, heterogeneous clusters become the dominant platform for low-cost, high-performance computing. Grid-enabled and heterogeneous implementations of MPI establish it as the de facto programming model for these environments. On the other hand, task parallelism provides a natural way for exploiting their hierarchical architecture. This hierarchy has been further extended with the advent of general-purpose GPU devices. In this paper we present the implementation of an MPI-based task library for heterogeneous and GPU clusters. The library offers an intuitive programming interface for multilevel task parallelism with transparent data management and load balancing. We discuss design and implementation issues regarding heterogeneity support and report performance results on heterogeneous cluster computing environments.","2377-5750","978-1-4673-0226-5","10.1109/PDP.2012.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169554","task parallelism;heterogeneous computing;runtime support;message passing","Graphics processing unit;Kernel;Programming;Parallel processing;Libraries;Central Processing Unit;Computer architecture","application program interfaces;data handling;graphics processing units;message passing;parallel processing;resource allocation","runtime library;platform-independent task parallelism;computing system;commodity hardware;heterogeneous cluster computing environment;high-performance computing;Grid-enabled MPI implementation;heterogeneous MPI implementation;message passing interface;de facto programming model;general-purpose GPU device;graphics processing unit;intuitive programming interface;transparent data management;load balancing;MPI-based task library;multilevel task parallelism","","6","","22","","15 Mar 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Parallel Computing Experiences with CUDA","M. Garland; S. Le Grand; J. Nickolls; J. Anderson; J. Hardwick; S. Morton; E. Phillips; Y. Zhang; V. Volkov","NVIDIA; NVIDIA; NVIDIA; Iowa State University and Ames Laboratory; TechniScan Medical Systems; Hess; University of California, Davis; University of California, Davis; University of California, Berkeley","IEEE Micro","19 Sep 2008","2008","28","4","13","27","The CUDA programming model provides a straightforward means of describing inherently parallel computations, and NVIDIA's Tesla GPU architecture delivers high computational throughput on massively parallel problems. This article surveys experiences gained in applying CUDA to a diverse set of problems and the parallel speedups over sequential codes running on traditional CPU architectures attained by executing key computations on the GPU.","1937-4143","","10.1109/MM.2008.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4626815","","Parallel processing;Programming profession;Parallel programming;Concurrent computing;Computer architecture;Computer graphics;Kernel;Throughput;Central Processing Unit","coprocessors;parallel processing","parallel computing;CUDA programming model;NVIDIA;Tesla GPU architecture;sequential codes","","291","10","22","IEEE","19 Sep 2008","","","IEEE","IEEE Magazines"
notebooks/data/ieee_2.csv:"An Initial Assessment of NVSHMEM for High Performance Computing","C. Hsu; N. Imam; A. Langer; S. Potluri; C. J. Newburn","Oak Ridge National Laboratory Oak Ridge TN,Computing & Computational Sciences,USA; Oak Ridge National Laboratory Oak Ridge TN,Computing & Computational Sciences,USA; NVIDIA Corporation,Compute Software,Santa Clara, CA,USA; NVIDIA Corporation,Compute Software,Santa Clara, CA,USA; NVIDIA Corporation,Compute Software,Santa Clara, CA,USA","2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","28 Jul 2020","2020","","","1","10","High Performance Computing has been a driving force behind important tasks such as scientific discovery and deep learning. It tends to achieve performance through greater concurrency and heterogeneity, where the underlying complexity of richer topologies is managed through software abstraction.In this paper, we present our initial assessment of NVSHMEM, an experimental programming library that supports the Partitioned Global Address Space programming model for NVIDIA GPU clusters. NVSHMEM offers several concrete advantages. One is that it reduces overheads and software complexity by allowing communication and computation to be interleaved vs. separating them into different phases. Another is that it implements the OpenSHMEM specification to provide efficient finegrained one-sided communication, streamlining away overheads due to tag matching, wildcards, and unexpected messages which have compounding effect with increasing concurrency. It also offers ease of use by abstracting away low-level configuration operations that are required to enable low-overhead communication and direct loads and stores across processes.We evaluated NVSHMEM in terms of usability, functionality, and scalability by running two math kernels, matrix multiplication and Jacobi solver, on the 27,648-GPU Summit supercomputer. Our exercise of NVSHMEM at scale contributed to making NVSHMEM more robust and preparing it for production release.","","978-1-7281-7445-7","10.1109/IPDPSW50202.2020.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150438","high Performance Computing (HPC);CUDA;openSHMEM;scalability","Graphics processing units;Programming;Kernel;Message systems;Jacobian matrices;Electronics packaging","application program interfaces;graphics processing units;matrix multiplication;message passing;parallel programming;software libraries;software performance evaluation","NVIDIA GPU clusters;Partitioned Global Address Space programming model;experimental programming library;software abstraction;deep learning;scientific discovery;driving force;high Performance Computing;low-overhead communication;one-sided communication;software complexity;NVSHMEM","","1","","8","","28 Jul 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Accelerating a C++ CFD Code with OpenACC","J. Kraus; M. Schlottke; A. Adinetz; D. Pleiter","NVIDIA GmbH, Wurselen, Germany; RWTH Aachen Univ., Aachen, Germany; Forschungszentrum Jυlich, Julich, Germany; Forschungszentrum Jυlich, Julich, Germany","2014 First Workshop on Accelerator Programming using Directives","9 Apr 2015","2014","","","47","54","Todays HPC systems are increasingly utilizing accelerators to lower time to solution for their users and reduce power consumption. To utilize the higher performance and energy efficiency of these accelerators, application developers need to rewrite at least parts of their codes. Taking the C++ flow solver ZFS as an example, we show that the directive-based programming model allows one to achieve good performance with reasonable effort, even for mature codes with many lines of code. Using OpenACC directives permitted us to incrementally accelerate ZFS, focusing on the parts of the program that are relevant for the problem at hand. The two new OpenACC 2.0 features, unstructured data regions and atomics, are required for this. OpenACC's interoperability with existing GPU libraries via the host_data use_device construct allowed to use CUDAaware MPI to achieve multi-GPU scalability comparable to the CPU version of ZFS. Like many other codes, the data structures of ZFS have been designed with traditional CPUs and their relatively large private caches in mind. This leads to suboptimal memory access patterns on accelerators, such as GPUs. We show how the texture cache on NVIDIA GPUs can be used to minimize the performance impact of these suboptimal patterns without writing platform specific code. For the kernel most affected by the memory access pattern, we compare the initial array of structures memory layout with a structure of arrays layout.","","978-1-4673-6753-0","10.1109/WACCPD.2014.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081677","","Graphics processing units;Acceleration;Computer architecture;Microprocessors;Programming;Kernel","application program interfaces;C++ language;computational fluid dynamics;graphics processing units;message passing;open systems;parallel architectures","C++ flow solver;CFD code;computational fluid dynamics;OpenACC interoperability;directive-based programming model;CUDA aware MPI;NVIDIA GPU","","16","","21","","9 Apr 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_2.csv:"Accelerating bootstrapping in FHEW using GPUs","M. S. Lee; Y. Lee; J. H. Cheon; Y. Paek","Dept. of Mathematical Sciences, Seoul National University, Korea; Dept. of Electrical and Computer Engineering and Inter-University Semiconductor Research Center (ISRC), Seoul National University, Korea; Dept. of Mathematical Sciences, Seoul National University, Korea; Dept. of Electrical and Computer Engineering and Inter-University Semiconductor Research Center (ISRC), Seoul National University, Korea","2015 IEEE 26th International Conference on Application-specific Systems, Architectures and Processors (ASAP)","10 Sep 2015","2015","","","128","135","Recently, the usage of GPU is not limited to the jobs associated with graphics and a wide variety of applications take advantage of the flexibility of GPUs to accelerate the computing performance. Among them, one of the most emerging applications is the fully homomorphic encryption (FHE) scheme, which enables arbitrary computations on encrypted data. Despite much research effort, it cannot be considered as practical due to the enormous amount of computations, especially in the bootstrapping procedure. In this paper, we accelerate the performance of the recently suggested fast bootstrapping method in FHEW scheme using GPUs, as a case study of a FHE scheme. In order to optimize, we explored the reference code and carried out profiling to find out candidates for performance acceleration. Based on the profiling results, combined with more flexible tradeoff method, we optimized the bootstrapping algorithm in FHEW using GPU and CUDA's programming model. The empirical result shows that the bootstrapping of FHEW ciphertext can be done in less than 0.11 second after optimization.","2160-052X","978-1-4799-1925-3","10.1109/ASAP.2015.7245720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7245720","","Graphics processing units;Encryption;Acceleration;Libraries;Noise;Polynomials","cryptography;graphics processing units;parallel programming","bootstrapping algorithm;FHEW scheme;fully homomorphic encryption scheme;GPU;graphics processing unit;performance acceleration;fast bootstrapping method;CUDA programming model;Compute Unified Device Architecture;FHEW ciphertext bootstrapping","","7","","26","","10 Sep 2015","","","IEEE","IEEE Conferences"
notebooks/data/springer.csv:"A comparative study of GPU programming models and architectures using neural networks","The Journal of Supercomputing","","61","3","10.1007/s11227-011-0631-3","Vivek K. PallipuramMohammad BhuiyanMelissa C. Smith","2012","http://link.springer.com/article/10.1007/s11227-011-0631-3","Article"
notebooks/data/springer.csv:"Exploring the interoperability of remote GPGPU virtualization using rCUDA and directive-based programming models","The Journal of Supercomputing","","74","11","10.1007/s11227-016-1791-y","Adrián CastellóAntonio J. PeñaRafael MayoJudit PlanasEnrique S. Quintana-OrtíPavan Balaji","2018","http://link.springer.com/article/10.1007/s11227-016-1791-y","Article"
notebooks/data/springer.csv:"Porting and scaling OpenACC applications on massively-parallel, GPU-accelerated supercomputers","The European Physical Journal Special Topics","","210","1","10.1140/epjst/e2012-01634-y","A. HartR. AnsaloniA. Gray","2012","http://link.springer.com/article/10.1140/epjst/e2012-01634-y","Article"
notebooks/data/springer.csv:"Providing Source Code Level Portability Between CPU and GPU with MapCG","Journal of Computer Science and Technology","","27","1","10.1007/s11390-012-1205-4","Chun-Tao HongDe-Hao ChenYu-Bei ChenWen-Guang ChenWei-Min ZhengHai-Bo Lin","2012","http://link.springer.com/article/10.1007/s11390-012-1205-4","Article"
notebooks/data/springer.csv:"Efficiency and productivity for decision making on low-power heterogeneous CPU+GPU SoCs","The Journal of Supercomputing","","77","1","10.1007/s11227-020-03257-3","Denisa-Andreea ConstantinescuAngeles NavarroFrancisco CorberaJuan-Antonio Fernández-MadrigalRafael Asenjo","2021","http://link.springer.com/article/10.1007/s11227-020-03257-3","Article"
notebooks/data/springer.csv:"Accelerating incompressible flow computations with a Pthreads-CUDA implementation on small-footprint multi-GPU platforms","The Journal of Supercomputing","","59","2","10.1007/s11227-010-0468-1","Julien C. ThibaultInanc Senocak","2012","http://link.springer.com/article/10.1007/s11227-010-0468-1","Article"
notebooks/data/springer.csv:              GPU Execution of 3D Stencil Computations on GPU-accelerated Supercomputers","International Journal of Parallel Programming","","45","3","10.1007/s10766-016-0454-1","Mohammed SourouriScott B. BadenXing Cai","2017","http://link.springer.com/article/10.1007/s10766-016-0454-1","Article"
notebooks/data/springer.csv:"CUDA-Zero: a framework for porting shared memory GPU applications to multi-GPUs","Science China Information Sciences","","55","3","10.1007/s11432-011-4497-z","DeHao ChenWenGuang ChenWeiMin Zheng","2012","http://link.springer.com/article/10.1007/s11432-011-4497-z","Article"
notebooks/data/springer.csv:"Optimizing Linpack Benchmark on GPU-Accelerated Petascale Supercomputer","Journal of Computer Science and Technology","","26","5","10.1007/s11390-011-0184-1","Feng WangCan-Qun YangYun-Fei DuJuan ChenHui-Zhan YiWei-Xia Xu","2011","http://link.springer.com/article/10.1007/s11390-011-0184-1","Article"
notebooks/data/springer.csv:"Boosting CUDA Applications with CPU–GPU Hybrid Computing","International Journal of Parallel Programming","","42","2","10.1007/s10766-013-0252-y","Changmin LeeWon Woo RoJean-Luc Gaudiot","2014","http://link.springer.com/article/10.1007/s10766-013-0252-y","Article"
notebooks/data/springer.csv:"Resource-efficient utilization of CPU/GPU-based heterogeneous supercomputers for Bayesian phylogenetic inference","The Journal of Supercomputing","","66","1","10.1007/s11227-013-0911-1","Jun ChaiHuayou SuMei WenXing CaiNan WuChunyuan Zhang","2013","http://link.springer.com/article/10.1007/s11227-013-0911-1","Article"
notebooks/data/springer.csv:"An efficient parallel collaborative filtering algorithm on multi-GPU platform","The Journal of Supercomputing","","72","6","10.1007/s11227-014-1333-4","Zhongya WangYing LiuSteve Chiu","2016","http://link.springer.com/article/10.1007/s11227-014-1333-4","Article"
notebooks/data/springer.csv:"Dual buffer rotation four-stage pipeline for CPU–GPU cooperative computing","Soft Computing","","23","3","10.1007/s00500-017-2795-0","Tao LiQiankun DongYifeng WangXiaoli GongYulu Yang","2019","http://link.springer.com/article/10.1007/s00500-017-2795-0","Article"
notebooks/data/springer.csv:"GPU-accelerated registration of hyperspectral images using KAZE features","The Journal of Supercomputing","","76","12","10.1007/s11227-020-03214-0","Álvaro OrdóñezFrancisco ArgüelloDora B. HerasBegüm Demir","2020","http://link.springer.com/article/10.1007/s11227-020-03214-0","Article"
notebooks/data/springer.csv:"On GPU’s viability as a middleware accelerator","Cluster Computing","","12","2","10.1007/s10586-009-0076-0","Samer Al-KiswanyAbdullah GharaibehElizeu Santos-NetoMatei Ripeanu","2009","http://link.springer.com/article/10.1007/s10586-009-0076-0","Article"
notebooks/data/springer.csv:"GPU acceleration of subgraph isomorphism search in large scale graph","Journal of Central South University","","22","6","10.1007/s11771-015-2748-7","Bo Yang 杨博Kai Lu 卢凯Ying-hui Gao 高颖慧Xiao-ping Wang 王小平Kai Xu 徐凯","2015","http://link.springer.com/article/10.1007/s11771-015-2748-7","Article"
notebooks/data/springer.csv:"Compiler support for general-purpose computation on GPUs","The Journal of Supercomputing","","50","1","10.1007/s11227-008-0252-7","Yu-Te LinPeng-Sheng Chen","2009","http://link.springer.com/article/10.1007/s11227-008-0252-7","Article"
notebooks/data/springer.csv:"CUDA compatible GPU cards as efficient hardware accelerators for Smith-Waterman sequence alignment","BMC Bioinformatics","","9","2","10.1186/1471-2105-9-S2-S10","Svetlin A ManavskiGiorgio Valle","2008","http://link.springer.com/article/10.1186/1471-2105-9-S2-S10","Article"
notebooks/data/springer.csv:"Implementation and comparison of binary thinning algorithms on GPU","Computing","","101","8","10.1007/s00607-018-0653-2","Lynda Ben BoudaoudBasel SolaimanAbdelkamel Tari","2019","http://link.springer.com/article/10.1007/s00607-018-0653-2","Article"
notebooks/data/springer.csv:"Parallel programing templates for remote sensing image processing on GPU architectures: design and implementation","Computing","","98","1 - 2","10.1007/s00607-014-0392-y","Yan MaLajiao ChenPeng LiuKe Lu","2016","http://link.springer.com/article/10.1007/s00607-014-0392-y","Article"
notebooks/data/springer.csv:"Multicore and GPU algorithms for Nussinov RNA folding","BMC Bioinformatics","","15","8","10.1186/1471-2105-15-S8-S1","Junjie LiSanjay RankaSartaj Sahni","2014","http://link.springer.com/article/10.1186/1471-2105-15-S8-S1","Article"
notebooks/data/springer.csv:"Efficient GPU-based parallelization of solvation calculation for the blind docking problem","The Journal of Supercomputing","","76","3","10.1007/s11227-019-02834-5","Hocine SaadiNadia Nouali TaboudjematAbdellatif RahmounBaldomero imbernónHoracio Pérez-SánchezJosé M. Cecilia","2020","http://link.springer.com/article/10.1007/s11227-019-02834-5","Article"
notebooks/data/springer.csv:"Correlation acceleration in GNSS software receivers using a CUDA-enabled GPU","GPS Solutions","","21","1","10.1007/s10291-016-0516-2","Liangchun XuNesreen I. ZiedanXiaoji NiuWenfei Guo","2017","http://link.springer.com/article/10.1007/s10291-016-0516-2","Article"
notebooks/data/springer.csv:"Swarm model checking on the GPU","International Journal on Software Tools for Technology Transfer","","22","5","10.1007/s10009-020-00576-x","Richard DeFranciscoShenghsun ChoMichael FerdmanScott A. Smolka","2020","http://link.springer.com/article/10.1007/s10009-020-00576-x","Article"
notebooks/data/springer.csv:"A compound OpenMP/MPI program development toolkit for hybrid CPU/GPU clusters","The Journal of Supercomputing","","66","1","10.1007/s11227-013-0912-0","Hung-Fu LiTyng-Yeu LiangJun-Yao Chiu","2013","http://link.springer.com/article/10.1007/s11227-013-0912-0","Article"
notebooks/data/springer.csv:"Accelerating MapReduce framework on multi-GPU systems","Cluster Computing","","17","2","10.1007/s10586-013-0276-5","Hai JiangYi ChenZhi QiaoKuan-Ching LiWonWoo RoJean-Luc Gaudiot","2014","http://link.springer.com/article/10.1007/s10586-013-0276-5","Article"
notebooks/data/springer.csv:"On construction of a virtual GPU cluster with InfiniBand and 10 Gb Ethernet virtualization","The Journal of Supercomputing","","74","12","10.1007/s11227-018-2484-5","Chao-Tung YangShuo-Tsung ChenYu-Sheng LoEndah KristianiYu-Wei Chan","2018","http://link.springer.com/article/10.1007/s11227-018-2484-5","Article"
notebooks/data/springer.csv:"An study of the effect of process malleability in the energy efficiency on GPU-based clusters","The Journal of Supercomputing","","76","1","10.1007/s11227-019-03034-x","Sergio IserteKrzysztof Rojek","2020","http://link.springer.com/article/10.1007/s11227-019-03034-x","Article"
notebooks/data/springer.csv:"Performance-aware composition framework for GPU-based systems","The Journal of Supercomputing","","71","12","10.1007/s11227-014-1105-1","Usman DastgeerChristoph Kessler","2015","http://link.springer.com/article/10.1007/s11227-014-1105-1","Article"
notebooks/data/springer.csv:"Novel parallel hybrid genetic algorithms on the GPU for the generalized assignment problem","The Journal of Supercomputing","","78","1","10.1007/s11227-021-03882-6","Huang Zhi-BinFu Guang-TaoDong Dan-YangXiao ChenDing Zhe-LunDai Zhi-Tao","2022","http://link.springer.com/article/10.1007/s11227-021-03882-6","Article"
notebooks/data/springer.csv:"Box-counting algorithm on GPU and multi-core CPU: an OpenCL cross-platform study","The Journal of Supercomputing","","65","3","10.1007/s11227-013-0885-z","Jesús JiménezJuan Ruiz de Miras","2013","http://link.springer.com/article/10.1007/s11227-013-0885-z","Article"
notebooks/data/springer.csv:"Numerical investigation of supersonic transverse jet interaction on CPU/GPU system","Journal of the Brazilian Society of Mechanical Sciences and Engineering","","42","2","10.1007/s40430-019-2160-6","Jianqi LaiZhengyu TianHang YuHua Li","2020","http://link.springer.com/article/10.1007/s40430-019-2160-6","Article"
notebooks/data/springer.csv:"Ignite-GPU: a GPU-enabled in-memory computing architecture on clusters","The Journal of Supercomputing","","77","3","10.1007/s11227-020-03390-z","Amir Hossein SojoodiMajid Salimi BeniFarshad Khunjush","2021","http://link.springer.com/article/10.1007/s11227-020-03390-z","Article"
notebooks/data/springer.csv:"MVAPICH2-GPU: optimized GPU to GPU communication for InfiniBand clusters","Computer Science - Research and Development","","26","3 - 4","10.1007/s00450-011-0171-3","Hao WangSreeram PotluriMiao LuoAshish Kumar SinghSayantan SurDhabaleswar K. Panda","2011","http://link.springer.com/article/10.1007/s00450-011-0171-3","Article"
notebooks/data/springer.csv:"A GPU-based algorithm for fast node label learning in large and unbalanced biomolecular networks","BMC Bioinformatics","","19","10","10.1186/s12859-018-2301-4","Marco FrascaGiuliano GrossiJessica GliozzoMarco MesitiMarco NotaroPaolo PerlascaAlessandro PetriniGiorgio Valentini","2018","http://link.springer.com/article/10.1186/s12859-018-2301-4","Article"
notebooks/data/springer.csv:"The GPU on the simulation of cellular computing models","Soft Computing","","16","2","10.1007/s00500-011-0716-1","José M. CeciliaJosé M. GarcíaGinés D. GuerreroMiguel A. Martínez-del-AmorMario J. Pérez-JiménezManuel Ujaldón","2012","http://link.springer.com/article/10.1007/s00500-011-0716-1","Article"
notebooks/data/springer.csv:"SkelCL: a high-level extension of OpenCL for multi-GPU systems","The Journal of Supercomputing","","69","1","10.1007/s11227-014-1213-y","Michel SteuwerSergei Gorlatch","2014","http://link.springer.com/article/10.1007/s11227-014-1213-y","Article"
notebooks/data/springer.csv:"GPU-Friendly Parallel Genome Matching with Tiled Access and Reduced State Transition Table","International Journal of Parallel Programming","","41","4","10.1007/s10766-012-0234-5","Yunho OhDoohwan OhWon W. Ro","2013","http://link.springer.com/article/10.1007/s10766-012-0234-5","Article"
notebooks/data/springer.csv:"GPU Accelerated Digital Volume Correlation","Experimental Mechanics","","56","2","10.1007/s11340-015-0091-4","T. WangZ. JiangQ. KemaoF. LinS. H. Soon","2016","http://link.springer.com/article/10.1007/s11340-015-0091-4","Article"
notebooks/data/springer.csv:"PartialRC: A Partial Recomputing Method for Efficient Fault Recovery on GPGPUs","Journal of Computer Science and Technology","","27","2","10.1007/s11390-012-1220-5","Xin-Hai XuXue-Jun YangJing-Ling XueYu-Fei LinYi-Song Lin","2012","http://link.springer.com/article/10.1007/s11390-012-1220-5","Article"
notebooks/data/springer.csv:"Comparison of analytical and ML-based models for predicting CPU–GPU data transfer time","Computing","","102","9","10.1007/s00607-019-00780-x","Ali RiahiAbdorreza SavadiMahmoud Naghibzadeh","2020","http://link.springer.com/article/10.1007/s00607-019-00780-x","Article"
notebooks/data/springer.csv:"Strategies for maximizing utilization on multi-CPU and multi-GPU heterogeneous architectures","The Journal of Supercomputing","","70","2","10.1007/s11227-014-1200-3","Angeles NavarroAntonio VilchesFrancisco CorberaRafael Asenjo","2014","http://link.springer.com/article/10.1007/s11227-014-1200-3","Article"
notebooks/data/springer.csv:"An Efficient GPU-Based Multiple Pattern Matching Algorithm for Packet Filtering","Journal of Signal Processing Systems","","86","2 - 3","10.1007/s11265-016-1139-0","Che-Lun HungChun-Yuan LinPo-Chang Wu","2017","http://link.springer.com/article/10.1007/s11265-016-1139-0","Article"
notebooks/data/springer.csv:"Performance analysis of a novel GPU computation-to-core mapping scheme for robust facet image modeling","Journal of Real-Time Image Processing","","10","3","10.1007/s11554-012-0272-7","Seung In ParkYong CaoLayne T. WatsonFrancis Quek","2015","http://link.springer.com/article/10.1007/s11554-012-0272-7","Article"
notebooks/data/springer.csv:"Transparent partial page migration between CPU and GPU","Frontiers of Computer Science","","14","3","10.1007/s11704-018-7386-4","Shiqing ZhangZheng QinYaohua YangLi ShenZhiying Wang","2019","http://link.springer.com/article/10.1007/s11704-018-7386-4","Article"
notebooks/data/springer.csv:"Cardiac simulation on multi-GPU platform","The Journal of Supercomputing","","59","3","10.1007/s11227-010-0540-x","Venkata Krishna NimmagaddaAli AkogluSalim HaririTalal Moukabary","2012","http://link.springer.com/article/10.1007/s11227-010-0540-x","Article"
notebooks/data/springer.csv:"GPU-based parallel computation for structural dynamic response analysis with CUDA","Journal of Mechanical Science and Technology","","28","10","10.1007/s12206-014-0928-2","Dong-Keun KangChang-Wan KimHyun-Ik Yang","2014","http://link.springer.com/article/10.1007/s12206-014-0928-2","Article"
notebooks/data/springer.csv:"Hierarchical parallel processing of large scale data clustering on a PC cluster with GPU co-processing","The Journal of Supercomputing","","36","3","10.1007/s11227-006-8294-1","Hiroyuki TakizawaHiroaki Kobayashi","2006","http://link.springer.com/article/10.1007/s11227-006-8294-1","Article"
notebooks/data/springer.csv:"Implementation of GPU virtualization using PCI pass-through mechanism","The Journal of Supercomputing","","68","1","10.1007/s11227-013-1034-4","Chao-Tung YangJung-Chun LiuHsien-Yi WangChing-Hsien Hsu","2014","http://link.springer.com/article/10.1007/s11227-013-1034-4","Article"
notebooks/data/springer.csv:"cuGimli: optimized implementation of the Gimli authenticated encryption and hash function on GPU for IoT applications","Cluster Computing","","25","1","10.1007/s10586-021-03415-z","KyungHyun HanWai-Kong LeeSeong Oun Hwang","2022","http://link.springer.com/article/10.1007/s10586-021-03415-z","Article"
notebooks/data/springer.csv:"A high-performance and energy-efficient exhaustive key search approach via GPU on DES-like cryptosystems","The Journal of Supercomputing","","74","1","10.1007/s11227-017-2120-9","Armin AhmadzadehOmid HajihassaniSaeid Gorgin","2018","http://link.springer.com/article/10.1007/s11227-017-2120-9","Article"
notebooks/data/springer.csv:"Fast implementation of block ciphers and PRNGs in Maxwell GPU architecture","Cluster Computing","","19","1","10.1007/s10586-016-0536-2","Wai-Kong LeeHon-Sang CheongRaphael C.-W. PhanBok-Min Goi","2016","http://link.springer.com/article/10.1007/s10586-016-0536-2","Article"
notebooks/data/springer.csv:"MPtostream: an OpenMP compiler for CPU-GPU heterogeneous parallel systems","Science China Information Sciences","","55","9","10.1007/s11432-011-4342-4","XueJun YangTao TangGuiBin WangJia JiaXinHai Xu","2012","http://link.springer.com/article/10.1007/s11432-011-4342-4","Article"
notebooks/data/springer.csv:"Toward a software transactional memory for heterogeneous CPU–GPU processors","The Journal of Supercomputing","","75","8","10.1007/s11227-018-2347-0","Alejandro VillegasAngeles NavarroRafael AsenjoOscar Plata","2019","http://link.springer.com/article/10.1007/s11227-018-2347-0","Article"
notebooks/data/springer.csv:"Performance of CPU/GPU compiler directives on ISO/TTI kernels","Computing","","96","12","10.1007/s00607-013-0367-4","Sayan GhoshTerrence LiaoHenri CalandraBarbara M. Chapman","2014","http://link.springer.com/article/10.1007/s00607-013-0367-4","Article"
notebooks/data/springer.csv:"Accelerating Data Analytics on Integrated GPU Platforms via Runtime Specialization","International Journal of Parallel Programming","","46","2","10.1007/s10766-016-0482-x","Naila FarooquiIndrajit RoyYuan ChenVanish TalwarRajkishore BarikBrian LewisTatiana ShpeismanKarsten Schwan","2018","http://link.springer.com/article/10.1007/s10766-016-0482-x","Article"
notebooks/data/springer.csv:"GPU-based image method for room impulse response calculation","Multimedia Tools and Applications","","75","9","10.1007/s11042-015-2943-4","Zhong-hua FuJian-wei Li","2016","http://link.springer.com/article/10.1007/s11042-015-2943-4","Article"
notebooks/data/springer.csv:"An analytical GPU performance model for 3D stencil computations from the angle of data traffic","The Journal of Supercomputing","","71","7","10.1007/s11227-015-1392-1","Huayou SuXing CaiMei WenChunyuan Zhang","2015","http://link.springer.com/article/10.1007/s11227-015-1392-1","Article"
notebooks/data/springer.csv:"Design and evaluation of multi-GPU enabled Multiple Symbol Detection algorithm","The Journal of Supercomputing","","72","6","10.1007/s11227-015-1475-z","Ying LiuHaixin ZhengRenliang ZhaoLiheng Jian","2016","http://link.springer.com/article/10.1007/s11227-015-1475-z","Article"
notebooks/data/springer.csv:"GPU-Accelerated Simulation of Massive Spatial Data Based on the Modified Planar Rotator Model","Mathematical Geosciences","","52","1","10.1007/s11004-019-09835-3","Milan ŽukovičMichal BorovskýMatúš LachDionissios T. Hristopulos","2020","http://link.springer.com/article/10.1007/s11004-019-09835-3","Article"
notebooks/data/springer.csv:"CUDASW++ 3.0: accelerating Smith-Waterman protein database search by coupling CPU and GPU SIMD instructions","BMC Bioinformatics","","14","1","10.1186/1471-2105-14-117","Yongchao LiuAdrianto WirawanBertil Schmidt","2013","http://link.springer.com/article/10.1186/1471-2105-14-117","Article"
notebooks/data/springer.csv:"DOPA: GPU-based protein alignment using database and memory access optimizations","BMC Research Notes","","4","1","10.1186/1756-0500-4-261","Laiq HasanMarijn KentieZaid Al-Ars","2011","http://link.springer.com/article/10.1186/1756-0500-4-261","Article"
notebooks/data/springer.csv:"GPU implementations of a relaxation scheme for image partitioning: GLSL versus CUDA","Computing and Visualization in Science","","14","5","10.1007/s00791-012-0176-x","Tetyana IvanovskaLars LinsenHorst K. HahnHenry Völzke","2011","http://link.springer.com/article/10.1007/s00791-012-0176-x","Article"
notebooks/data/springer.csv:"Addressing Memory and Speed Problems in Nondestructive Defect Characterization: Element-by-Element Processing on a GPU","Journal of Nondestructive Evaluation","","34","2","10.1007/s10921-015-0282-z","S. SivasuthanV. U. KarthikA. RahunanthanP. JayakumarR. S. ThyagarajanLalita UdpaS. R. H. Hoole","2015","http://link.springer.com/article/10.1007/s10921-015-0282-z","Article"
notebooks/data/springer.csv:"GPU-accelerated computing for Lagrangian coherent structures of multi-body gravitational regimes","Astrophysics and Space Science","","362","4","10.1007/s10509-017-3050-y","Mingpei LinMing XuXiaoyu Fu","2017","http://link.springer.com/article/10.1007/s10509-017-3050-y","Article"
notebooks/data/springer.csv:"Addressing GPU On-Chip Shared Memory Bank Conflicts Using Elastic Pipeline","International Journal of Parallel Programming","","41","3","10.1007/s10766-012-0201-1","Chunyang GouGeorgi N. Gaydadjiev","2013","http://link.springer.com/article/10.1007/s10766-012-0201-1","Article"
notebooks/data/springer.csv:"Classification and disease probability prediction via machine learning programming based on multi-GPU cluster MapReduce system","The Journal of Supercomputing","","73","5","10.1007/s11227-016-1883-8","Jinjing LiQingkui ChenBocheng Liu","2017","http://link.springer.com/article/10.1007/s11227-016-1883-8","Article"
notebooks/data/springer.csv:"A Generic Paradigm for Accelerating Laplacian-Based Mesh Smoothing on the GPU","Arabian Journal for Science and Engineering","","39","11","10.1007/s13369-014-1406-y","Gang MeiJohn C. TipperNengxiong Xu","2014","http://link.springer.com/article/10.1007/s13369-014-1406-y","Article"
notebooks/data/springer.csv:"Scaling up MapReduce-based Big Data Processing on Multi-GPU systems","Cluster Computing","","18","1","10.1007/s10586-014-0400-1","Hai JiangYi ChenZhi QiaoTien-Hsiung WengKuan-Ching Li","2015","http://link.springer.com/article/10.1007/s10586-014-0400-1","Article"
notebooks/data/springer.csv:"GPU acceleration of Fitch’s parsimony on protein data: from Kepler to Turing","The Journal of Supercomputing","","76","12","10.1007/s11227-020-03225-x","Sergio Santander-JiménezMiguel A. Vega-RodríguezAntonio Zahinos-MárquezLeonel Sousa","2020","http://link.springer.com/article/10.1007/s11227-020-03225-x","Article"
notebooks/data/springer.csv:"Leveraging HPC accelerator architectures with modern techniques — hydrologic modeling on GPUs with ParFlow","Computational Geosciences","","25","5","10.1007/s10596-021-10051-4","Jaro HokkanenStefan KolletJiri KrausAndreas HertenMarkus HrywniakDirk Pleiter","2021","http://link.springer.com/article/10.1007/s10596-021-10051-4","Article"
notebooks/data/springer.csv:"GPU-based leaves contour generation algorithm","Journal of Shanghai University (English Edition)","","15","5","10.1007/s11741-011-0754-3","Jing-qiao Zhang 张景峤Ting-ting Wang 王廷婷","2011","http://link.springer.com/article/10.1007/s11741-011-0754-3","Article"
notebooks/data/springer.csv:"Approximate similarity search for online multimedia services on distributed CPU–GPU platforms","The VLDB Journal","","23","3","10.1007/s00778-013-0329-7","George TeodoroEduardo ValleNathan MarianoRicardo TorresWagner Meira JrJoel H. Saltz","2014","http://link.springer.com/article/10.1007/s00778-013-0329-7","Article"
notebooks/data/springer.csv:"GPU-based efficient join algorithms on Hadoop","The Journal of Supercomputing","","77","1","10.1007/s11227-020-03262-6","Hongzhi WangNing LiZheng WangJianing Li","2021","http://link.springer.com/article/10.1007/s11227-020-03262-6","Article"
notebooks/data/springer.csv:"Fast kNN query processing over a multi-node GPU environment","The Journal of Supercomputing","","","","10.1007/s11227-021-03975-2","Ricardo J. BarrientosJavier A. RiquelmeRuber Hernández-GarcíaCristóbal A. NavarroWladimir Soto-Silva","2021","http://link.springer.com/article/10.1007/s11227-021-03975-2","Article"
notebooks/data/springer.csv:"Stencil computations on heterogeneous platforms for the Jacobi method: GPUs versus Cell BE","The Journal of Supercomputing","","62","2","10.1007/s11227-012-0749-y","José M. CeciliaJosé L. AbellánJuan FernándezManuel E. AcacioJosé M. GarcíaManuel Ujaldón","2012","http://link.springer.com/article/10.1007/s11227-012-0749-y","Article"
notebooks/data/springer.csv:"Introducing and Implementing the Allpairs Skeleton for Programming Multi-GPU Systems","International Journal of Parallel Programming","","42","4","10.1007/s10766-013-0265-6","Michel SteuwerMalte FrieseSebastian AlbersSergei Gorlatch","2014","http://link.springer.com/article/10.1007/s10766-013-0265-6","Article"
notebooks/data/springer.csv:"Implementation of a High Throughput 3GPP Turbo Decoder on GPU","Journal of Signal Processing Systems","","65","2","10.1007/s11265-011-0617-7","Michael WuYang SunGuohui WangJoseph R. Cavallaro","2011","http://link.springer.com/article/10.1007/s11265-011-0617-7","Article"
notebooks/data/springer.csv:"A real-time implementation of SIFT using GPU","Journal of Real-Time Image Processing","","14","2","10.1007/s11554-014-0446-6","K. Aniruddha AcharyaR. Venkatesh BabuSathish S. Vadhiyar","2018","http://link.springer.com/article/10.1007/s11554-014-0446-6","Article"
notebooks/data/springer.csv:"Optimizing tensor contraction expressions for hybrid CPU-GPU execution","Cluster Computing","","16","1","10.1007/s10586-011-0179-2","Wenjing MaSriram KrishnamoorthyOreste VillaKarol KowalskiGagan Agrawal","2013","http://link.springer.com/article/10.1007/s10586-011-0179-2","Article"
notebooks/data/springer.csv:"Accelerated parametric chamfer alignment using a parallel, pipelined GPU realization","Journal of Real-Time Image Processing","","16","5","10.1007/s11554-017-0668-5","Ahmed ElliethyGaurav Sharma","2019","http://link.springer.com/article/10.1007/s11554-017-0668-5","Article"
notebooks/data/springer.csv:"Reveal training performance mystery between TensorFlow and PyTorch in the single GPU environment","Science China Information Sciences","","65","1","10.1007/s11432-020-3182-1","Hulin DaiXuan PengXuanhua ShiLigang HeQian XiongHai Jin","2021","http://link.springer.com/article/10.1007/s11432-020-3182-1","Article"
notebooks/data/springer.csv:"GPU computing in discrete optimization. Part I: Introduction to the GPU","EURO Journal on Transportation and Logistics","","2","1 - 2","10.1007/s13676-013-0025-1","André R. BrodtkorbTrond R. HagenChristian SchulzGeir Hasle","2013","http://link.springer.com/article/10.1007/s13676-013-0025-1","Article"
notebooks/data/springer.csv:"Accelerating geospatial analysis on GPUs using CUDA","Journal of Zhejiang University SCIENCE C","","12","12","10.1631/jzus.C1100051","Ying-jie XiaLi KuangXiu-mei Li","2011","http://link.springer.com/article/10.1631/jzus.C1100051","Article"
notebooks/data/springer.csv:"Simulation of bevel gear cutting with GPGPUs—performance and productivity","Computer Science - Research and Development","","26","3 - 4","10.1007/s00450-011-0158-0","Sandra WienkeDmytro PlotnikovDieter an MeyChristian BischofArio HardjosuwitoChristof GorgelsChristian Brecher","2011","http://link.springer.com/article/10.1007/s00450-011-0158-0","Article"
notebooks/data/springer.csv:"A parallel solving method for block-tridiagonal equations on CPU–GPU heterogeneous computing systems","The Journal of Supercomputing","","73","5","10.1007/s11227-016-1881-x","Wangdong YangKenli LiKeqin Li","2017","http://link.springer.com/article/10.1007/s11227-016-1881-x","Article"
notebooks/data/springer.csv:"GMMA: GPU-based multiobjective memetic algorithms for vehicle routing problem with route balancing","Applied Intelligence","","49","1","10.1007/s10489-018-1210-6","Zizhen ZhangYuyan SunHong XieYi TengJiahai Wang","2019","http://link.springer.com/article/10.1007/s10489-018-1210-6","Article"
notebooks/data/springer.csv:"A GPU-oriented online recommendation algorithm for efficient processing of time-varying continuous data streams","Knowledge and Information Systems","","53","3","10.1007/s10115-016-0967-3","Chandima HewaNadungodageYuni XiaJohn Jaehwan Lee","2017","http://link.springer.com/article/10.1007/s10115-016-0967-3","Article"
notebooks/data/springer.csv:"Static detection of uncoalesced accesses in GPU programs","Formal Methods in System Design","","","","10.1007/s10703-021-00362-8","Rajeev AlurJoseph DeviettiOmar S. Navarro LeijaNimit Singhania","2021","http://link.springer.com/article/10.1007/s10703-021-00362-8","Article"
notebooks/data/springer.csv:"Efficient parallel algorithm for computing rough set approximation on GPU","Soft Computing","","22","22","10.1007/s00500-018-3050-z","Si-Yuan JingGong-Liang LiKai ZengWei PanCai-Ming Liu","2018","http://link.springer.com/article/10.1007/s00500-018-3050-z","Article"
notebooks/data/springer.csv:"Accelerating the discontinuous Galerkin method for seismic wave propagation simulations using multiple GPUs with CUDA and MPI","Earthquake Science","","26","6","10.1007/s11589-013-0047-7","Dawei MuPo ChenLiqiang Wang","2013","http://link.springer.com/article/10.1007/s11589-013-0047-7","Article"
notebooks/data/springer.csv:"Efficient graph computation on hybrid CPU and GPU systems","The Journal of Supercomputing","","71","4","10.1007/s11227-015-1378-z","Tao ZhangJingjie ZhangWei ShuMin-You WuXiaoyao Liang","2015","http://link.springer.com/article/10.1007/s11227-015-1378-z","Article"
notebooks/data/springer.csv:"Real-time patch-based medical image modality propagation by GPU computing","Journal of Real-Time Image Processing","","13","1","10.1007/s11554-016-0568-0","Eduardo AlcaínAngel Torrado-CarvajalAntonio S. MontemayorNorberto Malpica","2017","http://link.springer.com/article/10.1007/s11554-016-0568-0","Article"
notebooks/data/springer.csv:"Parallel implementation of 3D protein structure similarity searches using a GPU and the CUDA","Journal of Molecular Modeling","","20","2","10.1007/s00894-014-2067-1","Dariusz MrozekMiłosz BrożekBożena Małysiak-Mrozek","2014","http://link.springer.com/article/10.1007/s00894-014-2067-1","Article"
notebooks/data/springer.csv:"Implementation of the moving particle semi-implicit method on GPU","Science China Physics, Mechanics and Astronomy","","54","3","10.1007/s11433-010-4241-5","XiaoSong ZhuLiang ChengLin LuBin Teng","2011","http://link.springer.com/article/10.1007/s11433-010-4241-5","Article"
notebooks/data/springer.csv:"Evaluating application performance and energy consumption on hybrid CPU+GPU architecture","Cluster Computing","","16","3","10.1007/s10586-012-0219-6","Edson Luiz PadoinLaércio Lima PillaFrancieli Zanon BoitoRodrigo Virote KassickPedro VelhoPhilippe O. A. Navaux","2013","http://link.springer.com/article/10.1007/s10586-012-0219-6","Article"
notebooks/data/springer.csv:"Optimization and acceleration of flow simulations for CFD on CPU/GPU architecture","Journal of the Brazilian Society of Mechanical Sciences and Engineering","","41","7","10.1007/s40430-019-1793-9","Jiang LeiDa-li LiYun-long ZhouWei Liu","2019","http://link.springer.com/article/10.1007/s40430-019-1793-9","Article"
notebooks/data/springer.csv:"ADEPT: a domain independent sequence alignment strategy for gpu architectures","BMC Bioinformatics","","21","1","10.1186/s12859-020-03720-1","Muaaz G. AwanJack DeslippeAydin BulucOguz SelvitopiSteven HofmeyrLeonid OlikerKatherine Yelick","2020","http://link.springer.com/article/10.1186/s12859-020-03720-1","Article"
notebooks/data/springer.csv:"GPU Based N-Gram String Matching Algorithm with Score Table Approach for String Searching in Many Documents","Journal of The Institution of Engineers (India): Series B","","98","5","10.1007/s40031-017-0295-3","K. G. SrinivasaB. N. Shree Devi","2017","http://link.springer.com/article/10.1007/s40031-017-0295-3","Article"
notebooks/data/springer.csv:"A GPU implementation of a hybrid evolutionary algorithm: GPuEGO","The Journal of Supercomputing","","70","2","10.1007/s11227-014-1136-7","J. M. García-MartínezE. M. GarzónP. M. Ortigosa","2014","http://link.springer.com/article/10.1007/s11227-014-1136-7","Article"
notebooks/data/springer.csv:"NMF-mGPU: non-negative matrix factorization on multi-GPU systems","BMC Bioinformatics","","16","1","10.1186/s12859-015-0485-4","Edgardo Mejía-RoaDaniel Tabas-MadridJavier SetoainCarlos GarcíaFrancisco TiradoAlberto Pascual-Montano","2015","http://link.springer.com/article/10.1186/s12859-015-0485-4","Article"
notebooks/data/springer.csv:"A Parallel Algorithm for UAV Flight Route Planning on GPU","International Journal of Parallel Programming","","39","6","10.1007/s10766-011-0171-8","Seçkin SancıVeysi İşler","2011","http://link.springer.com/article/10.1007/s10766-011-0171-8","Article"
notebooks/data/springer.csv:"Accelerating data gravitation-based classification using GPU","The Journal of Supercomputing","","75","6","10.1007/s11227-018-2253-5","Lizhi PengHaibo ZhangHoucine HassanYuehui ChenBo Yang","2019","http://link.springer.com/article/10.1007/s11227-018-2253-5","Article"
notebooks/data/springer.csv:"CMSA: a heterogeneous CPU/GPU computing system for multiple similar RNA/DNA sequence alignment","BMC Bioinformatics","","18","1","10.1186/s12859-017-1725-6","Xi ChenChen WangShanjiang TangCe YuQuan Zou","2017","http://link.springer.com/article/10.1186/s12859-017-1725-6","Article"
notebooks/data/springer.csv:"Accelerating the problem of microrheology in colloidal systems on a GPU","The Journal of Supercomputing","","73","1","10.1007/s11227-016-1867-8","G. OrtegaA. M. PuertasE. M. Garzón","2017","http://link.springer.com/article/10.1007/s11227-016-1867-8","Article"
notebooks/data/springer.csv:"Offloading data encryption to GPU in database systems","The Journal of Supercomputing","","69","1","10.1007/s11227-014-1159-0","Heeseung JoSeung-Tae HongJae-Woo ChangDong Hoon Choi","2014","http://link.springer.com/article/10.1007/s11227-014-1159-0","Article"
notebooks/data/springer.csv:"Accelerating electron tomography reconstruction algorithm ICON with GPU","Biophysics Reports","","3","1 - 3","10.1007/s41048-017-0041-z","Yu ChenZihao WangJingrong ZhangLun LiXiaohua WanFei SunFa Zhang","2017","http://link.springer.com/article/10.1007/s41048-017-0041-z","Article"
notebooks/data/springer.csv:"GPU-based exhaustive algorithms processing kNN queries","The Journal of Supercomputing","","73","10","10.1007/s11227-017-2110-y","Ricardo J. BarrientosFabricio MillaguirJosé L. SánchezEnrique Arias","2017","http://link.springer.com/article/10.1007/s11227-017-2110-y","Article"
notebooks/data/springer.csv:"GPU parallel strategy for parameterized LSM-based topology optimization using isogeometric analysis","Structural and Multidisciplinary Optimization","","56","2","10.1007/s00158-017-1672-x","Zhaohui XiaYingjun WangQifu WangChao Mei","2017","http://link.springer.com/article/10.1007/s00158-017-1672-x","Article"
notebooks/data/springer.csv:"Physically based visual simulation of the Lattice Boltzmann method on the GPU: a survey","The Journal of Supercomputing","","74","7","10.1007/s11227-018-2392-8","Octavio Navarro-HinojosaSergio Ruiz-LozaMoisés Alencastre-Miranda","2018","http://link.springer.com/article/10.1007/s11227-018-2392-8","Article"
notebooks/data/springer.csv:"A review of CUDA optimization techniques and tools for structured grid computing","Computing","","102","4","10.1007/s00607-019-00744-1","Mayez A. Al-MouhamedAyaz H. KhanNazeeruddin Mohammad","2020","http://link.springer.com/article/10.1007/s00607-019-00744-1","Article"
notebooks/data/springer.csv:"Scalable CAIM discretization on multiple GPUs using concurrent kernels","The Journal of Supercomputing","","69","1","10.1007/s11227-014-1151-8","Alberto CanoSebastián VenturaKrzysztof J. Cios","2014","http://link.springer.com/article/10.1007/s11227-014-1151-8","Article"
notebooks/data/springer.csv:"Understanding co-run performance on CPU-GPU integrated processors: observations, insights, directions","Frontiers of Computer Science","","11","1","10.1007/s11704-016-5468-8","Qi ZhuBo WuXipeng ShenKai ShenLi ShenZhiying Wang","2017","http://link.springer.com/article/10.1007/s11704-016-5468-8","Article"
notebooks/data/springer.csv:"RT-CUDA: A Software Tool for CUDA Code Restructuring","International Journal of Parallel Programming","","45","3","10.1007/s10766-016-0433-6","Ayaz H. KhanMayez Al-MouhamedMuhammed Al-MulhemAdel F. Ahmed","2017","http://link.springer.com/article/10.1007/s10766-016-0433-6","Article"
notebooks/data/springer.csv:"Parallel data mining techniques on Graphics Processing Unit with Compute Unified Device Architecture (CUDA)","The Journal of Supercomputing","","64","3","10.1007/s11227-011-0672-7","Liheng JianCheng WangYing LiuShenshen LiangWeidong YiYong Shi","2013","http://link.springer.com/article/10.1007/s11227-011-0672-7","Article"
notebooks/data/springer.csv:"Locality-Aware Automatic Parallelization for GPGPU with OpenHMPP Directives","International Journal of Parallel Programming","","44","3","10.1007/s10766-015-0362-9","José M. AndiónManuel ArenazFrançois BodinGabriel RodríguezJuan Touriño","2016","http://link.springer.com/article/10.1007/s10766-015-0362-9","Article"
notebooks/data/springer.csv:"GPUs-RRTMG_LW: high-efficient and scalable computing for a longwave radiative transfer model on multiple GPUs","The Journal of Supercomputing","","77","5","10.1007/s11227-020-03451-3","Yuzhu WangMingxin GuoYuan ZhaoJinrong Jiang","2021","http://link.springer.com/article/10.1007/s11227-020-03451-3","Article"
notebooks/data/springer.csv:"Automatic CPU/GPU Generation of Multi-versioned OpenCL Kernels for C++ Scientific Applications","International Journal of Parallel Programming","","45","2","10.1007/s10766-016-0425-6","Rafael SotomayorLuis Miguel SanchezJavier Garcia BlasJavier FernandezJ. Daniel Garcia","2017","http://link.springer.com/article/10.1007/s10766-016-0425-6","Article"
notebooks/data/springer.csv:"A fast GPU-based hybrid algorithm for addition chains","Cluster Computing","","21","4","10.1007/s10586-018-2840-5","Hatem M. BahigKhaled A. AbdElbari","2018","http://link.springer.com/article/10.1007/s10586-018-2840-5","Article"
notebooks/data/springer.csv:"Hydrodynamic modeling of flash flood in mountain watersheds based on high-performance GPU computing","Natural Hazards","","91","2","10.1007/s11069-017-3141-7","Xiaozhang HuLixiang Song","2018","http://link.springer.com/article/10.1007/s11069-017-3141-7","Article"
notebooks/data/springer.csv:"GPU-based parallel Shadow Features generation at neural system for improving gait human activity recognition","Multimedia Tools and Applications","","80","8","10.1007/s11042-020-10274-0","Ricardo BritoRobert P. Biuk-AghaiSimon Fong","2021","http://link.springer.com/article/10.1007/s11042-020-10274-0","Article"
notebooks/data/springer.csv:"Parallel SUMIS soft detector for large MIMO systems on multicore and GPU","The Journal of Supercomputing","","75","3","10.1007/s11227-018-2403-9","Carla RamiroM. Ángeles SimarroAlberto GonzalezAntonio M. Vidal","2019","http://link.springer.com/article/10.1007/s11227-018-2403-9","Article"
notebooks/data/springer.csv:"CUDAMPF: a multi-tiered parallel framework for accelerating protein sequence search in HMMER on CUDA-enabled GPU","BMC Bioinformatics","","17","1","10.1186/s12859-016-0946-4","Hanyu JiangNarayan Ganesan","2016","http://link.springer.com/article/10.1186/s12859-016-0946-4","Article"
notebooks/data/springer.csv:"GPU acceleration of a 2D compressible Euler solver on CUDA-based block-structured Cartesian meshes","Journal of the Brazilian Society of Mechanical Sciences and Engineering","","42","5","10.1007/s40430-020-02290-w","Feng WeiLiang JinJun LiuFeng DingXinping Zheng","2020","http://link.springer.com/article/10.1007/s40430-020-02290-w","Article"
notebooks/data/springer.csv:"Implementation of a High Throughput Soft MIMO Detector on GPU","Journal of Signal Processing Systems","","64","1","10.1007/s11265-010-0523-4","Michael WuYang SunSiddharth GuptaJoseph R. Cavallaro","2011","http://link.springer.com/article/10.1007/s11265-010-0523-4","Article"
notebooks/data/springer.csv:"A GPU implementation of a structural-similarity-based aerial-image classification","The Journal of Supercomputing","","65","2","10.1007/s11227-013-0875-1","Rok ČešnovarVladimir RisojevićZdenka BabićTomaž DobravecPatricio Bulić","2013","http://link.springer.com/article/10.1007/s11227-013-0875-1","Article"
notebooks/data/springer.csv:              -Minimization Solvers on GPU","International Journal of Parallel Programming","","45","3","10.1007/s10766-016-0430-9","Jiaquan GaoZejie LiRonghua LiangGuixia He","2017","http://link.springer.com/article/10.1007/s10766-016-0430-9","Article"
notebooks/data/springer.csv:"A fast Hough Transform algorithm for straight lines detection in an image using GPU parallel computing with CUDA-C","The Journal of Supercomputing","","73","11","10.1007/s11227-017-2051-5","R. Yam-UicabJ. L. Lopez-MartinezJ. A. Trejo-SanchezH. Hidalgo-SilvaS. Gonzalez-Segura","2017","http://link.springer.com/article/10.1007/s11227-017-2051-5","Article"
notebooks/data/springer.csv:"GPU-accelerated level-set segmentation","Journal of Real-Time Image Processing","","12","1","10.1007/s11554-013-0378-6","Julián Lamas-RodríguezDora B. HerasFrancisco ArgüelloDagmar KainmuellerStefan ZachowMontserrat Bóo","2016","http://link.springer.com/article/10.1007/s11554-013-0378-6","Article"
notebooks/data/springer.csv:"Complex shading efficiently for ray tracing on GPU","Multimedia Tools and Applications","","74","3","10.1007/s11042-013-1712-5","Xin YangDuan-qing XuLei ZhaoBing Yang","2015","http://link.springer.com/article/10.1007/s11042-013-1712-5","Article"
notebooks/data/springer.csv:"GPU-accelerated computing of three-dimensional solar wind background","Science China Earth Sciences","","56","11","10.1007/s11430-013-4661-y","XueShang FengDingKun ZhongChangQing XiangYao Zhang","2013","http://link.springer.com/article/10.1007/s11430-013-4661-y","Article"
notebooks/data/springer.csv:"An efficient parallel entropy coding method for JPEG compression based on GPU","The Journal of Supercomputing","","","","10.1007/s11227-021-03971-6","Fushun ZhuHua Yan","2021","http://link.springer.com/article/10.1007/s11227-021-03971-6","Article"
notebooks/data/springer.csv:"Matrix-free GPU implementation of a preconditioned conjugate gradient solver for anisotropic elliptic PDEs","Computing and Visualization in Science","","16","2","10.1007/s00791-014-0223-x","Eike MüllerXu GuoRobert ScheichlSinan Shi","2013","http://link.springer.com/article/10.1007/s00791-014-0223-x","Article"
notebooks/data/springer.csv:"GPU-based MapReduce for large-scale near-duplicate video retrieval","Multimedia Tools and Applications","","74","23","10.1007/s11042-014-2185-x","Hanli WangFengkuangtian ZhuBo XiaoLei WangYu-Gang Jiang","2015","http://link.springer.com/article/10.1007/s11042-014-2185-x","Article"
notebooks/data/springer.csv:"Gene regulatory networks inference using a multi-GPU exhaustive search algorithm","BMC Bioinformatics","","14","18","10.1186/1471-2105-14-S18-S5","Fabrizio F BorelliRaphael Y de CamargoDavid C Martins JrLuiz CS Rozante","2013","http://link.springer.com/article/10.1186/1471-2105-14-S18-S5","Article"
notebooks/data/springer.csv:"Evolutionary induction of a decision tree for large-scale data: a GPU-based approach","Soft Computing","","21","24","10.1007/s00500-016-2280-1","Krzysztof JurczukMarcin CzajkowskiMarek Kretowski","2017","http://link.springer.com/article/10.1007/s00500-016-2280-1","Article"
notebooks/data/springer.csv:"Adapting hierarchical bidirectional inter prediction on a GPU-based platform for 2D and 3D H.264 video coding","EURASIP Journal on Advances in Signal Processing","","2013","1","10.1186/1687-6180-2013-67","Rafael Rodríguez-SánchezJosé Luis MartínezJan De CockGerardo Fernández–EscribanoBart PietersJosé L SánchezJosé M ClaverRik Van de Walle","2013","http://link.springer.com/article/10.1186/1687-6180-2013-67","Article"
notebooks/data/springer.csv:"HFPaC: GPU friendly height field parallel compression","GeoInformatica","","17","1","10.1007/s10707-012-0171-x","Đorđe M. ĐurđevićIgor I. Tartalja","2013","http://link.springer.com/article/10.1007/s10707-012-0171-x","Article"
notebooks/data/springer.csv:"GPU-based segmentation of retinal blood vessels","Journal of Real-Time Image Processing","","14","4","10.1007/s11554-014-0469-z","Francisco ArgüelloDavid L. VilariñoDora B. HerasAlejandro Nieto","2018","http://link.springer.com/article/10.1007/s11554-014-0469-z","Article"
notebooks/data/springer.csv:"GPU accelerated manifold correction method for spinning compact binaries","Astrophysics and Space Science","","363","4","10.1007/s10509-018-3265-6","Chong-xi RanSong LiuShuang-ying Zhong","2018","http://link.springer.com/article/10.1007/s10509-018-3265-6","Article"
notebooks/data/springer.csv:"CGMBE: a model-based tool for the design and implementation of real-time image processing applications on CPU–GPU platforms","Journal of Real-Time Image Processing","","18","3","10.1007/s11554-020-00994-9","Jiahao WuJing XieAlexandre BardakoffTimothy BlattnerWalid KeyrouzShuvra S. Bhattacharyya","2021","http://link.springer.com/article/10.1007/s11554-020-00994-9","Article"
notebooks/data/springer.csv:"Improving GPU-accelerated adaptive IDW interpolation algorithm using fast kNN search","SpringerPlus","","5","1","10.1186/s40064-016-3035-2","Gang MeiNengxiong XuLiangliang Xu","2016","http://link.springer.com/article/10.1186/s40064-016-3035-2","Article"
notebooks/data/springer.csv:"GPU accelerated novel particle filtering method","Computing","","96","8","10.1007/s00607-014-0400-2","Subhra Kanti DasChandan MazumdarKumardeb Banerjee","2014","http://link.springer.com/article/10.1007/s00607-014-0400-2","Article"
notebooks/data/springer.csv:"Global optimization model on power efficiency of GPU and multicore processing element for SIMD computing with CUDA","Computer Science - Research and Development","","27","4","10.1007/s00450-011-0197-6","Da-Qi RenReiji Suda","2012","http://link.springer.com/article/10.1007/s00450-011-0197-6","Article"
notebooks/data/springer.csv:"Efficient adaptive load balancing approach for compressive background subtraction algorithm on heterogeneous CPU–GPU platforms","Journal of Real-Time Image Processing","","17","5","10.1007/s11554-019-00916-4","Lhoussein MabroukSylvain HuetDominique HouzetSaid BelkouchAbdelkrim HamzaouiYahya Zennayi","2020","http://link.springer.com/article/10.1007/s11554-019-00916-4","Article"
notebooks/data/springer.csv:"GPU implementation of Jacobi Method and Gauss-Seidel Method for Data Arrays that Exceed GPU-dedicated Memory Size","Journal of Mathematical Modelling and Algorithms in Operations Research","","14","4","10.1007/s10852-015-9272-5","Aleksandr KochurovDimitrii Golovashkin","2015","http://link.springer.com/article/10.1007/s10852-015-9272-5","Article"
notebooks/data/springer.csv:"CLUS_GPU-BLASTP: accelerated protein sequence alignment using GPU-enabled cluster","The Journal of Supercomputing","","73","10","10.1007/s11227-017-2036-4","Sita RaniO. P. Gupta","2017","http://link.springer.com/article/10.1007/s11227-017-2036-4","Article"
notebooks/data/springer.csv:"Fault Table Computation on GPUs","Journal of Electronic Testing","","26","2","10.1007/s10836-010-5147-x","Kanupriya GulatiSunil P. Khatri","2010","http://link.springer.com/article/10.1007/s10836-010-5147-x","Article"
notebooks/data/springer.csv:"MPFFT: An Auto-Tuning FFT Library for OpenCL GPUs","Journal of Computer Science and Technology","","28","1","10.1007/s11390-013-1314-8","Yan LiYun-Quan ZhangYi-Qun LiuGuo-Ping LongHai-Peng Jia","2013","http://link.springer.com/article/10.1007/s11390-013-1314-8","Article"
notebooks/data/springer.csv:"High-speed TCP flow record extraction using GPUs","The Journal of Supercomputing","","71","10","10.1007/s11227-015-1478-9","Paula RoqueroJavier RamosVictor MorenoIván GonzálezJavier Aracil","2015","http://link.springer.com/article/10.1007/s11227-015-1478-9","Article"
notebooks/data/springer.csv:"Performance evaluation of a 3D multi-view-based particle filter for visual object tracking using GPUs and multicore CPUs","Journal of Real-Time Image Processing","","15","2","10.1007/s11554-014-0483-1","David ConchaRaúl CabidoJuan José PantrigoAntonio S. Montemayor","2018","http://link.springer.com/article/10.1007/s11554-014-0483-1","Article"
notebooks/data/springer.csv:"Fast computer simulation of reconstructed image from rainbow hologram based on GPU","Optical Review","","22","5","10.1007/s10043-015-0102-9","Jiao ShumingHiroshi Yoshikawa","2015","http://link.springer.com/article/10.1007/s10043-015-0102-9","Article"
notebooks/data/springer.csv:"Tuning remote GPU virtualization for InfiniBand networks","The Journal of Supercomputing","","72","12","10.1007/s11227-016-1754-3","Carlos ReañoFederico Silla","2016","http://link.springer.com/article/10.1007/s11227-016-1754-3","Article"
notebooks/data/springer.csv:"GPU-accelerated Gibbs sampling: a case study of the Horseshoe Probit model","Statistics and Computing","","29","2","10.1007/s11222-018-9809-3","Alexander TereninShawfeng DongDavid Draper","2019","http://link.springer.com/article/10.1007/s11222-018-9809-3","Article"
notebooks/data/springer.csv:"Reconstruction of 3D human motion in real-time using particle swarm optimization with GPU-accelerated fitness function","Journal of Real-Time Image Processing","","17","4","10.1007/s11554-018-0825-5","Bogdan KwolekBoguslaw Rymut","2020","http://link.springer.com/article/10.1007/s11554-018-0825-5","Article"
notebooks/data/springer.csv:"Hybrid CPU–GPU execution support in the skeleton programming framework SkePU","The Journal of Supercomputing","","76","7","10.1007/s11227-019-02824-7","Tomas ÖhbergAugust ErnstssonChristoph Kessler","2020","http://link.springer.com/article/10.1007/s11227-019-02824-7","Article"
notebooks/data/springer.csv:"Kernel concurrency opportunities based on GPU benchmarks characterization","Cluster Computing","","23","1","10.1007/s10586-018-02901-1","Pablo CarvalhoRommel CruzLucia M. A. DrummondCristiana BentesEsteban CluaEdson CataldoLeandro A. J. Marzulo","2020","http://link.springer.com/article/10.1007/s10586-018-02901-1","Article"
notebooks/data/springer.csv:"Fast weighting method for plasma PIC simulation on GPU-accelerated heterogeneous systems","Journal of Central South University","","20","6","10.1007/s11771-013-1644-2","Can-qun Yang 杨灿群Qiang Wu 吴强Hui-li Hu 胡慧俐Zhi-cai Shi 石志才Juan Chen 陈娟Tao Tang 唐滔","2013","http://link.springer.com/article/10.1007/s11771-013-1644-2","Article"
notebooks/data/springer.csv:"CPU versus GPU: which can perform matrix computation faster—performance comparison for basic linear algebra subprograms","Neural Computing and Applications","","31","8","10.1007/s00521-018-3354-z","Feng LiYunming YeZhaoyang TianXiaofeng Zhang","2019","http://link.springer.com/article/10.1007/s00521-018-3354-z","Article"
notebooks/data/springer.csv:"On the Virtualization of CUDA Based GPU Remoting on ARM and X86 Machines in the GVirtuS Framework","International Journal of Parallel Programming","","45","5","10.1007/s10766-016-0462-1","Raffaele MontellaGiulio GiuntaGiuliano LaccettiMarco LapegnaCarlo PalmieriCarmine FerraroValentina PellicciaCheol-Ho HongIvor SpenceDimitrios S. Nikolopoulos","2017","http://link.springer.com/article/10.1007/s10766-016-0462-1","Article"
notebooks/data/springer.csv:"GPU-Based Iterative Medical CT Image Reconstructions","Journal of Signal Processing Systems","","91","3 - 4","10.1007/s11265-018-1352-0","Xiaodong YuHao WangWu-chun FengHao GongGuohua Cao","2019","http://link.springer.com/article/10.1007/s11265-018-1352-0","Article"
notebooks/data/springer.csv:"Efficient implementation of data flow graphs on multi-gpu clusters","Journal of Real-Time Image Processing","","9","1","10.1007/s11554-012-0279-0","Vincent BoulosSylvain HuetVincent FristotLuc SalvoDominique Houzet","2014","http://link.springer.com/article/10.1007/s11554-012-0279-0","Article"
notebooks/data/springer.csv:"DEMCMC-GPU: An Efficient Multi-Objective Optimization Method with GPU Acceleration on the Fermi Architecture","New Generation Computing","","29","2","10.1007/s00354-010-0103-y","Weihang ZhuAshraf YaseenYaohang Li","2011","http://link.springer.com/article/10.1007/s00354-010-0103-y","Article"
notebooks/data/springer.csv:"Automatic Halo Management for the Uintah GPU-Heterogeneous Asynchronous Many-Task Runtime","International Journal of Parallel Programming","","47","5 - 6","10.1007/s10766-018-0619-1","Brad PetersonAlan HumphreyDan SunderlandJames SutherlandTony SaadHarish DasariMartin Berzins","2019","http://link.springer.com/article/10.1007/s10766-018-0619-1","Article"
notebooks/data/springer.csv:"Heterogeneous CPU-GPU Epsilon Grid Joins: Static and Dynamic Work Partitioning Strategies","Data Science and Engineering","","6","1","10.1007/s41019-020-00145-x","Benoit GalletMichael Gowanlock","2021","http://link.springer.com/article/10.1007/s41019-020-00145-x","Article"
notebooks/data/springer.csv:"Speeding up the evaluation phase of GP classification algorithms on GPUs","Soft Computing","","16","2","10.1007/s00500-011-0713-4","Alberto CanoAmelia ZafraSebastián Ventura","2012","http://link.springer.com/article/10.1007/s00500-011-0713-4","Article"
notebooks/data/springer.csv:"Computer Vision Accelerators for Mobile Systems based on OpenCL GPGPU Co-Processing","Journal of Signal Processing Systems","","76","3","10.1007/s11265-014-0878-z","Guohui WangYingen XiongJay YunJoseph R. Cavallaro","2014","http://link.springer.com/article/10.1007/s11265-014-0878-z","Article"
notebooks/data/springer.csv:"A GPU Implementation of OLPCA Method in Hybrid Environment","International Journal of Parallel Programming","","46","3","10.1007/s10766-017-0505-2","Pasquale De MicheleFrancesco MaioranoLivia MarcellinoFrancesco Piccialli","2018","http://link.springer.com/article/10.1007/s10766-017-0505-2","Article"
notebooks/data/springer.csv:"Impacts of optimization strategies on performance, power/energy consumption of a GPU based parallel reduction","Journal of Central South University","","24","11","10.1007/s11771-017-3676-5","Thi Yen PhuongDeok-Young LeeJeong-Gun Lee","2017","http://link.springer.com/article/10.1007/s11771-017-3676-5","Article"
notebooks/data/springer.csv:"GPU Framework for Change Detection in Multitemporal Hyperspectral Images","International Journal of Parallel Programming","","47","2","10.1007/s10766-017-0547-5","Javier López-FandiñoDora B. HerasFrancisco ArgüelloMauro Dalla Mura","2019","http://link.springer.com/article/10.1007/s10766-017-0547-5","Article"
notebooks/data/springer.csv:"A heterogeneous parallel implementation of the Markov clustering algorithm for large-scale biological networks on distributed CPU–GPU clusters","The Journal of Supercomputing","","","","10.1007/s11227-021-04204-6","You FuWei Zhou","2022","http://link.springer.com/article/10.1007/s11227-021-04204-6","Article"
notebooks/data/springer.csv:"Real-time dynamic tone-mapping operator on GPU","Journal of Real-Time Image Processing","","7","3","10.1007/s11554-011-0196-7","Mohamed AkilThierry GrandpierreLaurent Perroton","2012","http://link.springer.com/article/10.1007/s11554-011-0196-7","Article"
notebooks/data/springer.csv:"Non-dominated sorting procedure for Pareto dominance ranking on multicore CPU and/or GPU","Journal of Global Optimization","","69","3","10.1007/s10898-016-0468-7","G. OrtegaE. FilatovasE. M. GarzónL. G. Casado","2017","http://link.springer.com/article/10.1007/s10898-016-0468-7","Article"
notebooks/data/springer.csv:"Optimizing seam carving on multi-GPU systems for real-time content-aware image resizing","The Journal of Supercomputing","","71","9","10.1007/s11227-015-1446-4","Ikjoon KimJidong ZhaiYan LiWenguang Chen","2015","http://link.springer.com/article/10.1007/s11227-015-1446-4","Article"
notebooks/data/springer.csv:"High performance data clustering: a comparative analysis of performance for GPU, RASC, MPI, and OpenMP implementations","The Journal of Supercomputing","","70","1","10.1007/s11227-013-0906-y","Luobin YangSteve C. ChiuWei-Keng LiaoMichael A. Thomas","2014","http://link.springer.com/article/10.1007/s11227-013-0906-y","Article"
notebooks/data/springer.csv:"GPU-based parallel optimization for real-time scale-invariant feature transform in binocular visual registration","Personal and Ubiquitous Computing","","23","3 - 4","10.1007/s00779-019-01222-3","Jiashen LiYun Pan","2019","http://link.springer.com/article/10.1007/s00779-019-01222-3","Article"
notebooks/data/springer.csv:"Heterogeneous parallel_for Template for CPU–GPU Chips","International Journal of Parallel Programming","","47","2","10.1007/s10766-018-0555-0","Angeles NavarroFrancisco CorberaAndres RodriguezAntonio VilchesRafael Asenjo","2019","http://link.springer.com/article/10.1007/s10766-018-0555-0","Article"
notebooks/data/springer.csv:"Scalable hybrid implementation of the Schur complement method for multi-GPU systems","The Journal of Supercomputing","","69","1","10.1007/s11227-014-1209-7","Sergey KopysovIgor KuzminNikita NedozhoginAlexander NovikovYulia Sagdeeva","2014","http://link.springer.com/article/10.1007/s11227-014-1209-7","Article"
notebooks/data/springer.csv:"Power Analysis Attack of an AES GPU Implementation","Journal of Hardware and Systems Security","","2","1","10.1007/s41635-018-0032-7","Chao LuoYunsi FeiLiwei ZhangA. Adam DingPei LuoSaoni MukherjeeDavid Kaeli","2018","http://link.springer.com/article/10.1007/s41635-018-0032-7","Article"
notebooks/data/springer.csv:"GPU parallel computing: Programming language, debugging tools and data structures","Frontiers of Electrical and Electronic Engineering","","7","1","10.1007/s11460-012-0187-x","Kun Zhou","2012","http://link.springer.com/article/10.1007/s11460-012-0187-x","Article"
notebooks/data/springer.csv:"Fast motion estimation for HEVC on graphics processing unit (GPU)","Journal of Real-Time Image Processing","","12","2","10.1007/s11554-015-0522-6","Dongkyu LeeDonggyu SimKeeseong ChoSeoung-Jun Oh","2016","http://link.springer.com/article/10.1007/s11554-015-0522-6","Article"
notebooks/data/springer.csv:"Parallel MRI Reconstruction Algorithm Implementation on GPU","Applied Magnetic Resonance","","47","1","10.1007/s00723-015-0728-6","H. ShahzadM. F. SadaqatB. HassanW. AbbasiH. Omer","2016","http://link.springer.com/article/10.1007/s00723-015-0728-6","Article"
notebooks/data/springer.csv:"A GPU-based implementations of the fuzzy C-means algorithms for medical image segmentation","The Journal of Supercomputing","","71","8","10.1007/s11227-015-1431-y","Mahmoud Al-AyyoubAnsam M. Abu-DaloYaser JararwehMoath JarrahMohammad Al Sa’d","2015","http://link.springer.com/article/10.1007/s11227-015-1431-y","Article"
notebooks/data/springer.csv:"Improving the performance and energy of Non-Dominated Sorting for evolutionary multiobjective optimization on GPU/CPU platforms","Journal of Global Optimization","","71","3","10.1007/s10898-018-0669-3","J. J. MorenoG. OrtegaE. FilatovasJ. A. MartínezE. M. Garzón","2018","http://link.springer.com/article/10.1007/s10898-018-0669-3","Article"
notebooks/data/springer.csv:"Fast calculation of HELAS amplitudes using graphics processing unit (GPU)","The European Physical Journal C","","66","3 - 4","10.1140/epjc/s10052-010-1276-8","K. HagiwaraJ. KanzakiN. OkamuraD. RainwaterT. Stelzer","2010","http://link.springer.com/article/10.1140/epjc/s10052-010-1276-8","Article"
notebooks/data/springer.csv:"GPU-accelerated uncapacitated facility location and semi-dense SymStereo pipelines for piecewise-planar-based 3D reconstruction","Journal of Real-Time Image Processing","","18","3","10.1007/s11554-020-00974-z","Carlos GracaCarolina RaposoJoao P. BarretoUrbano NunesGabriel Falcao","2021","http://link.springer.com/article/10.1007/s11554-020-00974-z","Article"
notebooks/data/springer.csv:"GENIE: a software package for gene-gene interaction analysis in genetic association studies using multiple GPU or CPU cores","BMC Research Notes","","4","1","10.1186/1756-0500-4-158","Satish ChikkagoudarKai WangMingyao Li","2011","http://link.springer.com/article/10.1186/1756-0500-4-158","Article"
notebooks/data/springer.csv:"Accelerating finite difference wavefield-continuation depth migration by GPU","Applied Geophysics","","9","1","10.1007/s11770-012-0312-x","Guo-Feng LiuXiao-Hong MengHong Liu","2012","http://link.springer.com/article/10.1007/s11770-012-0312-x","Article"
notebooks/data/springer.csv:"Adaptive fast multipole methods on the GPU","The Journal of Supercomputing","","63","3","10.1007/s11227-012-0836-0","Anders GoudeStefan Engblom","2013","http://link.springer.com/article/10.1007/s11227-012-0836-0","Article"
notebooks/data/springer.csv:"Convolution of large 3D images on GPU and its decomposition","EURASIP Journal on Advances in Signal Processing","","2011","1","10.1186/1687-6180-2011-120","Pavel KarasDavid Svoboda","2011","http://link.springer.com/article/10.1186/1687-6180-2011-120","Article"
notebooks/data/springer.csv:"A memory-driven scheduling scheme and optimization for concurrent execution in GPU","Cluster Computing","","19","4","10.1007/s10586-016-0656-8","Bao-yu XuWu ZhangXian-he SunYang Wang","2016","http://link.springer.com/article/10.1007/s10586-016-0656-8","Article"
notebooks/data/springer.csv:"Kernel Polynomial Method on GPU","International Journal of Parallel Programming","","41","1","10.1007/s10766-012-0204-y","Shixun ZhangShinichi YamagiwaMasahiko OkumuraSeiji Yunoki","2013","http://link.springer.com/article/10.1007/s10766-012-0204-y","Article"
notebooks/data/springer.csv:"Parallelization of large vector similarity computations in a hybrid CPU+GPU environment","The Journal of Supercomputing","","74","2","10.1007/s11227-017-2159-7","Paweł Czarnul","2018","http://link.springer.com/article/10.1007/s11227-017-2159-7","Article"
notebooks/data/springer.csv:"Speeding up the high-accuracy surface modelling method with GPU","Environmental Earth Sciences","","74","8","10.1007/s12665-015-4138-8","Changqing YanGang ZhaoTianxiang YueChuanfa ChenJimin LiuHan LiNa Su","2015","http://link.springer.com/article/10.1007/s12665-015-4138-8","Article"
notebooks/data/springer.csv:"Multi-GPU approach to global induction of classification trees for large-scale data mining","Applied Intelligence","","51","8","10.1007/s10489-020-01952-5","Krzysztof JurczukMarcin CzajkowskiMarek Kretowski","2021","http://link.springer.com/article/10.1007/s10489-020-01952-5","Article"
notebooks/data/springer.csv:"An Autotuning Engine for the 3D Fast Wavelet Transform on Clusters with Hybrid CPU + GPU Platforms","International Journal of Parallel Programming","","43","6","10.1007/s10766-014-0328-3","Gregorio BernabéJavier CuencaDomingo Giménez","2015","http://link.springer.com/article/10.1007/s10766-014-0328-3","Article"
notebooks/data/springer.csv:"Financial applications on multi-CPU and multi-GPU architectures","The Journal of Supercomputing","","71","2","10.1007/s11227-014-1316-5","Emilio CastilloCristóbal CamareroAna BorregoJose Luis Bosque","2015","http://link.springer.com/article/10.1007/s11227-014-1316-5","Article"
notebooks/data/springer.csv:"CPU-GPU hybrid accelerating the Zuker algorithm for RNA secondary structure prediction applications","BMC Genomics","","13","1","10.1186/1471-2164-13-S1-S14","Guoqing LeiYong DouWen WanFei XiaRongchun LiMeng MaDan Zou","2012","http://link.springer.com/article/10.1186/1471-2164-13-S1-S14","Article"
notebooks/data/springer.csv:"Efficient Memory Access Patterns for Solving 3D Laplace Equation on GPU","Iranian Journal of Science and Technology, Transactions A: Science","","42","2","10.1007/s40995-016-0042-7","Muhammad Naveed AkhtarMuhammad Hanif DuradAnila UsmanMuhammad Abid Mughal","2018","http://link.springer.com/article/10.1007/s40995-016-0042-7","Article"
notebooks/data/springer.csv:"GPU-accelerated phase field simulation of directional solidification","Science China Technological Sciences","","57","6","10.1007/s11431-014-5541-1","Ang GaoYanSu HuZhiJun WangDeJun MuJunJie LiJinCheng Wang","2014","http://link.springer.com/article/10.1007/s11431-014-5541-1","Article"
notebooks/data/springer.csv:"GASAL2: a GPU accelerated sequence alignment library for high-throughput NGS data","BMC Bioinformatics","","20","1","10.1186/s12859-019-3086-9","Nauman AhmedJonathan LévyShanshan RenHamid MushtaqKoen BertelsZaid Al-Ars","2019","http://link.springer.com/article/10.1186/s12859-019-3086-9","Article"
notebooks/data/springer.csv:"GPU-assisted HEVC intra decoder","Journal of Real-Time Image Processing","","12","2","10.1007/s11554-015-0519-1","Diego F. de SouzaAleksandar IlicNuno RomaLeonel Sousa","2016","http://link.springer.com/article/10.1007/s11554-015-0519-1","Article"
notebooks/data/springer.csv:"Monte Carlo integration on GPU","The European Physical Journal C","","71","2","10.1140/epjc/s10052-011-1559-8","J. Kanzaki","2011","http://link.springer.com/article/10.1140/epjc/s10052-011-1559-8","Article"
notebooks/data/springer.csv:"Colloquium: Large scale simulations on GPU clusters","The European Physical Journal B","","88","6","10.1140/epjb/e2015-60180-8","Massimo BernaschiMauro BissonMassimiliano Fatica","2015","http://link.springer.com/article/10.1140/epjb/e2015-60180-8","Article"
notebooks/data/springer.csv:"Parallel Computer System for 3D Visualization Stereo on GPU","3D Research","","9","1","10.1007/s13319-018-0159-x","Anas M. Al-OraiqatSergii A. Zori","2018","http://link.springer.com/article/10.1007/s13319-018-0159-x","Article"
notebooks/data/springer.csv:"Efficient OLAP algorithms on GPU-accelerated Hadoop clusters","Distributed and Parallel Databases","","37","4","10.1007/s10619-018-7239-z","Hongzhi WangZheng WangNing LiXinxin Kong","2019","http://link.springer.com/article/10.1007/s10619-018-7239-z","Article"
notebooks/data/springer.csv:"Resolving the GPU responsiveness dilemma through program transformations","Frontiers of Computer Science","","12","3","10.1007/s11704-016-6206-y","Qi ZhuBo WuXipeng ShenKai ShenLi ShenZhiying Wang","2018","http://link.springer.com/article/10.1007/s11704-016-6206-y","Article"
notebooks/data/springer.csv:"Accelerating 2D orthogonal matching pursuit algorithm on GPU","The Journal of Supercomputing","","69","3","10.1007/s11227-014-1188-8","Yuan DaiDongjian HeYong FangLong Yang","2014","http://link.springer.com/article/10.1007/s11227-014-1188-8","Article"
notebooks/data/springer.csv:"GPU-accelerated parallel algorithms for linear rankSVM","The Journal of Supercomputing","","71","11","10.1007/s11227-015-1509-6","Jing JinXianggao CaiGuoming LaiXiaola Lin","2015","http://link.springer.com/article/10.1007/s11227-015-1509-6","Article"
notebooks/data/springer.csv:"Real-time 3D registration using GPU","Machine Vision and Applications","","22","5","10.1007/s00138-010-0282-z","Soon-Yong ParkSung-In ChoiJun KimJeong Sook Chae","2011","http://link.springer.com/article/10.1007/s00138-010-0282-z","Article"
notebooks/data/springer.csv:"GPU fuzzy c-means algorithm implementations: performance analysis on medical image segmentation","Multimedia Tools and Applications","","77","16","10.1007/s11042-017-5589-6","Noureddine Ait AliBouchaib CherradiAhmed El AbbassiOmar BouattaneMohamed Youssfi","2018","http://link.springer.com/article/10.1007/s11042-017-5589-6","Article"
notebooks/data/springer.csv:"GPU-accelerated preconditioned iterative linear solvers","The Journal of Supercomputing","","63","2","10.1007/s11227-012-0825-3","Ruipeng LiYousef Saad","2013","http://link.springer.com/article/10.1007/s11227-012-0825-3","Article"
notebooks/data/springer.csv:"GPU-based collision analysis between a multi-body system and numerous particles","Journal of Mechanical Science and Technology","","27","4","10.1007/s12206-013-0226-4","Hye-Young JungChul-Woong JunJeong-Hyun Sohn","2013","http://link.springer.com/article/10.1007/s12206-013-0226-4","Article"
notebooks/data/springer.csv:"GPU accelerated radio astronomy signal convolution","Experimental Astronomy","","22","1 - 2","10.1007/s10686-008-9114-9","Chris HarrisKaren HainesLister Staveley-Smith","2008","http://link.springer.com/article/10.1007/s10686-008-9114-9","Article"
notebooks/data/springer.csv:"GPU accelerated waterpixel algorithm for superpixel segmentation of hyperspectral images","The Journal of Supercomputing","","77","9","10.1007/s11227-021-03666-y","Pablo Quesada-BarriusoDora Blanco HerasFrancisco Argüello","2021","http://link.springer.com/article/10.1007/s11227-021-03666-y","Article"
notebooks/data/springer.csv:"GPU-accelerated iterative solutions for finite element analysis of soil–structure interaction problems","Computational Geosciences","","17","4","10.1007/s10596-013-9352-4","Xi ChenYuxin JieYuzhen Yu","2013","http://link.springer.com/article/10.1007/s10596-013-9352-4","Article"
notebooks/data/springer.csv:"Hybrid multi-GPU computing: accelerated kernels for segmentation and object detection with medical image processing applications","Journal of Real-Time Image Processing","","13","1","10.1007/s11554-015-0517-3","Carlos GracaGabriel FalcaoIsabel N. FigueiredoSunil Kumar","2017","http://link.springer.com/article/10.1007/s11554-015-0517-3","Article"
notebooks/data/springer.csv:"Implementation of GPU accelerated SPECT reconstruction with Monte Carlo-based scatter correction","Annals of Nuclear Medicine","","32","5","10.1007/s12149-018-1252-1","Tobias BexeliusAntti Sohlberg","2018","http://link.springer.com/article/10.1007/s12149-018-1252-1","Article"
notebooks/data/springer.csv:"GPU Parallelization of HEVC In-Loop Filters","International Journal of Parallel Programming","","45","6","10.1007/s10766-017-0488-z","Biao WangDiego F. de SouzaMauricio Alvarez-MesaChi Ching ChiBen JuurlinkAleksandar IlicNuno RomaLeonel Sousa","2017","http://link.springer.com/article/10.1007/s10766-017-0488-z","Article"
notebooks/data/springer.csv:"Accelerating Time and Depth Seismic Migration by CPU and GPU Cooperation","International Journal of Parallel Programming","","40","3","10.1007/s10766-011-0185-2","Jairo PanettaThiago TeixeiraPaulo R. P. de Souza FilhoCarlos A. da Cunha FilhoDavid SoteloFernando M. Roxo da MottaSilvio Sinedino PinheiroAndre L. Romanelli RosaLuiz R. MonneratLeandro T. CarneiroCarlos H. B. de Albrecht","2012","http://link.springer.com/article/10.1007/s10766-011-0185-2","Article"
notebooks/data/springer.csv:"A Jacobi_PCG solver for sparse linear systems on multi-GPU cluster","The Journal of Supercomputing","","73","1","10.1007/s11227-016-1887-4","Shaozhong LinZhiqiang Xie","2017","http://link.springer.com/article/10.1007/s11227-016-1887-4","Article"
notebooks/data/springer.csv:"Optimization of HEP codes on GPUs","The European Physical Journal Plus","","126","1","10.1140/epjp/i2011-11001-5","M. Al-Turany","2011","http://link.springer.com/article/10.1140/epjp/i2011-11001-5","Article"
notebooks/data/springer.csv:"Regular Lattice and Small-World Spin Model Simulations Using CUDA and GPUs","International Journal of Parallel Programming","","39","2","10.1007/s10766-010-0143-4","K. A. HawickA. LeistD. P. Playne","2011","http://link.springer.com/article/10.1007/s10766-010-0143-4","Article"
notebooks/data/springer.csv:"Pragma Directed Shared Memory Centric Optimizations on GPUs","Journal of Computer Science and Technology","","31","2","10.1007/s11390-016-1624-8","Jing LiLei LiuYuan WuXiang-Hua LiuYi GaoXiao-Bing FengCheng-Yong Wu","2016","http://link.springer.com/article/10.1007/s11390-016-1624-8","Article"
notebooks/data/springer.csv:"A GPU-Based Kalman Filter for Track Fitting","Computing and Software for Big Science","","5","1","10.1007/s41781-021-00065-z","Xiaocong AiGeorgiana ManiaHeather M. GrayMichael KuhnNicholas Styles","2021","http://link.springer.com/article/10.1007/s41781-021-00065-z","Article"
notebooks/data/springer.csv:"Optimization of lateral interaction in accumulative computation on GPU-based platform","The Journal of Supercomputing","","75","3","10.1007/s11227-018-02736-y","Aurelio BermúdezFrancisco MonteroMaría T. LópezAntonio Fernández-CaballeroJosé L. Sánchez","2019","http://link.springer.com/article/10.1007/s11227-018-02736-y","Article"
notebooks/data/springer.csv:"Real-time thinning algorithms for 2D and 3D images using GPU processors","Journal of Real-Time Image Processing","","17","5","10.1007/s11554-019-00886-7","Martin G. Wagner","2020","http://link.springer.com/article/10.1007/s11554-019-00886-7","Article"
notebooks/data/springer.csv:"CudaChain: an alternative algorithm for finding 2D convex hulls on the GPU","SpringerPlus","","5","1","10.1186/s40064-016-2284-4","Gang Mei","2016","http://link.springer.com/article/10.1186/s40064-016-2284-4","Article"
notebooks/data/springer.csv:"GPU Acceleration of a Configurable N-Way MIMO Detector for Wireless Systems","Journal of Signal Processing Systems","","76","2","10.1007/s11265-014-0877-0","Michael WuBei YinGuohui WangChristoph StuderJoseph R. Cavallaro","2014","http://link.springer.com/article/10.1007/s11265-014-0877-0","Article"
notebooks/data/springer.csv:"Fast computation of 2D and 3D Legendre moments using multi-core CPUs and GPU parallel architectures","Journal of Real-Time Image Processing","","16","6","10.1007/s11554-017-0708-1","Khalid M. HosnyAhmad SalahHassan I. SalehMahmoud Sayed","2019","http://link.springer.com/article/10.1007/s11554-017-0708-1","Article"
notebooks/data/springer.csv:"Spectral volume rendering using GPU-based raycasting","The Visual Computer","","22","8","10.1007/s00371-006-0028-0","Magnus StrengertThomas KleinRalf BotchenSimon StegmaierMin ChenThomas Ertl","2006","http://link.springer.com/article/10.1007/s00371-006-0028-0","Article"
notebooks/data/springer.csv:"Triangular mesh simplification on the GPU","The Visual Computer","","31","2","10.1007/s00371-014-1039-x","Alexandros PapageorgiouNikos Platis","2015","http://link.springer.com/article/10.1007/s00371-014-1039-x","Article"
notebooks/data/springer.csv:"Implementation of a parallel ADI algorithm on a finite volume GPU-based elementary porous media flow computation","Journal of the Brazilian Society of Mechanical Sciences and Engineering","","39","10","10.1007/s40430-017-0882-x","L. Henríquez-VargasE. VillaroelJ. GutierrezP. Donoso-García","2017","http://link.springer.com/article/10.1007/s40430-017-0882-x","Article"
notebooks/data/springer.csv:"An efficient GPU-based fractional-step domain decomposition scheme for the reaction–diffusion equation","Computational and Applied Mathematics","","39","4","10.1007/s40314-020-01357-7","Ali FoadaddiniSeyed Alireza ZolfaghariHossein Mahmoodi DarianHamid Saadatfar","2020","http://link.springer.com/article/10.1007/s40314-020-01357-7","Article"
notebooks/data/springer.csv:"Appliance of effective clustering technique for gene expression datasets using GPU","Cluster Computing","","22","5","10.1007/s10586-017-1621-x","V. SaveethaS. SophiaP. D. R. Vijayakumar","2019","http://link.springer.com/article/10.1007/s10586-017-1621-x","Article"
notebooks/data/springer.csv:"The performances of iterative type-2 fuzzy C-mean on GPU for image segmentation","The Journal of Supercomputing","","","","10.1007/s11227-021-03928-9","Noureddine Ait AliAhmed El abbassiBouchaib Cherradi","2021","http://link.springer.com/article/10.1007/s11227-021-03928-9","Article"
notebooks/data/springer.csv:"Collective behavior of large-scale neural networks with GPU acceleration","Cognitive Neurodynamics","","11","6","10.1007/s11571-017-9446-0","Jingyi QuRubin Wang","2017","http://link.springer.com/article/10.1007/s11571-017-9446-0","Article"
notebooks/data/springer.csv:"Design Flow for GPU and Multicore Execution of Dynamic Dataflow Programs","Journal of Signal Processing Systems","","89","3","10.1007/s11265-017-1260-8","J. BoutellierT. Nyländen","2017","http://link.springer.com/article/10.1007/s11265-017-1260-8","Article"
notebooks/data/springer.csv:"GPU material point method (MPM) and its application on slope stability analysis","Bulletin of Engineering Geology and the Environment","","80","7","10.1007/s10064-021-02265-8","Ze-Kang FengWen-Jie Xu","2021","http://link.springer.com/article/10.1007/s10064-021-02265-8","Article"
notebooks/data/springer.csv:"GSA: a GPU-accelerated structure similarity algorithm and its application in progressive virtual screening","Molecular Diversity","","16","4","10.1007/s11030-012-9403-0","Xin YanQiong GuFeng LuJiabo LiJun Xu","2012","http://link.springer.com/article/10.1007/s11030-012-9403-0","Article"
notebooks/data/springer.csv:"Efficient GPU and CPU-based LDPC decoders for long codewords","Analog Integrated Circuits and Signal Processing","","73","2","10.1007/s10470-012-9895-7","Stefan GrönroosKristian NybomJerker Björkqvist","2012","http://link.springer.com/article/10.1007/s10470-012-9895-7","Article"
notebooks/data/springer.csv:"Genetic improvement of GPU software","Genetic Programming and Evolvable Machines","","18","1","10.1007/s10710-016-9273-9","William B. LangdonBrian Yee Hong LamMarc ModatJustyna PetkeMark Harman","2017","http://link.springer.com/article/10.1007/s10710-016-9273-9","Article"
notebooks/data/springer.csv:"Motion vector extrapolation for parallel motion estimation on GPU","Multimedia Tools and Applications","","68","3","10.1007/s11042-012-1074-4","Yi GaoJun Zhou","2014","http://link.springer.com/article/10.1007/s11042-012-1074-4","Article"
notebooks/data/springer.csv:"Optimizing Image Reconstruction in SENSE Using GPU","Applied Magnetic Resonance","","49","2","10.1007/s00723-017-0951-4","Sohaib A. QaziSaima NasirAbeera SaeedHammad Omer","2018","http://link.springer.com/article/10.1007/s00723-017-0951-4","Article"
notebooks/data/springer.csv:"A GPU-based elastic shape registration approach in implicit spaces","Journal of Real-Time Image Processing","","16","6","10.1007/s11554-017-0710-7","Ahmed Hassan YousefHossam E. Abd El Munim","2019","http://link.springer.com/article/10.1007/s11554-017-0710-7","Article"
notebooks/data/springer.csv:"A self-organization based optical flow estimator with GPU implementation","Machine Vision and Applications","","23","6","10.1007/s00138-011-0352-x","Manish P. ShiralkarRobert J. Schalkoff","2012","http://link.springer.com/article/10.1007/s00138-011-0352-x","Article"
notebooks/data/springer.csv:"A GPU implementation of secret sharing scheme based on cellular automata","The Journal of Supercomputing","","72","4","10.1007/s11227-016-1646-6","Rogelio Adrian Hernandez-BecerrilAriana Guadalupe Bucio-RamirezMariko Nakano-MiyatakeHector Perez-MeanaMarco Pedro Ramirez-Tachiquin","2016","http://link.springer.com/article/10.1007/s11227-016-1646-6","Article"
notebooks/data/springer.csv:"Cooperative CPU, GPU, and FPGA heterogeneous execution with EngineCL","The Journal of Supercomputing","","75","3","10.1007/s11227-019-02768-y","María Angélica Dávila GuzmánRaúl NozalRubén Gran TejeroMaría Villarroya-GaudóDarío Suárez GraciaJose Luis Bosque","2019","http://link.springer.com/article/10.1007/s11227-019-02768-y","Article"
notebooks/data/springer.csv:"Parallel edge-based visual assessment of cluster tendency on GPU","International Journal of Data Science and Analytics","","6","4","10.1007/s41060-018-0100-7","Tao MengBo Yuan","2018","http://link.springer.com/article/10.1007/s41060-018-0100-7","Article"
notebooks/data/springer.csv:"Knowledge based fuzzy c-means method for rapid brain tissues segmentation of magnetic resonance imaging scans with CUDA enabled GPU machine","Journal of Ambient Intelligence and Humanized Computing","","","","10.1007/s12652-020-02132-6","Prajoona ValsalanP. SriramakrishnanS. SridharG. Charlyn Pushpa LathaA. PriyaS. RamkumarA. Robert SinghT. Rajendran","2020","http://link.springer.com/article/10.1007/s12652-020-02132-6","Article"
notebooks/data/springer.csv:"Forward and back substitution algorithms on GPU: a case study on modified incomplete Cholesky Preconditioner for three-dimensional finite difference method","The Journal of Supercomputing","","62","1","10.1007/s11227-011-0736-8","Yigitcan AksariHarun Artuner","2012","http://link.springer.com/article/10.1007/s11227-011-0736-8","Article"
notebooks/data/springer.csv:"Fast differential box-counting algorithm on GPU","The Journal of Supercomputing","","76","1","10.1007/s11227-019-03030-1","Juan Ruiz de Miras","2020","http://link.springer.com/article/10.1007/s11227-019-03030-1","Article"
notebooks/data/springer.csv:"Computational Approach for Securing Radiology-Diagnostic Data in Connected Health Network using High-Performance GPU-Accelerated AES","Interdisciplinary Sciences: Computational Life Sciences","","9","1","10.1007/s12539-015-0140-9","A. M. AdeshinaR. Hashim","2017","http://link.springer.com/article/10.1007/s12539-015-0140-9","Article"
notebooks/data/springer.csv:"Combined kernel for fast GPU computation of Zernike moments","Journal of Real-Time Image Processing","","18","3","10.1007/s11554-020-00979-8","Zengjun ZhaoXinkai KuangYukuan ZhuYecheng LiangYubo Xuan","2021","http://link.springer.com/article/10.1007/s11554-020-00979-8","Article"
notebooks/data/springer.csv:"A novel CT image segmentation algorithm using PCNN and Sobolev gradient methods in GPU frameworks","Pattern Analysis and Applications","","23","2","10.1007/s10044-019-00837-9","Biswajit BiswasSwarup Kr. GhoshAnupam Ghosh","2020","http://link.springer.com/article/10.1007/s10044-019-00837-9","Article"
notebooks/data/springer.csv:"Massively parallel palmprint identification system using GPU","Cluster Computing","","22","3","10.1007/s10586-017-1121-z","Syed Ali TariqShahzaib IqbalMubeen GhafoorImtiaz A. TajNoman M. JafriSaad RazzaqTehseen Zia","2019","http://link.springer.com/article/10.1007/s10586-017-1121-z","Article"
notebooks/data/springer.csv:"GPU Supported Simulation of Transition-Edge Sensor Arrays","Journal of Low Temperature Physics","","200","5 - 6","10.1007/s10909-020-02450-1","M. LorenzC. KirschP. E. Merino-AlonsoP. PeilleT. DauserE. CucchettiS. J. SmithJ. Wilms","2020","http://link.springer.com/article/10.1007/s10909-020-02450-1","Article"
notebooks/data/springer.csv:"Effective naive Bayes nearest neighbor based image classification on GPU","The Journal of Supercomputing","","68","2","10.1007/s11227-013-1068-7","Lei ZhuHai JinRan ZhengXiaowen Feng","2014","http://link.springer.com/article/10.1007/s11227-013-1068-7","Article"
notebooks/data/springer.csv:"GPU-Based Blind Watermarking Scheme for 3D Multiresolution Meshes Using Unlifted Butterfly Wavelet Transformation","Circuits, Systems, and Signal Processing","","39","3","10.1007/s00034-019-01220-z","Soumaya HachichaIkbel SayahiAkram ElkefiChokri Ben AmarMourad Zaied","2020","http://link.springer.com/article/10.1007/s00034-019-01220-z","Article"
notebooks/data/springer.csv:"Efficient extraction of clustering-based feature signatures using GPU architectures","Multimedia Tools and Applications","","75","13","10.1007/s11042-015-2726-y","Martin KrulišJakub LokočTomáš Skopal","2016","http://link.springer.com/article/10.1007/s11042-015-2726-y","Article"
notebooks/data/springer.csv:"Direct private query in location-based services with GPU run time analysis","The Journal of Supercomputing","","71","2","10.1007/s11227-014-1309-4","Charles AsanyaRatan Guha","2015","http://link.springer.com/article/10.1007/s11227-014-1309-4","Article"
notebooks/data/springer.csv:"An optimized hybrid remote display protocol using GPU-assisted M-JPEG encoding and novel high-motion detection algorithm","The Journal of Supercomputing","","66","3","10.1007/s11227-013-0972-1","Biao SongWei TangTien-Dung NguyenMohammad Mehedi HassanEui Nam Huh","2013","http://link.springer.com/article/10.1007/s11227-013-0972-1","Article"
notebooks/data/springer.csv:"Acceleration techniques and evaluation on multi-core CPU, GPU and FPGA for image processing and super-resolution","Journal of Real-Time Image Processing","","16","4","10.1007/s11554-016-0619-6","Georgios GeorgisGeorge LentarisDionysios Reisis","2019","http://link.springer.com/article/10.1007/s11554-016-0619-6","Article"
notebooks/data/springer.csv:"Enhancing GPU parallelism in nature-inspired algorithms","The Journal of Supercomputing","","63","3","10.1007/s11227-012-0770-1","José M. CeciliaAndy NisbetMartyn AmosJosé M. GarcíaManuel Ujaldón","2013","http://link.springer.com/article/10.1007/s11227-012-0770-1","Article"
notebooks/data/springer.csv:"Efficient GPU algorithms for parallel decomposition of graphs into strongly connected and maximal end components","Formal Methods in System Design","","48","3","10.1007/s10703-016-0246-7","Anton WijsJoost-Pieter KatoenDragan Bošnački","2016","http://link.springer.com/article/10.1007/s10703-016-0246-7","Article"
notebooks/data/springer.csv:"Exploring the parallel capabilities of GPU: Berlekamp-Massey algorithm case study","Cluster Computing","","23","2","10.1007/s10586-019-02961-x","Hanan AliGhada M. FathyZeinab FayezWalaa Sheta","2020","http://link.springer.com/article/10.1007/s10586-019-02961-x","Article"
notebooks/data/springer.csv:"Forecasting large scale conditional volatility and covariance using neural network on GPU","The Journal of Supercomputing","","63","2","10.1007/s11227-012-0827-1","Xianggao CaiGuoming LaiXiaola Lin","2013","http://link.springer.com/article/10.1007/s11227-012-0827-1","Article"
notebooks/data/springer.csv:"Nearest Neighbor Searches on the GPU","International Journal of Parallel Programming","","40","3","10.1007/s10766-011-0184-3","Pedro LeiteJoão Marcelo TeixeiraThiago FariasBernardo ReisVeronica TeichriebJudith Kelner","2012","http://link.springer.com/article/10.1007/s10766-011-0184-3","Article"
notebooks/data/springer.csv:"gEMpicker: a highly parallel GPU-accelerated particle picking tool for cryo-electron microscopy","BMC Structural Biology","","13","1","10.1186/1472-6807-13-25","Thai V HoangXavier CavinPatrick SchultzDavid W Ritchie","2013","http://link.springer.com/article/10.1186/1472-6807-13-25","Article"
notebooks/data/springer.csv:"MSKD: multi-split KD-tree design on GPU","Multimedia Tools and Applications","","75","2","10.1007/s11042-014-2371-x","Xin YangBing YangPengjie WangDuanqing Xu","2016","http://link.springer.com/article/10.1007/s11042-014-2371-x","Article"
notebooks/data/springer.csv:"A modular lattice boltzmann solver for GPU computing processors","SeMA Journal","","59","1","10.1007/BF03322610","M. AstorinoJ. Becerra SagredoA. Quarteroni","2012","http://link.springer.com/article/10.1007/BF03322610","Article"
notebooks/data/springer.csv:"Efficient electro-magnetic analysis of a GPU bitsliced AES implementation","Cybersecurity","","3","1","10.1186/s42400-020-0045-8","Yiwen GaoYongbin ZhouWei Cheng","2020","http://link.springer.com/article/10.1186/s42400-020-0045-8","Article"
notebooks/data/springer.csv:"A CPU-GPU-based parallel search algorithm for the best differential characteristics of block ciphers","The Journal of Supercomputing","","77","10","10.1007/s11227-021-03703-w","Pei LiShihao ZhouJiageng Chen","2021","http://link.springer.com/article/10.1007/s11227-021-03703-w","Article"
notebooks/data/springer.csv:"A GPU implementation of an iterative receiver for energy saving MIMO ID-BICM systems","The Journal of Supercomputing","","70","2","10.1007/s11227-013-1081-x","Carla RamiroM. Ángeles SimarroF. J. Martínez-ZaldívarAntonio M. VidalAlberto González","2014","http://link.springer.com/article/10.1007/s11227-013-1081-x","Article"
notebooks/data/springer.csv:"GPU-Based FFT Computation for Multi-Gigabit WirelessHD Baseband Processing","EURASIP Journal on Wireless Communications and Networking","","2010","1","10.1155/2010/359081","Nicholas HinittTaskin Kocak","2010","http://link.springer.com/article/10.1155/2010/359081","Article"
notebooks/data/springer.csv:"Comparing GPU-based multi-volume ray casting techniques","Computer Science - Research and Development","","26","1 - 2","10.1007/s00450-010-0141-1","Nicole SchubertIngrid Scholl","2011","http://link.springer.com/article/10.1007/s00450-010-0141-1","Article"
notebooks/data/springer.csv:"Accelerating number theoretic transform in GPU platform for fully homomorphic encryption","The Journal of Supercomputing","","77","2","10.1007/s11227-020-03156-7","Jia-Zheng GoeyWai-Kong LeeBok-Min GoiWun-She Yap","2021","http://link.springer.com/article/10.1007/s11227-020-03156-7","Article"
notebooks/data/springer.csv:"GPU implementation of the 2D shallow water equations for the simulation of rainfall/runoff events","Environmental Earth Sciences","","74","11","10.1007/s12665-015-4215-z","Asier LacastaMario Morales-HernándezJavier MurilloPilar García-Navarro","2015","http://link.springer.com/article/10.1007/s12665-015-4215-z","Article"
notebooks/data/springer.csv:"Almost optimal column-wise prefix-sum computation on the GPU","The Journal of Supercomputing","","74","4","10.1007/s11227-018-2242-8","Hiroki TokuraToru FujitaKoji NakanoYasuaki ItoJacir L. Bordim","2018","http://link.springer.com/article/10.1007/s11227-018-2242-8","Article"
notebooks/data/springer.csv:"GPU-acceleration of waveform relaxation methods for large differential systems","Numerical Algorithms","","71","2","10.1007/s11075-015-9993-6","Dajana ConteRaffaele D’AmbrosioBeatrice Paternoster","2016","http://link.springer.com/article/10.1007/s11075-015-9993-6","Article"
notebooks/data/springer.csv:"A non-sequential refinement approach to improve word embeddings using GPU-based string matching algorithms","Cluster Computing","","24","4","10.1007/s10586-021-03321-4","Behzad NaderalvojoudAdnan Ozsoy","2021","http://link.springer.com/article/10.1007/s10586-021-03321-4","Article"
notebooks/data/springer.csv:"Caffe CNN-based classification of hyperspectral images on GPU","The Journal of Supercomputing","","75","3","10.1007/s11227-018-2300-2","Alberto S. GareaDora B. HerasFrancisco Argüello","2019","http://link.springer.com/article/10.1007/s11227-018-2300-2","Article"
notebooks/data/springer.csv:"SPH-DEM coupling method based on GPU and its application to the landslide tsunami. Part I: method and validation","Acta Geotechnica","","","","10.1007/s11440-021-01388-2","Qian ZhouWen-Jie XuXue-Yang Dong","2021","http://link.springer.com/article/10.1007/s11440-021-01388-2","Article"
notebooks/data/springer.csv:"Inertia based filtering of high resolution images using a GPU cluster","Computing and Visualization in Science","","14","4","10.1007/s00791-012-0171-2","Daniel JungblutGillian QueisserGabriel Wittum","2011","http://link.springer.com/article/10.1007/s00791-012-0171-2","Article"
notebooks/data/springer.csv:"Rapid Automated Classification of Anesthetic Depth Levels using GPU Based Parallelization of Neural Networks","Journal of Medical Systems","","39","2","10.1007/s10916-015-0197-3","Musa PekerBaha ŞenHüseyin Gürüler","2015","http://link.springer.com/article/10.1007/s10916-015-0197-3","Article"
notebooks/data/springer.csv:"GPU-parallel interpolation using the edge-direction based normal vector method for terrain triangular mesh","Journal of Real-Time Image Processing","","14","4","10.1007/s11554-016-0575-1","Jiaji WuLong DengGwanggil JeonJechang Jeong","2018","http://link.springer.com/article/10.1007/s11554-016-0575-1","Article"
notebooks/data/springer.csv:"GPU-based RFA simulation for minimally invasive cancer treatment of liver tumours","International Journal of Computer Assisted Radiology and Surgery","","12","1","10.1007/s11548-016-1469-1","Panchatcharam MariappanPhil WeirRonan FlanaganPhilip VoglreiterTuomas AlhonnoroMika PollariMichael MocheHarald BusseJurgen FuttererHorst Rupert PortugallerRoberto Blanco SequeirosMarina Kolesnik","2017","http://link.springer.com/article/10.1007/s11548-016-1469-1","Article"
notebooks/data/springer.csv:"Implementation and performance analysis of DVB-T2 rotated constellation demappers on a GPU","Analog Integrated Circuits and Signal Processing","","78","3","10.1007/s10470-013-0101-3","Stefan GrönroosKristian NybomJerker Björkqvist","2014","http://link.springer.com/article/10.1007/s10470-013-0101-3","Article"
notebooks/data/springer.csv:"Parallel ILU preconditioners in GPU computation","Soft Computing","","22","24","10.1007/s00500-017-2764-7","Yan ChenXuhong TianHui LiuZhangxin ChenBo YangWenyuan LiaoPeng ZhangRuijian HeMin Yang","2018","http://link.springer.com/article/10.1007/s00500-017-2764-7","Article"
notebooks/data/springer.csv:"Liutex-based analysis of drag force and vortex in two-phase flow past 2-D square obstacle using LBM on GPU","Journal of Hydrodynamics","","32","5","10.1007/s42241-020-0058-5","Peng-xin ChengNan GuiXing-tuan YangJi-yuan TuSheng-yao JiangHai-jun Jia","2020","http://link.springer.com/article/10.1007/s42241-020-0058-5","Article"
notebooks/data/springer.csv:"Reinforcement learning-based spatial sorting based dynamic task allocation on networked multicore GPU processors","Journal of Ambient Intelligence and Humanized Computing","","12","10","10.1007/s12652-020-02716-2","K. RameshA. Thilagavathy","2021","http://link.springer.com/article/10.1007/s12652-020-02716-2","Article"
notebooks/data/springer.csv:"On GPU–CUDA as preprocessing of fuzzy-rough data reduction by means of singular value decomposition","Soft Computing","","22","5","10.1007/s00500-017-2887-x","Salvatore CuomoArdelio GallettiLivia MarcellinoGuglielmo NavarraGerardo Toraldo","2018","http://link.springer.com/article/10.1007/s00500-017-2887-x","Article"
notebooks/data/springer.csv:"Parallel Digital Predistortion Design on Mobile GPU and Embedded Multicore CPU for Mobile Transmitters","Journal of Signal Processing Systems","","89","3","10.1007/s11265-017-1233-y","Kaipeng LiAmanullah GhaziChance TarverJani BoutellierMahmoud AbdelazizLauri AnttilaMarkku JunttiMikko ValkamaJoseph R. Cavallaro","2017","http://link.springer.com/article/10.1007/s11265-017-1233-y","Article"
notebooks/data/springer.csv:"GPU-aware resource management in heterogeneous cloud data centers","The Journal of Supercomputing","","77","11","10.1007/s11227-021-03779-4","Ashwin Kumar KulkarniB. Annappa","2021","http://link.springer.com/article/10.1007/s11227-021-03779-4","Article"
notebooks/data/springer.csv:"Parallel computing of 3D smoking simulation based on OpenCL heterogeneous platform","The Journal of Supercomputing","","61","1","10.1007/s11227-011-0652-y","Zhiyong YuanWeixin SiXiangyun LiaoZhaoliang DuanYihua DingJianhui Zhao","2012","http://link.springer.com/article/10.1007/s11227-011-0652-y","Article"
notebooks/data/springer.csv:"A novel parallel image encryption algorithm based on hybrid chaotic maps with OpenCL implementation","Soft Computing","","24","16","10.1007/s00500-020-04683-4","Lin YouErsong YangGuangyi Wang","2020","http://link.springer.com/article/10.1007/s00500-020-04683-4","Article"
notebooks/data/springer.csv:"Hybrid of genetic algorithm and local search to solve MAX-SAT problem using nVidia CUDA framework","Genetic Programming and Evolvable Machines","","10","4","10.1007/s10710-009-9091-4","Asim MunawarMohamed WahibMasaharu MunetomoKiyoshi Akama","2009","http://link.springer.com/article/10.1007/s10710-009-9091-4","Article"
notebooks/data/springer.csv:"Comparison of OpenCL and RenderScript for mobile devices","Multimedia Tools and Applications","","75","22","10.1007/s11042-016-3244-2","SeongKi KimSeok-Kyoo Kim","2016","http://link.springer.com/article/10.1007/s11042-016-3244-2","Article"
notebooks/data/springer.csv:"High performance evaluation of evolutionary-mined association rules on GPUs","The Journal of Supercomputing","","66","3","10.1007/s11227-013-0937-4","Alberto CanoJosé María LunaSebastián Ventura","2013","http://link.springer.com/article/10.1007/s11227-013-0937-4","Article"
notebooks/data/springer.csv:"GPUSVM: a comprehensive CUDA based support vector machine package","Central European Journal of Computer Science","","1","4","10.2478/s13537-011-0028-7","Qi LiRaied SalmanErik TestRobert StrackVojislav Kecman","2011","http://link.springer.com/article/10.2478/s13537-011-0028-7","Article"
notebooks/data/springer.csv:"Programming GPGPU Graph Applications with Linear Algebra Building Blocks","International Journal of Parallel Programming","","45","3","10.1007/s10766-016-0448-z","Shuai CheBradford M. BeckmannSteven K. Reinhardt","2017","http://link.springer.com/article/10.1007/s10766-016-0448-z","Article"
notebooks/data/springer.csv:"SDAM: a combined stack distance-analytical modeling approach to estimate memory performance in GPUs","The Journal of Supercomputing","","77","5","10.1007/s11227-020-03483-9","Mohsen KianiAmir Rajabzadeh","2021","http://link.springer.com/article/10.1007/s11227-020-03483-9","Article"
notebooks/data/springer.csv:"An efficient parallelization technique for x264 encoder on heterogeneous platforms consisting of CPUs and GPUs","Journal of Real-Time Image Processing","","9","1","10.1007/s11554-012-0317-y","Youngsub KoYoungmin YiSoonhoi Ha","2014","http://link.springer.com/article/10.1007/s11554-012-0317-y","Article"
notebooks/data/springer.csv:"GPU implementation of a road sign detector based on particle swarm optimization","Evolutionary Intelligence","","3","3 - 4","10.1007/s12065-010-0043-y","Luca MussiStefano CagnoniElena CardarelliFabio DaolioPaolo MediciPier Paolo Porta","2010","http://link.springer.com/article/10.1007/s12065-010-0043-y","Article"
notebooks/data/springer.csv:"A Resource Selection System for Cycle Stealing in GPU Grids","Journal of Grid Computing","","6","4","10.1007/s10723-008-9099-7","Y. KotaniF. InoK. Hagihara","2008","http://link.springer.com/article/10.1007/s10723-008-9099-7","Article"
notebooks/data/springer.csv:"Simultaneous CPU–GPU Execution of Data Parallel Algorithmic Skeletons","International Journal of Parallel Programming","","46","1","10.1007/s10766-016-0483-9","Fabian WredeSteffen Ernsting","2018","http://link.springer.com/article/10.1007/s10766-016-0483-9","Article"
notebooks/data/springer.csv:"Real-time anomaly detection in hyperspectral images using multivariate normal mixture models and GPU processing","Journal of Real-Time Image Processing","","4","3","10.1007/s11554-008-0105-x","Yuliya TarabalkaTrym Vegard HaavardsholmIngebjørg KåsenTorbjørn Skauli","2009","http://link.springer.com/article/10.1007/s11554-008-0105-x","Article"
notebooks/data/springer.csv:"An Infrastructure for Tackling Input-Sensitivity of GPU Program Optimizations","International Journal of Parallel Programming","","41","6","10.1007/s10766-012-0236-3","Xipeng ShenYixun LiuEddy Z. ZhangPoornima Bhamidipati","2013","http://link.springer.com/article/10.1007/s10766-012-0236-3","Article"
notebooks/data/springer.csv:"Tracing and Profiling Machine Learning Dataflow Applications on GPU","International Journal of Parallel Programming","","47","5 - 6","10.1007/s10766-019-00630-5","Pierre ZinsMichel Dagenais","2019","http://link.springer.com/article/10.1007/s10766-019-00630-5","Article"
notebooks/data/springer.csv:"Integration of GPU Computing in a Software Radio Environment","Journal of Signal Processing Systems","","69","1","10.1007/s11265-011-0639-1","Pierre-Henri HorreinChristine HennebertFrédéric Pétrot","2012","http://link.springer.com/article/10.1007/s11265-011-0639-1","Article"
notebooks/data/springer.csv:"Evaluations of OpenCL-written tsunami simulation on FPGA and comparison with GPU implementation","The Journal of Supercomputing","","74","6","10.1007/s11227-018-2315-8","Fumiya KonoNaohito NakasatoKensaku HayashiAlexander VazheninStanislav Sedukhin","2018","http://link.springer.com/article/10.1007/s11227-018-2315-8","Article"
notebooks/data/springer.csv:"Impact of data layouts on the efficiency of GPU-accelerated IDW interpolation","SpringerPlus","","5","1","10.1186/s40064-016-1731-6","Gang MeiHong Tian","2016","http://link.springer.com/article/10.1186/s40064-016-1731-6","Article"
notebooks/data/springer.csv:"Exploiting task and data parallelism for advanced video coding on hybrid CPU + GPU platforms","Journal of Real-Time Image Processing","","11","3","10.1007/s11554-013-0357-y","Svetislav MomcilovicNuno RomaLeonel Sousa","2016","http://link.springer.com/article/10.1007/s11554-013-0357-y","Article"
notebooks/data/springer.csv:"Two-Dimensional Compact Third-Order Polynomial Reconstructions. Solving Nonconservative Hyperbolic Systems Using GPUs","Journal of Scientific Computing","","48","1 - 3","10.1007/s10915-011-9470-x","José M. GallardoSergio OrtegaMarc de la AsunciónJosé Miguel Mantas","2011","http://link.springer.com/article/10.1007/s10915-011-9470-x","Article"
notebooks/data/springer.csv:"A middleware for efficient stream processing in CUDA","Computer Science - Research and Development","","25","1 - 2","10.1007/s00450-010-0107-3","Shinta NakagawaFumihiko InoKenichi Hagihara","2010","http://link.springer.com/article/10.1007/s00450-010-0107-3","Article"
notebooks/data/springer.csv:"CUDASW++2.0: enhanced Smith-Waterman protein database search on CUDA-enabled GPUs based on SIMT and virtualized SIMD abstractions","BMC Research Notes","","3","1","10.1186/1756-0500-3-93","Yongchao LiuBertil SchmidtDouglas L Maskell","2010","http://link.springer.com/article/10.1186/1756-0500-3-93","Article"
notebooks/data/springer.csv:"Solving finite difference linear systems on GPUs: CUDA based Parallel Explicit Preconditioned Biconjugate Conjugate Gradient type Methods","The Journal of Supercomputing","","61","3","10.1007/s11227-011-0619-z","G. A. GravvanisC. K. Filelis-PapadopoulosK. M. Giannoutakis","2012","http://link.springer.com/article/10.1007/s11227-011-0619-z","Article"
notebooks/data/springer.csv:"A framework for accelerating local feature extraction with OpenCL on multi-core CPUs and co-processors","Journal of Real-Time Image Processing","","16","4","10.1007/s11554-016-0576-0","Konrad MorenDiana Göhringer","2019","http://link.springer.com/article/10.1007/s11554-016-0576-0","Article"
notebooks/data/springer.csv:"A dynamic acceleration method for remote sensing image processing based on CUDA","Wireless Networks","","27","6","10.1007/s11276-021-02715-x","Xianyu ZuoZhe ZhangBaojun QiaoJunfeng TianLiming ZhouYunzhou Zhang","2021","http://link.springer.com/article/10.1007/s11276-021-02715-x","Article"
notebooks/data/springer.csv:"A first look at integrated GPUs for green high-performance computing","Computer Science - Research and Development","","25","3 - 4","10.1007/s00450-010-0128-y","T. R. W. ScoglandH. LinW. Feng","2010","http://link.springer.com/article/10.1007/s00450-010-0128-y","Article"
notebooks/data/springer.csv:"Multiscale and local search methods for real time region tracking with particle filters: local search driven by adaptive scale estimation on GPUs","Machine Vision and Applications","","21","1","10.1007/s00138-008-0140-4","Raúl CabidoAntonio S. MontemayorJuan José PantrigoBryson R. Payne","2008","http://link.springer.com/article/10.1007/s00138-008-0140-4","Article"
notebooks/data/springer.csv:"CRState: checkpoint/restart of OpenCL program for in-kernel applications","The Journal of Supercomputing","","77","6","10.1007/s11227-020-03460-2","Genlang ChenJiajian ZhangZufang ZhuQiangqiang JiangHai JiangChaoyi Pang","2021","http://link.springer.com/article/10.1007/s11227-020-03460-2","Article"
notebooks/data/springer.csv:"Exploiting OpenMP and OpenACC to accelerate a geometric approach to molecular docking in heterogeneous HPC nodes","The Journal of Supercomputing","","75","7","10.1007/s11227-019-02875-w","Emanuele VitaliDavide GadioliGianluca PalermoAndrea BeccariCarlo CavazzoniCristina Silvano","2019","http://link.springer.com/article/10.1007/s11227-019-02875-w","Article"
notebooks/data/springer.csv:"A quantitative evaluation of unified memory in GPUs","The Journal of Supercomputing","","76","4","10.1007/s11227-019-03079-y","Qi YuBruce ChildersLibo HuangCheng QianZhiying Wang","2020","http://link.springer.com/article/10.1007/s11227-019-03079-y","Article"
notebooks/data/springer.csv:"A Fuzzy Neural Network Based Dynamic Data Allocation Model on Heterogeneous Multi-GPUs for Large-scale Computations","International Journal of Automation and Computing","","15","2","10.1007/s11633-018-1120-4","Chao-Long ZhangYuan-Ping XuZhi-Jie XuJia HeJing WangJian-Hua Adu","2018","http://link.springer.com/article/10.1007/s11633-018-1120-4","Article"
notebooks/data/springer.csv:"On the effect of using rCUDA to provide CUDA acceleration to Xen virtual machines","Cluster Computing","","22","1","10.1007/s10586-018-2845-0","Javier PradesCarlos ReañoFederico Silla","2019","http://link.springer.com/article/10.1007/s10586-018-2845-0","Article"
notebooks/data/springer.csv:"DecGPU: distributed error correction on massively parallel graphics processing units using CUDA and MPI","BMC Bioinformatics","","12","1","10.1186/1471-2105-12-85","Yongchao LiuBertil SchmidtDouglas L Maskell","2011","http://link.springer.com/article/10.1186/1471-2105-12-85","Article"
notebooks/data/springer.csv:"GPU-based normalized cuts for road extraction using satellite imagery","Journal of Earth System Science","","123","8","10.1007/s12040-014-0513-1","J SENTHILNATHS SINDHUS N OMKAR","2014","http://link.springer.com/article/10.1007/s12040-014-0513-1","Article"
notebooks/data/springer.csv:"Object oriented framework for real-time image processing on GPU","Multimedia Tools and Applications","","70","3","10.1007/s11042-013-1440-x","Nicolas SeillerWilliemNitin SinghalIn Kyu Park","2014","http://link.springer.com/article/10.1007/s11042-013-1440-x","Article"
notebooks/data/springer.csv:"Vectorized algorithm for multidimensional Monte Carlo integration on modern GPU, CPU and MIC architectures","The Journal of Supercomputing","","74","2","10.1007/s11227-017-2172-x","Przemysław Stpiczyński","2018","http://link.springer.com/article/10.1007/s11227-017-2172-x","Article"
notebooks/data/springer.csv:"Software for numerical simulation of convection in spherical shells for hybrid CPU/GPU computing systems","Mathematical Models and Computer Simulations","","7","3","10.1134/S2070048215030047","I. V. BychinV. A. GalkinT. V. GavrilenkoA. V. GorelikovA. V. Ryakhovsky","2015","http://link.springer.com/article/10.1134/S2070048215030047","Article"
notebooks/data/springer.csv:"GPU-accelerated denoising of 3D magnetic resonance images","Journal of Real-Time Image Processing","","13","4","10.1007/s11554-014-0436-8","Mark HowisonE. Wes Bethel","2017","http://link.springer.com/article/10.1007/s11554-014-0436-8","Article"
notebooks/data/springer.csv:"Parallel regressions for variable selection using GPU","Computing","","99","3","10.1007/s00607-016-0487-8","Lauro Cássio Martins de PaulaAnderson S. SoaresTelma W. L. SoaresArlindo R. G. FilhoClarimar J. CoelhoAlexandre C. B. DelbemWellington S. Martins","2017","http://link.springer.com/article/10.1007/s00607-016-0487-8","Article"
notebooks/data/springer.csv:"CPU/GPU computing for a multi-block structured grid based high-order flow solver on a large heterogeneous system","Cluster Computing","","17","2","10.1007/s10586-013-0332-1","Wei CaoChuan-fu XuZheng-hua WangLu YaoHua-yong Liu","2014","http://link.springer.com/article/10.1007/s10586-013-0332-1","Article"
notebooks/data/springer.csv:"A fast single-image super-resolution method implemented with CUDA","Journal of Real-Time Image Processing","","16","1","10.1007/s11554-018-0774-z","Yuan YuanXiaomin YangWei WuHu LiYiguang LiuKai Liu","2019","http://link.springer.com/article/10.1007/s11554-018-0774-z","Article"
notebooks/data/springer.csv:"CUDA-NP: Realizing Nested Thread-Level Parallelism in GPGPU Applications","Journal of Computer Science and Technology","","30","1","10.1007/s11390-015-1500-y","Yi YangChao LiHuiyang Zhou","2015","http://link.springer.com/article/10.1007/s11390-015-1500-y","Article"
notebooks/data/springer.csv:"Iris recognition in unconstrained environment on graphic processing units with CUDA","Artificial Intelligence Review","","53","5","10.1007/s10462-019-09776-7","Ali NoruziMahmoud MahloujiAli Shahidinejad","2020","http://link.springer.com/article/10.1007/s10462-019-09776-7","Article"
notebooks/data/springer.csv:"Relational Learning with GPUs: Accelerating Rule Coverage","International Journal of Parallel Programming","","44","3","10.1007/s10766-015-0364-7","Carlos Alberto Martínez-AngelesHaicheng WuInês DutraVítor Santos CostaJorge Buenabad-Chávez","2016","http://link.springer.com/article/10.1007/s10766-015-0364-7","Article"
notebooks/data/springer.csv:"Scaling database performance on GPUs","Information Systems Frontiers","","14","4","10.1007/s10796-011-9322-0","Yue-Shan ChangRuey-Kai SheuShyan-Ming YuanJyn-Jie Hsu","2012","http://link.springer.com/article/10.1007/s10796-011-9322-0","Article"
notebooks/data/springer.csv:"The spectral cell method for wave propagation in heterogeneous materials simulated on multiple GPUs and CPUs","Computational Mechanics","","63","5","10.1007/s00466-018-1623-4","Farshid MossaibyMeysam JoulaianAlexander Düster","2019","http://link.springer.com/article/10.1007/s00466-018-1623-4","Article"
notebooks/data/springer.csv:"SWIFOLD: Smith-Waterman implementation on FPGA with OpenCL for long DNA sequences","BMC Systems Biology","","12","5","10.1186/s12918-018-0614-6","Enzo RucciCarlos GarciaGuillermo BotellaArmando De GiustiMarcelo NaioufManuel Prieto-Matias","2018","http://link.springer.com/article/10.1186/s12918-018-0614-6","Article"
notebooks/data/springer.csv:"High-performance blob-based iterative three-dimensional reconstruction in electron tomography using multi-GPUs","BMC Bioinformatics","","13","10","10.1186/1471-2105-13-S10-S4","Xiaohua WanFa ZhangQi ChuZhiyong Liu","2012","http://link.springer.com/article/10.1186/1471-2105-13-S10-S4","Article"
notebooks/data/springer.csv:"An fast simulation tool for fluid animation in VR application based on GPUs","Multimedia Tools and Applications","","79","23 - 24","10.1007/s11042-019-08002-4","Fengquan ZhangQiuming WeiLiuqing Xu","2020","http://link.springer.com/article/10.1007/s11042-019-08002-4","Article"
notebooks/data/springer.csv:"Optimized OpenCL™ kernels for frequency domain image high-boost filters using image vectorization technique","SN Applied Sciences","","1","11","10.1007/s42452-019-1445-9","Ashutosh SatapathyL. M. Jenila Livingston","2019","http://link.springer.com/article/10.1007/s42452-019-1445-9","Article"
notebooks/data/springer.csv:"Fast and accurate protein substructure searching with simulated annealing and GPUs","BMC Bioinformatics","","11","1","10.1186/1471-2105-11-446","Alex D StivalaPeter J StuckeyAnthony I Wirth","2010","http://link.springer.com/article/10.1186/1471-2105-11-446","Article"
notebooks/data/springer.csv:"Parallel mutual information estimation for inferring gene regulatory networks on GPUs","BMC Research Notes","","4","1","10.1186/1756-0500-4-189","Haixiang ShiBertil SchmidtWeiguo LiuWolfgang Müller-Wittig","2011","http://link.springer.com/article/10.1186/1756-0500-4-189","Article"
notebooks/data/springer.csv:"A Credit-Based Load-Balance-Aware CTA Scheduling Optimization Scheme in GPGPU","International Journal of Parallel Programming","","44","1","10.1007/s10766-014-0318-5","Yulong YuXubin HeHe GuoYuxin WangXin Chen","2016","http://link.springer.com/article/10.1007/s10766-014-0318-5","Article"
notebooks/data/springer.csv:"Performance evaluation of Unified Memory with prefetching and oversubscription for selected parallel CUDA applications on NVIDIA Pascal and Volta GPUs","The Journal of Supercomputing","","75","11","10.1007/s11227-019-02966-8","Marcin KnapPaweł Czarnul","2019","http://link.springer.com/article/10.1007/s11227-019-02966-8","Article"
notebooks/data/springer.csv:"Implementation of a high-throughput low-latency polyphase channelizer on GPUs","EURASIP Journal on Advances in Signal Processing","","2014","1","10.1186/1687-6180-2014-141","Scott C KimShuvra S Bhattacharyya","2014","http://link.springer.com/article/10.1186/1687-6180-2014-141","Article"
notebooks/data/springer.csv:"PRODA: improving parallel programs on GPUs through dependency analysis","Cluster Computing","","22","1","10.1007/s10586-017-1295-4","Xiong WeiMing HuTao PengMinghua JiangZhiying WangXiao Qin","2019","http://link.springer.com/article/10.1007/s10586-017-1295-4","Article"
notebooks/data/springer.csv:"Algorithms and framework for computing 2-body statistics on GPUs","Distributed and Parallel Databases","","37","4","10.1007/s10619-018-7238-0","Napath PitaksiriananZhila Nouri LewisYi-Cheng Tu","2019","http://link.springer.com/article/10.1007/s10619-018-7238-0","Article"
notebooks/data/springer.csv:"Revised simplex algorithm for linear programming on GPUs with CUDA","Multimedia Tools and Applications","","77","22","10.1007/s11042-018-5947-z","Lili HeHongtao BaiYu JiangDantong OuyangShanshan Jiang","2018","http://link.springer.com/article/10.1007/s11042-018-5947-z","Article"
notebooks/data/springer.csv:"High resolution topology optimization using graphics processing units (GPUs)","Structural and Multidisciplinary Optimization","","49","2","10.1007/s00158-013-0980-z","Vivien J. ChallisAnthony P. RobertsJoseph F. Grotowski","2014","http://link.springer.com/article/10.1007/s00158-013-0980-z","Article"
notebooks/data/springer.csv:"Real-Time Big Data Stream Processing Using GPU with Spark Over Hadoop Ecosystem","International Journal of Parallel Programming","","46","3","10.1007/s10766-017-0513-2","M. Mazhar RathoreHojae SonAwais AhmadAnand PaulGwanggil Jeon","2018","http://link.springer.com/article/10.1007/s10766-017-0513-2","Article"
notebooks/data/springer.csv:"SIMD Monte-Carlo Numerical Simulations Accelerated on GPU and Xeon Phi","International Journal of Parallel Programming","","46","3","10.1007/s10766-017-0509-y","Bastien PlazollesDidier El BazMartin SpelVincent RivolaPascal Gegout","2018","http://link.springer.com/article/10.1007/s10766-017-0509-y","Article"
notebooks/data/springer.csv:"Parallel performance analysis of coupled heat and fluid flow in parallel plate channel using CUDA","Computational and Applied Mathematics","","39","3","10.1007/s40314-020-01244-1","Asif AfzalZahid AnsariM. K. Ramis","2020","http://link.springer.com/article/10.1007/s40314-020-01244-1","Article"
notebooks/data/springer.csv:"Elastodynamic full waveform inversion on GPUs with time-space tiling and wavefield reconstruction","The Journal of Supercomputing","","77","3","10.1007/s11227-020-03352-5","Ole Edvard AakerEspen Birger RaknesBørge Arntsen","2021","http://link.springer.com/article/10.1007/s11227-020-03352-5","Article"
notebooks/data/springer.csv:"3D Tomography Back-Projection Parallelization on Intel FPGAs Using OpenCL","Journal of Signal Processing Systems","","91","7","10.1007/s11265-018-1403-6","Maxime MartelliNicolas GacAlain MérigotCyrille Enderli","2019","http://link.springer.com/article/10.1007/s11265-018-1403-6","Article"
notebooks/data/springer.csv:"Interval-based performance modeling for the all-pairs-shortest-path problem on GPUs","The Journal of Supercomputing","","71","11","10.1007/s11227-015-1514-9","Jörg DümmlerSebastian Egerland","2015","http://link.springer.com/article/10.1007/s11227-015-1514-9","Article"
notebooks/data/springer.csv:"Highly interactive computational steering for coupled 3D flow problems utilizing multiple GPUs","Computing and Visualization in Science","","13","7","10.1007/s00791-010-0151-3","Jan LinxweilerManfred KrafczykJonas Tölke","2010","http://link.springer.com/article/10.1007/s00791-010-0151-3","Article"
notebooks/data/springer.csv:"Performance evaluation of unified memory and dynamic parallelism for selected parallel CUDA applications","The Journal of Supercomputing","","73","12","10.1007/s11227-017-2091-x","Łukasz JarząbekPaweł Czarnul","2017","http://link.springer.com/article/10.1007/s11227-017-2091-x","Article"
notebooks/data/springer.csv:"Gravitational search algorithm using CUDA: a case study in high-performance metaheuristics","The Journal of Supercomputing","","71","4","10.1007/s11227-014-1360-1","Amirreza ZarrabiKhairulmizam SamsudinEttikan K. Karuppiah","2015","http://link.springer.com/article/10.1007/s11227-014-1360-1","Article"
notebooks/data/springer.csv:"Implementation of algorithms with a fine-grained parallelism on GPUs","Numerical Analysis and Applications","","4","1","10.1134/S1995423911010058","K. V. Kalgin","2011","http://link.springer.com/article/10.1134/S1995423911010058","Article"
notebooks/data/springer.csv:"A preliminary evaluation of OpenACC implementations","The Journal of Supercomputing","","65","3","10.1007/s11227-012-0853-z","Ruymán ReyesIván LópezJuan J. FumeroFrancisco de Sande","2013","http://link.springer.com/article/10.1007/s11227-012-0853-z","Article"
notebooks/data/springer.csv:"Biased solution of integral illumination equation via irradiance caching and path tracing on GPUs","Programming and Computer Software","","37","5","10.1134/S0361768811050021","V. A. FrolovA. A. KharlamovA. V. Ignatenko","2011","http://link.springer.com/article/10.1134/S0361768811050021","Article"
notebooks/data/springer.csv:"Parallel implementations of frame rate up-conversion algorithm using OpenCL on heterogeneous computing devices","Multimedia Tools and Applications","","78","7","10.1007/s11042-018-6532-1","Huming ZhuDuo WangPeng ZhangZheng LuoLicheng JiaoHong Han","2019","http://link.springer.com/article/10.1007/s11042-018-6532-1","Article"
notebooks/data/springer.csv:"Protein alignment algorithms with an efficient backtracking routine on multiple GPUs","BMC Bioinformatics","","12","1","10.1186/1471-2105-12-181","Jacek BlazewiczWojciech FrohmbergMichal KierzynkaErwin PeschPawel Wojciechowski","2011","http://link.springer.com/article/10.1186/1471-2105-12-181","Article"
notebooks/data/springer.csv:"Accelerating the scoring module of mass spectrometry-based peptide identification using GPUs","BMC Bioinformatics","","15","1","10.1186/1471-2105-15-121","You LiHao ChiLeihao XiaXiaowen Chu","2014","http://link.springer.com/article/10.1186/1471-2105-15-121","Article"
notebooks/data/springer.csv:"Real-time implementation of remotely sensed hyperspectral image unmixing on GPUs","Journal of Real-Time Image Processing","","10","3","10.1007/s11554-012-0269-2","Sergio SánchezRui RamalhoLeonel SousaAntonio Plaza","2015","http://link.springer.com/article/10.1007/s11554-012-0269-2","Article"
notebooks/data/springer.csv:"Memory bandwidth optimization of SpMV on GPGPUs","Frontiers of Computer Science","","9","3","10.1007/s11704-014-4127-1","Chenggang Clarence YanHui YuWeizhi XuYingping ZhangBochuan ChenZhu TianYuxuan WangJian Yin","2015","http://link.springer.com/article/10.1007/s11704-014-4127-1","Article"
notebooks/data/springer.csv:"Implementation of a Multirate Resampler for Multi-carrier Systems on GPUs","Journal of Signal Processing Systems","","89","3","10.1007/s11265-017-1239-5","Scott C. KimShuvra S. Bhattacharyya","2017","http://link.springer.com/article/10.1007/s11265-017-1239-5","Article"
notebooks/data/springer.csv:"GPGPU Based Parallel Implementation of Spectral Correlation Density Function","Journal of Signal Processing Systems","","92","1","10.1007/s11265-019-01448-7","Scott MarshallGarrett VanhoyAli AkogluTamal BoseBo Ryu","2020","http://link.springer.com/article/10.1007/s11265-019-01448-7","Article"
notebooks/data/springer.csv:"Virtualizing high-end GPGPUs on ARM clusters for the next generation of high performance cloud computing","Cluster Computing","","17","1","10.1007/s10586-013-0341-0","Raffaele MontellaGiulio GiuntaGiuliano Laccetti","2014","http://link.springer.com/article/10.1007/s10586-013-0341-0","Article"
notebooks/data/springer.csv:"Exploiting GPUs with the Super Instruction Architecture","International Journal of Parallel Programming","","44","2","10.1007/s10766-014-0319-4","Nakul JindalVictor LotrichErik DeumensBeverly A. Sanders","2016","http://link.springer.com/article/10.1007/s10766-014-0319-4","Article"
notebooks/data/springer.csv:"Accelerating exact and approximate inference for (distributed) discrete optimization with GPUs","Constraints","","23","1","10.1007/s10601-017-9274-1","Ferdinando FiorettoEnrico PontelliWilliam YeohRina Dechter","2018","http://link.springer.com/article/10.1007/s10601-017-9274-1","Article"
notebooks/data/springer.csv:"Parallel bitsliced AES through PHAST: a single-source high-performance library for multi-cores and GPUs","Journal of Cryptographic Engineering","","9","2","10.1007/s13389-017-0175-4","Biagio PeccerilloSandro BartoliniÇetin Kaya Koç","2019","http://link.springer.com/article/10.1007/s13389-017-0175-4","Article"
notebooks/data/springer.csv:"O2WebCL: an automatic OpenCL-to-WebCL translator for high performance web computing","The Journal of Supercomputing","","71","6","10.1007/s11227-014-1260-4","Myeongjin ChoYoungsun HanMinseong KimSeon Wook Kim","2015","http://link.springer.com/article/10.1007/s11227-014-1260-4","Article"
notebooks/data/springer.csv:"Understanding the Efficiency of kD-tree Ray-Traversal Techniques over a GPGPU Architecture","International Journal of Parallel Programming","","40","3","10.1007/s10766-011-0186-1","Artur SantosJoão Marcelo TeixeiraThiago FariasVeronica TeichriebJudith Kelner","2012","http://link.springer.com/article/10.1007/s10766-011-0186-1","Article"
notebooks/data/springer.csv:"An FPGA accelerator for PatchMatch multi-view stereo using OpenCL","Journal of Real-Time Image Processing","","17","2","10.1007/s11554-017-0745-9","Shunsuke TatsumiMasanori HariyamaKoichi ItoTakafumi Aoki","2020","http://link.springer.com/article/10.1007/s11554-017-0745-9","Article"
notebooks/data/springer.csv:"Efficient scheduling of streams on GPGPUs","The Journal of Supercomputing","","76","11","10.1007/s11227-020-03209-x","Mohamad Beheshti RouiS. Kazem ShekoftehHamid NooriAhad Harati","2020","http://link.springer.com/article/10.1007/s11227-020-03209-x","Article"
notebooks/data/springer.csv:"A high-performance batched matrix multiplication framework for GPUs under unbalanced input distribution","The Journal of Supercomputing","","","","10.1007/s11227-021-03936-9","Ruimin WangZhiwei YangHao XuLu Lu","2021","http://link.springer.com/article/10.1007/s11227-021-03936-9","Article"
notebooks/data/springer.csv:"CUDAQuat: new parallel framework for fast computation of quaternion moments for color images applications","Cluster Computing","","24","3","10.1007/s10586-021-03271-x","Khalid M. HosnyMohamed M. DarwishAhmad SalahKenli LiAmr M. Abdelatif","2021","http://link.springer.com/article/10.1007/s10586-021-03271-x","Article"
notebooks/data/springer.csv:"Accelerating MRI reconstruction via three-dimensional dual-dictionary learning using CUDA","The Journal of Supercomputing","","71","7","10.1007/s11227-015-1386-z","Jiansen LiJianqi SunYing SongJun Zhao","2015","http://link.springer.com/article/10.1007/s11227-015-1386-z","Article"
notebooks/data/springer.csv:"CUDASW++: optimizing Smith-Waterman sequence database searches for CUDA-enabled graphics processing units","BMC Research Notes","","2","1","10.1186/1756-0500-2-73","Yongchao LiuDouglas L MaskellBertil Schmidt","2009","http://link.springer.com/article/10.1186/1756-0500-2-73","Article"
notebooks/data/springer.csv:"High performance memetic algorithm particle filter for multiple object tracking on modern GPUs","Soft Computing","","16","2","10.1007/s00500-011-0715-2","Raúl CabidoAntonio S. MontemayorJuan J. Pantrigo","2012","http://link.springer.com/article/10.1007/s00500-011-0715-2","Article"
notebooks/data/springer.csv:"HGP4CNN: an efficient parallelization framework for training convolutional neural networks on modern GPUs","The Journal of Supercomputing","","77","11","10.1007/s11227-021-03746-z","Hao FuShanjiang TangBingsheng HeCe YuJizhou Sun","2021","http://link.springer.com/article/10.1007/s11227-021-03746-z","Article"
notebooks/data/springer.csv:"Parallel LDPC Decoding on GPUs Using a Stream-Based Computing Approach","Journal of Computer Science and Technology","","24","5","10.1007/s11390-009-9266-8","Gabriel FalcãoShinichi YamagiwaVitor SilvaLeonel Sousa","2009","http://link.springer.com/article/10.1007/s11390-009-9266-8","Article"
notebooks/data/springer.csv:"Exploiting Task Parallelism with OpenCL: A Case Study","Journal of Signal Processing Systems","","91","1","10.1007/s11265-018-1416-1","Pekka JääskeläinenVille KorhonenMatias KoskelaJarmo TakalaKaren EgiazarianAram DanielyanCristóvão CruzJames PriceSimon McIntosh-Smith","2019","http://link.springer.com/article/10.1007/s11265-018-1416-1","Article"
notebooks/data/springer.csv:"Efficient application of GPGPU for lava flow hazard mapping","The Journal of Supercomputing","","65","2","10.1007/s11227-013-0949-0","Donato D’AmbrosioGiuseppe FilipponeDavide MaroccoRocco RongoWilliam Spataro","2013","http://link.springer.com/article/10.1007/s11227-013-0949-0","Article"
notebooks/data/springer.csv:"Application-aware NoC management in GPUs multitasking","The Journal of Supercomputing","","75","8","10.1007/s11227-018-2694-x","Zhen XuXia ZhaoZhiying WangCanqun Yang","2019","http://link.springer.com/article/10.1007/s11227-018-2694-x","Article"
notebooks/data/springer.csv:"Fast network centrality analysis using GPUs","BMC Bioinformatics","","12","1","10.1186/1471-2105-12-149","Zhiao ShiBing Zhang","2011","http://link.springer.com/article/10.1186/1471-2105-12-149","Article"
notebooks/data/springer.csv:"Parallel strategies for 2D Discrete Wavelet Transform in shared memory systems and GPUs","The Journal of Supercomputing","","64","1","10.1007/s11227-012-0750-5","V. GalianoO. LópezM. P. MalumbresH. Migallón","2013","http://link.springer.com/article/10.1007/s11227-012-0750-5","Article"
notebooks/data/springer.csv:"A CUDA-powered method for the feature extraction and unsupervised analysis of medical images","The Journal of Supercomputing","","77","8","10.1007/s11227-020-03565-8","Leonardo RundoAndrea TangherloniPaolo CazzanigaMatteo MistriSimone GalimbertiRamona WoitekEvis SalaGiancarlo MauriMarco S. Nobile","2021","http://link.springer.com/article/10.1007/s11227-020-03565-8","Article"
notebooks/data/springer.csv:"DQN-based OpenCL workload partition for performance optimization","The Journal of Supercomputing","","75","8","10.1007/s11227-019-02766-0","Sanghyun ParkTaeweon Suh","2019","http://link.springer.com/article/10.1007/s11227-019-02766-0","Article"
notebooks/data/springer.csv:"Three-dimensional multi-phase-field simulation of eutectoid alloy based on OpenCL parallel","China Foundry","","18","3","10.1007/s41230-021-0123-x","Chang-sheng ZhuYu-jie LiFang-lan MaLi FengPeng Lei","2021","http://link.springer.com/article/10.1007/s41230-021-0123-x","Article"
notebooks/data/springer.csv:"Accelerating metagenomic read classification on CUDA-enabled GPUs","BMC Bioinformatics","","18","1","10.1186/s12859-016-1434-6","Robin KobusChristian HundtAndré MüllerBertil Schmidt","2017","http://link.springer.com/article/10.1186/s12859-016-1434-6","Article"
notebooks/data/springer.csv:"A statistical performance analyzer framework for OpenCL kernels on Nvidia GPUs","The Journal of Supercomputing","","71","8","10.1007/s11227-014-1338-z","Ali KaramiFarshad KhunjushSeyyed Ali Mirsoleimani","2015","http://link.springer.com/article/10.1007/s11227-014-1338-z","Article"
notebooks/data/springer.csv:"Simulation of one-layer shallow water systems on multicore and CUDA architectures","The Journal of Supercomputing","","58","2","10.1007/s11227-010-0406-2","Marc de la AsunciónJosé M. MantasManuel J. Castro","2011","http://link.springer.com/article/10.1007/s11227-010-0406-2","Article"
notebooks/data/springer.csv:"On-line range images registration with GPGPU","Opto-Electronics Review","","21","1","10.2478/s11772-013-0074-x","J. BędkowskiJ. Naruniec","2013","http://link.springer.com/article/10.2478/s11772-013-0074-x","Article"
notebooks/data/springer.csv:"ginSODA: massive parallel integration of stiff ODE systems on GPUs","The Journal of Supercomputing","","75","12","10.1007/s11227-018-2549-5","Marco S. NobilePaolo CazzanigaDaniela BesozziGiancarlo Mauri","2019","http://link.springer.com/article/10.1007/s11227-018-2549-5","Article"
notebooks/data/springer.csv:"HCudaBLAST: an implementation of BLAST on Hadoop and Cuda","Journal of Big Data","","4","1","10.1186/s40537-017-0102-7","Nilay KhareAlind KhareFarhan Khan","2017","http://link.springer.com/article/10.1186/s40537-017-0102-7","Article"
notebooks/data/springer.csv:"GPUs and chaos: a new true random number generator","Nonlinear Dynamics","","82","4","10.1007/s11071-015-2287-7","Je Sen TehAzman SamsudinMishal Al-MazrooieAmir Akhavan","2015","http://link.springer.com/article/10.1007/s11071-015-2287-7","Article"
notebooks/data/springer.csv:"Monte Carlo Simulation of the Solar Radiation Transfer in a Cloudy Atmosphere with the Use of Graphic Processor and NVIDIA CUDA Technology","Atmospheric and Oceanic Optics","","31","2","10.1134/S1024856018020100","T. V. Russkova","2018","http://link.springer.com/article/10.1134/S1024856018020100","Article"
notebooks/data/springer.csv:"A CUDA approach to compute perishable inventory control policies using value iteration","The Journal of Supercomputing","","75","3","10.1007/s11227-018-2692-z","G. OrtegaE. M. T. HendrixI. García","2019","http://link.springer.com/article/10.1007/s11227-018-2692-z","Article"
notebooks/data/springer.csv:"A Hybrid Circular Queue Method for Iterative Stencil Computations on GPUs","Journal of Computer Science and Technology","","27","1","10.1007/s11390-012-1206-3","Yang YangHui-Min CuiXiao-Bing FengJing-Ling Xue","2012","http://link.springer.com/article/10.1007/s11390-012-1206-3","Article"
notebooks/data/springer.csv:"Parallel Bayesian ARTMAP and Its OpenCL Implementation","Neural Processing Letters","","47","2","10.1007/s11063-017-9663-x","István LőrentzRăzvan AndonieLucian M. Sasu","2018","http://link.springer.com/article/10.1007/s11063-017-9663-x","Article"
notebooks/data/springer.csv:"A massively parallel algorithm for Bordered Almost Block Diagonal Systems on GPUs","Numerical Algorithms","","86","3","10.1007/s11075-020-00931-8","M. DessoleF. Marcuzzi","2021","http://link.springer.com/article/10.1007/s11075-020-00931-8","Article"
notebooks/data/springer.csv:"Accelerating calculations of RNA secondary structure partition functions using GPUs","Algorithms for Molecular Biology","","8","1","10.1186/1748-7188-8-29","Harry A SternDavid H Mathews","2013","http://link.springer.com/article/10.1186/1748-7188-8-29","Article"
notebooks/data/springer.csv:"Speed and accuracy improvement of higher-order epistasis detection on CUDA-enabled GPUs","Cluster Computing","","20","3","10.1007/s10586-017-0938-9","Daniel JüngerChristian HundtJorge González DomínguezBertil Schmidt","2017","http://link.springer.com/article/10.1007/s10586-017-0938-9","Article"
notebooks/data/springer.csv:"CUDA implementation of fractal image compression","Journal of Real-Time Image Processing","","17","5","10.1007/s11554-019-00894-7","Abir Al SideiriNasser AlzeidiMayyada Al HammoshiMunesh Singh ChauhanGhaliya AlFarsi","2020","http://link.springer.com/article/10.1007/s11554-019-00894-7","Article"
notebooks/data/springer.csv:"A lightweight BLASTP and its implementation on CUDA GPUs","The Journal of Supercomputing","","77","1","10.1007/s11227-020-03267-1","Liang-Tsung HuangKai-Cheng WeiChao-Chin WuChao-Yu ChenJian-An Wang","2021","http://link.springer.com/article/10.1007/s11227-020-03267-1","Article"
notebooks/data/springer.csv:"CUDA-based solver for large-scale groundwater flow simulation","Engineering with Computers","","28","1","10.1007/s00366-011-0213-2","Xiaohui JiTangpei ChengQun Wang","2012","http://link.springer.com/article/10.1007/s00366-011-0213-2","Article"
notebooks/data/springer.csv:"Optimizing an APSP implementation for NVIDIA GPUs using kernel characterization criteria","The Journal of Supercomputing","","70","2","10.1007/s11227-014-1212-z","Hector Ortega-ArranzYuri TorresArturo Gonzalez-EscribanoDiego R. Llanos","2014","http://link.springer.com/article/10.1007/s11227-014-1212-z","Article"
notebooks/data/springer.csv:"Optimizing CUDA code by kernel fusion: application on BLAS","The Journal of Supercomputing","","71","10","10.1007/s11227-015-1483-z","Jiří FilipovičMatúš MadzinJan FousekLuděk Matyska","2015","http://link.springer.com/article/10.1007/s11227-015-1483-z","Article"
notebooks/data/springer.csv:"Real-time video denoising on multicores and GPUs with Kalman-based and Bilateral filters fusion","Journal of Real-Time Image Processing","","16","5","10.1007/s11554-016-0659-y","Sergio G. PflegerPatricia D. M. PlentzRodrigo C. O. RochaAlyson D. PereiraMárcio Castro","2019","http://link.springer.com/article/10.1007/s11554-016-0659-y","Article"
notebooks/data/springer.csv:"Accelerating Single Iteration Performance of CUDA-Based 3D Reaction–Diffusion Simulations","International Journal of Parallel Programming","","42","2","10.1007/s10766-013-0251-z","John K. HolmenDavid L. Foster","2014","http://link.springer.com/article/10.1007/s10766-013-0251-z","Article"
notebooks/data/springer.csv:"A new memory mapping mechanism for GPGPUs’ stencil computation","Computing","","97","8","10.1007/s00607-014-0434-5","Tieqiang MoRenfa Li","2015","http://link.springer.com/article/10.1007/s00607-014-0434-5","Article"
notebooks/data/springer.csv:"High Level Data Structures for GPGPU Programming in a Statically Typed Language","International Journal of Parallel Programming","","45","2","10.1007/s10766-016-0424-7","Mathias BourgoinEmmanuel ChaillouxJean-Luc Lamotte","2017","http://link.springer.com/article/10.1007/s10766-016-0424-7","Article"
notebooks/data/springer.csv:"The 2D wavelet transform on emerging architectures: GPUs and multicores","Journal of Real-Time Image Processing","","7","3","10.1007/s11554-011-0224-7","Joaquín FrancoGregorio BernabéJuan FernándezManuel Ujaldón","2012","http://link.springer.com/article/10.1007/s11554-011-0224-7","Article"
notebooks/data/springer.csv:"Development of a 3D Hybrid Finite-Discrete Element Simulator Based on GPGPU-Parallelized Computation for Modelling Rock Fracturing Under Quasi-Static and Dynamic Loading Conditions","Rock Mechanics and Rock Engineering","","53","3","10.1007/s00603-019-01960-z","Daisuke FukudaMojtaba MohammadnejadHongyuan LiuQianbing ZhangJian ZhaoSevda DehkhodaAndrew ChanJun-ichi KodamaYoshiaki Fujii","2020","http://link.springer.com/article/10.1007/s00603-019-01960-z","Article"
notebooks/data/springer.csv:"GPUBlocks: GUI Programming Tool for CUDA and OpenCL","Journal of Signal Processing Systems","","91","3 - 4","10.1007/s11265-018-1395-2","Yuan-Shin HwangHsih-Hsin LinShen-Hung PaiChia-Heng Tu","2019","http://link.springer.com/article/10.1007/s11265-018-1395-2","Article"
notebooks/data/springer.csv:"Automatic code generation for GPUs in llc","The Journal of Supercomputing","","58","3","10.1007/s11227-011-0591-7","Ruyman ReyesFrancisco de Sande","2011","http://link.springer.com/article/10.1007/s11227-011-0591-7","Article"
notebooks/data/springer.csv:"A high performance parallel DCT with OpenCL on heterogeneous computing environment","Multimedia Tools and Applications","","64","2","10.1007/s11042-012-1028-x","Cheong Ghil KimYong Soo Choi","2013","http://link.springer.com/article/10.1007/s11042-012-1028-x","Article"
notebooks/data/springer.csv:"CUDA-accelerated fast Sauvola’s method on Kepler architecture","Multimedia Tools and Applications","","74","24","10.1007/s11042-014-2269-7","Xin ChenYuefang GaoZhonghong Huang","2015","http://link.springer.com/article/10.1007/s11042-014-2269-7","Article"
notebooks/data/springer.csv:"A 3D graphics rendering pipeline implementation based on the openCL massively parallel processing","The Journal of Supercomputing","","77","7","10.1007/s11227-020-03581-8","Mingyu KimNakhoon Baek","2021","http://link.springer.com/article/10.1007/s11227-020-03581-8","Article"
notebooks/data/springer.csv:"pocl: A Performance-Portable OpenCL Implementation","International Journal of Parallel Programming","","43","5","10.1007/s10766-014-0320-y","Pekka JääskeläinenCarlos Sánchez de La LamaErik SchnetterKalle RaiskilaJarmo TakalaHeikki Berg","2015","http://link.springer.com/article/10.1007/s10766-014-0320-y","Article"
notebooks/data/springer.csv:"Towards predicting GPGPU performance for concurrent workloads in Multi-GPGPU environment","Cluster Computing","","23","3","10.1007/s10586-020-03105-2","Sunggon KimDongwhan KimYongseok SonHyeonsang Eom","2020","http://link.springer.com/article/10.1007/s10586-020-03105-2","Article"
notebooks/data/springer.csv:"Real-Time FPGA Implementation of FIR Filter Using OpenCL Design","Journal of Signal Processing Systems","","","","10.1007/s11265-021-01723-6","Iman FirmansyahYoshiki Yamaguchi","2022","http://link.springer.com/article/10.1007/s11265-021-01723-6","Article"
notebooks/data/springer.csv:"High-Level Heterogeneous and Hierarchical Parallel Systems (HLPGPU 2014)","International Journal of Parallel Programming","","43","5","10.1007/s10766-015-0367-4","Christopher Brown","2015","http://link.springer.com/article/10.1007/s10766-015-0367-4","Article"
notebooks/data/ieee_5.csv:"CUDA accelerated iris template matching on Graphics Processing Units (GPUs)","N. A. Vandal; M. Savvides","Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15232, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University","2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS)","11 Nov 2010","2010","","","1","7","In this paper we develop a parallelized iris template matching implementation on inexpensive Graphics Processing Units (GPUs) with Nvidia's CUDA programming model to achieve matching rates of 44 million iris template comparisons per second without rotation invariance. With tolerance to head tilt, we achieve 4.2 million matches per second and compare our implementation to state of the art prior work performed on GPU and FPGA, emphasizing our improvements. Additionally a comparison to highly optimized CPU implementations of iris template matching is performed, showing a 14X speedup using our approach. In contrast to other published work, we develop an implementation for parallel iris template matching that incorporates iris code shifting for rotation invariance and provide timing data showing our proposed architecture is efficiently implemented, capitalizing on shared and texture memory to speedup the bit shifting process beyond current prior art.","","978-1-4244-7582-7","10.1109/BTAS.2010.5634505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634505","","Iris recognition;Instruction sets;Probes;Graphics processing unit;Field programmable gate arrays;Hamming distance;Hardware","computer graphic equipment;coprocessors;field programmable gate arrays;image matching;iris recognition","iris template matching;graphics processing units;Nvidia CUDA programming model;field programmable gate array;bit shifting process","","12","1","20","","11 Nov 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"GPGPU-Based ATPG System: Myth or Reality?","L. Lai; K. -H. Tsai; H. Li","Department of Electrical Engineering, Shantou University, Shantou, China; Silicon Test Division, Mentor Graphics Corporation, Wilsonville, OR, USA; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","23 Dec 2019","2020","39","1","239","247","General-purpose computing on graphics processing units (GPGPUs) is a programming model that uses graphics cards to perform computations traditionally done by CPU. It began to become practical with the advent of programmable shaders and floating-point support on GPU in around 2001. The spread of GPGPU has been accelerated with introduction of CUDA from NVIDIA in 2006 and later OpenCL in 2009. Nowadays GPGPU is widely deployed in various applications, such as data mining, artificial intelligence, and many scientific computations. GPGPU seemingly promises immense parallelism with massive concurrent cores, and thus much shorter run times. This is true for algorithms that bear intrinsic data and task parallelism, such as image and video processing. For an ATPG system where some algorithms are sequential in nature, the speedup is not easy to achieve in the real world. Flaws in setting up speedup evaluation can lead to false promises. Will GPGPU-based ATPG system become a reality? Or it is just a myth. In this paper, we try to provide an answer by surveying state-of-the-art works and by analyzing practical aspects of today's industrial designs.","1937-4151","","10.1109/TCAD.2018.2884992","Shantou University(grant numbers:140-760163); Yangfang Career Award of Guangdong Province, China(grant numbers:140-14600602); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558526","ATPG;fault simulation;general-purpose computing on graphics processing units (GPGPUs)","Graphics processing units;Memory management;Instruction sets;Integrated circuit modeling;Circuit faults;Test pattern generators;Kernel","automatic test pattern generation;general purpose computers;graphics processing units;parallel architectures","OpenCL;CUDA;task parallelism;floating-point support;programmable shaders;programming model;general-purpose computing;GPGPU-based ATPG system","","1","","42","IEEE","4 Dec 2018","","","IEEE","IEEE Journals"
notebooks/data/ieee_5.csv:"Flacc: Towards OpenACC support for Fortran in the LLVM Ecosystem","V. Clement; J. S. Vetter","Oak Ridge National Laboratory,Programming Systems Group; Oak Ridge National Laboratory,Advanced Computing Systems Research Section","2021 IEEE/ACM 7th Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)","20 Dec 2021","2021","","","12","19","OpenACC is a directive-based programming model for heterogeneous accelerators initially launched in 2010 to provide a portable solution at a level of abstraction above OpenCL, CUDA, and other lower-level programming models. Various implementations of OpenACC for C, C++, and Fortran exist; however, only one open-source, production implementation of OpenACC for Fortran does exist. Moreover, most contemporary compiler tool chains for heterogeneous computing are based on LLVM. This lack of support poses a serious risk for high-performance computing application developers targeting GPUs and other accelerators, and it limits the ability of the community to experiment with, extend, and contribute to the OpenACC specification and open-source implementation itself. To address this gap, we have designed and begun implementing Flacc: an effort funded by the US Exascale Computing Project to develop production OpenACC compiler support for Fortran based on Flang within the LLVM ecosystem. In this paper, we describe the Flacc goals, initial design and prototype, and challenges that we have encountered so far in our prototyping efforts. Flacc is implemented as a MLIR dialect in the Flang Fortran front end in LLVM. The Flacc front end currently supports OpenACC version 3.1, and the Flacc run time is currently under development and relies on contributions from the Clacc project. Current contributions to Flacc are available in the main ${\color{Green}{\mathbf{LLVM}}\;{\mathbf{repository}}}$.<sup>1</sup>","","978-1-6654-1134-9","10.1109/LLVMHPC54804.2021.00007","Office of Science; UT-Battelle; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651310","OpenACC;OpenMP;LLVM;MLIR;multicore;GPU;accelerators;compiler","Codes;Exascale computing;Ecosystems;Semantics;Prototypes;Graphics processing units;Production","","","","","","26","","20 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Performance Portability Evaluation of OpenCL Benchmarks across Intel and NVIDIA Platforms","C. Bertoni; J. Kwack; T. Applencourt; Y. Ghadar; B. Homerding; C. Knight; B. Videau; H. Zheng; V. Morozov; S. Parker","Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439","2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","28 Jul 2020","2020","","","330","339","We evaluate the capabilities of vendor-provided OpenCL implementations for performance portability across multiple computing platforms. The Rodinia benchmark suite is used for this evaluation. We apply the metric defined by Pennycook et al., and we use roofline efficiency from the Roofline performance model as the “performance efficiency” in the metric's definition. We found that the delivered performance portability is similar for several benchmarks, even if the roofline-based performance efficiencies across platforms are very different among the benchmarks. To help distinguish between these instances, we extend the metric by adding the standard deviation of the performance efficiencies for each benchmark. We argue that the standard deviation gives additional insight into performance portability assessment since it adds the performance variability across platforms. Additionally, we discuss the challenges to measure performance portability associated with algorithms and system software. In terms of algorithms, we need to carefully construct the benchmarks and appropriately use the concurrency available on a platform. In terms of system software, we depend on the vendor performance tools to support the desired programming model and runtime to be able to measure the metrics of interest.","","978-1-7281-7445-7","10.1109/IPDPSW50202.2020.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150432","high performance computing;performance efficiency;performance portability;roofline performance analysis;OpenCL;GPU","Benchmark testing;Computer architecture;Measurement;Computational modeling;Kernel;Programming;Bandwidth","application program interfaces;concurrency control;graphics processing units;parallel processing;software metrics;software performance evaluation","performance portability evaluation;OpenCL benchmarks;Rodinia benchmark suite;roofline efficiency;roofline performance model;performance portability assessment;performance variability;vendor performance tools;NVIDIA platform;Intel platform;OpenCL implementations;concurrency","","3","","26","","28 Jul 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Reactive Molecular Dynamics on Massively Parallel Heterogeneous Architectures","S. B. Kylasa; H. M. Aktulga; A. Y. Grama","Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN; Michigan State University, 428 S. Shaw Lane, Room 3115, East Lansing, MI; Department of Computer Science, Purdue University, West Lafayette, IN","IEEE Transactions on Parallel and Distributed Systems","9 Dec 2016","2017","28","1","202","214","We present a parallel implementation of the ReaxFF force field on massively parallel heterogeneous architectures, called PuReMD-Hybrid. PuReMD, on which this work is based, along with its integration into LAMMPS, is currently used by a large number of research groups worldwide. Accelerating this important community codebase that implements a complex reactive force field poses a number of algorithmic, design, and optimization challenges, as we discuss in detail. In particular, different computational kernels are best suited to different computing substrates-CPUs or GPUs. Scheduling these computations requires complex resource management, as well as minimizing data movement across CPUs and GPUs. Integrating powerful nodes, each with multiple CPUs and GPUs, into clusters and utilizing the immense compute power of these clusters requires significant optimizations for minimizing communication and, potentially, redundant computations. From a programming model perspective, PuReMD-Hybrid relies on MPI across nodes, pthreads across cores, and CUDA on the GPUs to address these challenges. Using a variety of innovative algorithms and optimizations, we demonstrate that our code can achieve over 565-fold speedup compared to a single core implementation on a cluster of 36 state-of-the-art GPUs for complex systems. In terms of application performance, our code enables simulations of over 1.8M atoms in under 0.68 seconds per simulation time step.","1558-2183","","10.1109/TPDS.2016.2548462","National Science Foundation(grant numbers:CCF 1533795); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444209","Reactive molecular dynamics;parallel GPU implementations;material simulations","Graphics processing units;Force;Kernel;Biological system modeling;Computational modeling;Clustering algorithms;Numerical models","graphics processing units;microprocessor chips;molecular dynamics method;parallel architectures","CUDA;pthreads across cores;MPI across nodes;data movement;complex resource management;GPUs;CPUs;computing substrates;computational kernels;complex reactive force field;LAMMPS;PuReMD-hybrid;ReaxFF force field;massively parallel heterogeneous architectures;reactive molecular dynamics","","10","","45","IEEE","30 Mar 2016","","","IEEE","IEEE Journals"
notebooks/data/ieee_5.csv:"Understanding Error Propagation in GPGPU Applications","G. Li; K. Pattabiraman; C. -Y. Cher; P. Bose","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; T.J. Watson Res. Center, IBM, Yorktown Heights, NY, USA; T.J. Watson Res. Center, IBM, Yorktown Heights, NY, USA","SC '16: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","16 Mar 2017","2016","","","240","251","GPUs have emerged as general-purpose accelerators in high-performance computing (HPC) and scientific applications. However, the reliability characteristics of GPU applications have not been investigated in depth. While error propagation has been extensively investigated for non-GPU applications, GPU applications have a very different programming model which can have a significant effect on error propagation in them. We perform an empirical study to understand and characterize error propagation in GPU applications. We build a compilerbased fault-injection tool for GPU applications to track error propagation, and define metrics to characterize propagation in GPU applications. We find GPU applications exhibit significant error propagation for some kinds of errors, but not others, and the behaviour is highly application specific. We observe the GPUCPU interaction boundary naturally limits error propagation in these applications compared to traditional non-GPU applications. We also formulate various guidelines for the design of faulttolerance mechanisms in GPU applications based on our results.","2167-4337","978-1-4673-8815-3","10.1109/SC.2016.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877099","Fault Injection;Error Resilience;GPGPU;CUDA;Error Propagation","Graphics processing units;Kernel;Circuit faults;Hardware;Programming;Computational modeling;Central Processing Unit","graphics processing units;parallel processing;program compilers;software reliability","error propagation;GPGPU;general-purpose accelerators;high-performance computing;HPC;reliability characteristics;compiler-based fault-injection tool","","43","","55","","16 Mar 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"RAJA: Portable Performance for Large-Scale Scientific Applications","D. A. Beckingsale; J. Burmark; R. Hornung; H. Jones; W. Killian; A. J. Kunen; O. Pearce; P. Robinson; B. S. Ryujin; T. R. Scogland","Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA","2019 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","2 Jan 2020","2019","","","71","81","Modern high-performance computing systems are diverse, with hardware designs ranging from homogeneous multi- core CPUs to GPU or FPGA accelerated systems. Achieving desir- able application performance often requires choosing a program- ming model best suited to a particular platform. For large codes used daily in production that are under continual development, architecture-specific ports are untenable. Maintainability re- quires single-source application code that is performance portable across a range of architectures and programming models. In this paper we describe RAJA, a portability layer that enables C++ applications to leverage various programming models, and thus architectures, with a single-source codebase. We describe preliminary results using RAJA in three large production codes at Lawrence Livermore National Laboratory, observing 17×, 13× and 12× speedup on GPU-only over CPU- only nodes with single-source application code in each case.","","978-1-7281-6003-0","10.1109/P3HPC49587.2019.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945721","","C++ languages;Graphics processing units;Programming;Production;Computer architecture;Kernel;Libraries","application program interfaces;field programmable gate arrays;graphics processing units;microprocessor chips;multiprocessing systems;parallel processing;software portability","C++ applications;single-source codebase;RAJA;production codes;high-performance computing systems;hardware designs;programming model;architecture-specific ports;homogeneous multicore CPU;Lawrence Livermore National Laboratory","","21","","23","","2 Jan 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Directive-based Programming for GPUs: A Comparative Study","R. Reyes; I. López; J. J. Fumero; F. de Sande","Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain","2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems","18 Oct 2012","2012","","","410","417","GPUs and other accelerators are available on many different devices, while GPGPU has been massively adopted by the HPC research community. Although a plethora of libraries and applications providing GPU support are available, the need of implementing new algorithms from scratch, or adapting sequential programs to accelerators, will always exist. Writing CUDA or OpenCL codes, although an easier task than using their predecessors, is not trivial. Obtaining performance is even harder, as it requires deep understanding of the underlying architecture. Some efforts have been directed toward the automatic code generation for GPU devices, with different results. In particular, several directive-oriented programming models, taking advantage of the OpenMP success, have been created. Although future OpenMP releases will integrate accelerators into the standard, tools are needed in the meantime. In this work, we present a comparison between three directive-based programming models: hiCUDA, PGI Accelerator and OpenACC, using for the last our novel accULL implementation. With this comparison, we aim to showcase the evolution of the directive-based programming models and how users can guide tools toward better performance results.","","978-1-4673-2164-8","10.1109/HPCC.2012.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6332201","OpenACC;PGI;Accelerators;GPGPU;CUDA;OpenCL;OpenMP;compiler;productivity","Graphics processing unit;Kernel;Programming;Standards;Runtime;Performance evaluation","graphics processing units;multiprocessing systems;parallel architectures;program compilers","directive-based programming model;GPGPU;HPC;scratch;automatic code generation;OpenMP;hiCUDA;PGI accelerator;OpenACC;accULL","","13","1","14","","18 Oct 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Liszt: A domain specific language for building portable mesh-based PDE solvers","Z. DeVito; N. Joubert; F. Palacios; S. Oakley; M. Medina; M. Barrientos; E. Elsen; F. Ham; A. Aiken; K. Duraisamy; E. Darve; J. Alonso; P. Hanrahan","Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Institute for Computational and Mathematical Engineering, Stanford University; Institute for Computational and Mathematical Engineering, Stanford University; Department of Computer Science, Stanford University; Department of Mechanical Engineering, Stanford University; Department of Mechanical Engineering, Stanford University; Department of Computer Science, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Mechanical Engineering, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Computer Science, Stanford University","SC '11: Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis","29 Dec 2011","2011","","","1","12","Heterogeneous computers with processors and accelerators are becoming widespread in scientific computing. However, it is difficult to program hybrid architectures and there is no commonly accepted programming model. Ideally, applications should be written in a way that is portable to many platforms, but providing this portability for general programs is a hard problem. By restricting the class of programs considered, we can make this portability feasible. We present Liszt, a domain- specific language for constructing mesh-based PDE solvers. We introduce language statements for interacting with an unstructured mesh, and storing data at its elements. Pro- gram analysis of these statements enables our compiler to expose the parallelism, locality, and synchronization of Liszt programs. Using this analysis, we generate applications for multiple platforms: a cluster, an SMP, and a GPU. This approach allows Liszt applications to perform within 12% of hand-written C++, scale to large clusters, and experience order-of-magnitude speedups on GPUs.","2167-4337","978-1-4503-0771-0","10.1145/2063384.2063396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114401","compiler analysis and program transformations;programming and runtime environments for high performance and high throughput computing","Jacobian matrices;Face;Hardware;Computer architecture;Synchronization;Graphics processing unit;Heating","graphics processing units;mathematics computing;mesh generation;partial differential equations;program compilers;program diagnostics;specification languages","domain specific language;portable mesh-based PDE solver;heterogeneous computers;scientific computing;language statements;program analysis;compiler;Liszt programs;cluster;SMP;GPU;C++;partial differential equations","","34","","36","","29 Dec 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"TC-Release++: An Efficient Timestamp-Based Coherence Protocol for Many-Core Architectures","Y. Yao; W. Chen; T. Mitra; Y. Xiang","School of Computer Science and Technology, Zhejiang University, Hangzhou, P.R. China; School of Computer Science and Technology, Zhejiang University, Hangzhou, P.R. China; School of Computing, National University of Singapore, Singapore; Swinburne Research, Swinburne University of Technology, Hawthorn, Victoria, Australia","IEEE Transactions on Parallel and Distributed Systems","9 Oct 2017","2017","28","11","3313","3327","As we enter the era of many-core, providing the shared memory abstraction through cache coherence has become progressively difficult. The standard directory-based coherence does not scale well with increasing core count. Timestamp-based hardware coherence protocols introduced recently offer an attractive alternative solution. This paper proposes a timestamp-based coherence protocol, called TC-Release<sub>++</sub>, that efficiently supports cache coherence in large-scale systems. Our approach is inspired by TC-Weak, a recently proposed timestamp-based coherence protocol targeting GPU architectures. We first design TC-Release in an attempt to straightforwardly port TC-Weak to general-purpose many-cores. But re-purposing TC-Weak for general-purpose many-core architectures is challenging due to significant differences both in architecture and the programming model. Indeed the performance of TC-Release turns out to be worse than conventional directory protocols. We overcome the limitations and overheads of TC-Release by exploiting simple hardware support to eliminate frequent memory stalls, and an optimized lifetime prediction mechanism to improve cache performance. The resulting optimized coherence protocol TC-Release<sub>++</sub> is highly scalable (storage scales logarithmically with core count) and shows better performance (3.0 percent) and comparable network traffic (within 1.3 percent) relative to the baseline MESI directory protocol. We use Murphi to formally verify that TC-Release<sub>++</sub> is error-free and imposes small verification cost.","1558-2183","","10.1109/TPDS.2017.2719679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959101","Cache coherence;many-core architecture;timestamp-based system;memory consistency model","Coherence;Protocols;Graphics processing units;Hardware;Memory management;Programming;Electronic mail","cache storage;graphics processing units;multiprocessing systems;protocols;shared memory systems","general-purpose many-cores;re-purposing TC;general-purpose many-core architectures;conventional directory protocols;resulting optimized coherence protocol TC;core count;baseline MESI directory protocol;shared memory abstraction;cache coherence;timestamp-based hardware coherence protocols;GPU architectures;design TC","","2","","43","IEEE","26 Jun 2017","","","IEEE","IEEE Journals"
notebooks/data/ieee_5.csv:"Optimal balance between energy and performance in hybrid computing applications","D. LaKomski; Z. Zong; T. Jin; R. Ge","Computer Science Department, Texas State University, USA; Computer Science Department, Texas State University, USA; Ingram School of Engineering, Texas State University, USA; School of Computing, Clemson University, USA","2015 Sixth International Green and Sustainable Computing Conference (IGSC)","28 Jan 2016","2015","","","1","8","The latest top 10 supercomputers are dominated by heterogeneous systems with CPUs and accelerators (GPU or Xeon Phi) tightly coupled together. As the heterogeneity of future high performance computing systems keeps increasing, it becomes paramount to judiciously use CPUs and accelerators to improve performance and/or reduce energy consumption. The widely used programming model today is to offload computation intensive workload to accelerators. Theoretically, the hybrid computing model (i.e. running a subset of calculations concurrently on both CPUs and accelerators) can potentially offer advantages of improved energy efficiency and performance. However, this is not yet a common practice due to the uncertainty of energy/performance benefits as well as the increased programming complexity. In this paper, we conduct a comprehensive study on achieving the balance between energy and performance of hybrid computing applications. We show that performance and energy optimization can be conflicting goals, the sweet spot between performance and energy consumption varies with application characteristics and is highly dependent on specific implementations, that the choice of compiler can not only influence runtime but also energy use, and that the choice of cross platform strategies (e.g. OpenCL) can result in degraded performance and increased energy.","","978-1-5090-0172-9","10.1109/IGCC.2015.7393697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393697","energy efficient computing;green programming;hybrid computing;heterogeneous systems;performance optimization","Graphics processing units;Runtime;Programming;Fractals;Energy consumption;Computational modeling;Performance evaluation","energy consumption;graphics processing units;optimisation;parallel machines","optimal balance;hybrid computing application;supercomputers;CPU;accelerator;GPU;Xeon Phi;high performance computing system;energy consumption;energy efficiency;energy optimization;OpenCL","","4","","29","","28 Jan 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Towards a robust, real-time face processing system using CUDA-enabled GPUs","B. Sharma; R. Thota; N. Vydyanathan; A. Kale","Siemens Corporate Technology, Bangalore, India; Siemens Corporate Technology, Bangalore, India; Siemens Corporate Technology, Bangalore, India; Siemens Corporate Technology, Bangalore, India","2009 International Conference on High Performance Computing (HiPC)","18 Mar 2010","2009","","","368","377","Processing of human faces finds application in various domains like law enforcement and surveillance, entertainment (interactive video games), information security, smart cards etc. Several of these applications are interactive and require reliable and fast face processing. A generic face processing system may comprise of face detection, recognition, tracking and rendering. In this paper, we develop a GPU accelerated real-time and robust face processing system that does face detection and tracking. Face detection is done by adapting the Viola and Jones algorithm that is based on the Adaboost learning system. For robust tracking of faces across real-life illumination conditions, we leverage the algorithm proposed by Thota and others, that combines the strengths of Adaboost and an image based parametric illumination model. We design and develop optimized parallel implementations of these algorithms on graphics processors using the Compute Unified Device Architecture (CUDA), a C-based programming model from NVIDIA. We evaluate our face processing system using both static image databases as well as using live frames captured from a firewire camera under realistic conditions. Our experimental results indicate that our parallel face detector and tracker achieve much greater detection speeds as compared to existing work, while maintaining accuracy. We also demonstrate that our tracking system is robust to extreme illumination conditions.","1094-7256","978-1-4244-4921-7","10.1109/HIPC.2009.5433189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5433189","Parallel computing;face detection;face tracking;graphics processors;real-time algorithms","Robustness;Real time systems;Face detection;Lighting;Firewire;Humans;Law enforcement;Surveillance;Games;Information security","C language;computer graphic equipment;computer graphics;coprocessors;face recognition","face processing system;CUDA-enabled GPU;face detection;face tracking;Viola-Jones algorithm;Adaboost learning system;image based parametric illumination model;compute unified device architecture;C-based programming","","30","2","15","","18 Mar 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Static WCET Analysis of GPUs with Predictable Warp Scheduling","Y. Huangfu; W. Zhang","Virginia Commonwealth Univ., Richmond, VA, USA; Virginia Commonwealth Univ., Richmond, VA, USA","2017 IEEE 20th International Symposium on Real-Time Distributed Computing (ISORC)","3 Jul 2017","2017","","","101","108","The capability of GPUs to accelerate general-purpose applications that can be parallelized into massive number of threads makes it promising to apply GPUs to real-time applications as well, where high throughput and intensive computation are also needed. However, due to the different architecture and programming model of GPUs, the worst-case execution time (WCET) analysis methods and techniques designed for CPUs cannot be used directly to estimate the WCET of GPUs. In this work, based on the analysis of the architecture and dynamic behavior of GPUs, we propose a WCET timing model and analyzer based on a predictable GPU warp scheduling policy to enable the WCET estimation on GPUs.","2375-5261","978-1-5386-1574-4","10.1109/ISORC.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964876","","Graphics processing units;Instruction sets;Kernel;Analytical models;Computer architecture;Mathematical model;Dynamic scheduling","general purpose computers;graphics processing units;microprocessor chips;parallel processing;program diagnostics;scheduling","GPU;predictable warp scheduling;general purpose applications;static worst-case execution time analysis;static WCET analysis;CPU","","4","","23","","3 Jul 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Performance Portability of an SpMV Kernel Across Scientific Computing and Data Science Applications","S. L. Olivier; N. D. Ellingwood; J. Berry; D. M. Dunlavy","Sandia National Laboratories,Albuquerque,NM; Sandia National Laboratories,Albuquerque,NM; Sandia National Laboratories,Albuquerque,NM; Sandia National Laboratories,Albuquerque,NM","2021 IEEE High Performance Extreme Computing Conference (HPEC)","1 Dec 2021","2021","","","1","8","Both the data science and scientific computing communities are embracing GPU acceleration for their most demanding workloads. For scientific computing applications, the massive volume of code and diversity of hardware platforms at supercomputing centers has motivated a strong effort toward performance portability. This property of a program, denoting its ability to perform well on multiple architectures and varied datasets, is heavily dependent on the choice of parallel programming model and which features of the programming model are used. In this paper, we evaluate performance portability in the context of a data science workload in contrast to a scientific computing workload, evaluating the same sparse matrix kernel on both. Among our implementations of the kernel in different performance-portable programming models, we find that many struggle to consistently achieve performance improvements using the GPU compared to simple one-line OpenMP parallelization on high-end multicore CPUs. We show one that does, and its performance approaches and sometimes even matches that of vendor-provided GPU math libraries.","2643-1971","978-1-6654-2369-4","10.1109/HPEC49654.2021.9622869","National Nuclear Security Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622869","performance portability;SpMV;sparse matrix operations;graph computations","Runtime;Codes;Scientific computing;Multicore processing;Computational modeling;Graphics processing units;Computer architecture","","","","","","27","","1 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Single Kernel Soft Synchronization Technique for Task Arrays on CUDA-enabled GPUs, with Applications","S. Funasaka; K. Nakano; Y. Ito","Dept. of Inf. Eng., Hiroshima Univ., Higashi-Hiroshima, Japan; Dept. of Inf. Eng., Hiroshima Univ., Higashi-Hiroshima, Japan; Dept. of Inf. Eng., Hiroshima Univ., Higashi-Hiroshima, Japan","2017 Fifth International Symposium on Computing and Networking (CANDAR)","26 Apr 2018","2017","","","11","20","A task array is a 2-dimensional array of tasks with dependency relations. Each task uses the resulting values of some tasks in the left columns, and so it can be started only after these left tasks are completed. Conventional CUDA implementations repeatedly perform a separated CUDA kernel call for each column from left to right to synchronize the computation for tasks. However, this conventional CUDA implementation has several drawbacks: a CUDA kernel call has a certain overhead, and the running time of a CUDA kernel is determined by a CUDA block that terminates lastly. Also, every task must write and preserve the resulting values in the global memory with low memory access performance for the following tasks. The main contribution of this paper is to introduce task arrays and to present Single Kernel Soft Synchronization (SKSS) technique that significantly reduces such overheads for task arrays. The SKSS performs only one CUDA kernel call and CUDA blocks assigned to each row of a task array using a global counter. To clarify the potentiality of our SKSS technique, we have implemented the dynamic programming for the 0-1 knapsack problem, the summed area table computation, and the error diffusion of a gray-scale image using our SKSS technique and compared with previously published best GPU implementations. Quite surprisingly, the experimental results using NVIDIA Titan X show that, our SKSS implementations are 1.29-2.11 times faster for the 0-1 knapsack problem, 1.08-1.56 times faster for the summed area table computation, and 1.61-2.11 times faster for the error diffusion.","2379-1896","978-1-5386-2087-8","10.1109/CANDAR.2017.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345405","dynamic programming;knapsack problem;summed area table;error diffusion","Graphics processing units;Task analysis;Kernel;Parallel algorithms;Synchronization;Computer architecture;Dynamic programming","dynamic programming;graphics processing units;operating system kernels;parallel algorithms;parallel architectures;parallel programming;synchronisation","task array;CUDA block;SKSS technique;CUDA-enabled GPUs;Single Kernel Soft Synchronization;CUDA kernel call;dynamic programming;knapsack problem;summed area table computation;error diffusion;parallel computing architecture;Compute Unified Device Architecture;CUDA programming model;parallel algorithms","","12","","16","","26 Apr 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Parallelization of Virtual Screening in Drug Discovery on Massively Parallel Architectures","G. D. Guerrero; H. E. Perez-S´nchez; J. M. Cecilia; J. M. Garcia","Dipt. de Ing. y Tecnol. de Comput., Univ. de Murcia, Murcia, Spain; NA; Dipt. de Ing. y Tecnol. de Comput., Univ. de Murcia, Murcia, Spain; Dipt. de Ing. y Tecnol. de Comput., Univ. de Murcia, Murcia, Spain","2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing","15 Mar 2012","2012","","","588","595","The current trend in medical research for the discovery of new drugs is the use of Virtual Screening (VS) methods. In these methods, the calculation of the non-bonded interactions, such as electrostatics or van der Waals forces, plays an important role, representing up to 80% of the total execution time. These kernels are computational intensive and massively parallel in nature, and thus they are well suited to be accelerated on parallel architectures. In this work, we discuss the effective parallelization of the non-bonded electrostatic interactions kernel for VS on three different parallel architectures: a shared memory system, a distributed memory system, and a Graphics Processing Units (GPUs). For an efficient handling of the computational intensive and massively parallelism of this kernel, we enable different data policies on those architectures to take advantage of all computational resources offered by them. Four implementations are provided based on MPI, OpenMP, Hybrid MPI Open MP and CUDA programming models. The sequential implementation is defeated by a wide margin by all parallel implementations, obtaining up to 72x speed-up factor on the shared memory system through OpenMP, up to 60x and229x speed-ups factors on the distributed memory system for the MPI implementation and the Hybrid MPI-Open MP implementation respectively, and finally, up to 213x speedup factor for the CUDA implementation on the GPU architecture to offer the best alternative in terms of performance/cost ratio.","2377-5750","978-1-4673-0226-5","10.1109/PDP.2012.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169645","Drug Discovery;Non-bonded interactions;CUDA;OpenMP;MPI;Hybrid OpenMP-MPI;High-Performance Computing","Graphics processing unit;Kernel;Instruction sets;Message systems;Parallel processing;Programming;Computer architecture","application program interfaces;distributed shared memory systems;graphics processing units;medical computing;message passing;parallel architectures","virtual screening parallelization;drug discovery;massively parallel architecture;medical research;virtual screening method;electrostatics;van der Waals force;shared memory system;distributed memory system;graphics processing units;data policy;computational resource;CUDA programming model;message passing interface;compute unified device architecture;sequential implementation;parallel implementation;performance-cost ratio;speedup factor;hybrid MPI openMP","","8","","29","","15 Mar 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Scalable Programming Models for Massively Multicore Processors","M. D. McCool","Rapid Mind Inc., Waterloo","Proceedings of the IEEE","15 Apr 2008","2008","96","5","816","831","Including multiple cores on a single chip has become the dominant mechanism for scaling processor performance. Exponential growth in the number of cores on a single processor is expected to lead in a short time to mainstream computers with hundreds of cores. Scalable implementations of parallel algorithms will be necessary in order to achieve improved single-application performance on such processors. In addition, memory access will continue to be an important limiting factor on achieving performance, and heterogeneous systems may make use of cores with varying capabilities and performance characteristics. An appropriate programming model can address scalability and can expose data locality while making it possible to migrate application code between processors with different parallel architectures and variable numbers and kinds of cores. We survey and evaluate a range of multicore processor architectures and programming models with a focus on GPUs and the Cell BE processor. These processors have a large number of cores and are available to consumers today, but the scalable programming models developed for them are also applicable to current and future multicore CPUs.","1558-2256","","10.1109/JPROC.2008.917731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4490125","Computer architecture;multicore processors;parallel programming and computation;programming and processing models","Multicore processing;Parallel processing;Parallel programming;Concurrent computing;Hardware;Computer architecture;Programming profession;Pipeline processing;Parallel algorithms;Scalability","microprocessor chips;parallel algorithms;parallel architectures","scalable programming models;multicore processors;parallel algorithms;heterogeneous systems;parallel architectures;GPU;cell BE processor;graphics processing units","","32","25","64","","15 Apr 2008","","","IEEE","IEEE Journals"
notebooks/data/ieee_5.csv:"Enable OpenCL Compiler with Open64 Infrastructures","Y. Lin; S. Wang; W. Shih; B. K. Hsieh; J. Lee","Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Cloud Comput. Res. Center for Mobile Applic., Ind. Technol. Res. Inst., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan","2011 IEEE International Conference on High Performance Computing and Communications","31 Oct 2011","2011","","","863","868","As microprocessors evolve into heterogeneous architectures with multi-cores of MPUs and GPUs, programming model supports become important for programming such architectures. To address this issue, OpenCL is proposed. Currently, most of OpenCL implementations take LLVM as their infrastructures. This presents an opportunity to demonstrate whether OpenCL can be effectively implemented on other compiler infrastructures. For example, Open64, which is another open source compiler and known to generate efficient codes for microprocessors, can contribute further to performance improvements and enhancing the adoption of heterogeneous computing based on OpenCL. In this paper, we describe the flow to enable an OpenCL compiler based on Open64 infrastructures for ATI GPUs. Our work includes the extension of the front-end parser for OpenCL, the generation of high-level intermediate representations with OpenCL linguistics, performing high-level optimization, and finally applying OpenCL specific optimization for code generations. Preliminary experimental results show that our compiler based on Open64 is able to generate efficient codes for OpenCL programs.","","978-1-4577-1564-8","10.1109/HPCC.2011.123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063089","","Vectors;Registers;Optimization;Programming;Graphics processing unit;Hardware;Computer architecture","computer architecture;microprocessor chips;optimising compilers","OpenCL compiler;Open64 infrastructure;microprocessor;heterogeneous architecture;MPU;LLVM;open source compiler;ATI GPU;front-end parser;OpenCL linguistics;code generation","","5","","23","","31 Oct 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Performance Portability across Diverse Computer Architectures","T. Deakin; S. McIntosh-Smith; J. Price; A. Poenaru; P. Atkinson; C. Popa; J. Salmon","University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK","2019 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","2 Jan 2020","2019","","","1","13","Previous studies into performance portability have typically analysed a single application (and its various imple- mentations) in isolation. In this study we explore the wider landscape of performance portability by considering a number of applications from across the space of dwarfs, written in multiple parallel programming models, and across a diverse set of architectures. We apply rigorous performance portability metrics, as defined by Pennycook et al [1]. We believe this is the broadest and most rigorous performance portability study to date, representing a far reaching exploration of the state of performance portability that is achievable today. We will present a summary of the performance portability of each application and programming model across our diverge range of twelve computer architectures, including six different server CPUs from five different vendors, five different GPUs from two different vendors, and one vector architecture. We will conclude with an analysis of the performance portability of key programming models in general, across different application spaces as well across differing architectures, allowing us to comment on more general performance portability principles.","","978-1-7281-6003-0","10.1109/P3HPC49587.2019.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945642","performance portability;productivity;mini-app;programming models","Productivity;Analytical models;Computational modeling;Computer architecture;Programming;Hardware;Standards","coprocessors;multiprocessing systems;parallel programming","performance portability principles;performance portability study;performance portability metrics;programming models;GPU","","11","","19","","2 Jan 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"A CUDA-based parallel implementation of K-nearest neighbor algorithm","S. Liang; Y. Liu; C. Wang; L. Jian","Graduate University of Chinese Academy of Sciences, Beijing, China; Graduate University of Chinese Academy of Sciences, Beijing, China; Agilent Technologies Co. Ltd., Beijing, China; Graduate University of Chinese Academy of Sciences, Beijing, China","2009 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","26 Jan 2010","2009","","","291","296","Recent developments in Graphics Processing Units (GPUs) have enabled inexpensive high performance computing for general-purpose applications. Due to GPU's tremendous computing capability, it has emerged as the co-processor of the CPU to achieve a high overall throughput. CUDA programming model provides the programmers adequate C language like APIs to better exploit the parallel power of the GPU. K-nearest neighbor (KNN) is a widely used classification technique and has significant applications in various domains, especially in text classification. The computational-intensive nature of KNN requires a high performance implementation. In this paper, we present a CUDA-based parallel implementation of KNN, CUKNN, using CUDA multi-thread model, where the data elements are processed in a data-parallel fashion. Various CUDA optimization techniques are applied to maximize the utilization of the GPU. CUKNN outperforms the serial KNN on an HP xw8600 workstation significantly, achieving up to 46.71X speedup including I/O time. It also shows good scalability when varying the dimension of the reference dataset, the number of records in the reference dataset, and the number of records in the query dataset.","","978-1-4244-5218-7","10.1109/CYBERC.2009.5399145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5399145","KNN, classification, parallel computing, CUDA","High performance computing;Graphics;Coprocessors;Central Processing Unit;Throughput;Parallel programming;Programming profession;Text categorization;Workstations;Scalability","","","","17","","17","","26 Jan 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"GCN Inference Acceleration using High-Level Synthesis","Y. C. Lin; B. Zhang; V. Prasanna","University of Southern California,Los Angeles,California; University of Southern California,Los Angeles,California; University of Southern California,Los Angeles,California","2021 IEEE High Performance Extreme Computing Conference (HPEC)","1 Dec 2021","2021","","","1","6","GCN (Graph Convolutional Network) has become a promising solution for many applications, such as recommendation systems, social data mining, etc. Many of these applications requires low latency GCN inference.In this paper, we provide a case study of a GCN inference acceleration on FPGA. We explore high-level synthesis programming model to achieve low-latency inference. First, we propose a partition-centric mapping strategy to map the execution tasks of GCN onto FPGA to exploit data reuse, which reduces external memory access overhead. Second, we provide HLS-based kernel design with improved memory performance and achieve massive data parallelism. Third, we perform design space exploration to facilitate feasible pre-placement which avoids potential Place-and-Route (PnR) failures. We evaluate our design on a state-of-the-art FPGA platform using three commonly used datasets: Reddit, Yelp and Amazon-2M. We compare our design with two state-of-the-art libraries PyTorch-Geometric (PyG) and Deep Graph Library (DGL) running on high-end CPU and GPU by evaluating their latency and energy efficiency to perform full-batch GCN inference on a two-layer Vanilla-GCN model. Compared with PyG CPU version, our design reduces the latency by 59.95× and is 96.22× more energy efficient on the average. Compared with DGL, our design achieves 2.9 × –6.4× speedup and is 5.87× more energy efficient compared with the CPU version. Compared with the DGL GPU version, although the latency of our design is 1.67 × –2.5× that of DGL GPU, our design is 1.8× more energy efficient.","2643-1971","978-1-6654-2369-4","10.1109/HPEC49654.2021.9622801","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622801","","Social networking (online);Graphics processing units;Programming;Energy efficiency;Libraries;Space exploration;Low latency communication","","","","","","19","","1 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Network-on-Chip Design for Heterogeneous Multiprocessor System-on-Chip","B. Phanibhushana; S. Kundu","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts Amherst, Amherst, MA, USA; Dept. of Electr. & Comput. Eng., Univ. of Massachusetts Amherst, Amherst, MA, USA","2014 IEEE Computer Society Annual Symposium on VLSI","22 Sep 2014","2014","","","486","491","With burgeoning growth of mobile systems, multiprocessor System-on-Chip (MPSoC) connected via Network-on-Chip (NoC) has become ubiquitous. A typical MPSoC in mobile applications consists of multiple CPU cores of varying capabilities, GPU cores, DSP cores, and crypto accelerators and such cores differ widely in their physical size and their bandwidth requirements. Traditional mesh based NoC systems work well for regular structures, but do not map well to heterogeneous MPSoCs. In MPSoC programming model, an application consists of tasks, that represent a unit of work on a core which can be executed asynchronously. The communication between tasks is represented in the form of a directed acyclic graph. The temporal burstness of data which arise from programming model provide opportunity for multiplexing communication between cores, which may be advantageous in reducing network size. Often a task graph needs to meet a real-time deadline. The actual execution time may vary based on the application data. The uncertainty in the execution time may be modeled by a statistical distribution, which further complicates the NoC design. In this paper, we present a synthesis method for hierarchical design of NoC for a given task graph system deadline, that optimizes for router area. A 2-phase design flow is proposed, which consists of topology generation and statistical analysis in an iterative loop. We adopt proportion of Monte-Carlo test cases that meet the deadline as a metric for goodness. The proposed solution is compared against static design approach and simulated annealing (SA) based network generation. On an average, a performance benefit of 10% over SA, 16% over standard mesh and 30% over static design was obtained and a total router area benefit of 59% over SA, 48% over mesh and 55% over static design was observed.","2159-3477","978-1-4799-3765-3","10.1109/ISVLSI.2014.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6903411","Network-on-chip;Realtime systems;Statistical design;Kernighan-Lin","Partitioning algorithms;Bandwidth;Topology;System-on-chip;Monte Carlo methods;Algorithm design and analysis;Cost function","integrated circuit design;Monte Carlo methods;multiprocessing systems;network-on-chip;statistical analysis","network-on-chip design;heterogeneous multiprocessor system-on-chip;hierarchical design;NoC;task graph system deadline;router area;2-phase design flow;topology generation;statistical analysis;iterative loop;Monte-Carlo test cases","","3","","24","","22 Sep 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"FCUDA: Enabling efficient compilation of CUDA kernels onto FPGAs","A. Papakonstantinou; K. Gururaj; J. A. Stratton; D. Chen; J. Cong; W. W. Hwu","Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA; Computer Science Dept., University of California, Los-Angeles, USA; Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA; Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA; Computer Science Dept., University of California, Los-Angeles, USA; Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA","2009 IEEE 7th Symposium on Application Specific Processors","28 Aug 2009","2009","","","35","42","As growing power dissipation and thermal effects disrupted the rising clock frequency trend and threatened to annul Moore's law, the computing industry has switched its route to higher performance through parallel processing. The rise of multicore systems in all domains of computing has opened the door to heterogeneous multiprocessor, where processors of different compute characteristics can be combined to effectively boost the performance per watt of different application kernels. GPUs and FPGAs are becoming very popular in PC-based heterogeneous systems for speeding up compute intensive kernels of scientific, imaging and simulation applications. GPUs can execute hundreds of concurrent threads, while FPGAs provide customized concurrency for highly parallel kernels. However, exploiting the parallelism available in these applications is currently not a push-button task. Often the programmer has to expose the application's fine and coarse grained parallelism by using special APIs. CUDA is such a parallel computing API that is driven by the GPU industry and is gaining significant popularity. In this work, we adapt the CUDA programming model into a new FPGA design flow called FCUDA, which efficiently maps the coarse and fine grained parallelism exposed in CUDA onto the reconfigurable fabric. Our CUDA-to-FPGA flow employs autopilot, an advanced high level synthesis tool which enables high abstraction FPGA programming. FCUDA is based on a source-to-source compilation that transforms the SPMD CUDA thread blocks into parallel C code for autopilot. We describe the details of our CUDA-to-FPGA flow and demonstrate the highly competitive performance of the resulting customized FPGA multi-core accelerators. To the best of our knowledge, this is the first CUDA-to-FPGA flow to demonstrate the applicability and potential advantage of using the CUDA programming model for high-performance computing in FPGAs.","","978-1-4244-4939-2","10.1109/SASP.2009.5226333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226333","","Kernel;Field programmable gate arrays;Parallel processing;Concurrent computing;Computer industry;Yarn;Power dissipation;Clocks;Frequency;Moore's Law","application program interfaces;field programmable gate arrays;multiprocessing systems;parallel architectures","CUDA kernel;FPGA programming;field programmable gate array;power dissipation;clock frequency;Moores law;computing industry;parallel processing;multicore system;multiprocessor system;performance per watt boosting;application program interface;compute unified device architecture;graphics processing unit","","82","1","23","","28 Aug 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Implementing Performance Portable Graph Algorithms Using Task-Based Execution","Ü. V. Çatalyürek",Georgia Institute of Technology,"2021 IEEE/ACM 11th Workshop on Irregular Applications: Architectures and Algorithms (IA3)","28 Dec 2021","2021","","","1","1","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Designing flexible graph kernels that can run well on various platforms is a crucial research problem due to the frequent usage of graphs for modeling data and recent architectural advances and variety. In this talk, I will present our recent graph processing model and framework, PGAbB, for modern shared-memory heterogeneous platforms. PGAbB implements a block-based programming model. This allows a user to express a graph algorithm using functors that operate on an ordered list of blocks (subgraphs). Our framework deploys these computations to all available resources in a heterogeneous architecture. We will demonstrate that one can implement a diverse set of graph algorithms in our framework, and task-based execution enables graph computations even on large graphs that do not fit in GPU device memory. Our experimental results show that PGAbB achieves competitive or superior performance compared to hand-optimized implementations or existing state-of-the-art graph computing frameworks.","2767-942X","978-1-6654-1126-4","10.1109/IA354616.2021.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653075","","","","","","","","","","28 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"High Performance Matrix Multiplication on General Purpose Graphics Processing Units","F. Wu; M. Cabral; J. Brazelton","Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA; Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA; Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA","2010 International Conference on Computational Intelligence and Software Engineering","30 Dec 2010","2010","","","1","4","In recent years, there has been significant interest from both academia and industry in applying commodity graphics processing units (GPUs) toward general computing problems. The nVidia CUDA programming model provides a straightforward means of describing inherently parallel computations. In this paper, we present our GPU-based matrix multiplication with high performance on General Purpose Graphics Processing Unit (GPGPUs). We implemented our algorithm using nVidia CUDA API and compared its performance with an optimized CPU-implementation on a high-end AMD Opteron Dual Core CPU. Our experimental results show that a significant performance improvement over CPU-based algorithm and the maximum observed speedups are about 100 times.","","978-1-4244-5391-7","10.1109/CISE.2010.5677044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677044","","Graphics processing unit;Kernel;Instruction sets;Computer architecture;Central Processing Unit;Programming","coprocessors;matrix multiplication","matrix multiplication;general purpose graphics processing units;nVidia CUDA programming;parallel computations;AMD Opteron Dual Core CPU","","","","5","","30 Dec 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Cellular Neural Networks for FPGAs with OpenCL","F. Richter-Gottfried; D. Fey",NA; NA,"CNNA 2016; 15th International Workshop on Cellular Nanoscale Networks and their Applications","23 Jan 2017","2016","","","1","2","Cellular Neural Networks (CNNs) are an inherently parallel computational model for multiple applications, and they are especially appropriate for image processing tasks. Besides of implementing them with analogue electronic circuits, they can be simulated on digital processor architectures like CPUs and GPUs, with the drawback of limited parallelism. FPGAs offer a fine-grained parallel execution with low power consumption and are thus attractive for embedded systems like smart cameras, for which it is not possible to use a full-featured CPU or GPU with tens or hundrets of watts. The drawback of implementing CNNs with FPGAs, to profit from the high performance-to-power ratio, is the time-consuming design process with conventional hardware descriptions languages. High-level-synthesis, e.g., from OpenCL, eases the process of generating CNNs in FPGAs. By using the OpenCL programming model, the programmer can explicitly express the parallel nature of CNNs in a platform-independent way. To investigate its applicability to CNNs, we compare the execution of an unmodified OpenCL kernel on a recent CPU with an FPGA design generated with Altera's SDK for OpenCL. The results show, that though the CPU is faster, the FPGA solution performs better in terms of energy efficiency and fits for smart camera systems.","","978-3-8007-4252-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827967","","","","","","","","","","23 Jan 2017","","","VDE","VDE Conferences"
notebooks/data/ieee_5.csv:"Gemma in April: A matrix-like parallel programming architecture on OpenCL","T. Wu; D. Wu; Y. Wang; X. Zhang; H. Luo; N. Xu; H. Yang","Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Hardware Computing Group, Microsoft Research Asia; Department of Electronic Engineering, TNList, Tsinghua University","2011 Design, Automation & Test in Europe","5 May 2011","2011","","","1","6","Nowadays, Graphics Processing Unit (GPU), as a kind of massive parallel processor, has been widely used in general purposed computing tasks. Although there have been mature development tools, it is not a trivial task for programmers to write GPU programs. Based on this consideration, we propose a novel parallel computing architecture. The architecture includes a parallel programming model, named Gemma, and a programming framework, named April. Gemma is based on generalized matrix operations, and helps to alleviate the difficulty of describing parallel algorithms. April is a high-level framework that can compile and execute tasks described in Gemma with OpenCL. In particular, April can automatically 1) choose the best parallel algorithm and mapping scheme, and generate OpenCL kernels, 2) schedule Gemma tasks based on execution costs such as data storing and transferring. Our experimental results show that with competitive performance, April considerably reduces the programs' code length compared with OpenCL.","1558-1101","978-3-9810801-8-6","10.1109/DATE.2011.5763119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763119","","Graphics processing unit;Computer architecture;Sparse matrices;Computational modeling;Kernel;Parallel programming","computer graphic equipment;coprocessors;parallel programming;programming languages","matrix-like parallel programming architecture;graphics processing unit;parallel computing architecture;Gemma;April;parallel algorithms;OpenCL kernels;data storing;data transferring;open computing language","","","","11","","5 May 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Evaluating Performance and Portability of a core bioinformatics kernel on multiple vendor GPUs","M. Haseeb; N. Ding; J. Deslippe; M. Awan","Florida International University,Miami,USA; Lawrence Berkeley National Laboratory,Berkeley,USA; Lawrence Berkeley National Laboratory,Berkeley,USA; Lawrence Berkeley National Laboratory,Berkeley,USA","2021 International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","28 Dec 2021","2021","","","68","78","Traditional scientific simulations have for quite some time, dominated the workloads of high-performance computing infrastructures across the world. With recent advancement in data generation capabilities of systems biology equipment, a rise in bioinformatics workloads has been observed. Bioinformatics applications deploy algorithmic motifs that use unique memory access patterns and rely heavily on integer-only computations. These applications place unique requirements on modern programming environments as well as GPU accelerators which are becoming an integral part of next generation of supercomputers. In this paper, we evaluate the performance and code portability of a core bioinformatics kernel that uses dynamic programming method for performing DNA and protein sequence alignments in several bioinformatics software pipelines. Our study evaluates the performance of a GPU accelerated sequence alignment algorithm across multiple vendor GPUs and programming models. We use a highly optimized adaptation of sequence alignment kernel and find the most productive way of porting it across multiple vendor GPUs and then assess its performance portability using Pennycook's method. Methods used in this paper and the insights drawn from those can be extended to a large number of integer-heavy scientific kernels and may aid in future accelerator design and design of programming model requirements.","","978-1-6654-2439-4","10.1109/P3HPC54578.2021.00010","U.S. Department of Energy(grant numbers:17-SC-20-SC); National Nuclear Security Administration; Oak Ridge National Laboratory; Office of Science of the U.S. Department of Energy(grant numbers:DE-AC05-000R22725); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652848","Performance;Portability;GPUs;Bioinformatics;DNA;Protein;Sequence Alignment","Performance evaluation;Codes;Biological system modeling;Graphics processing units;Computer architecture;Programming;Supercomputers","","","","","","39","","28 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"An open-source solution to performance portability for Summit and Sierra supercomputers","G. T. Bercea; A. Bataev; A. E. Eichenberger; C. Bertolli; J. K. O'Brien",NA; NA; NA; NA; NA,"IBM Journal of Research and Development","13 May 2020","2020","64","3/4","12:1","12:23","Programming models that use a higher level of abstraction to express parallelism can target both CPUs and any attached devices, alleviating the maintainability and portability concerns facing today's heterogenous systems. This article describes the design, implementation, and delivery of a compliant OpenMP device offloading implementation for IBM-NVIDIA heterogeneous servers composing the Summit and Sierra supercomputers in the mainline open-source Clang/LLVM compiler and OpenMP runtime projects. From a performance perspective, reconciling the GPU programming model, best suited for massively parallel workloads, with the generality of the OpenMP model was a significant challenge. To achieve both high performance and full portability, we map high-level programming patterns to fine-tuned code generation schemes and customized runtimes that preserve the OpenMP semantics. In the compiler, we implement a low-overhead single-program multiple-data scheme that leverages the GPU native execution model and a fallback scheme to support the generality of OpenMP. Modular design enables the implementation to be extended with new schemes for frequently occurring patterns. Our implementation relies on key optimizations: sharing data among threads, leveraging unified memory, aggressive inlining of runtime calls, memory coalescing, and runtime simplification. We show that for commonly used patterns, performance on the Summit and Sierra GPUs matches that of hand-written native CUDA code.","0018-8646","","10.1147/JRD.2019.2955944","CORAL(grant numbers:B604142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928619","","Programming;Graphics processing units;Instruction sets;Runtime;Computational modeling;Open source software;Performance evaluation","","","","","","39","IBM","9 Dec 2019","","","IBM","IBM Journals"
notebooks/data/ieee_5.csv:"Designing APU Oriented Scientific Computing Applications in OpenCL","M. Doerksen; S. Solomon; P. Thulasiraman","Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada","2011 IEEE International Conference on High Performance Computing and Communications","31 Oct 2011","2011","","","587","592","The future of high performance computing is moving towards exa-scale computing. Graphical Processing Units (GPUs) have demonstrated their capabilities beyond graphics rendering or general purpose computing and are well suited for data intensive applications. However, the communication bottleneck for data transfer between the GPU and CPU has led to the design of AMD's Accelerated Processing Unit (APU) which combines the CPU and GPU on a single chip. This new architecture poses new challenges: algorithms must be redesigned to take advantage of this architecture and programming models differ between vendors, hindering the portability of algorithms across heterogeneous platforms. Recently, OpenCL has been regarded as the standard programming model for heterogeneous platforms. With the future of general purpose computing moving towards APUs, in this paper, we study the design and implementation of two problems: 0-1 knapsack and Gaussian Elimination in OpenCL. This pair of algorithms showcases similar synchronization behaviors, enabling a more direct comparison. We discuss the design and performance of these algorithms using OpenCL.","","978-1-4577-1564-8","10.1109/HPCC.2011.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063044","","Graphics processing unit;Instruction sets;Synchronization;Central Processing Unit;Algorithm design and analysis;Computer architecture;Equations","computer graphic equipment;coprocessors;parallel algorithms;programming languages","APU oriented scientific computing application;accelerated processing unit;high performance computing;OpenCL;exascale computing;graphical processing unit;graphics rendering;general purpose computing;0-1 knapsack problem;Gaussian elimination problem;synchronization behavior;open computing language","","9","","12","","31 Oct 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Cambricon-G: A Polyvalent Energy-Efficient Accelerator for Dynamic Graph Neural Networks","X. Song; T. Zhi; Z. Fan; Z. Zhang; X. Zeng; W. Li; X. Hu; Z. Du; Q. Guo; Y. Chen","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","22 Dec 2021","2022","41","1","116","128","Graph neural networks (GNNs), which extend traditional neural networks for processing graph-structured data, have been widely used in many fields. The GNN computation mainly consists of the <italic>edge processing</italic> to generate messages by combining the edge/vertex features and the <italic>vertex processing</italic> to update the vertex features with aggregated messages. In addition to nontrivial vector operations in the edge processing, huge random accesses and neural network operations in the vertex processing, the graph topology of GNNs may also vary during the computation (i.e., dynamic GNNs). The above characteristics pose significant challenges on existing architectures. In this article, we propose a novel accelerator named CAMBRICON-G for efficient processing of both dynamic and static GNNs. The key of CAMBRICON-G is to abstract the irregular computation of a broad range of GNN variants to the process of regularly tiled <italic>adjacent cuboid</italic> (which extends the traditional adjacent matrix of graph by adding the dimension of vertex features). The intuition is that the adjacent cuboid facilitates exploitation of both data locality and parallelism by offering <italic>multidimensional multilevel tiling</italic> (including spatial and temporal tiling) opportunities. To perform the <italic>multidimensional spatial tiling</italic>, the CAMBRICON-G architecture mainly consists of the cuboid engine (CE) and hybrid on-chip memory. The CE has multiple vertex processing units (VPUs) working in a coordinated manner to efficiently process the sparse data and dynamically update the graph topology with dedicated instructions. The hybrid on-chip memory contains the topology-aware cache and multiple scratchpad memory to reduce off-chip memory access. To perform the <italic>multidimensional temporal tiling</italic>, an easy-to-use programming model is provided to flexibly explore different tiling options for large graphs. Experimental results show that compared against Nvidia P100 GPU, the performance and energy efficiency can be improved by <inline-formula> <tex-math notation=""LaTeX"">$7.14\times $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$20.18\times $ </tex-math></inline-formula>, respectively, on various GNNs, which validates both the versatility and energy efficiency of CAMBRICON-G.","1937-4151","","10.1109/TCAD.2021.3052138","National Key Research and Development Program of China(grant numbers:2017YFA0700900,2017YFA0700902,2017YFA0700901); NSF of China(grant numbers:61925208,61732007,61732002,61702478,61906179,62002338,61702459,U19B2019,U20A20227); Beijing Natural Science Foundation(grant numbers:JQ18013); Key Research Projects in Frontier Science of Chinese Academy of Sciences(grant numbers:QYZDB-SSW-JSC001); Strategic Priority Research Program of Chinese Academy of Science(grant numbers:XDB32050200,XDC05010300,XDC08040102); Beijing Academy of Artificial Intelligence (BAAI) and Beijing Nova Program of Science and Technology(grant numbers:Z191100001119093); Science and Technology Planning Project of Guangdong Province(grant numbers:2019B090909005); Youth Innovation Promotion Association CAS and Xplore Prize; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326339","Accelerator;architecture;graph neural networks (GNNs)","Hardware;Programming;Topology;System-on-chip;Graphics processing units;Convolution;Engines","","","","","","32","IEEE","18 Jan 2021","","","IEEE","IEEE Journals"
notebooks/data/ieee_5.csv:"HyGCN: A GCN Accelerator with Hybrid Architecture","M. Yan; L. Deng; X. Hu; L. Liang; Y. Feng; X. Ye; Z. Zhang; D. Fan; Y. Xie","Chinese Academy of Sciences; University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of California, Santa Barbara","2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)","16 Apr 2020","2020","","","15","29","Inspired by the great success of neural networks, graph convolutional neural networks (GCNs) are proposed to analyze graph data. GCNs mainly include two phases with distinct execution patterns. The Aggregation phase, behaves as graph processing, showing a dynamic and irregular execution pattern. The Combination phase, acts more like the neural networks, presenting a static and regular execution pattern. The hybrid execution patterns of GCNs require a design that alleviates irregularity and exploits regularity. Moreover, to achieve higher performance and energy efficiency, the design needs to leverage the high intra-vertex parallelism in Aggregation phase, the highly reusable inter-vertex data in Combination phase, and the opportunity to fuse phase-by-phase execution introduced by the new features of GCNs. However, existing architectures fail to address these demands. In this work, we first characterize the hybrid execution patterns of GCNs on Intel Xeon CPU. Guided by the characterization, we design a GCN accelerator, HyGCN, using a hybrid architecture to efficiently perform GCNs. Specifically, first, we build a new programming model to exploit the fine-grained parallelism for our hardware design. Second, we propose a hardware design with two efficient processing engines to alleviate the irregularity of Aggregation phase and leverage the regularity of Combination phase. Besides, these engines can exploit various parallelism and reuse highly reusable data efficiently. Third, we optimize the overall system via inter-engine pipeline for inter-phase fusion and priority-based off-chip memory access coordination to improve off-chip bandwidth utilization. Compared to the state-of-the-art software framework running on Intel Xeon CPU and NVIDIA V100 GPU, our work achieves on average 1509× speedup with 2500× energy reduction and average 6.5× speedup with 10× energy reduction, respectively.","2378-203X","978-1-7281-6149-5","10.1109/HPCA47549.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065592","Hardware Accelerator, Graph Convolution Neural Network, Graph Processing, Hybrid Execution Pattern","Computer architecture;Neural networks;Engines;Parallel processing;Aggregates;Fuses;Hardware","convolutional neural nets;graph theory;graphics processing units;microprocessor chips;multiprocessing systems;parallel architectures;parallel processing;power aware computing","hybrid execution patterns;GCNs;energy efficiency;high intra-vertex parallelism;Aggregation phase;phase-by-phase execution;Intel Xeon CPU;GCN accelerator;HyGCN;hybrid architecture;hardware design;inter-phase fusion;priority-based off-chip memory access coordination;graph convolutional neural networks;graph data;graph processing;inter-vertex data;off-chip bandwidth utilization;software framework","","38","","46","","16 Apr 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"CoSMo: Intent-based composition of shader modules","G. Haaser; H. Steinlechner; M. May; M. Schwärzler; S. Maierhofer; R. Tobler","VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria","2014 International Conference on Computer Graphics Theory and Applications (GRAPP)","12 Oct 2015","2014","","","1","11","We propose a novel shader programming model which operates on intent-oriented shader modules instead of specific programs for dedicated GPU rasterization pipeline stages. In constrast to existing pipeline shader frameworks, our system exposes a radically simplified pipeline, which we purposefully aligned with our basic intuition of shaders as per-primitive and per-pixel operations and compositions thereof. This simplicity lends itself to structure modules purely based on their intent, instead of dealing with structure enforced by specific versions of graphics APIs. Consequently, this offers great flexibility when it comes to reusing and combining modules with completely different semantics, or when targeting different graphics APIs. The simplicity and uniformity of our system also motivates automatic parameterization and simplification of shader programs as well as interesting interactive shader development and management techniques.","","978-9-8975-8078-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296051","Shader;Composition;Rendering;Language;Embedded","Semantics;Pipelines;Programming;Lighting;Rendering (computer graphics);Synthesizers;Surface treatment","","","","","","22","","12 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"A Hybrid Cache HW/SW Stack for Optimizing Neural Network Runtime, Power and Endurance","W. A. Simon; A. Levisse; M. Zapater; D. Atienza","Embedded Systems Laboratory (ESL), Swiss Federal Institute of Technology Lausanne (EPFL); Embedded Systems Laboratory (ESL), Swiss Federal Institute of Technology Lausanne (EPFL); University of Applied Sciences Western Switzerland (HEIG-VD / HES-SO); Embedded Systems Laboratory (ESL), Swiss Federal Institute of Technology Lausanne (EPFL)","2020 IFIP/IEEE 28th International Conference on Very Large Scale Integration (VLSI-SOC)","10 Feb 2021","2020","","","94","99","Hybrid caches consisting of both SRAM and emerging Non-Volatile Random Access Memory (eNVRAM) bitcells increase cache capacity and reduce power consumption by taking advantage of eNVRAM's small area footprint and low leakage energy. However, they also inherit eNVRAM's drawbacks, including long write latency and limited endurance. To mitigate these drawbacks, many works propose heuristic strategies to allocate memory blocks into SRAM or eNVRAM arrays at runtime based on block content or access pattern. In contrast, this work presents a HW/SW Stack for Hybrid Caches (SHyCache), consisting of a hybrid cache architecture and supporting programming model, reminiscent of those that enable GP-GPU acceleration, in which application variables can be allocated explicitly to the eNVRAM cache, eliminating the need for heuristics and reducing cache access time, power consumption, and area overhead while maintaining maximal cache utilization efficiency and ease of programming. SHyCache improves performance for applications such as neural networks, which contain large numbers of invariant weight values with high read/write access ratios that can be explicitly allocated to the eNVRAM array. We simulate SHyCache on the gem5-X architectural simulator and demonstrate its utility by benchmarking a range of cache hierarchy variations using three neural networks, namely, Inception v4, ResNet-50, and SqueezeNet 1.0. We demonstrate a design space that can be exploited to optimize performance, power consumption, or endurance, depending on the expected use case of the architecture, while demonstrating maximum performance gains of 1.7 /1.4/1.3x and power consumption reductions of 5.1/5.2/5.4x, for Inception/ResNet/SqueezeNet, respectively.","2324-8440","978-1-7281-5409-1","10.1109/VLSI-SOC46417.2020.9344087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344087","eNVRAM;STT-MRAM;hybrid caches;neural networks;low-power systems","Power demand;Runtime;Random access memory;Programming;Benchmark testing;Hybrid power systems;Resource management","","","","","","26","","10 Feb 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"VSIPL++ Acceleration Using Commodity Graphics Processors","D. Campbell","Georgia Tech Research Institute, Smyrna, GA","2006 HPCMP Users Group Conference (HPCMP-UGC'06)","19 Mar 2007","2006","","","315","320","The High Performance Embedded Computing Software Initiative (HPEC-SI) is developing a unified software framework for computation and communication for high performance signal processing tasks on parallel computers. The goal of the program is to address the high cost of software in Department of Defense (DoD) systems by improving the portability and productivity of signal processing application development, while simultaneously improving performance compared to current practices. The Vector, Signal, and Image Processing Library (VSIPL) is a portable application programming interface (API) that is widely used for embedded DoD signal processing systems. One portion of the HPEC-SI effort includes the development of C++ extensions for the existing VSIPL standard, called VSIPL++. Commodity graphics processing units (GPUs) are application-specific processors that implement a standardized three-dimensional graphics-rendering pipeline, and provide significant floating-point processing capacity at much lower cost, power consumption, and physical space compared to general-purpose processors. Recent changes in GPUs have increased programmability and flexibility in portions of the rendering pipeline, allowing non-graphics applications to exploit their computational capacity. Restrictions on the programming model, lack of appropriate tools, unusual performance behavior, and other factors make exploiting GPUs a costly, difficult, and time-consuming process for application developers. The embedded systems that VSIPL and VSIPL++ are commonly used on share several important characteristics with GPUs, making VSIPL++ well suited to abstract and exploit GPUs. This paper describes GPUVSIPL++, an implementation of portions of the VSIPL++ standard that exploits a GPU to accelerate computation beyond what is possible on a development workstation","","0-7695-2797-3","10.1109/HPCMP-UGC.2006.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4134073","","Acceleration;Graphics;Signal processing;Embedded computing;Software performance;Embedded software;Concurrent computing;High performance computing;Costs;Application software","application program interfaces;microprocessor chips","VSIPL++ acceleration;commodity graphics processors;unified software framework;high performance signal processing;parallel computers;portable application programming interface;3D graphics-rendering pipeline;floating-point processing;GPUVSIPL++","","2","","13","","19 Mar 2007","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"Benchmarking and Extending SYCL Hierarchical Parallelism","T. Deakin; S. McIntosh-Smith; A. Alpay; V. Heuveline","University of Bristol,Department of Computer Science,Bristol,UK; University of Bristol,Department of Computer Science,Bristol,UK; Universität Heidelberg,Engineering Mathematics and Computing Lab and Interdisciplinary Center for Scientific Computing,Heidelberg,Germany; Universität Heidelberg,Engineering Mathematics and Computing Lab and Interdisciplinary Center for Scientific Computing,Heidelberg,Germany","2021 IEEE/ACM International Workshop on Hierarchical Parallelism for Exascale Computing (HiPar)","24 Dec 2021","2021","","","10","19","SYCL is an open-standard, parallel programming model for programming heterogeneous devices from Khronos. It allows single-source programming of diverse attached devices in a cross-platform manner in modern C++. SYCL provides different layers of parallel abstractions, including Same Instruction Multiple Thread (SIMT) kernels, data-parallel loop concurrency and hierarchical parallelism. We discuss Scoped Parallelism as an extension to the existing Hierarchical Parallelism in SYCL, and highlight the advantages and disadvantages of these models from the perspective of the programmer and an implementer of SYCL. In this paper, we compare writing benchmark programs using SIMT kernel, hierarchical parallelism and scoped parallelism paradigms, and present results running on a high-performance CPU and GPU.","","978-1-6654-1132-5","10.1109/HiPar54615.2021.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654235","","Concurrent computing;Parallel programming;Exascale computing;Conferences;Graphics processing units;C++ languages;Parallel processing","","","","","","8","","24 Dec 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"CPUs and GPUs: Who Owns the Future?","E. R. Altman",ealtman@us.ibm.com,"IEEE Micro","17 Oct 2011","2011","31","5","2","3","This column addresses issues facing CPUs, GPUs, and how to program them and other computing devices.","1937-4143","","10.1109/MM.2011.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045683","CPU;GPU;performance;application-specific integrated circuit;field-programmable gate array;programming model;productivity","","","","","1","","","IEEE","17 Oct 2011","","","IEEE","IEEE Magazines"
notebooks/data/ieee_5.csv:"A nodal discontinuous Galerkin method for reverse-time migration on GPU clusters","A. Modave; A. St-Cyr; W. A. Mulder; T. Warburton",NA; NA; NA; NA,"Geophysical Journal International","18 Jan 2018","2015","203","2","1419","1435","Improving both accuracy and computational performance of numerical tools is a major challenge for seismic imaging and generally requires specialized implementations to make full use of modern parallel architectures. We present a computational strategy for reverse-time migration (RTM) with accelerator-aided clusters. A new imaging condition computed from the pressure and velocity fields is introduced. The model solver is based on a high-order discontinuous Galerkin time-domain (DGTD) method for the pressure–velocity system with unstructured meshes and multirate local time stepping. We adopted the MPI+X approach for distributed programming where X is a threaded programming model. In this work we chose OCCA, a unified framework that makes use of major multithreading languages (e.g. CUDA and OpenCL) and offers the flexibility to run on several hardware architectures. DGTD schemes are suitable for efficient computations with accelerators thanks to localized element-to-element coupling and the dense algebraic operations required for each element. Moreover, compared to high-order finite-difference schemes, the thin halo inherent to DGTD method reduces the amount of data to be exchanged between MPI processes and storage requirements for RTM procedures. The amount of data to be recorded during simulation is reduced by storing only boundary values in memory rather than on disk and recreating the forward wavefields. Computational results are presented that indicate that these methods are strong scalable up to at least 32 GPUs for a three-dimensional RTM case.","1365-246X","","10.1093/gji/ggv380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8188177","Image processing;Numerical solutions;Computational seismology","","","","","1","","","","18 Jan 2018","","","OUP","OUP Journals"
notebooks/data/ieee_5.csv:"Keynote 1 — It's about time","E. A. Lee",U. C. Berkeley,"2014 International Conference on ReConFigurable Computing and FPGAs (ReConFig14)","9 Feb 2015","2014","","","1","1","Summary form only given. Cyber-physical systems are integrations of computation, communication networks, and physical dynamics. Although time plays a central role in the physical world, all widely used software abstractions lack temporal semantics. The notion of correct execution of a program written in every widely-used programming language today does not depend on the temporal behavior of the program. But temporal behavior matters in almost all systems. Even in systems with no particular real-time requirements, timing of programs is relevant to the value delivered by programs, and in the case of concurrent programs, also affects the functionality. In cyber-physical systems, temporal behavior affects not just the value delivered by a system but also its correctness. In this talk, I will argue that time can and must become part of the semantics of programs for a large class of applications. To illustrate that this is both practical and useful, we will describe two recent efforts at Berkeley in the design and implementation of timing-centric software systems. On the implementation side, I will describe PRET machines, which redefine the instruction-set architecture (ISA) of a microprocessor to include temporal semantics. Such machines can be used in high-confidence and safety-critical systems, in energy-constrained systems, in mixed-criticality systems, and as a Real-Time Unit (RTU) that cooperates with a general-purpose processor to provide real-time services, in a manner similar to how a GPU provides graphics services. On the design side, I will briefly describe PTIDES, a programming model for distributed real-time systems.","2325-6532","978-1-4799-5944-0","10.1109/ReConFig.2014.7032479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7032479","","","instruction sets;programming language semantics","distributed real time systems;programming model;PTIDES;RTU;real time unit;mixed criticality systems;energy constrained systems;safety critical systems;microprocessor;ISA;instruction set architecture;timing centric software systems;Berkeley;concurrent programs;temporal behavior;programming language;program written;software abstractions lack temporal semantics;physical dynamics;communication networks;cyber physical systems","","","","","","9 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"[Front matter]","",,"International Symposium on Code Generation and Optimization (CGO 2011)","5 May 2011","2011","","","i","ii","The following topics are dealt with: polyhedral compilation; machine learning; software-hardware co-design; DSP; data parallel heterogeneous system; GPU programming model; source-to-source compiler optimisation; safety-critical real-time system; WCET-aware C compiler; high-level language; low level code optimization; performance asymmetric multicore processors; tagless instruction cache; software transactional memory optimization; multiprocessor chip; vapor SIMD; on-chip cache hierarchy aware tile scheduling; data locality; NoC based multicore; embedded language; virtual machine; Java JIT compiler; highly scalable distributed dataflow analysis; and flow sensitive pointer analysis.","","978-1-61284-357-5","10.1109/CGO.2011.5764642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5764642","","","cache storage;data flow analysis;hardware-software codesign;Java;multiprocessing systems;network-on-chip;optimising compilers;parallel processing;safety-critical software;virtual machines","polyhedral compilation;machine learning;software-hardware co-design;DSP;data parallel heterogeneous system;GPU programming model;source-to-source compiler optimisation;safety-critical real-time system;WCET-aware C compiler;high-level language;low level code optimization;performance asymmetric multicore processors;tagless instruction cache;software transactional memory optimization;multiprocessor chip;vapor SIMD;on-chip cache hierarchy aware tile scheduling;data locality;NoC based multicore;embedded language;virtual machine;Java JIT compiler;highly scalable distributed dataflow analysis;flow sensitive pointer analysis","","","","","","5 May 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_5.csv:"[Title page i]","",,"2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","11 Jul 2011","2011","","","i","i","The following topics are dealt with: cluster computing; cloud computing; grid computing; virtual machines; GPU-based computing; programming models; runtime systems; volunteer computing; distributed systems; resource scheduling; data streaming; caching memory; shared memory; data-driven computing; fault tolerance; checkpointing; communication management; network management; distributed hash tables; I/O systems; file systems; QoS; data intensive computing; MapReduce; security; social network; business workshop; industry workshop; and enterprise workshop.","","978-1-4577-0129-0","10.1109/CCGrid.2011.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948665","","","cache storage;cloud computing;computer graphic equipment;coprocessors;cryptography;data analysis;distributed shared memory systems;fault tolerant computing;grid computing;pattern clustering;quality of service;resource allocation;social networking (online);telecommunication network management;virtual enterprises;virtual machines","cluster computing;cloud computing;grid computing;virtual machine;GPU-based computing;programming model;runtime system;volunteer computing;distributed system;resource scheduling;data streaming;caching memory;shared memory;data-driven computing;fault tolerance;checkpointing;communication management;network management;distributed hash tables;I/O system;QoS;data intensive computing;MapReduce;security;social network;business workshop;industry workshop;enterprise workshop;file system","","","","","","11 Jul 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Can GPGPU Programming Be Liberated from the Data-Parallel Bottleneck?","B. R. Gaster; L. Howes",Advanced Micro Devices; Advanced Micro Devices,"Computer","17 Aug 2012","2012","45","8","42","52","With the growth in transistor counts in modern hardware, heterogeneous systems are becoming commonplace. Core counts are increasing such that GPU and CPU designs are reaching deep into the tens of cores. For performance reasons, different cores in a heterogeneous platform follow different design choices. Based on throughput computing goals, GPU cores tend to support wide vectors and substantial register files. Current designs optimize CPU cores for latency, dedicating logic to caches and out-of-order dependence control. Heterogeneous parallel primitives (HPP) addresses two major shortcomings in current GPGPU programming models: it supports full composability by defining abstractions and increases flexibility in execution by introducing braided parallelism. Heterogeneous parallel primitives is an object-oriented, C++11-based programming model that addresses these shortcomings on both CPUs and massively multithreaded GPUs: it supports full composability by defining abstractions using distributed arrays and barrier objects, and it increases flexibility in execution by introducing braided parallelism. This paper implemented a feature-complete version of HPP, including all syntactic constructs, that runs on top of a task-parallel runtime executing on the CPU. They continue to develop and improve the model, including reducing overhead due to channel management, and plan to make a public version available sometime in the future.","1558-0814","","10.1109/MC.2012.257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6272260","massively threaded computing systems;heterogeneous parallel primitives;braided parallelism;persistent threading;GPGPU programming;data-parallel execution;distributed arrays;hardware","Graphics processing unit;Programming;Performance evaluation;Parellel processing;Indexes;Hardware;Multithreading","C++ language;graphics processing units;integrated circuit design;multi-threading;object-oriented programming","GPGPU programming;data-parallel bottleneck;heterogeneous systems;core counts;GPU designs;CPU designs;heterogeneous parallel primitives;general-purpose computing-on-graphics processing units;object-oriented C++11-based programming model;distributed arrays;barrier objects;task-parallel runtime;channel management;braided parallelism","","24","2","16","","17 Aug 2012","","","IEEE","IEEE Magazines"
notebooks/data/ieee_4.csv:"CUDAsmith: A Fuzzer for CUDA Compilers","B. Jiang; X. Wang; W. K. Chan; T. H. Tse; N. Li; Y. Yin; Z. Zhang","Beihang University, China; Beihang University, China; City University of Hong Kong; The University of Hong Kong, Hong Kong; CAST; Beihang University, China; Chinese Academy of Sciences, China","2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)","22 Sep 2020","2020","","","861","871","CUDA is a parallel computing platform and programming model for the graphics processing unit (GPU) of NVIDIA. With CUDA programming, general purpose computing on GPU (GPGPU) is possible. However, the correctness of CUDA programs relies on the correctness of CUDA compilers, which is difficult to test due to its complexity. In this work, we propose CUDAsmith, a fuzzing framework for CUDA compilers. Our tool can randomly generate deterministic and valid CUDA kernel code with several different strategies. Moreover, it adopts random differential testing and EMI testing techniques to solve the test oracle problems of CUDA compiler testing. In particular, we lift live code injection to CUDA compiler testing to help generate EMI variants. Our fuzzing experiments with both the NVCC compiler and the Clang compiler for CUDA have detected thousands of failures, some of which have been confirmed by compiler developers. Finally, the cost-effectiveness of CUDAsmith is also thoroughly evaluated in our fuzzing experiment.","0730-3157","978-1-7281-7303-0","10.1109/COMPSAC48688.2020.0-156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9202798","Compiler, compute unified device architecture (CUDA), differential testing, equivalence modulo inputs (EMI) testing, fuzzing, general purpose computing on graphics processing unit (GPGPU)","Graphics processing units;Kernel;Electromagnetic interference;Fuzzing;Tools;Computational modeling","computational complexity;graphics processing units;program compilers;program testing","CUDA programming;general purpose computing;GPU;CUDA programs;CUDA compilers;CUDAsmith;deterministic CUDA kernel code;random differential testing;test oracle problems;CUDA compiler testing;NVCC compiler;Clang compiler;compiler developers;parallel computing platform;programming model","","1","","29","","22 Sep 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Task-based parallel breadth-first search in heterogeneous environments","L. Munguía; D. A. Bader; E. Ayguade","Barcelona School of Informatics, Universitat Politècnica de Catalunya, Barcelona, Spain; College of Computing Georgia Institute of Technology, Atlanta GA 30332; Barcelona Supercomputing Center (BSC), Spain","2012 19th International Conference on High Performance Computing","25 Apr 2013","2012","","","1","10","Breadth-first search (BFS) is an essential graph traversal strategy widely used in many computing applications. Because of its irregular data access patterns, BFS has become a non-trivial problem hard to parallelize efficiently. In this paper, we introduce a parallelization strategy that allows the load balancing of computation resources as well as the execution of graph traversals in hybrid environments composed of CPUs and GPUs. To achieve that goal, we use a fine-grained task-based parallelization scheme and the OmpSs programming model. We obtain processing rates up to 2.8 billion traversed edges per second with a single GPU and a multi-core processor. Our study shows high processing rates are achievable with hybrid environments despite the GPU communication latency and memory coherence.","","978-1-4673-2371-0","10.1109/HiPC.2012.6507474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6507474","","","graph theory;graphics processing units;multiprocessing systems;parallel processing;resource allocation;tree searching","task-based parallel breadth-first search;heterogeneous environment;BFS;graph traversal strategy;irregular data access pattern;parallelization strategy;load balancing;computation resource;hybrid environment;CPU;fine-grained task-based parallelization scheme;OmpSs programming model;processing rate;multicore processor;GPU communication latency;memory coherence","","16","1","15","","25 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"SOLAR: Services-Oriented Learning Architectures","C. Wang; X. Li; Q. Yu; A. Wang; P. Hung; X. Zhou","Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China","2016 IEEE International Conference on Web Services (ICWS)","1 Sep 2016","2016","","","662","665","Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data sizes have posed significant challenge to construct a flexible and high efficient implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA based approaches. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.","","978-1-5090-2675-3","10.1109/ICWS.2016.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7558064","Services-oriented Architecture;Deep Learning;Neural Network;Accelerator","Hardware;Machine learning;Field programmable gate arrays;Computer architecture;Graphics processing units;Service-oriented architecture","field programmable gate arrays;graphics processing units;learning (artificial intelligence);multiprocessing systems;neural nets;service-oriented architecture","SOLAR;machine learning;deep learning neural networks;services-oriented deep learning architecture;GPU;FPGA based approaches;uniform programming model;ubiquitous framework;Intel i5 processors","","7","","9","","1 Sep 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Massively Parallel Network Coding on GPUs","X. Chu; K. Zhao; M. Wang","Department of Computer Science, Hong Kong Baptist University, Hong Kong, P.R.C, chxw@comp.hkbu.edu.hk; Department of Computer Science, Hong Kong Baptist University, Hong Kong, P.R.C, kyzhao@comp.hkbu.edu.hk; Department of Computer Science, University of Calgary, Alberta, Canada, meawang@ucalgary.ca","2008 IEEE International Performance, Computing and Communications Conference","9 Jan 2009","2008","","","144","151","Network coding has recently been widely applied in various networks for system throughput improvement and/or resilience to network dynamics. However, the computational overhead introduced by the network coding operations is not negligible and has become the cornerstone for real deployment of network coding. In this paper, we exploit the computing power of contemporary Graphic Processing Units (GPUs) to accelerate the network coding operations. We proposed three parallel algorithms that maximize the parallelism of the encoding and decoding processes, i.e., the power of GPUs is fully utilized. This paper also shares our optimization design choices and our workarounds to the challenges encountered in working with GPUs. With our implementation of the algorithms, we are able to achieve up to 12 times of speedup over the highly optimized CPU counterpart, using the NVIDIA GPU and the Computer Unified Device Architecture (CUDA) programming model.","2374-9628","978-1-4244-3368-1","10.1109/PCCC.2008.4745113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745113","Network coding;GPU computing;CUDA","Network coding;Computer networks;Throughput;Resilience;Graphics;Acceleration;Parallel algorithms;Parallel processing;Encoding;Decoding","microprocessor chips;parallel algorithms","massively parallel network coding;system throughput improvement;graphic processing units;parallel algorithms;NVIDIA GPU;computer unified device architecture programming","","22","","21","","9 Jan 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"The Intel® Many Integrated Core Architecture","A. Duran; M. Klemm",Intel Corporation; Intel Corporation,"2012 International Conference on High Performance Computing & Simulation (HPCS)","16 Aug 2012","2012","","","365","366","In recent years, an observable trend in High Performance Computing (HPC) architectures has been the inclusion of accelerators, such as GPUs and field programmable arrays (FPGAs), to improve the performance of scientific applications. To rise to this challenge Intel announced the Intel<sup>®</sup> Many Integrated Core Architecture (Intel<sup>®</sup> MIC Architecture). In contrast with other accelerated platforms, the Intel MIC Architecture is a general purpose, manycore coprocessor that improves the programmability of such devices by supporting the well-known shared-memory execution model that is the base of most nodes in HPC machines. In this presentation, we will introduce key properties of the Intel MIC Architecture and we will also cover programming models for parallelization and vectorization of applications targeting this architecture.","","978-1-4673-2362-8","10.1109/HPCSim.2012.6266938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6266938","","Coprocessors;Computer architecture;Microwave integrated circuits;Programming;Hardware;Program processors;Syntactics","field programmable gate arrays;graphics processing units;parallel architectures;shared memory systems","Intel many integrated core architecture;high performance computing;accelerators;GPU;field programmable arrays;Intel MIC architecture;many core coprocessor;shared-memory execution model;programming model;parallelization;vectorization","","48","1","2","","16 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Monte Carlo simulation of X-ray imaging using a graphics processing unit","A. Badal; A. Badano","U.S. Food and Drug Administration, Division of Imaging and Applied Mathematics, Office of Science and Engineering Laboratories, Center for Devices and Radiological Health, Silver Spring, MD 20993-0002 USA; U.S. Food and Drug Administration, Division of Imaging and Applied Mathematics, Office of Science and Engineering Laboratories, Center for Devices and Radiological Health, Silver Spring, MD 20993-0002 USA","2009 IEEE Nuclear Science Symposium Conference Record (NSS/MIC)","29 Jan 2010","2009","","","4081","4084","A code for Monte Carlo simulations of radiation transport using a Graphics Processing Unit (GPU) is introduced. The code has been developed using the CUDA¿ programming model, an extension to the C language that allows the execution of general purpose computations on the new generation of GPUs from NVIDIA. The accurate Compton and Rayleigh interaction models and interaction mean free paths from the PENELOPE package, and a generic voxelized geometry model, have been implemented in the new code. The secondary particles generated by Compton, photoelectric and pair-production events are not transported. An ideal x-ray detector and a cone beam source can be defined to reproduce an imaging system and facilitate the simulations of medical imaging applications. A 24-fold speed up factor with the GPU compared to the CPU is reported for a radiographic projection of a detailed anthropomorphic female phantom. A description of the simulation algorithm and the technical implementation in the GPU are provided. This work shows that GPUs are already a good alternative to CPUs for Monte Carlo simulation of x-ray transport.","1082-3654","978-1-4244-3961-4","10.1109/NSSMIC.2009.5402382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402382","","X-ray imaging;Graphics;Solid modeling;Medical simulation;Packaging;Geometry;X-ray detectors;Optical imaging;Biomedical imaging;Central Processing Unit","biomedical imaging;Monte Carlo methods;radiography;X-ray detection;X-ray imaging","Monte Carlo simulation;X-ray imaging;graphics processing unit;radiation transport;CUDA¿ programming model;general purpose computations;Compton interaction model;Rayleigh interaction model;PENELOPE package;generic voxelized geometry model;X-ray detector;cone beam source;imaging system;medical imaging applications;radiographic projection;anthropomorphic female phantom;simulation algorithm;X-ray transport","","13","","12","","29 Jan 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Improving 3D lattice boltzmann method stencil with asynchronous transfers on many-core processors","M. Q. Ho; C. Obrecht; B. Tourancheau; B. D. de Dinechin; J. Hascoet","CNRS, LIG UMR 5217, Grenoble Alps University, F-38058 Grenoble, France; Univ Lyon, CNRS, INSA-Lyon, Université Claude Bernard Lyon 1, CETHIL UMR5008, F-69621 Villeurbanne, France; CNRS, LIG UMR 5217, Grenoble Alps University, F-38058 Grenoble, France; Kalray S.A., F-38330 Montbonnot, France; Kalray S.A., F-38330 Montbonnot, France","2017 IEEE 36th International Performance Computing and Communications Conference (IPCCC)","5 Feb 2018","2017","","","1","9","CPU-based many-core processors present an alternative to multicore CPU and GPU processors. In particular, the 93-Petaflops Sunway supercomputer, built from clustered many-core processors, has opened a new era for high performance computing that does not rely on GPU acceleration. However, memory bandwidth remains the main challenge for these architectures. This motivates our endeavor for optimizing one of the most data-intensive kind of stencil computations, namely the three-dimensional applications of the lattice Boltzmann method (LBM). We propose optimizations on many-cores processors by using local memory and asynchronous software-prefetching on a representative 3D LBM solver as an example. We achieve 33 % performance gain on the Kalray MPPA-256 many-core processor by actively streaming data from/to local memory, compared to the “passive” OpenCL programming model.","2374-9628","978-1-5090-6468-7","10.1109/PCCC.2017.8280472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8280472","","Three-dimensional displays;Program processors;Lattices;Computer architecture;Bandwidth;Computational modeling;Kernel","graphics processing units;lattice Boltzmann methods;multiprocessing systems;parallel processing","3D lattice Boltzmann method stencil;many-core processor cluster;LBM;asynchronous software-prefetching;representative 3D LBM solver;data streaming;OpenCL programming;Kalray MPPA-256 many-core processor;local memory;many-cores processors;stencil computations;GPU acceleration;high performance computing;93-Petaflops Sunway supercomputer;GPU processors;CPU;asynchronous transfers","","","","15","","5 Feb 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Automating CUDA Synchronization via Program Transformation","M. Wu; L. Zhang; C. Liu; S. H. Tan; Y. Zhang",Southern University of Science and Technology; University of Texas at Dallas; University of Texas at Dallas; Southern University of Science and Technology; Southern University of Science and Technology,"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","9 Jan 2020","2019","","","748","759","While CUDA has been the most popular parallel computing platform and programming model for general purpose GPU computing, CUDA synchronization undergoes significant challenges for GPU programmers due to its intricate parallel computing mechanism and coding practices. In this paper, we propose AuCS, the first general framework to automate synchronization for CUDA kernel functions. AuCS transforms the original LLVM-level CUDA program control flow graph in a semantic-preserving manner for exploring the possible barrier function locations. Accordingly, AuCS develops mechanisms to correctly place barrier functions for automating synchronization in multiple erroneous (challenging-to-be-detected) synchronization scenarios, including data race, barrier divergence, and redundant barrier functions. To evaluate the effectiveness and efficiency of AuCS, we conduct an extensive set of experiments and the results demonstrate that AuCS can automate 20 out of 24 erroneous synchronization scenarios.","2643-1572","978-1-7281-2508-4","10.1109/ASE.2019.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952529","CUDA;program repair;synchronization automation;program transformation","Graphics processing units;Synchronization;Computer bugs;Kernel;Instruction sets;Parallel processing;Computer science","flow graphs;graphics processing units;parallel architectures;parallel programming;program processors","CUDA synchronization;program transformation;parallel computing platform;general purpose GPU computing;GPU programmers;AuCS;CUDA kernel functions;original LLVM-level CUDA;program control flow graph;multiple erroneous synchronization scenarios","","5","","60","","9 Jan 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"One Size Doesn't Fit All: Quantifying Performance Portability of Graph Applications on GPUs","T. Sorensen; S. Pai; A. F. Donaldson","Princeton University, USA,UC Santa Cruz,USA; University of Rochester,USA; Imperial College London,UK","2019 IEEE International Symposium on Workload Characterization (IISWC)","19 Mar 2020","2019","","","155","166","Hand-optimising graph algorithm code for different GPUs is particularly labour-intensive and error-prone, involving complex and ill-understood interactions between GPU chips, applications, and inputs. Although the generation of optimised variants has been automated through graph algorithm DSL compilers, these do not yet use an optimisation policy. Instead they defer to techniques like autotuning, which can produce good results, but at the expense of portability. In this work, we propose a methodology to automatically identify portable optimisation policies that can be tailored (“semi-specialised”) as needed over a combination of chips, applications and inputs. Using a graph algorithm DSL compiler that targets the OpenCL programming model, we demonstrate optimising graph algorithms to run in a portable fashion across a wide range of GPU devices for the first time. We use this compiler and its optimisation space as the basis for a large empirical study across 17 graph applications, 3 diverse graph inputs and 6 GPUs spanning multiple vendors. We show that existing automatic approaches for building a portable optimisation policy fall short on our dataset, providing trivial or biased results. Thus, we present a new statistical analysis which can characterise optimisations and quantify performance trade-offs at various degrees of specialisation. We use this analysis to quantify the performance tradeoffs as portability is sacrificed for specialisation across three natural dimensions: chip, application, and input. Compared to not optimising programs at all, a fully portable approach provides a 1.15× improvement in geometric mean performance, rising to 1.29 × when specialised to application and inputs (but not hardware). Furthermore, these semi-specialised optimisations provide insights into performance-critical features of specialisation. For example, optimisations specialised by chip reveal subtle, yet performance-critical, characteristics of various GPUs.","","978-1-7281-4045-2","10.1109/IISWC47752.2019.9042139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042139","","","graph theory;graphics processing units;program compilers;statistical analysis","hand-optimising graph algorithm code;GPU chips;graph algorithm DSL compiler;portable optimisation policies;graph algorithms;optimisation space;GPU;optimising programs;portable optimisation policy","","1","","33","","19 Mar 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Fast parallel cutoff pair interactions for molecular dynamics on heterogeneous systems","Q. Wu; C. Yang; T. Tang; K. Lu","School of Computer Science, National University of Defense Technology, Changsha 410073, China; School of Computer Science, National University of Defense Technology, Changsha 410073, China; School of Computer Science, National University of Defense Technology, Changsha 410073, China; School of Computer Science, National University of Defense Technology, Changsha 410073, China","Tsinghua Science and Technology","15 Jun 2012","2012","17","3","265","277","Heterogeneous systems with both Central Processing Units (CPUs) and Graphics Processing Units (GPUs) are frequently used to accelerate short-ranged Molecular Dynamics (MD) simulations. The most time-consuming task in short-ranged MD simulations is the computation of particle-to-particle interactions. Beyond a certain distance, these interactions decrease to zero. To minimize the operations to investigate distance, previous works have tiled interactions by employing the spatial attribute, which increases the memory access and GPU computations, hence decreasing performance. Other studies ignore the spatial attribute and construct an all-versus-all interaction matrix, which has poor scalability. This paper presents an improved algorithm. The algorithm first bins particles into voxels according to the spatial attributes, and then tiles the all-versus-all matrix into voxel-versus-voxel sub-matrixes. Only the sub-matrixes between neighboring voxels are computed on the GPU. Therefore, the algorithm reduces the distance examine operations and limits additional memory access and GPU computations. This paper also adopts a multi-level programming model to implement the algorithm on multi-nodes of Tianhe-lA. By employing (1) a patch design to exploit parallelism across the simulation domain, (2) a communication overlapping method to overlap the communications between CPUs and GPUs, and (3) a dynamic workload balancing method to adjust the workloads among compute nodes, the implementation achieves a speedup of 4.16× on one NVIDIA Tesla M2050 GPU compared to a 2.93 GHz six-core Intel Xeon X5670 CPU. In addition, it runs 2.41× faster on 256 compute nodes of Tianhe-lA (with two CPUs and one GPU inside a node) than on 256 GPU-excluded nodes.","1007-0214","","10.1109/TST.2012.6216756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216756","cutoff pair interactions;molecular dynamics;heterogeneous computing;GPU computing","Graphics processing unit;Instruction sets;Computational modeling;Heuristic algorithms;Computer architecture;Central Processing Unit","","","","1","","","","15 Jun 2012","","","TUP","TUP Journals"
notebooks/data/ieee_4.csv:"Integration of CUDA Processing within the C++ Library for Parallelism and Concurrency (HPX)","P. Diehl; M. Seshadri; T. Heller; H. Kaiser","Center for Comput. & Technol., Louisiana State Univ., Baton Rouge, LA, USA; Nanyang Technol. Univ., Singapore, Singapore; Center for Comput. & Technol., Louisiana State Univ., Baton Rouge, LA, USA; Center for Comput. & Technol., Louisiana State Univ., Baton Rouge, LA, USA","2018 IEEE/ACM 4th International Workshop on Extreme Scale Programming Models and Middleware (ESPM2)","14 Feb 2019","2018","","","19","28","Experience shows that on today's high performance systems the utilization of different acceleration cards in conjunction with a high utilization of all other parts of the system is difficult. Future architectures, like exascale clusters, are expected to aggravate this issue as the number of cores are expected to increase and memory hierarchies are expected to become deeper. One big aspect for distributed applications is to guarantee high utilization of all available resources, including local or remote acceleration cards on a cluster while fully using all the available CPU resources and the integration of the GPU work into the overall programming model. For the integration of CUDA code we extended HPX, a general purpose C++ run time system for parallel and distributed applications of any scale, and enabled asynchronous data transfers from and to the GPU device and the asynchronous invocation of CUDA kernels on this data. Both operations are well integrated into the general programming model of HPX which allows to seamlessly overlap any GPU operation with work on the main cores. Any user defined CUDA kernel can be launched on any (local or remote) GPU device available to the distributed application. We present asynchronous implementations for the data transfers and kernel launches for CUDA code as part of a HPX asynchronous execution graph. Using this approach we can combine all remotely and locally available acceleration cards on a cluster to utilize its full performance capabilities. Overhead measurements show, that the integration of the asynchronous operations (data transfer + launches of the kernels) as part of the HPX execution graph imposes no additional computational overhead and significantly eases orchestrating coordinated and concurrent work on the main cores and the used GPU devices.","","978-1-7281-0178-1","10.1109/ESPM2.2018.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8638479","Asynchronous-many-task-systems-(ATM),-CUDA,-parallelism,-concurrency,-HPX","Graphics processing units;Kernel;C++ languages;Data transfer;Task analysis;Programming;Message systems","C++ language;concurrency (computers);graphics processing units;parallel architectures;parallel processing","local acceleration cards;remote acceleration cards;CUDA code;distributed application;asynchronous data transfers;asynchronous invocation;CUDA kernel;GPU operation;data transfer;HPX asynchronous execution graph;CUDA processing;high performance systems;exascale clusters;memory hierarchies;CPU resources;general purpose C++ run time system;parallel applications","","2","","26","","14 Feb 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Parallel computing with CUDA","M. Garland",NVIDIA,"2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)","24 May 2010","2010","","","1","1","Summary form only given. NVIDIA's CUDA architecture provides a powerful platform for writing highly parallel programs. By providing simple abstractions for hierarchical thread organization, memories, and synchronization, the CUDA programming model allows programmers to write scalable programs without the burden of learning a multitude of new programming constructs. The CUDA architecture can support many languages and programming environments, including C, Fortran, OpenCL, and DirectX Compute. In this tutorial, I will provide an overview of modern GPU processor design and its implications for successful parallel programming models. I will present the programming model adopted by the CUDA architecture, and demonstrate how this is exposed in the C/C++ language. Finally, I will sketch some techniques for implementing common data-parallel algorithms in the CUDA model.","1530-2075","978-1-4244-6443-2","10.1109/IPDPS.2010.5470378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470378","","Parallel processing;Computer architecture;Visualization;Parallel programming;Multicore processing;Programming environments;Process design","C++ language;computer graphic equipment;coprocessors;parallel algorithms;parallel architectures;parallel programming","parallel computing;NVIDIA CUDA architecture;hierarchical thread organization;synchronization;C;Fortran;OpenCL;DirectX Compute;GPU processor design;parallel programming;C++ language;data parallel algorithms","","12","","","","24 May 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Programming for GPUs: The Directive-Based Approach","L. Grillo; F. De Sande; J. J. Fumero; R. Reyes","Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Inst. Tecnol. de Energias Renovables, Granadilla de Abona, Spain; Edinburgh Parallel Comput. Centre, Univ. of Edinburgh, Edinburgh, UK","2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","12 Dec 2013","2013","","","612","617","In the last years, hardware accelerators, such as GPUs have become ubiquitous in the HPC landscape and GPGPU has been massively adopted by the HPC research community. If something is slowing down further expansion of this technology are its difficulties in terms of programmability. Although several libraries and applications providing GPU support are available, the need of implementing new algorithms from scratch, or adapting sequential programs to accelerators, still exist. Writing programs to be executed on accelerators is not easy, particularly for non-expert developers coming from the science or engineering fields, as it requires deep understanding of the underlying architecture. Different alternatives have appeared aimed to diminish the GPU programming effort. In the wake of the success of OpenMP, several directive-oriented programming models have been created. Although future OpenMP releases will integrate accelerators, tools are needed in the meantime. In this work, we present a comparison of directive-based approaches for GPU platforms, hiCUDA, PGI Accelerator and OpenACC. For the last, in addition to the two commercial compilers available, we include results using accULL, our own OpenACC implementation. To illustrate the portability of these alternatives, we show performance figures for both Fermi and Kepler NVIDIA cards.","","978-0-7695-5094-7","10.1109/3PGCIC.2013.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681300","OpenACC;GPGPU;Compilers;PGI;HMPP;accULL;CUDA","Graphics processing units;Kernel;Programming;Standards;Runtime;Parallel processing","graphics processing units;message passing;parallel architectures;program compilers;software libraries","hardware accelerator;HPC;sequential program;program execution;GPU programming;OpenMP;directive-oriented programming model;hiCUDA;PGI accelerator;OpenACC;compiler;accULL;Kepler NVIDIA card;Fermi card;program library","","1","","12","","12 Dec 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Use case analysis of OpenACC directives in the implementation of image processing algorithms","M. J. Mišić; D. D. Dašić; M. V. Tomašević","Elektroteh. Fak., Univ. u Beogradu, Belgrade, Serbia; Elektroteh. Fak., Univ. u Beogradu, Belgrade, Serbia; Elektroteh. Fak., Univ. u Beogradu, Belgrade, Serbia","2013 21st Telecommunications Forum Telfor (TELFOR)","20 Jan 2014","2013","","","959","962","Graphics processing units have been intensively used in general-purpose computations in the recent years. Although new programming models (CUDA, OpenCL) have been developed and widely applied to support GPU programming, they still impose demanding environments for those users who want to speed up their applications without the knowledge of low level details of the underlying hardware. To cope with this problem, the paper analyzes and evaluates the usage of OpenACC directive-based programming model in the case of image processing algorithms that are amenable for GPU execution.","","978-1-4799-1420-3","10.1109/TELFOR.2013.6716390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716390","","Graphics processing units;Computational modeling;Programming;Central Processing Unit;Kernel;Electronic mail;Image processing","graphics processing units;image processing","case analysis;OpenACC directives;image processing algorithms;graphics processing units programming;GPU programming;demanding environments","","1","","6","","20 Jan 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Hedgehog: Understandable Scheduler-Free Heterogeneous Asynchronous Multithreaded Data-Flow Graphs","A. Bardakoff; B. Bachelet; T. Blattner; W. Keyrouz; G. C. Kroiz; L. Yon","National Institute of Standards & Technology,Gaithersburg,MD,20899-8970; Université Clermont Auvergne, CNRS, LIMOS,Clermont-Ferrand,France,F-63000; National Institute of Standards & Technology,Gaithersburg,MD,20899-8970; National Institute of Standards & Technology,Gaithersburg,MD,20899-8970; University of Maryland,Department of Mathematics and Statistics,Baltimore,MD,USA,21250; ISIMA, CNRS, LIMOS,Clermont-Ferrand,France,F-63000","2020 IEEE/ACM 3rd Annual Parallel Applications Workshop: Alternatives To MPI+X (PAW-ATM)","29 Dec 2020","2020","","","1","15","Getting performance on high-end heterogeneous nodes is challenging. This is due to the large semantic gap between a computation's specification-possibly mathematical formulas or an abstract sequential algorithm-and its parallel implementation; this gap obscures the program's parallel structures and how it gains or loses performance. We present Hedgehog, a library aimed at coarse-grain parallelism. It explicitly embeds a dataflow graph in a program and uses this graph at runtime to drive the program's execution so it takes advantage of hardware parallelism (multicore CPUs and multiple accelerators). Hedgehog has asynchronicity built in. It statically binds individual threads to graph nodes, which are ready to fire when any of their inputs are available. This allows Hedgehog to avoid using a global scheduler and the loss of performance associated with global synchronizations and managing of thread pools. Hedgehog provides a separation of concerns and distinguishes between compute and state maintenance tasks. Its API reflects this separation and allows a developer to gain a better understanding of performance when executing the graph. Hedgehog is implemented as a C++ 17 headers-only library. One feature of the framework is its low overhead; it transfers control of data between two nodes in ≈ 1 μs. This low overhead combines with Hedgehog's API to provide essentially cost-free profiling of the graph, thereby enabling experimentation for performance, which enhances a developer's insight into a program's performance. Hedgehog's asynchronous data-flow graph supports a data streaming programming model both within and between graphs. We demonstrate the effectiveness of this approach by highlighting the performance of streaming implementations of two numerical linear algebra routines, which are comparable to existing libraries: matrix multiplication achieves >95 % of the theoretical peak of 4 GPUs; LU decomposition with partial pivoting starts streaming partial final result blocks 40× earlier than waiting for the full result. The relative ease and understandability of obtaining performance with Hedgehog promises to enable non-specialists to target performance on high-end single nodes.","","978-1-7281-5450-3","10.1109/PAWATM51920.2020.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306983","high performance computing, data-flow, heterogeneous computing, dataflow, pipelining, HPC, parallelism, heterogeneity, metaprogramming, C++, GPU","Task analysis;Libraries;Parallel processing;Hardware;Computational modeling;Signal processing algorithms;Tools","application program interfaces;data flow computing;data flow graphs;graph theory;linear algebra;matrix multiplication;multiprocessing systems;multi-threading;parallel algorithms;scheduling","coarse-grain parallelism;hardware parallelism;graph nodes;data streaming programming model;scheduler-free heterogeneous asynchronous multithreaded data-flow graphs;Hedgehog API;numerical linear algebra routines","","","","22","","29 Dec 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"CLACC: Translating OpenACC to OpenMP in Clang","J. E. Denny; S. Lee; J. S. Vetter",Oak Ridge National Laboratory; Oak Ridge National Laboratory; Oak Ridge National Laboratory,"2018 IEEE/ACM 5th Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)","14 Feb 2019","2018","","","18","29","OpenACC was launched in 2010 as a portable programming model for heterogeneous accelerators. Although various implementations already exist, no extensible, open-source, production-quality compiler support is available to the community. This deficiency poses a serious risk for HPC application developers targeting GPUs and other accelerators, and it limits experimentation and progress for the OpenACC specification. To address this deficiency, Clacc is a recent effort funded by the US Exascale Computing Project to develop production OpenACC compiler support for Clang and LLVM. A key feature of the Clacc design is to translate OpenACC to OpenMP to build on Clang's existing OpenMP compiler and runtime support. In this paper, we describe the Clacc goals and design. We also describe the challenges that we have encountered so far in our prototyping efforts, and we present some early performance results.","","978-1-7281-0188-0","10.1109/LLVM-HPC.2018.8639349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639349","OpenACC;OpenMP;LLVM;multicore;GPU;accelerators;source-to-source translation;compiler","Tools;Runtime;Ecosystems;Production;Programming;Graphics processing units;Computer architecture","parallel processing;program compilers;public domain software;software portability","OpenMP;portable programming model;heterogeneous accelerators;production-quality compiler support;OpenACC specification;US Exascale Computing Project;HPC application;CLACC;Clang;open-source software;OpenACC compiler support","","4","","20","","14 Feb 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"MDACCER: Modified Distributed Assessment of the Closeness CEntrality Ranking in Complex Networks for Massively Parallel Environments","F. L. Cabral; C. Osthoff; D. Ramos; R. Nardes","Lab. Nac. de Comput. Cienc., Centro de Comput. de Alto Desempenho, Brazil; Lab. Nac. de Comput. Cienc., Centro de Comput. de Alto Desempenho, Brazil; Lab. Nac. de Comput. Cienc., Centro de Comput. de Alto Desempenho, Brazil; Lab. Nac. de Comput. Cienc., Centro de Comput. de Alto Desempenho, Brazil","2015 International Symposium on Computer Architecture and High Performance Computing Workshop (SBAC-PADW)","3 Mar 2016","2015","","","43","48","We propose a new method derived from DACCER (Distributed Assessment of the Closeness CEntrality Ranking): the modified DACCER (MDACCER), for assessing traditional closeness centrality ranking. MDACCER presents a relaxation that allows it to take advantage of massively parallel environments like General Purpose Graphics Processing Units (GPGPUs). Traditional DACCER proposal assesses Closeness centrality ranking in a limited neighborhood using only information around each node at low computational cost and capability to be executed in a distributed environment. Despite all the advantages, DACCER presents some difficulties in GPGPUs programming model that increases its computational cost at this particular environment. In contrast to the poor performance of DACCER on GPGPUs, experimental results demonstrate MDACCER is as simple and efficient as DACCER to assess Closeness centrality ranking in complex networks and moreover it does not have the same bottlenecks in GPGPUs computing about memory usage and time complexity. We performed MDACCER for some synthetically generated networks, specifically Barabási-Albert ones and results indicate MADCCER correlates Closeness centrality ranking almost as well as DACCER does with lower computational costs.","","978-1-4673-8621-0","10.1109/SBAC-PADW.2015.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423179","Parallel Computing;Network Centrality Ranking;DACCER;Closeness;GPU;CUDA","Correlation;Kernel;Proposals;Computational efficiency;Computer architecture;Complex networks;Graphics processing units","complex networks;computational complexity;graphics processing units;parallel programming","time complexity;GPGP programming model;general purpose graphics processing unit;modified DACCER;massively parallel environment;complex network;closeness centrality ranking;MDACCER;modified distributed assessment","","","","13","","3 Mar 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"High-Performance Graph Analytics on Manycore Processors","G. M. Slota; S. Rajamanickam; K. Madduri","Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA; Scalable Algorithms Dept., Sandia Nat. Labs., Albuquerque, NM, USA; Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA","2015 IEEE International Parallel and Distributed Processing Symposium","20 Jul 2015","2015","","","17","27","The divergence in the computer architecture landscape has resulted in different architectures being considered mainstream at the same time. For application and algorithm developers, a dilemma arises when one must focus on using underlying architectural features to extract the best performance on each of these architectures, while writing portable code at the same time. We focus on this problem with graph analytics as our target application domain. In this paper, we present an abstraction-based methodology for performance-portable graph algorithm design on manicure architectures. We demonstrate our approach by systematically optimizing algorithms for the problems of breadth-first search, color propagation, and strongly connected components. We use Kokkos, a manicure library and programming model, for prototyping our algorithms. Our portable implementation of the strongly connected components algorithm on the NVIDIA Tesla K40M is up to 3.25× faster than a state-of-the-art parallel CPU implementation on a dual-socket Sandy Bridge compute node.","1530-2075","978-1-4799-8649-1","10.1109/IPDPS.2015.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7161272","graph computations;BFS;color propagation;GPU;parallel performance;portability","Instruction sets;Silicon;Optimization;Synchronization;Color;Arrays;Parallel processing","feature extraction;graph theory;multiprocessing systems;parallel architectures;tree searching","high-performance graph analytics;manycore processors;computer architecture landscape;architectural feature extraction;portable code writing;abstraction-based methodology;performance-portable graph algorithm design;manicure architectures;breadth-first search problems;color propagation;optimizing algorithms;Kokkos manicure library;programming model;strongly connected components algorithm;NVIDIA Tesla K40M;parallel CPU;dual-socket Sandy Bridge compute node","","8","","37","","20 Jul 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Real-time block matching motion estimation onto GPGPU","E. Monteiro; M. Maule; F. Sampaio; C. Diniz; B. Zatt; S. Bampi","Informatics Institute - PPGC - PGMICRO, Federal University of Rio Grande do Sul (UFRGS) - Porto Alegre, Brazil; Informatics Institute - PPGC - PGMICRO, Federal University of Rio Grande do Sul (UFRGS) - Porto Alegre, Brazil; Informatics Institute - PPGC - PGMICRO, Federal University of Rio Grande do Sul (UFRGS) - Porto Alegre, Brazil; Informatics Institute - PPGC - PGMICRO, Federal University of Rio Grande do Sul (UFRGS) - Porto Alegre, Brazil; Informatics Institute - PPGC - PGMICRO, Federal University of Rio Grande do Sul (UFRGS) - Porto Alegre, Brazil; Informatics Institute - PPGC - PGMICRO, Federal University of Rio Grande do Sul (UFRGS) - Porto Alegre, Brazil","2012 19th IEEE International Conference on Image Processing","21 Feb 2013","2012","","","1693","1696","This work presents an efficient method to map Motion Estimation (ME) algorithms onto General Purpose Graphic Processing Unit (GPGPU) architectures using CUDA programming model. Our method jointly exploits the massive parallelism available in current GPGPU devices and the parallelization potential of ME algorithms: Full Search (FS) and Diamond Search (DS). Our main goal is to evaluate the feasibility of achieving real-time high-definition video encoding performance running on GPUs. For comparison reasons, multi-core parallel and distributed versions of these algorithms were developed using OpenMP and MPI (Message Passing Interface) libraries, respectively. The CUDA-based solutions achieve the highest speed-up in comparison with OpenMP and MPI versions for both algorithms and, when compared to the state-of-the-art, our FS and DS solutions reach up to 18x and 11x speed-up, respectively.","2381-8549","978-1-4673-2533-2","10.1109/ICIP.2012.6467204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6467204","Motion Estimation;Block Matching Algorithms;GPU;CUDA;OpenMP;MPI","Graphics processing units;Motion estimation;Algorithm design and analysis;Computer architecture;Real-time systems;Diamonds;Programming","application program interfaces;graphics processing units;image matching;message passing;motion estimation;multiprocessing systems;parallel algorithms;parallel architectures;parallel programming;search problems;video coding","real-time block matching motion estimation;map motion estimation algorithms;general purpose graphic processing unit architectures;GPGPU architectures;CUDA programming model;GPGPU devices;parallelization potential;full search;diamond search;real-time high-definition video encoding performance;multicore parallel algorithms;distributed algorithms;MPI libraries;OpenMP libraries;message passing interface libraries;CUDA-based solutions;DS solutions;FS solutions","","9","","13","","21 Feb 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Locality-Aware Scheduling for Scalable Heterogeneous Environments","A. V. Kamatar; R. D. Friese; R. Gioiosa","Pacific Northwest National Laboratory,High Performance Computing,Richland,US; Pacific Northwest National Laboratory,High Performance Computing,Richland,US; Pacific Northwest National Laboratory,High Performance Computing,Richland,US","2020 IEEE/ACM International Workshop on Runtime and Operating Systems for Supercomputers (ROSS)","29 Dec 2020","2020","","","50","58","Heterogeneous computing promise boost performance of scientific applications by allowing massively parallel execution of computational tasks. However, manually managing extremely heterogeneous, multi-device systems is complicated and may result in sub-optimal performance. Specifically, data management is an extremely challenging problem on multi-device systems. In this work, we introduce two locality-aware schedulers for the Minos Computing Library (MCL), an asynchronous, task-based programming model and runtime for extremely heterogeneous systems. The first scheduler implements a pure locality-aware algorithm to maximize data reuse, though it might incur in “hot-spots” that limit system utilization. The second scheduler mitigates this drawback by dynamically targeting between locality-awareness and system utilization based on the current workload and available computing devices. Our results show that locality-awareness greatly benefit applications that exhibit data reuse, providing up to 6.9x and 7.9x over the original MCL scheduler and equivalent OpenCL implementations, respectively. Moreover, our schedulers introduce negligible overhead compared with the original MCL scheduler and achieve similar performance for applications that don't benefit from data locality.","","978-1-6654-2268-0","10.1109/ROSS51935.2020.00011","Research and Development; Advanced Scientific Computing Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307939","heterogeneous computing, gpu, gpgpu, openCL","Task analysis;Performance evaluation;Runtime;Programming;Computational modeling;Round robin;Graphics processing units","multiprocessing systems;parallel architectures;parallel processing;parallel programming;resource allocation;scheduling;shared memory systems","pure locality-aware algorithm;limit system utilization;locality-awareness;available computing devices;exhibit data reuse;original MCL scheduler;data locality;locality-aware scheduling;scalable heterogeneous environments;heterogeneous computing promise;scientific applications;massively parallel execution;computational tasks;multidevice systems;sub-optimal performance;data management;extremely challenging problem;locality-aware schedulers;Minos Computing Library;task-based programming model;extremely heterogeneous systems","","1","","31","","29 Dec 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Implementation and Optimization of a 1D2V PIC Method for Nonlinear Kinetic Models on GPUs","M. Korch; P. Raithel; T. Werner","University of Bayreuth,Department of Computer Science,Bayreuth,Germany,95440; University of Bayreuth,Department of Computer Science,Bayreuth,Germany,95440; University of Bayreuth,Department of Computer Science,Bayreuth,Germany,95440","2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","14 May 2020","2020","","","30","37","This paper considers the parallel numerical simulation of the time evolution of galaxies and globular clusters on GPUs. The model used is the Einstein-Vlasov system, which is designed, in particular, to study the formation of black holes and spacetime singularities in a general relativistic framework.First, a reference implementation is derived using NVIDIA CUDA as programming model, which is then optimized in several steps. Bottlenecks are identified by profiling, and different approaches, namely particle sort, improved treatment of atomic operations, and kernel fusion are investigated to overcome these bottlenecks. Each optimized variant is evaluated in relation to the other variants using detailed runtime experiments and profiling results. Using in the order of 10<sup>7</sup> to 10<sup>8</sup> particles, speedups between 1.84 and 2.38 w.r.t. the reference implementation have been observed.","2377-5750","978-1-7281-6582-0","10.1109/PDP50117.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092350","particle-in-cell;kinetic models;Einstein–Vlasov;parallelization;GPU","Graphics processing units;Kernel;Mathematical model;Numerical models;Computational modeling;Measurement;Arrays","astronomy computing;black holes;general relativity;numerical analysis;parallel architectures;space-time configurations","atomic operations;kernel fusion;optimized variant;runtime experiments;profiling results;reference implementation;1D2V PIC Method;nonlinear kinetic models;GPUs;parallel numerical simulation;globular clusters;Einstein-Vlasov system;black holes;spacetime singularities;general relativistic framework;NVIDIA CUDA;programming model;particle sort","","","","20","","14 May 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Convergence and scalarization for data-parallel architectures","Y. Lee; R. Krashinsky; V. Grover; S. W. Keckler; K. Asanović",University of California at Berkeley; NVIDIA; NVIDIA; NVIDIA; University of California at Berkeley,"Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)","8 Apr 2013","2013","","","1","11","Modern throughput processors such as GPUs achieve high performance and efficiency by exploiting data parallelism in application kernels expressed as threaded code. One draw-back of this approach compared to conventional vector architectures is redundant execution of instructions that are common across multiple threads, resulting in energy inefficiency due to excess instruction dispatch, register file accesses, and memory operations. This paper proposes to alleviate these overheads while retaining the threaded programming model by automatically detecting the scalar operations and factoring them out of the parallel code. We have developed a scalarizing compiler that employs convergence and variance analyses to statically identify values and instructions that are invariant across multiple threads. Our compiler algorithms are effective at identifying convergent execution even in programs with arbitrary control flow, identifying two-thirds of the opportunity captured by a dynamic oracle. The compile-time analysis leads to a reduction in instructions dispatched by 29%, register file reads and writes by 31% memory address counts by 47%, and data access counts by 38%.","","978-1-4673-5525-4","10.1109/CGO.2013.6494995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6494995","CUDA;GPU;Scalarization","Instruction sets;Convergence;Registers;Kernel;Computer architecture;Graphics processing units;Algorithm design and analysis","convergence;multi-threading;optimising compilers;parallel architectures;power aware computing","data-parallel architecture scalarization;data-parallel architecture convergence;throughput processors;GPUs;data parallelism;application kernels;threaded code;vector architectures;energy inefficiency;instruction dispatch;memory operations;threaded programming model;automatic scalar operation detection;parallel code;scalarizing compiler;compiler algorithms;convergent execution;arbitrary control flow;dynamic oracle;compile-time analysis;register file reads;register file writes;memory address counts;data access counts","","21","3","29","","8 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"OpenMPC: Extended OpenMP Programming and Tuning for GPUs","S. Lee; R. Eigenmann","Sch. of ECE, Purdue Univ. West Lafayette, West Lafayette, IN, USA; Sch. of ECE, Purdue Univ. West Lafayette, West Lafayette, IN, USA","SC '10: Proceedings of the 2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis","29 Nov 2010","2010","","","1","11","General-Purpose Graphics Processing Units (GPGPUs) are promising parallel platforms for high performance computing. The CUDA (Compute Unified Device Architecture) programming model provides improved programmability for general computing on GPGPUs. However, its unique execution model and memory model still pose significant challenges for developers of efficient GPGPU code. This paper proposes a new programming interface, called OpenMPC, which builds on OpenMP to provide an abstraction of the complex CUDA programming model and offers high-level controls of the involved parameters and optimizations. We have developed a fully automatic compilation and user-assisted tuning system supporting OpenMPC. In addition to a range of compiler transformations and optimizations, the system includes tuning capabilities for generating, pruning, and navigating the search space of compilation variants. Our results demonstrate that OpenMPC offers both programmability and tunability. Our system achieves 88% of the performance of the hand-coded CUDA programs.","2167-4337","978-1-4244-7559-9","10.1109/SC.2010.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644879","","Graphics processing unit;Kernel;Optimization;Instruction sets;Tuning;Programming;Registers","computer graphic equipment;coprocessors;parallel programming;public domain software","OpenMPC;extended OpenMP programming;GPU;general purpose graphics processing units;high performance computing;CUDA programming model;user assisted tuning system;compiler transformations;compiler optimizations;Compute Unified Device Architecture","","128","1","16","","29 Nov 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Medical Imaging Processing on a Big Data Platform Using Python: Experiences with Heterogeneous and Homogeneous Architectures","E. Serrano; J. G. Blas; J. Carretero; M. Abella; M. Desco","Comput. Archit. & Technol. Group, Univ. Carlos III of Madrid, Leganes, Spain; Comput. Archit. & Technol. Group, Univ. Carlos III of Madrid, Leganes, Spain; Comput. Archit. & Technol. Group, Univ. Carlos III of Madrid, Leganes, Spain; Inst. de Investigacin Sanitaria Gregorio Maranon, Madrid, Spain; Inst. de Investigacin Sanitaria Gregorio Maranon, Madrid, Spain","2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)","13 Jul 2017","2017","","","830","837","The apparition of new paradigms, programming models, and languages that offer better programmability and better performance turns the implementation of current scientific applications into a less time-consuming task than years ago. One significant example of this trend is the MapReduce programming model and its implementation using Apache Spark. Nowadays, this programming model is mainly used for data analysis and machine learning applications, although it has been expanded to its usage in the HPC community. On the side of programming languages, Python has positioned itself as an alternative to other scientific programming languages, such as Matlab or Julia. In this work we explore the capabilities of Python and Apache Spark as partners in the implementation of the backprojection operator of a CT reconstruction application. We present two interesting approaches with two different types of architectures: a heterogeneous architecture including NVidia GPUs and a full performance CPU mode with the compatibility with C/C++ native source code. We experimentally demonstrate that current CPU-based implementations scale with the number of computational units.","","978-1-5090-6611-7","10.1109/CCGRID.2017.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973788","CUDA;Big Data;Apache Spark;CT;backprojection;Python","Computer architecture;Programming;Computed tomography;Computational modeling;Sparks;Image reconstruction;Big Data","Big Data;C++ language;data analysis;graphics processing units;learning (artificial intelligence);medical image processing;microprocessor chips;parallel processing;programming languages;public domain software;source code (software);workstation clusters","medical imaging processing;Big Data platform;Python;heterogeneous architectures;homogeneous architectures;MapReduce programming model;Apache Spark;data analysis;machine learning;HPC community;programming languages;NVidia GPU;CPU mode;C/C++ native source code","","7","","27","","13 Jul 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Porting Real-World Applications to GPU Clusters: A Celerity and Cronos Case Study","P. Gschwandtner; R. Kissmann; D. Huber; P. Salzmann; F. Knorr; P. Thoman; T. Fahringer","University of Innsbruck,Research Center HPC,Innsbruck,Austria; University of Innsbruck,Institute for Astro- and Particle Physics,Innsbruck,Austria; University of Innsbruck,Institute for Astro- and Particle Physics,Innsbruck,Austria; University of Innsbruck,Department of Computer Science,Innsbruck,Austria; University of Innsbruck,Department of Computer Science,Innsbruck,Austria; University of Innsbruck,Department of Computer Science,Innsbruck,Austria; University of Innsbruck,Department of Computer Science,Innsbruck,Austria","2021 IEEE 17th International Conference on eScience (eScience)","26 Oct 2021","2021","","","90","98","Accelerator clusters are an ongoing trend in high performance computing, continuously gaining traction and forming a ubiquitous hardware resource for domain scientists to run large-scale simulations on. However, there is often a gap between new hardware technologies and adoption by legacy code bases. Porting real-world applications to new programming models is a difficult undertaking, aggravated by the need for support for both distributed-memory and accelerator parallelism. In this work, we present a case study of porting Cronos, a real-world code from the field of magnetohydrodynamics, to Celerity, a high-level programming model for distributed-memory accelerator clusters. We discuss the numerical, algorithmic and implementation properties of the application and motivate our decisions for adapting them where necessary. Preliminary results show a parallel efficiency of up to 87% for 16 GPUs.","","978-1-6654-0361-0","10.1109/eScience51609.2021.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582351","accelerators;gpus;sycl;celerity;distributed memory;parallel programming","Codes;Magnetohydrodynamics;Parallel programming;Computational modeling;High performance computing;Graphics processing units;Parallel processing","","","","","","20","","26 Oct 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Impacts of Multi-GPU MPI Collective Communications on Large FFT Computation","A. Ayala; S. Tomov; X. Luo; H. Shaeik; A. Haidar; G. Bosilca; J. Dongarra","University of Tennessee, USA; University of Tennessee, USA; University of Tennessee, USA; University of Tennessee, USA; Nvidia Corporation, USA; University of Tennessee, USA; University of Tennessee, USA","2019 IEEE/ACM Workshop on Exascale MPI (ExaMPI)","13 Jan 2020","2019","","","12","18","Most applications targeting exascale, such as those part of the Exascale Computing Project (ECP), are designed for heterogeneous architectures and rely on the Message Passing Interface (MPI) as their underlying parallel programming model. In this paper we analyze the limitations of collective MPI communication for the computation of fast Fourier transforms (FFTs), which are relied on heavily for large-scale particle simulations. We present experiments made at one of the largest heterogeneous platforms, the Summit supercomputer at ORNL. We discuss communication models from state-of-the-art FFT libraries, and propose a new FFT library, named HEFFTE (Highly Efficient FFTs for Exascale), which supports heterogeneous architectures and yields considerable speedups compared with CPU libraries, while maintaining good weak as well as strong scalability.","","978-1-7281-6009-2","10.1109/ExaMPI49596.2019.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955469","","","application program interfaces;fast Fourier transforms;graphics processing units;message passing;parallel programming","multiGPU MPI collective communications;FFT computation;MPI communication;fast Fourier transforms;particle simulations;FFT library;Highly Efficient FFTs for Exascale;HEFFTE","","7","","18","","13 Jan 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Optimal Kernel Design for Finite-Element Numerical Integration on GPUs","K. Banaś; F. Krużel; J. Bielański",AGH University of Science and Technology; Cracow University of Technology; AGH University of Science and Technology,"Computing in Science & Engineering","13 Oct 2020","2020","22","6","61","74","This article presents the design and optimization of the GPU kernels for numerical integration, as it is applied in the standard form in finite-element codes. The optimization process employs autotuning, with the main emphasis on the placement of variables in the shared memory or registers. OpenCL and the first order finite-element method (FEM) approximation are selected for code design, but the techniques are also applicable to the CUDA programming model and other types of finite-element discretizations (including discontinuous Galerkin and isogeometric). The autotuning optimization is performed for four example graphics processors and the obtained results are discussed.","1558-366X","","10.1109/MCSE.2019.2940656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843948","","Finite element analysis;Graphics processing units;Jacobian matrices;Solid modeling;Approximation algorithms;Optimization;Computational modeling","finite element analysis;Galerkin method;graphics processing units;integration;optimisation;parallel architectures;parallel programming;shared memory systems","isogeometric discretization;discontinuous Galerkin discretization;OpenCL;graphics processors;first order finite-element method approximation;autotuning optimization;finite-element discretizations;CUDA programming model;code design;shared memory;finite-element codes;GPU kernels;finite-element numerical integration;optimal kernel design","","","","21","IEEE","18 Sep 2019","","","IEEE","IEEE Magazines"
notebooks/data/ieee_4.csv:"Towards an efficient multi-stage Riemann solver for nuclear physics simulations","S. Cygert; J. Porter-Sobieraj; D. Kikoła; J. Sikorski; M. Słodkowski","Warsaw University of Technology, Faculty of Mathematics and Information Science, Koszykowa 75, 00-662, Poland; Warsaw University of Technology, Faculty of Mathematics and Information Science, Koszykowa 75, 00-662, Poland; Purdue University, Department of Physics, 525 Northwestern Ave., West Lafayette, IN 47907, United States; Warsaw University of Technology, Faculty of Physics, Koszykowa 75, 00-662, Poland; Warsaw University of Technology, Faculty of Physics, Koszykowa 75, 00-662, Poland","2013 Federated Conference on Computer Science and Information Systems","7 Nov 2013","2013","","","441","446","Relativistic numerical hydrodynamics is an important tool in high energy nuclear science. However, such simulations are extremely demanding in terms of computing power. This paper focuses on improving the speed of solving the Riemann problem with the MUSTA-FORCE algorithm by employing the CUDA parallel programming model. We also propose a new approach to 3D finite difference algorithms, which employ a GPU that uses surface memory. Numerical experiments show an unprecedented increase in the computing power compared to a CPU.","","978-83-60810-52-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6644038","","Graphics processing units;Computational modeling;Instruction sets;Mathematical model;Hydrodynamics;Registers;Numerical models","digital simulation;finite difference methods;hydrodynamics;mathematics computing;nuclear engineering computing;parallel architectures;parallel programming","multistage Riemann solver;nuclear physics simulations;relativistic numerical hydrodynamics;high energy nuclear science;MUSTA-FORCE algorithm;CUDA parallel programming model;3D finite difference algorithms;GPU;surface memory;CPU","","","","15","","7 Nov 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Using Fermi Architecture Knowledge to Speed up CUDA and OpenCL Programs","Y. Torres; A. Gonzalez-Escribano; D. R. Llanos","Dipt. Inf., Univ. Valladolid, Valladolid, Spain; Dipt. Inf., Univ. Valladolid, Valladolid, Spain; Dipt. Inf., Univ. Valladolid, Valladolid, Spain","2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications","23 Aug 2012","2012","","","617","624","The NVIDIA graphics processing units (GPUs) are playing an important role as general purpose programming devices. The implementation of parallel codes to exploit the GPU hardware architecture is a task for experienced programmers. The threadblock size and shape choice is one of the most important user decisions when a parallel problem is coded. The threadblock configuration has a significant impact on the global performance of the program. While in CUDA parallel programming model it is always necessary to specify the threadblock size and shape, the OpenCL standard also offers an automatic mechanism to take this delicate decision. In this paper we present a study of these criteria for Fermi architecture, introducing a general approach for threadblock choice, and showing that there is considerable room for improvement in OpenCL automatic strategy.","2158-9208","978-1-4673-1631-6","10.1109/ISPA.2012.92","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6280352","GPGPU;automatic code tuning;Fermi;CUDA;OpenCL","Instruction sets;Shape;Graphics processing unit;Computer architecture;Kernel;Benchmark testing;Tuning","graphics processing units;parallel architectures;parallel programming","fermi architecture knowledge;speed up CUDA programs;speed up OpenCL programs;NVIDIA graphics processing units;GPU hardware architecture;threadblock size;parallel problem;threadblock configuration;CUDA parallel programming model;automatic mechanism","","6","","17","","23 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"High-Performance and Real-Time Volume Rendering in CUDA","Y. Zhao; X. Cui; Y. Cheng","Sino-Dutch Biomed. & Inf. Eng. Sch., Northeastern Univ., Shenyang, China; Sino-Dutch Biomed. & Inf. Eng. Sch., Northeastern Univ., Shenyang, China; Sino-Dutch Biomed. & Inf. Eng. Sch., Northeastern Univ., Shenyang, China","2009 2nd International Conference on Biomedical Engineering and Informatics","30 Oct 2009","2009","","","1","4","In order to improve the image quality and rendering speed, how to deal with a large scale of voxel computation is a challenge for programmers who work at medical image visualization. CUDA is a parallel programming model and software environment designed to overcome this challenge while maintaining a low learning curve for programmers familiar with standard programming languages such as C. In this paper, we propose an optimization algorithm of volume ray casting using CUDA; compare the performance to previous implementation in old version of GPU. The experiments show that our method can achieve a high image quality and rendering speed.","1948-2922","978-1-4244-4132-7","10.1109/BMEI.2009.5304981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5304981","","Rendering (computer graphics);Image quality;Programming profession;Large-scale systems;Biomedical imaging;Visualization;Parallel programming;Software maintenance;Software performance;Software design","coprocessors;data visualisation;medical image processing;rendering (computer graphics)","real-time volume rendering;CUDA;image quality;voxel computation;medical image visualization;parallel programming model;C programming language;volume ray casting;GPU;Compute United Device Architecture;graphics processor unit","","6","","21","","30 Oct 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Shortening Design Time through Multiplatform Simulations with a Portable OpenCL Golden-model: The LDPC Decoder Case","G. Falcao; M. Owaida; D. Novo; M. Purnaprajna; N. Bellas; C. D. Antonopoulos; G. Karakonstantis; A. Burg; P. Ienne","Dept. of Electr. & Comput. Eng., Univ. of Coimbra, Coimbra, Portugal; Dept. of Comput. & Commun. Eng., Univ. of Thessaly Volos, Volos, Greece; Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland; Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland; Dept. of Comput. & Commun. Eng., Univ. of Thessaly Volos, Volos, Greece; Dept. of Comput. & Commun. Eng., Univ. of Thessaly Volos, Volos, Greece; Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland; Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland; Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland","2012 IEEE 20th International Symposium on Field-Programmable Custom Computing Machines","16 Jul 2012","2012","","","224","231","Hardware designers and engineers typically need to explore a multi-parametric design space in order to find the best configuration for their designs using simulations that can take weeks to months to complete. For example, designers of special purpose chips need to explore parameters such as the optimal bit width and data representation. This is the case for the development of complex algorithms such as Low-Density Parity-Check (LDPC) decoders used in modern communication systems. Currently, high-performance computing offers a wide set of acceleration options, that range from multicore CPUs to graphics processing units (GPUs) and FPGAs. Depending on the simulation requirements, the ideal architecture to use can vary. In this paper we propose a new design flow based on Open CL, a unified multiplatform programming model, which accelerates LDPC decoding simulations, thereby significantly reducing architectural exploration and design time. Open CL-based parallel kernels are used without modifications or code tuning on multicore CPUs, GPUs and FPGAs. We use SOpen CL (Silicon to Open CL), a tool that automatically converts Open CL kernels to RTL for mapping the simulations into FPGAs. To the best of our knowledge, this is the first time that a single, unmodified Open CL code is used to target those three different platforms. We show that, depending on the design parameters to be explored in the simulation, on the dimension and phase of the design, the GPU or the FPGA may suit different purposes more conveniently, providing different acceleration factors. For example, although simulations can typically execute more than 3× faster on FPGAs than on GPUs, the overhead of circuit synthesis often outweighs the benefits of FPGA-accelerated execution.","","978-1-4673-1605-7","10.1109/FCCM.2012.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239819","design space exploration;simulation tools;parallel computing;FPGAs;GPUs;LDPC decoding","Kernel;Parity check codes;Field programmable gate arrays;Computational modeling;Decoding;Hardware;Algorithm design and analysis","codecs;field programmable gate arrays;logic design;logic simulation;microprocessor chips;parity check codes;public domain software","design time shortening;multiplatform simulation;portable OpenCL golden model;LDPC decoder case;hardware designers;multiparametric design space;complex algorithms;low density parity check decoders;unified multiplatform programming model;SOpen CL;Silicon to Open CL;RTL;FPGA;GPU;register transfer level","","16","","17","","16 Jul 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Accelerating error correction in high-throughput short-read DNA sequencing data with CUDA","H. Shi; B. Schmidt; W. Liu; W. Muller-Wittig","School of Computer Engineering, Nanyang Technological University, Singapore 639798; School of Computer Engineering, Nanyang Technological University, Singapore 639798; School of Computer Engineering, Nanyang Technological University, Singapore 639798; School of Computer Engineering, Nanyang Technological University, Singapore 639798","2009 IEEE International Symposium on Parallel & Distributed Processing","10 Jul 2009","2009","","","1","8","Emerging DNA sequencing technologies open up exciting new opportunities for genome sequencing by generating read data with a massive throughput. However, produced reads are significantly shorter and more error-prone compared to the traditional Sanger shotgun sequencing method. This poses challenges for de-novo DNA fragment assembly algorithms in terms of both accuracy (to deal with short, error-prone reads) and scalability (to deal with very large input data sets). In this paper we present a scalable parallel algorithm for correcting sequencing errors in high-throughput short-read data. It is based on spectral alignment and uses the CUDA programming model. Our computational experiments on a GTX 280 GPU show runtime savings between 10 and 19 times (for different error-rates using simulated datasets as well as real Solexa/Illumina datasets).","1530-2075","978-1-4244-3751-1","10.1109/IPDPS.2009.5160924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5160924","","Acceleration;Error correction;DNA;Genomics;Bioinformatics;Throughput;Assembly;Scalability;Parallel algorithms;Runtime","biology computing;DNA;genomics;molecular biophysics;parallel algorithms","error correction;high-throughput short-read DNA sequencing data;CUDA programming model;genome sequencing;scalable parallel algorithm;GTX 280 GPU","","2","","20","","10 Jul 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Fast BFS-Based Triangle Counting on GPUs","L. Wang; J. D. Owens","University of California,Department of Computer Science,Davis,California,95616; University of California,Department of Electrical & Computer Engineering,Davis,California,95616","2019 IEEE High Performance Extreme Computing Conference (HPEC)","28 Nov 2019","2019","","","1","6","In this paper, we propose a novel method to compute triangle counting on GPUs. Unlike previous formulations of graph matching, our approach is BFS-based by traversing the graph in an all-source-BFS manner and thus can be mapped onto GPUs in a massively parallel fashion. Our implementation uses the Gunrock programming model and we evaluate our implementation in runtime and memory consumption compared with previous state-of-the-art work. We sustain a peak traversed-edgesper-second (TEPS) rate of nearly 10 GTEPS. Our algorithm is the most scalable and parallel among all existing GPU implementations and also outperforms all existing CPU distributed implementations. This work specifically focuses on leveraging our implementation on the triangle counting problem for the Subgraph Isomorphism Graph Challenge 2019, demonstrating a geometric mean speedup over the 2018 champion of 3.84×.","2643-1971","978-1-7281-5020-8","10.1109/HPEC.2019.8916434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8916434","","Graphics processing units;Memory management;Computational complexity;Parallel algorithms;Decision trees;Graph theory","computational complexity;graph theory;graphics processing units;parallel algorithms;tree searching","Subgraph Isomorphism Graph Challenge 2019;triangle counting problem;existing GPU implementations;peak traversed-edgesper-second rate;previous state-of-the-art work;memory consumption;Gunrock programming model;massively parallel fashion;all-source-BFS manner;graph matching;GPUs;fast BFS-based triangle counting","","3","","11","","28 Nov 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Ultra low latency dataflow renderer","S. Friston; A. Steed; S. Tilbury; G. Gaydadjiev","University College London, Computer Science Department, Gower Street, WC1E 6BT, UK; University College London, Computer Science Department, Gower Street, WC1E 6BT, UK; Maxeler Technologies Ltd., 1 Down Place, London W6 9JH, UK; Maxeler Technologies Ltd., 1 Down Place, London W6 9JH, UK","2015 25th International Conference on Field Programmable Logic and Applications (FPL)","8 Oct 2015","2015","","","1","4","Reconfigurable hardware has been used before for low latency image synthesis. These are typically low level implementations with tight vertical integration. For example the apparatus of both Regan et al and Ng et al had the tracker driven by the same device performing the rendering. Reconfigurable hardware combined with the dataflow programming model can make application specific rendering hardware cost effective. Our sprite renderer has comparable scope to both prior examples, but our dataflow graph can be adapted to other use cases with an effort comparable to GPU shader programming.","1946-1488","978-0-9934-2800-5","10.1109/FPL.2015.7293974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293974","","Computer architecture;Image color analysis;Hardware;Rendering (computer graphics);Streaming media;Transceivers;Sprites (computer)","graphics processing units;image processing;rendering (computer graphics)","ultra low latency dataflow renderer;low latency image synthesis;tight vertical integration;dataflow programming model;application specific rendering hardware cost;sprite renderer;dataflow graph;GPU shader programming","","","","18","","8 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Dynamic Task-Based D3Q19 Lattice-Boltzmann Method for Heterogeneous Architectures","J. V. F. Lima; G. Freytag; V. G. Pinto; C. Schepke; P. O. A. Navaux","Universidade Federal de Santa Maria, Brazil; Universidade Federal do Rio Grande do Sul, Brazil; Universidade Federal do Rio Grande do Sul, Brazil; Universidade Federal do Pampa, Campus Alegrete, Brazil; Universidade Federal do Rio Grande do Sul, Brazil","2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","21 Mar 2019","2019","","","108","115","Nowadays computing platforms expose a significant number of heterogeneous processing units such as multicore processors and accelerators. The task-based programming model has been a de facto standard model for such architectures since its model simplifies programming by unfolding parallelism at runtime based on data-flow dependencies between tasks. Many studies have proposed parallel strategies over heterogeneous platforms with accelerators. However, to the best of our knowledge, no dynamic task-based strategy of the Lattice-Boltzmann Method (LBM) has been proposed to exploit CPU+GPU computing nodes. In this paper, we present a dynamic task-based D3Q19 LBM implementation using three runtime systems for heterogeneous architectures: OmpSs, StarPU, and XKaapi. We detail our implementations and compare performance over two heterogeneous platforms. Experimental results demonstrate that our task-based approach attained up to 8.8 of speedup over an OpenMP parallel loop version.","2377-5750","978-1-7281-1644-0","10.1109/EMPDP.2019.8671583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8671583","","Task analysis;Runtime;Graphics processing units;Computational modeling;Parallel processing;Programming;Computer architecture","flow simulation;graphics processing units;lattice Boltzmann methods;multiprocessing systems;parallel algorithms;parallel architectures;parallel processing;parallel programming;shared memory systems","CPU+GPU computing nodes;dynamic task-based D3Q19 LBM implementation;heterogeneous architectures;heterogeneous platforms;task-based approach;significant number;heterogeneous processing units;multicore processors;accelerators;task-based programming model;facto standard model;data-flow dependencies;parallel strategies;dynamic task-based strategy;dynamic task-based D3Q19 Lattice-Boltzmann method;OmpSs;StarPU;XKaapi;OpenMP parallel loop version","","1","","27","","21 Mar 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Breaking Weak 1024-bit RSA Keys with CUDA","K. Scharfglass; D. Weng; J. White; C. Lupo","Comput. Sci. Dept., California Polytech. State Univ., San Luis Obispo, CA, USA; Comput. Sci. Dept., California Polytech. State Univ., San Luis Obispo, CA, USA; Comput. Sci. Dept., California Polytech. State Univ., San Luis Obispo, CA, USA; Comput. Sci. Dept., California Polytech. State Univ., San Luis Obispo, CA, USA","2012 13th International Conference on Parallel and Distributed Computing, Applications and Technologies","9 Sep 2013","2012","","","207","212","An exploit involving the greatest common divisor (GCD) of RSA moduli was recently discovered [1]. This paper presents a tool that can efficiently and completely compare a large number of 1024-bit RSA public keys, and identify any keys that are susceptible to this weakness. NVIDIA's graphics processing units (GPU) and the CUDA massively-parallel programming model are powerful tools that can be used to accelerate this tool. Our method using CUDA has a measured performance speedup of 27.5 compared to a sequential CPU implementation, making it a more practical method to compare large sets of keys. A computation for finding GCDs between 200,000 keys, i.e., approximately 20 billion comparisons, was completed in 113 minutes, the equivalent of approximately 2.9 million 1024-bit GCD comparisons per second.","2379-5352","978-0-7695-4879-1","10.1109/PDCAT.2012.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6589265","CUDA;RSA;greatest common divisor;parallel computation","Graphics processing units;Instruction sets;Arrays;Organizations;Public key;Matrix decomposition;Kernel","graphics processing units;parallel architectures;parallel programming;performance evaluation;public key cryptography","CUDA;greatest common divisor;GCD;RSA moduli;1024-bit RSA public keys;NVIDIA;graphics processing units;GPU;massively-parallel programming model;performance speedup;word length 1024 bit","","6","","9","","9 Sep 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Simulee: Detecting CUDA Synchronization Bugs via Memory-Access Modeling","M. Wu; Y. Ouyang; H. Zhou; L. Zhang; C. Liu; Y. Zhang","Southern University of Science and Technology,Shenzhen,China; Southern University of Science and Technology,Shenzhen,China; University of Texas at Dallas,Dallas,USA; University of Texas at Dallas,Dallas,USA; University of Texas at Dallas,Dallas,USA; Southern University of Science and Technology,Shenzhen,China","2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)","21 Dec 2020","2020","","","937","948","While CUDA has become a mainstream parallel computing platform and programming model for general-purpose GPU computing, how to effectively and efficiently detect CUDA synchronization bugs remains a challenging open problem. In this paper, we propose the first lightweight CUDA synchronization bug detection framework, namely Simulee, to model CUDA program execution by interpreting the corresponding LLVM bytecode and collecting the memory-access information for automatically detecting general CUDA synchronization bugs. To evaluate the effectiveness and efficiency of Simulee, we construct a benchmark with 7 popular CUDA-related projects from GitHub, upon which we conduct an extensive set of experiments. The experimental results suggest that Simulee can detect 21 out of the 24 manually identified bugs in our preliminary study and also 24 previously unknown bugs among all projects, 10 of which have already been confirmed by the developers. Furthermore, Simulee significantly outperforms state-of-the-art approaches for CUDA synchronization bug detection.","1558-1225","978-1-4503-7121-6","10.1145/3377811.3380358","National Natural Science Foundation of China(grant numbers:61902169); Shenzhen Peacock Plan(grant numbers:KQTD2016112514355531); National Science Foundation(grant numbers:CCF-1763906,CCF-1942430); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284094","","Computational modeling;Computer bugs;Graphics processing units;Benchmark testing;Synchronization;Software engineering;Software development management","graphics processing units;multiprocessing systems;parallel architectures;parallel programming;program compilers;program debugging","Simulee;CUDA program execution;memory-access information;general CUDA synchronization bugs;7 popular CUDA-related projects;24 manually identified bugs;24 previously unknown bugs;memory-access modeling;mainstream parallel computing platform;programming model;general-purpose GPU computing;challenging open problem;lightweight CUDA synchronization bug detection framework","","1","","54","","21 Dec 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Performance and Power Efficient Massive Parallel Computational Model for HPC Heterogeneous Exascale Systems","M. U. Ashraf; F. Alburaei Eassa; A. Ahmad Albeshri; A. Algarni","Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia","IEEE Access","15 May 2018","2018","6","","23095","23107","The emerging high-performance computing Exascale supercomputing system, which is anticipated to be available in 2020, will unravel many scientific mysteries. This extraordinary processing framework will accomplish a thousand-folds increment in figuring power contrasted with the current Petascale framework. The prospective framework will help development communities and researchers in exploring from conventional homogeneous to the heterogeneous frameworks that will be joined into energy efficient GPU devices along with traditional CPUs. For accomplishing ExaFlops execution through the Ultrascale framework, the present innovations are confronting several challenges. Huge parallelism is one of these challenges, which requires a novel low power consuming parallel programming approach for attaining massive performance. This paper introduced a new parallel programming model that achieves massive parallelism by combining coarse-grained and fine-grained parallelism over inter-node and intranode computation respectively. The proposed framework is tri-hybrid of MPI, OpenMP, and compute unified device architecture (MOC) that compute input data over heterogeneous framework. We implemented the proposed model in linear algebraic dense matrix multiplication application, and compared the quantified metrics with well-known basic linear algebra subroutine libraries such as CUDA basic linear algebra subroutines library and KAUST basic linear algebra subprograms. MOC outperformed to all implemented methods and achieved massive performance by consuming less power. The proposed MOC approach can be considered an initial and leading model to deal emerging Exascale computing systems.","2169-3536","","10.1109/ACCESS.2018.2823299","Deanship of Scientific Research at King Abdulaziz University, Jeddah(grant numbers:RG-3-611-38); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334408","Exascale computing;HPC;massive parallelism;super computing;energy efficiency;hybrid programming;CUDA;OpenMP;MPI","Graphics processing units;Computational modeling;Parallel processing;Performance evaluation;Computer architecture;Acceleration;Parallel programming","application program interfaces;graphics processing units;mathematics computing;matrix multiplication;message passing;multiprocessing systems;parallel architectures;parallel machines;parallel programming;power aware computing","achieves massive parallelism;fine-grained parallelism;intranode computation;compute unified device architecture;compute input data;heterogeneous framework;parallel programming model;Ultrascale framework;power efficient massive parallel computational model;OpenMP;MPI;internode computation;coarse-grained parallelism;low power consuming parallel programming approach;ExaFlops execution;Petascale framework;high-performance computing Exascale supercomputing system;traditional CPU;energy efficient GPU devices;development communities;extraordinary processing framework;scientific mysteries;HPC heterogeneous Exascale systems;Exascale computing systems;initial leading model;KAUST basic linear algebra subprograms;CUDA basic linear algebra subroutines library;linear algebraic dense matrix multiplication application","","15","","65","OAPA","9 Apr 2018","","","IEEE","IEEE Journals"
notebooks/data/ieee_4.csv:"The Memory Controller Wall: Benchmarking the Intel FPGA SDK for OpenCL Memory Interface","H. R. Zohouri; S. Matsuoka","Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan","2019 IEEE/ACM International Workshop on Heterogeneous High-performance Reconfigurable Computing (H2RC)","2 Jan 2020","2019","","","11","18","Supported by their high power efficiency and recent advancements in High Level Synthesis (HLS), FPGAs are quickly finding their way into HPC and cloud systems. Large amounts of work have been done so far on loop and area optimizations for different applications on FPGAs using HLS. However, a comprehensive analysis of the behavior and efficiency of the memory controller of FPGAs is missing in literature, which becomes even more crucial when the limited memory bandwidth of modern FPGAs compared to their GPU counterparts is taken into account. In this work, we will analyze the memory interface generated by Intel FPGA SDK for OpenCL with different configurations for input/output arrays, vector size, interleaving, kernel programming model, on-chip channels, operating frequency, padding, and multiple types of overlapped blocking. Our results point to multiple shortcomings in the memory controller of Intel FPGAs, especially with respect to memory access alignment, that can hinder the programmer's ability in maximizing memory performance in their design. For some of these cases, we will provide work-arounds to improve memory bandwidth efficiency; however, a general solution will require major changes in the memory controller itself.","","978-1-7281-5999-7","10.1109/H2RC49586.2019.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945518","","Kernel;Field programmable gate arrays;Memory management;Benchmark testing;Bandwidth;Indexes;Graphics processing units","application program interfaces;cloud computing;electronic engineering computing;field programmable gate arrays;graphics processing units;high level synthesis;optimisation;power aware computing","loop;area optimizations;HLS;Intel FPGA SDK;memory access alignment;memory controller wall;OpenCL memory interface;power efficiency;high level synthesis;cloud systems;GPU;kernel programming model;on-chip channels;operating frequency","","5","","15","","2 Jan 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Space-Efficient Pointwise Computation of the Distance Transform on GPUs","N. Khan; M. Zahran","Comput. Sci. Dept., Brown Univ., Providence, RI, USA; Comput. Sci. Dept., New York Univ., New York, NY, USA","2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","3 Jul 2017","2017","","","557","566","To minimize the amount of computation, traditional approaches to calculating the distance transform (DT) on a discrete volume propagate distance values in a local neighborhood. This results in recursive dependencies across the volume, requiring the DT to be calculated for all points in the domain en mass and stored as static values in memory. On the other hand, the ability to calculate the distance transform point-wise not only offers the prospect of efficient memory usage and scalability, but also a high degree of flexibility in accommodating the unique requirements of new application domains. However, among the current DT algorithms, the computationally intensive brute-force algorithm is the only one that allows point-wise computation. We demonstrate that the by decomposing it into a map and a reduction pattern on the massively parallel architecture of a modern Graphics Processing Unit (GPU), the brute-force distance transform algorithm achieves the threefold goals of memory efficiency, flexibility, and performance. We discuss a memory constrained implementation in the CUDA parallel programming model. The flexibility of point-wise computation at runtime is demonstrated by presenting an approximate and an anisotropic variant of the standard distance transform algorithm, and using these variants for the rendering of a CT scan image. Our approach allows the distance transform to be calculated for 1024 query points and up to 16 million feature points in 141.25 milliseconds while allowing direct control over the memory working-set size. These results demonstrate the potential of pointwise computation of the DT at runtime and the need for future algorithms to incorporate this capability.","","978-1-5386-3408-0","10.1109/IPDPSW.2017.90","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965093","Rendering;Medical Imaging;Vision;Map;Reduction;Memory;Patterns;Anisotropic;Approximate","Transforms;Graphics processing units;Approximation algorithms;Memory management;Runtime;Parallel processing;Measurement","graphics processing units;parallel architectures","space-efficient pointwise computation;GPU;discrete volume;memory usage;DT algorithms;point-wise computation;Graphics Processing Unit;brute-force distance transform algorithm;memory efficiency;CUDA parallel programming model;standard distance transform algorithm;rendering;CT scan image;query points;memory working-set size","","","","41","","3 Jul 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Pygion: Flexible, Scalable Task-Based Parallelism with Python","E. Slaughter; A. Aiken","SLAC National Accelerator Laboratory, USA; Stanford University, USA","2019 IEEE/ACM Parallel Applications Workshop, Alternatives To MPI (PAW-ATM)","13 Apr 2020","2019","","","58","72","Dynamic languages provide the flexibility needed to implement expressive support for task-based parallel programming constructs. We present Pygion, a Python interface for the Legion task-based programming system, and show that it can provide features comparable to Regent, a statically typed programming language with dedicated support for the Legion programming model. Furthermore, we show that the dynamic nature of Python permits the implementation of several key optimizations (index launches, futures, mapping) currently implemented in the Regent compiler. Together these features enable Pygion code that is comparable in expressiveness but more flexible than Regent, and substantially more concise, less error prone, and easier to use than C++ Legion code. Pygion is designed to interoperate with Regent and can use Regent to generate high- performance CPU and GPU kernel implementations. We show that, in combination with high-performance kernels written in Regent, Pygion is able to achieve efficient, scalable execution on up to 512 nodes of the heterogeneous supercomputer Piz Daint.","","978-1-7281-5979-9","10.1109/PAW-ATM49560.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062721","task-based parallelism;Pygion;Legion;Python","Task analysis;Runtime;Python;C++ languages;Optimization;Performance analysis","data flow computing;graphics processing units;parallel machines;parallel programming;Python","scalable task-based parallelism;dynamic languages;task-based parallel program;Python interface;statically typed programming language;Legion programming model;Regent compiler;Pygion code;Legion code;GPU kernel implementations;scalable execution;Legion task-based programming","","2","","37","","13 Apr 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"OpenCL Performance Prediction using Architecture-Independent Features","B. Johnston; G. Falzon; J. Milthorpe","Res. Sch. of Comput. Sci., Australian Nat. Univ., Canberra, ACT, Australia; Sch. of Sci. & Technol., Univ. of New England, Armidale, NSW, Australia; Res. Sch. of Comput. Sci., Australian Nat. Univ., Canberra, ACT, Australia","2018 International Conference on High Performance Computing & Simulation (HPCS)","1 Nov 2018","2018","","","561","569","OpenCL is an attractive programming model for heterogeneous high-performance computing systems, with wide support from hardware vendors and significant performance portability. To support efficient scheduling on HPC systems it is necessary to perform accurate performance predictions for OpenCL workloads on varied compute devices, which is challenging due to diverse computation, communication and memory access characteristics which result in varying performance between devices. The Architecture Independent Workload Characterization (AIWC) tool can be used to characterize OpenCL kernels according to a set of architecture-independent features. This work presents a methodology where AIWC features are used to form a model capable of predicting accelerator execution times. We used this methodology to predict execution times for a set of 37 computational kernels running on 15 different devices representing a broad range of CPU, GPU and MIC architectures. The predictions are highly accurate, differing from the measured experimental run-times by an average of only 1.2%, and correspond to actual execution time mispredictions of 9 ps to 1 sec according to problem size. A previously unencountered code can be instrumented once and the AIWC metrics embedded in the kernel, to allow performance prediction across the full range of modelled devices. The results suggest that this methodology supports correct selection of the most appropriate device for a previously unen- countered code, which is highly relevant to the HPC scheduling setting.","","978-1-5386-7879-4","10.1109/HPCS.2018.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8514400","","Graphics processing units;Computational modeling;Memory management;Predictive models;Kernel;Performance evaluation;Parallel processing","graphics processing units;multiprocessing systems;parallel processing;performance evaluation;scheduling","OpenCL workloads;memory access characteristics;OpenCL kernels;AIWC features;accelerator execution times;AIWC metrics;modelled devices;OpenCL performance prediction;heterogeneous high-performance computing systems;hardware vendors;HPC systems;GPU;CPU;HPC scheduling;MIC architectures;architecture independent workload characterization tool;performance portability;programming model;computational kernels","","4","","24","","1 Nov 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A CUDA-enabled Hadoop cluster for fast distributed image processing","R. Malakar; N. Vydyanathan","Corporate Research and Technology, Siemens Technology Services, Bangalore, India; Corporate Research and Technology, Siemens Technology Services, Bangalore, India","2013 National Conference on Parallel Computing Technologies (PARCOMPTECH)","7 Oct 2013","2013","","","1","5","Hadoop is a map-reduce based distributed processing framework, frequently used in the industry today, in areas of big data analysis, particularly text analysis. Graphics processing units (GPUs), on the other hand, are massively parallel platforms with attractive performance to price and power ratios, used extensively in the recent years for acceleration of data parallel computations. CUDA or Compute Unified Device Architecture is a C-based programming model proposed by NVIDIA for leveraging the parallel computing capabilities of the GPU for general purpose computations. This paper attempts to integrate CUDA acceleration into the Hadoop distributed processing framework to create a heterogeneous high performance image processing system. As Hadoop primarily is used for text analysis, this involves facilitating efficient image processing in Hadoop. Our experimental evaluations using a Adaboost based face detection algorithm indicate that CUDA-enabling a Hadoop cluster, even with low-end GPUs, can result in a 25% improvement in data processing throughput, indicating that an integration of these two technologies can help build scalable, high throughput, power and cost-efficient computing platforms.","","978-1-4799-1591-0","10.1109/ParCompTech.2013.6621392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6621392","Hadoop;Map-reduce;CUDA;GPGPU","Graphics processing units;Face detection;Java;Acceleration;Throughput;Image processing;Streaming media","C language;data analysis;face recognition;graphics processing units;learning (artificial intelligence);parallel architectures;text analysis","CUDA-enabled Hadoop cluster;distributed image processing;Map-reduce based distributed processing framework;big data analysis;text analysis;graphics processing units;GPU;parallel platforms;data parallel computations;Compute Unified Device Architecture;C-based programming model;NVIDIA;general purpose computations;Hadoop distributed processing framework;heterogeneous high performance image processing system;Adaboost based face detection algorithm","","8","","19","","7 Oct 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Accelerating a 3D Finite-Difference Earthquake Simulation with a C-to-CUDA Translator","D. Unat; J. Zhou; Y. Cui; S. B. Baden; X. Cai","University of California, San Diego; University of California, San Diego; University of California, San Diego; University of California, San Diego; Simula Research Laboratory, Norway","Computing in Science & Engineering","20 Apr 2012","2012","14","3","48","59","GPUs provide impressive computing power, but GPU programming can be challenging. Here, an experience in porting real-world earthquake code to Nvidia GPUs is described. Specifically, an annotation-based programming model, called Mint, and its accompanying source-to-source translator are used to automatically generate CUDA source code and simplify the exploration of performance tradeoffs.","1558-366X","","10.1109/MCSE.2012.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188562","Code generation;optimization;emerging technologies;Earth and atmospheric sciences;scientific computing","Graphics processing unit;Instruction sets;Three dimensional displays;Optimization;Mathematical model","earthquakes;finite difference methods;graphics processing units;parallel architectures","3D finite difference earthquake simulation;GPU;annotation based programming model;source to source translator;CUDA source code","","9","","15","","20 Apr 2012","","","IEEE","IEEE Magazines"
notebooks/data/ieee_4.csv:"OpenCL programmable exposed datapath high performance low-power image signal processor","J. Multanen; H. Kultala; M. Koskela; T. Viitanen; P. Jääskelainen; J. Takala; A. Danielyan; C. Cruz","Tampere University of Technology, Finland; Tampere University of Technology, Finland; Tampere University of Technology, Finland; Tampere University of Technology, Finland; Tampere University of Technology, Finland; Tampere University of Technology, Finland; Noiseless Imaging Ltd, Finland; Noiseless Imaging Ltd, Finland","2016 IEEE Nordic Circuits and Systems Conference (NORCAS)","22 Dec 2016","2016","","","1","6","Sophisticated computational imaging algorithms require both high performance and good energy-efficiency when executed on mobile devices. Recent trend has been to exploit the abundant data-level parallelism found in general purpose programmable GPUs. However, for low-power mobile use cases, generic GPUs consume excessive amounts of power. This paper proposes a programmable computational imaging processor with 16-bit half-precision SIMD floating point vector processing capabilities combined with power efficiency of an exposed datapath. In comparison to traditional VLIW architectures with similar computational resources, the exposed datapath reduces the register file traffic and complexity. These and the specific optimizations enabled by the explicit programming model enable extremely good power-performance. When synthesized on a 28nm ASIC technology, the accelerator consumes 71mW of power while running a state-of-the-art denoising algorithm, and occupies only 0.2mm<sup>2</sup> of chip area. For the algorithm, energy usage per frame is 7mJ, which is 10x less than the best found GPU-based implementation.","","978-1-5090-1095-0","10.1109/NORCHIP.2016.7792906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792906","","Radio frequency;Registers;VLIW;Computer architecture;Signal processing algorithms;Hardware;Ports (Computers)","application specific integrated circuits;floating point arithmetic;graphics processing units;parallel processing","data-level parallelism;general purpose programmable GPU;low-power mobile use cases;programmable computational imaging processor;half-precision SIMD floating point vector processing capabilities;computational resources;exposed datapath;register file traffic;explicit programming model;ASIC technology;state-of-the-art denoising algorithm;word length 16 bit;size 28 nm;power 71 mW;energy 7 mJ","","1","","15","","22 Dec 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Automatic Mapping Single-Device OpenCL Program to Heterogeneous Multi-device Platform","D. Chen; C. Xun; D. Huang; M. Wen; C. Zhang","Nat. Key Lab. of Parallel & Distrib. Process., Nat. Univ. of Defense Technol. Changsha, Changsha, China; Nat. Key Lab. of Parallel & Distrib. Process., Nat. Univ. of Defense Technol. Changsha, Changsha, China; Nat. Key Lab. of Parallel & Distrib. Process., Nat. Univ. of Defense Technol. Changsha, Changsha, China; Nat. Key Lab. of Parallel & Distrib. Process., Nat. Univ. of Defense Technol. Changsha, Changsha, China; Nat. Key Lab. of Parallel & Distrib. Process., Nat. Univ. of Defense Technol. Changsha, Changsha, China","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","12 Jun 2014","2013","","","135","142","In this paper, we propose a framework to automatically map single-device OpenCL programs to heterogeneous multi-device platforms with performance concerns. Our framework is based on the independence of work groups which built inside the OpenCL programming model and relies heavily on the knowledge of global memory access regions of work groups. So global memory access patterns of work groups are analyzed and an abstract representation CCRwS is designed to describe the exact memory access regions of each memory access statement in the kernels. A global memory access analyzer is designed to get CCRwSs by performing static program analysis on kernel codes. Based on CCRwSs, data transfer between multiple devices and host can be fully controlled by our framework. Then a kernel code regenerator is designed to distribute the workload and perform architecture specific optimizations by code transformation. Then we tested our framework on a platform with 2 Intel E5-2650 CPUs and 4 NVIDIA Tesla C2050 GPUs. Compared with the performance on single GPU, the kernels running on all the 6 devices can achieve about 4.5x faster.","","978-0-7695-5088-6","10.1109/HPCC.and.EUC.2013.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6825555","Automatic;Performance;Code transformation;multi-device","Kernel;Indexes;Performance evaluation;Benchmark testing;Abstracts;Optimization;Computer architecture","graphics processing units;parallel programming;program diagnostics","automatic mapping single-device OpenCL program;heterogeneous multi-device platform;OpenCL programming model;global memory access regions;global memory access patterns;abstract representation CCRwS;static program analysis;kernel codes;data transfer;multiple devices;code transformation;Intel E5-2650 CPU;NVIDIA Tesla C2050 GPU","","1","","10","","12 Jun 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Employing Compression Solutions under OpenACC","E. Salehi; A. Lashgar; A. Baniasadi",NA; NA; NA,"2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","4 Aug 2016","2016","","","348","356","For GPUs to achieve their peak performance, effective and efficient usage of memory bandwidth is necessary. To this end, programmers invest extensive development effort to optimize a GPU program, specially its memory bandwidth usage. The OpenACC programming model has been introduced to tackle the accelerators programming complexity. However, this model's coarse-grained control on a program can make the memory bandwidth utilization even worse than the utilization achieved under CUDA. We propose an extension to OpenACC in order to reduce the traffic on the memory interconnection network, using a compression method on floating point numbers. We examine our method on three case studies and achieve up to 1.36X speedup.","","978-1-5090-3682-0","10.1109/IPDPSW.2016.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529890","OpenACC;Compression;Accelerators","Kernel;Graphics processing units;Bandwidth;Programming;Parallel processing;Standards;Data transfer","graphics processing units;parallel architectures;parallel programming;storage management","compression solution;memory bandwidth;GPU program;OpenACC programming model;accelerator programming complexity;coarse-grained control;CUDA;memory interconnection network;floating point number","","","","17","","4 Aug 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Fast 1-itemset frequency count using CUDA","R. L. Uy; N. Marcos","Computer Technology Department, De La Salle University, Manila, Philippines; Software Technology Department, De La Salle University, Manila, Philippines","2016 IEEE Region 10 Conference (TENCON)","9 Feb 2017","2016","","","210","213","Frequent itemset mining is one of the main and compute-intensive operations in the field of data mining. The said algorithm is use in finding frequent patterns in transactional databases. The 1-itemset frequent count is used as basis for finding succeeding k-itemset mining. Thus there is a need to speed-up this process. One of the techniques to speed-up the process is using the Single Instruction Multiple Thread (SIMT) architecture. This architecture allows a single instruction to be applied to multiple threads at the same time. Current graphics processing unit (GPU), which contains multiple streaming processing units, uses SIMT architecture. In order to abstract the GPU hardware from the programming model, NVIDIA introduces the compute unified device architecture (CUDA) as an extension to existing programming languages in order to support SIMT. This paper discusses how 1-itemset frequent count is implemented in SIMT using CUDA.","2159-3450","978-1-5090-2597-8","10.1109/TENCON.2016.7847991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847991","Frequent itemset mining;CUDA programming;graphics processing unit;data mining;big data","Graphics processing units;Instruction sets;Data mining;Kernel;Itemsets;Hardware;Computer architecture","data mining;graphics processing units;parallel architectures","fast 1-itemset frequency count;CUDA;frequent itemset mining;data mining;k-itemset mining;single-instruction multiple thread architecture;SIMT architecture;graphics processing unit;GPU hardware;NVIDIA;compute unified device architecture","","1","","12","","9 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"CUDA: Scalable parallel programming for high-performance scientific computing","D. Luebke","NVIDIA Corporation, U.S.A.","2008 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro","13 Jun 2008","2008","","","836","838","Graphics processing units (GPUs) originally designed for computer video cards have emerged as the most powerful chip in a high-performance workstation. Unlike multicore CPU architectures, which currently ship with two or four cores, GPU architectures are ""manycore"" with hundreds of cores capable of running thousands of threads in parallel. NVIDIA's CUDA is a co-evolved hardware-software architecture that enables high-performance computing developers to harness the tremendous computational power and memory bandwidth of the GPU in a familiar programming environment - the C programming language. We describe the CUDA programming model and motivate its use in the biomedical imaging community.","1945-8452","978-1-4244-2002-5","10.1109/ISBI.2008.4541126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4541126","","Parallel programming;Scientific computing;Computer architecture;Biomedical computing;Computer graphics;Workstations;Multicore processing;Central Processing Unit;Marine vehicles;Yarn","biomedical imaging;C language;computer graphic equipment;computer graphics;medical computing;parallel programming","CUDA;scalable parallel programming;high-performance scientific computing;graphics processing units;co-evolved hardware-software architecture;computational power;memory bandwidth;C programming language;biomedical imaging;GPU computing","","71","3","13","","13 Jun 2008","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"AI Drives Domain Specific Processors","Y. Kang","UNISOC Technologies Inc, Beijing, China","2018 IEEE Asian Solid-State Circuits Conference (A-SSCC)","16 Dec 2018","2018","","","13","16","In this paper we first list some of basic requirements for domain specific processors. Then we discuss several commonly used architectures for artificial intelligence domain applications. Their pros and cons are also compared. A new architecture defined as In-Cluster Coprocessor is presented which can best utilize existing memory hierarchy in a general processor and has an easy programming model. CBC has potential advantages of power saving and low cost. Further investigation on CBC is underway.","","978-1-5386-6413-1","10.1109/ASSCC.2018.8579282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579282","Domain-specific;GPU;TPU;SIMD;Vector;Cache Coherence;Cluster;Coprocessors","Computer architecture;Task analysis;Coprocessors;Graphics processing units","artificial intelligence;coprocessors","artificial intelligence domain;in-cluster coprocessor;memory hierarchy;AI drives;domain specific processors","","1","","7","","16 Dec 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Design and Experimental Evaluation of Distributed Heterogeneous Graph-Processing Systems","Y. Guo; A. L. Varbanescu; D. Epema; A. Iosup","Tech. Univ. Delft, Delft, Netherlands; Univ. of Amsterdam, Amsterdam, Netherlands; Tech. Univ. Delft, Delft, Netherlands; Tech. Univ. Delft, Delft, Netherlands","2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)","21 Jul 2016","2016","","","203","212","Graph processing is increasingly used in a variety of domains, from engineering to logistics and from scientific computing to online gaming. To process graphs efficiently, GPU-enabled graph-processing systems such as TOTEM and Medusa exploit the GPU or the combined CPU+GPU capabilities of a single machine. Unlike scalable distributed CPU-based systems such as Pregel and GraphX, existing GPU-enabled systems are restricted to the resources of a single machine, including the limited amount of GPU memory, and thus cannot analyze the increasingly large-scale graphs we see in practice. To address this problem, we design and implement three families of distributed heterogeneous graph-processing systems that can use both the CPUs and GPUs of multiple machines. We further focus on graph partitioning, for which we compare existing graph-partitioning policies and a new policy specifically targeted at heterogeneity. We implement all our distributed heterogeneous systems based on the programming model of the single-machine TOTEM, to which we add (1) a new communication layer for CPUs and GPUs across multiple machines to support distributed graphs, and (2) a workload partitioning method that uses offline profiling to distribute the work on the CPUs and the GPUs. We conduct a comprehensive real-world performance evaluation for all three families. To ensure representative results, we select 3 typical algorithms and 5 datasets with different characteristics. Our results include algorithm run time, performance breakdown, scalability, graph partitioning time, and comparison with other graph-processing systems. They demonstrate the feasibility of distributed heterogeneous graph processing and show evidence of the high performance that can be achieved by combining CPUs and GPUs in a distributed environment.","","978-1-5090-2453-7","10.1109/CCGrid.2016.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515690","Graph Processing;Distributed Heterogeneous Systems","Central Processing Unit;Graphics processing units;Programming;Partitioning algorithms;Space exploration;Arrays","computer games;engineering;graph theory;graphics processing units;logistics;parallel processing","distributed heterogeneous graph-processing systems;engineering;logistics;scientific computing;online gaming;GPU-enabled graph-processing systems;scalable distributed CPU-based systems;large-scale graphs;single-machine TOTEM;high performance computing","","2","","45","","21 Jul 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Neneta: Heterogeneous computing complex-valued neural network framework","V. Lekić; Z. Babić","Faculty of Electrical Engineering, University of Banja Luka, 78000, Bosnia and Herzegovina; Faculty of Electrical Engineering, University of Banja Luka, 78000, Bosnia and Herzegovina","2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","13 Jul 2017","2017","","","192","196","Due to increased demand for computational efficiency for the training, validation and testing of artificial neural networks, many open source software frameworks have emerged. Almost exclusively GPU programming model of choice in such software frameworks is CUDA. Symptomatic is also lack of the support for complex-valued neural networks. With our research going exactly in that direction, we developed and made publicly available yet another software framework, completely based on C++ and OpenCL standards with which we try to solve problems we identified with already existing solutions.","","978-953-233-090-8","10.23919/MIPRO.2017.7973416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973416","","Graphics processing units;Training;Neural networks;Kernel;Performance evaluation","C++ language;graphics processing units;neural nets;parallel architectures;public domain software","Neneta;heterogeneous computing;complex-valued neural network;artificial neural networks;open source software frameworks;GPU programming;CUDA;C++ language;OpenCL standards","","","","16","","13 Jul 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Parallel implementation of the modified subset sum problem in CUDA","Z. Ristovski; I. Mishkovski; S. Gramatikov; S. Filiposka","Faculty of Computer Sciences and Engineering, P.O. Box 393, 1000 Skopje, R. Macedonia; Faculty of Computer Sciences and Engineering, P.O. Box 393, 1000 Skopje, R. Macedonia; Faculty of Computer Sciences and Engineering, P.O. Box 393, 1000 Skopje, R. Macedonia; Faculty of Computer Sciences and Engineering, P.O. Box 393, 1000 Skopje, R. Macedonia","2014 22nd Telecommunications Forum Telfor (TELFOR)","9 Feb 2015","2014","","","923","926","In the recent years, computing is shifting from “central processing” on the CPU to “co-processing” on the CPU and GPU. This computing paradigm shift is due to the development of CUDA (Compute Unified Device Architecture) parallel computing architecture. CUDA is a programming model for parallel computing in Graphics Processing Units (GPUs). In this work, we have implemented parallel solution of the NP-complete modified subset sum algorithm using CUDA. With our implementation, for a certain problem size, we have obtained speedup of 20 times, compared to the CPU version.","","978-1-4799-6191-7","10.1109/TELFOR.2014.7034556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7034556","CUDA;Modified subset sum algorithm;GPGPU;Parallel Speedup","Graphics processing units;Vectors;Instruction sets;Central Processing Unit;Programming;Peer-to-peer computing;Computer architecture","graphics processing units;mathematics computing;optimisation;parallel architectures;set theory","CUDA;CPU;GPU;coprocessing;central processing;computing paradigm shift;compute unified device architecture;parallel computing architecture;graphics processing units;NP-complete modified subset sum algorithm","","2","","11","","9 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Throughput-Effective On-Chip Networks for Manycore Accelerators","A. Bakhoda; J. Kim; T. M. Aamodt","ECE Dept., Univ. of British Columbia, Vancouver, BC, Canada; CS Dept., KAIST, Daejeon, South Korea; ECE Dept., Univ. of British Columbia, Vancouver, BC, Canada","2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture","20 Jan 2011","2010","","","421","432","As the number of cores and threads in manycore compute accelerators such as Graphics Processing Units (GPU) increases, so does the importance of on-chip interconnection network design. This paper explores throughput-effective network-on-chips (NoC) for future manycore accelerators that employ bulk-synchronous parallel (BSP) programming models such as CUDA and OpenCL. A hardware optimization is ""throughput-effective"" if it improves parallel application level performance per unit chip area. We evaluate performance of future looking workloads using detailed closed-loop simulations modeling compute nodes, NoC and the DRAM memory system. We start from a mesh design with bisection bandwidth balanced with off-chip demand. Accelerator workloads tend to demand high off-chip memory bandwidth which results in a many-to-few traffic pattern when coupled with expected technology constraints of slow growth in pins-per-chip. Leveraging these observations we reduce NoC area by proposing a ""checkerboard"" NoC which alternates between conventional full-routers and half-routers with limited connectivity. Checkerboard employs a new oblivious routing algorithm that maintains a minimum hop-count for architectures that place L2 cache banks at the half-router nodes. Next, we show that increasing network injection bandwidth for the large amount of read reply traffic at the nodes connected to DRAM controllers alleviates a significant fraction of the remaining imbalance resulting from the many-to-few traffic pattern. The combined effect of the above optimizations with an improved placement of memory controllers in the mesh and channel slicing improves application throughput per unit area by 25.4%.","2379-3155","978-1-4244-9071-4","10.1109/MICRO.2010.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5695555","NoC;Compute accelerator;GPGPU","Bandwidth;Throughput;Computational modeling;Instruction sets;Benchmark testing;Computer architecture;Random access memory","circuit optimisation;circuit simulation;multiprocessing systems;multiprocessor interconnection networks;network routing;network-on-chip;parallel programming","manycore compute accelerator;on-chip interconnection network design;throughput-effective network-on-chip;throughput-effective NoC;bulk-synchronous parallel programming model;BSP programming model;hardware optimization;closed-loop simulation;DRAM memory system;off-chip memory bandwidth;pins-per-chip;checkerboard NoC;routing algorithm;L2 cache banks;network injection bandwidth","","94","1","49","","20 Jan 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"An MDE Approach for Automatic Code Generation from UML/MARTE to OpenCL","A. W. O. Rodrigues; F. Guyomarc'h; J. Dekeyser","Federal Institute of Education, Science, and Technology of Ceará; University of Lille; University of Lille","Computing in Science & Engineering","21 Jan 2013","2013","15","1","46","55","To reduce the design complexity of OpenCL programming, the approach proposed here generates application code automatically, based on model-driven engineering (MDE) and modeling and analysis of real-time and embedded (MARTE) systems. The aim is to provide application-development resources for nonspecialists in parallel programming, exploiting concepts such as reuse and platform independence.","1558-366X","","10.1109/MCSE.2012.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171148","model-driven engineering;MARTE;OpenCL;GPU;high-performance computing;scientific computing","Unified modeling language;Computational modeling;Computer architecture;Software engineering;Resource management;Parallel programming;Scientific computing","computational complexity;program compilers;software engineering;Unified Modeling Language","MDE approach;automatic code generation;UML/MARTE system;OpenCL programming;model-driven engineering;modeling and analysis of real-time and embedded systems;application-development resources;parallel programming;design complexity","","20","","9","","19 Mar 2012","","","IEEE","IEEE Magazines"
notebooks/data/ieee_4.csv:"Fast Motion Estimation on Graphics Hardware for H.264 Video Encoding","M. Schwalb; R. Ewerth; B. Freisleben","Dept. of Math. & Comput. Sci., Univ. of Marburg, Marburg; Dept. of Math. & Comput. Sci., Univ. of Marburg, Marburg; Dept. of Math. & Comput. Sci., Univ. of Marburg, Marburg","IEEE Transactions on Multimedia","13 Jan 2009","2009","11","1","1","10","The video coding standard H.264 supports video compression with a higher coding efficiency than previous standards. However, this comes at the expense of an increased encoding complexity, in particular for motion estimation which becomes a very time consuming task even for today's central processing units (CPU). On the other hand, modern graphics hardware includes a powerful graphics processing unit (GPU) whose computing power remains idle most of the time. In this paper, we present a GPU based approach to motion estimation for the purpose of H.264 video encoding. A small diamond search is adapted to the programming model of modern GPUs to exploit their available parallel computing power and memory bandwidth. Experimental results demonstrate a significant reduction of computation time and a competitive encoding quality compared to a CPU UMHexagonS implementation while enabling the CPU to process other encoding tasks in parallel.","1941-0077","","10.1109/TMM.2008.2008873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721593","Parallel motion estimation;H.264;GPGPU (general purpose computation on GPU);programmable graphics hardware;MPEG-4 part 10/AVC","Motion estimation;Graphics;Hardware;Encoding;Central Processing Unit;Video compression;Video coding;Parallel programming;Parallel processing;Bandwidth","computer graphic equipment;data compression;motion estimation;video coding","fast motion estimation;graphics hardware;H.264 video encoding;video compression;graphics processing unit;parallel computing","","25","2","12","IEEE","22 Dec 2008","","","IEEE","IEEE Journals"
notebooks/data/ieee_4.csv:"Porting an explicit time-domain volume-integral-equation solver on gpus with openacc [open problems in cem]","S. Feki; A. Al-Jarro; A. Clo; H. Bagci","KAUST Supercomputing Laboratory; Division of Computer, Electrical and Mathematical Sciences and Engineering, University College London, London WC1E 7JE, UK; Photonics Group, Department of Electronic and Electrical Engineering, University College London, London WC1E 7JE, UK; KAUST Research Computing, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, KSA; Division of Computer, Electrical and Mathematical Sciences and Engineering, University College London, London WC1E 7JE, UK","IEEE Antennas and Propagation Magazine","17 Jun 2014","2014","56","2","265","277","Graphics processing units (GPUs) are gradually becoming mainstream in high-performance computing, as their capabilities for enhancing performance of a large spectrum of scientific applications to many fold when compared to multi-core CPUs have been clearly identified and proven. In this paper, implementation and performance-tuning details for porting an explicit marching-on-in-time (MOT)-based time-domain volume-integral-equation (TDVIE) solver onto GPUs are described in detail. To this end, a high-level approach, utilizing the OpenACC directive-based parallel programming model, is used to minimize two often-faced challenges in GPU programming: developer productivity and code portability. The MOT-TDVIE solver code, originally developed for CPUs, is annotated with compiler directives to port it to GPUs in a fashion similar to how OpenMP targets multi-core CPUs. In contrast to CUDA and OpenCL, where significant modifications to CPU-based codes are required, this high-level approach therefore requires minimal changes to the codes. In this work, we make use of two available OpenACC compilers, CAPS and PGI. Our experience reveals that different annotations of the code are required for each of the compilers, due to different interpretations of the fairly new standard by the compiler developers. Both versions of the OpenACC accelerated code achieved significant performance improvements, with up to 30× speedup against the sequential CPU code using recent hardware technology. Moreover, we demonstrated that the GPU-accelerated fully explicit MOT-TDVIE solver leveraged energy-consumption gains of the order of 3× against its CPU counterpart.","1558-4143","","10.1109/MAP.2014.6837098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6837098","Time domain volume integral equation;explicit marching-on-in-time scheme;parallel programming;parallel processing;graphics processing unit (GPU);OpenACC","Graphics processing units;Acceleration;Finite element analysis;Convolutional codes;Time-domain analysis;Programming","","","","3","","27","IEEE","17 Jun 2014","","","IEEE","IEEE Magazines"
notebooks/data/ieee_4.csv:"Speeding Up Homomorpic Hashing Using GPUs","K. Zhao; X. Chu; M. Z. Wang; Y. Jiang","Dept. of Comput. Sci., Hong Kong Baptist Univ., Hong Kong, China; Dept. of Comput. Sci., Hong Kong Baptist Univ., Hong Kong, China; NA; NA","2009 IEEE International Conference on Communications","11 Aug 2009","2009","","","1","5","Homomorphic hash functions (HHFs) have been applied into peer-to-peer networks with erasure coding or network coding to defend against pollution attacks. Unfortunately HHFs are computationally expensive for contemporary CPUs, This paper to exploit the computing power of graphic processing units (GPUs) for homomorphic hashing. Specifically, we demonstrate how to use NVIDIA GPUs and the computer unified device architecture (CUDA) programming model to achieve 38 times of speedup over the CPU counterpart. We also develop a multi-precision modular arithmetic library on CUDA platform, which is not only key to our specific application, but also very useful for a large number of cryptographic applications.","1938-1883","978-1-4244-3435-0","10.1109/ICC.2009.5199483","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5199483","","Application software;Peer to peer computing;Network coding;Pollution;Computer graphics;Computer architecture;Central Processing Unit;Arithmetic;Libraries;Cryptography","computer graphics;coprocessors;cryptography;Internet;peer-to-peer computing;telecommunication security","homomorphic hash functions;NVIDIA GPU;graphic processing units;peer-to-peer networks;erasure coding;network coding;pollution attacks;contemporary CPU;computer unified device architecture programming model;cryptographic applications;Internet applications","","2","","17","","11 Aug 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"CuMAPz: A tool to analyze memory access patterns in CUDA","Y. Kim; A. Shrivastava","Compiler and Microarchitecture Laboratory, Arizona State University, Tempe 85281, USA; Compiler and Microarchitecture Laboratory, Arizona State University, Tempe 85281, USA","2011 48th ACM/EDAC/IEEE Design Automation Conference (DAC)","11 Aug 2011","2011","","","128","133","CUDA programming model provides a simple interface to program on GPUs, but tuning GPGPU applications for high performance is still quite challenging. Programmers need to consider several architectural details, and small changes in source code, especially on memory access pattern, affect performance significantly. This paper presents CuMAPz, a tool to compare the memory performance of a CUDA program. CuMAPz can help programmers explore different ways of using shared and global memories, and optimize their program for memory behavior. CuMAPz models several memory effects, e.g., data reuse, global memory access coalescing, shared memory bank conflict, channel skew, and branch divergence. By using CuMAPz to explore memory access design space, we could improve the performance of our benchmarks by 62% over the naive cases, and 32% over previous approach.","85-644924","978-1-4503-0636-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5981927","GPGPU;CUDA;Memory access pattern;Performance Estimation;Analytical Model","Instruction sets;Graphics processing unit;Kernel;Estimation;Channel estimation;Correlation;Benchmark testing","computer graphic equipment;coprocessors;parallel architectures;parallel programming;storage management","CuMAPz;memory access patterns;CUDA;CUDA programming model;GPU;GPGPU;source code;memory behavior;memory effects;data reuse;global memory access coalescing;shared memory bank conflict;channel skew;branch divergence;graphics processing units","","1","","21","","11 Aug 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Legion-based scientific data analytics on heterogeneous processors","L. Yu; H. Yu",University of Nebraska-Lincoln; University of Nebraska-Lincoln,"2016 IEEE International Conference on Big Data (Big Data)","6 Feb 2017","2016","","","2305","2314","We present a study of scientific data analytics on heterogeneous architectures using the Legion runtime system. Legion is a new programming model and runtime system targeting distributed heterogeneous architectures. It introduces logical regions as a new abstraction for describing the structures and usages of program data. We describe how to leverage logical regions to express important properties of program data, such as locality and independence, for scientific data analytics that can consist of multiple operations with different data types. Our approach can help users simplify programming on the data partition, data organization, and data movement for distributed-memory heterogeneous architectures, thereby facilitating a simultaneous execution of multiple analytics operations on modern and future supercomputers. We demonstrate the scalability and the usability of our approach by a hybrid data partitioning and distribution scheme for different data types using both CPUs and GPUs on a heterogeneous system.","","978-1-4673-9005-7","10.1109/BigData.2016.7840863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840863","scientific data analytics;heterogeneous processors;Legion","Program processors;Programming;Computer architecture;Data analysis;Supercomputers;Runtime;Parallel processing","data analysis;parallel programming;scientific information systems","legion-based scientific data analytics;heterogeneous processors;Legion runtime system;Legion programming model;logical regions;program data structures;program data usages;logical region leveraging;program data locality property;program data independence property;data partitioning;data organization;data movement;distributed-memory heterogeneous architectures;hybrid data partitioning-and-distribution scheme;CPU;GPU","","","","33","","6 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Intermediate-Level Synthesis of a Gauss-Jordan Elimination Linear Solver","M. Daigneault; J. P. David","Ecole Polytech. de Montreal, Univ. de Montreal, Montreal, QC, Canada; Ecole Polytech. de Montreal, Univ. de Montreal, Montreal, QC, Canada","2015 IEEE International Parallel and Distributed Processing Symposium Workshop","1 Oct 2015","2015","","","176","181","As the world of computing goes more and more parallel, reconfigurable computing can enable interesting compromises in terms of processing speed and power consumption between CPUs and GPUs. Yet, from a developer's perspective, programming Field-Programmable Gate Arrays to implement application specific processors still represents a significant challenge. In this paper, we present the application of an Intermediate-Level Synthesis methodology to the design of a Gauss-Jordan elimination linear solver on FPGA. The ILS methodology takes for input a language offering an Algorithmic-State Machine programming model. Each ASM handles blocking and non-blocking connections between data-synchronized channels having streaming interfaces with implicit ready-to-send/receive signals. Using our compiler, a scalable linear solver design reaching as much as 46.2 GFLOPS was designed and tested in a matter of days, showing how the ILS methodology can enable an interesting design time/performance compromise between RTL and HLS methodologies.","","978-1-4673-7684-6","10.1109/IPDPSW.2015.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284306","","Hardware;Field programmable gate arrays;Synchronization;Data transfer;Algorithm design and analysis;Coprocessors;Clocks","field programmable gate arrays;graphics processing units","Gauss-Jordan elimination linear solver;parallel computing;reconfigurable computing;processing speed;power consumption;CPU;GPU;programming field-programmable gate arrays;application specific processors;intermediate-level synthesis methodology;FPGA;algorithmic-state machine programming model;nonblocking connections;data-synchronized channels;streaming interfaces;compiler;scalable linear solver design","","1","","15","","1 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Efficient Compilation and Execution of JVM-Based Data Processing Frameworks on Heterogeneous Co-Processors","C. Kotselidis; S. Diamantopoulos; O. Akrivopoulos; V. Rosenfeld; K. Doka; H. Mohammed; G. Mylonas; V. Spitadakis; W. Morgan","The University of Manchester; Exus Ltd.; SparkWorks ITC Ltd.; German Research Center for Artificial Intelligence; National Technical University of Athens; Kaleao Ltd.; Computer Technology Institute & Press Diophantus; Neurocom,Luxembourg; IProov Ltd.","2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)","15 Jun 2020","2020","","","175","179","This paper addresses the fundamental question of how modern Big Data frameworks can dynamically and transparently exploit heterogeneous hardware accelerators. After presenting the major challenges that have to be addressed towards this goal, we describe our proposed architecture for automatic and transparent hardware acceleration of Big Data frameworks and applications. Our vision is to retain the uniform programming model of Big Data frameworks and enable automatic, dynamic Just-In-Time compilation of the candidate code segments that benefit from hardware acceleration to the corresponding format. In conjunction with machine learning-based device selection, that respect user-defined constraints (e.g., cost, time, etc.), we enable dynamic code execution on GPUs and FPGAs transparently to the user. In addition, we dynamically re-steer execution at runtime based on the availability of resources. Our preliminary results demonstrate that our approach can accelerate an existing Apache Flink application by up to 16.5x.","1558-1101","978-3-9819263-4-7","10.23919/DATE48585.2020.9116246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116246","","Europe;Automation;Task analysis;Artificial intelligence;Presses;Data processing;Engines","Big Data;coprocessors;field programmable gate arrays;graphics processing units;Java;learning (artificial intelligence);parallel programming;program compilers;virtual machines","modern Big Data frameworks;heterogeneous hardware accelerators;automatic hardware acceleration;transparent hardware acceleration;uniform programming model;just-in-time compilation;candidate code segments;machine learning-based device selection;dynamic code execution;heterogeneous coprocessors;JVM-based data processing frameworks;GPU;FPGA","","","","35","","15 Jun 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Optimizing sparse matrix-vector multiplication on CUDA","Zhuowei Wang; Xianbin Xu; Wuqing Zhao; Yuping Zhang; Shuibing He","school of computer, wuhan university, China; school of computer, wuhan university, China; school of computer, wuhan university, China; school of computer, wuhan university, China; school of computer, wuhan university, China","2010 2nd International Conference on Education Technology and Computer","29 Jul 2010","2010","4","","V4-109","V4-113","In recent years, GPUs have attracted the attention of many application developers as powerful massively parallel system. CUDA as a general purpose parallel computing architecture make GPUs an appealing choice to solve many complex computational problems in a more efficient way. In this paper, we discuss implementing optimizing spare matrix-vector multiplication on NVIDIA GPUs using CUDA programming model. We outline three optimizations include: (1) optimized CSR storage format, (2) optimized threads mapping, and (3) avoiding divergence judgment. We experimentally evaluate our optimizations on GeForce 9600 GTX, connect to Windows xp 64-bit system. In comparison with NVIDIA's SpMV library and NVIDIA's CUDDPA library, the results show that optimizing sparse matrix-vector multiplication on CUDA achieves better performance than other SpMV implementations.","2155-1812","978-1-4244-6370-1","10.1109/ICETC.2010.5529724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5529724","GPUs;CUDA;SpMV;NVIDIA's SpMV library;NVIDIA's CUDDPA library","Sparse matrices;Concurrent computing;Libraries;Educational institutions;Graphics processing unit;Parallel processing;Parallel programming;Kernel;Computer science education","microprocessor chips;parallel processing;performance evaluation","sparse matrix-vector multiplication;powerful massively parallel system;general purpose parallel computing architecture;complex computational problem;NVIDIA GPU;CUDA programming model;optimized CSR storage format;optimized thread mapping;GeForce 9600 GTX;Windows xp 64-bit system","","5","","12","","29 Jul 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Comparative Evaluation of Parallel Programming Models for Shared-Memory Architectures","L. M. Sanchez; J. Fernandez; R. Sotomayor; J. D. Garcia","Comput. Sci. Dept., Univ. Carlos III de Madrid, Leganés, Spain; Comput. Sci. Dept., Univ. Carlos III de Madrid, Leganés, Spain; Comput. Sci. Dept., Univ. Carlos III de Madrid, Leganés, Spain; Comput. Sci. Dept., Univ. Carlos III de Madrid, Leganés, Spain","2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications","23 Aug 2012","2012","","","363","370","Nowadays, most computers that are commercially available off-the-shelf (COTS) include hardware features that increase the performance of parallel general-purpose threads (hyper threading, multicore, ccNUMA architectures) or SIMD kernels (CPU vector instructions, GPUs). The purpose of this paper is to perform a compared evaluation of several parallel programming models where each one is fitted to exploit some of these features but also each one requires a different level of programming skills. Four parallel programming models (OpenMP, Intel TBB, Intel ArBB, and CUDA) have been selected. The idea is to cover a wide spectrum of programming models and most of the parallel hardware features included in modern computers. On one hand, OpenMP and TBB platforms, that exploits parallel threads running on multicore systems. On the other hand, ArBB, that combines multicore parallel threads and multicore SIMD features with a simpler programming model, and CUDA that exploits SIMD features of the GPU hardware. Our results obtained with the benchmarks used on this paper suggest that OpenMP and TBB have a lower performance compared to ArBB and CUDA. But also that ArBB performance tends to be comparable with CUDA performance in most cases (although it is normally lower). Thus, there are evidences that a careful designed top range multicore and multisocket architecture, can be comparable in terms of performance with top range GPU cards for many applications, with the advantage of a simpler programming model.","2158-9208","978-1-4673-1631-6","10.1109/ISPA.2012.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6280314","GPGPU;Paralel computing;SIMD;Multicore","Computer architecture;Graphics processing unit;Parallel processing;Instruction sets;Computers;Benchmark testing;Programming","memory architecture;multi-threading;parallel architectures;performance evaluation;shared memory systems","parallel programming models;shared-memory architectures;commercially available off-the-shelf;COTS;parallel general-purpose threads;hyper threading;ccNUMA architectures;SIMD kernels;CPU vector instructions;GPU cards;programming skills;OpenMP;Intel TBB;Intel ArBB;CUDA;multicore SIMD features;multicore parallel threads;multisocket architecture","","","","28","","23 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Enabling an OpenCL Compiler for Embedded Multicore DSP Systems","J. Li; C. Kuan; T. Wu; J. K. Lee","Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan","2012 41st International Conference on Parallel Processing Workshops","25 Oct 2012","2012","","","545","552","OpenCL is an industry's attempt to unify heterogeneous multicore programming. With its programming model defining SPMD kernels, vector types, and address space qualifiers, OpenCL allows programmers to exploit data parallelism with multicore processors and SIMD instructions as well as data locality with memory hierarchy. Recently, OpenCL has gained success on many architectures, including multicore CPUs, GPUs, vector processors, embedded systems with application-specific processors, and even FPGAs. However, how to support OpenCL for embedded multicore DSP systems remains unaddressed. In this paper, we illustrate our OpenCL support for embedded multicore DSP systems. Our target platform consists of one MPU and a DSP subsystem with multiple DSPs. The DSPs we address are VLIW processors with clustered functional units and distributed register files. To generate efficient code for such DSPs, compilers are required to consider irregular register file access in many optimization phases. To utilize the DSPs with distributed register files, we propose a cluster-aware work-item dispatching scheme to vectorize OpenCL kernels and assign independent workload to clusters of a DSP. In addition, we also incorporate several optimizations to enable efficient DSP code generation. In our experiments, we employ a set of OpenCL benchmark programs to evaluate the effectiveness of our OpenCL support. The experiments are conducted on a DSP cycle-accurate simulator and a multicore evaluation board. We report average 29% performance improvement with our vectorization scheme and a near 2-fold speedup with two DSPs compared with a single-MPU setup.","2332-5690","978-1-4673-2509-7","10.1109/ICPPW.2012.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337524","","Digital signal processing;Kernel;Vectors;Registers;Program processors;Multicore processing;VLIW","digital signal processing chips;electronic engineering computing;embedded systems;field programmable gate arrays;graphics processing units;multiprocessing systems;operating system kernels;optimising compilers;parallel processing;program compilers;software performance evaluation","OpenCL compiler;embedded multicore DSP systems;heterogeneous multicore programming;programming model;SPMD kernels;vector types;address space qualifiers;data parallelism;multicore processors;SIMD instructions;data locality;memory hierarchy;multicore CPU;GPU;vector processors;embedded systems;application-specific processors;FPGA;OpenCL support;MPU subsystem;DSP subsystem;VLIW processors;clustered functional units;distributed register files;compilers;irregular register file access;optimization phases;cluster-aware work-item dispatching scheme;OpenCL kernels;independent workload;DSP code generation;OpenCL benchmark programs;DSP cycle-accurate simulator;multicore evaluation board;performance improvement;vectorization scheme;single-MPU setup","","7","","15","","25 Oct 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"OpenACC Cache Directive: Opportunities and Optimizations","A. Lashgar; A. Baniasadi",NA; NA,"2016 Third Workshop on Accelerator Programming Using Directives (WACCPD)","2 Feb 2017","2016","","","46","56","OpenACC's programming model presents a simple interface to programmers, offering a trade-off between performance and development effort. OpenACC relies on compiler technologies to generate efficient code and optimize for performance. Among the difficult to implement directives, is the cache directive. The cache directive allows the programmer to utilize accelerator's hardware- or software-managed caches by passing hints to the compiler. In this paper, we investigate the implementation aspect of cache directive under NVIDIA-like GPUs and propose optimizations for the CUDA backend. We use CUDA's shared memory as the software-managed cache space. We first show that a straightforward implementation can be very inefficient, and downgrade performance. We investigate the differences between this implementation and hand-written CUDA alternatives and introduce the following optimizations to bridge the performance gap between the two: i) improving occupancy by sharing the cache among several parallel threads and ii) optimizing cache fetch and write routines via parallelization and minimizing control flow. We present compiler passes to apply these optimizations. Investigating three test cases, we show that the best cache directive implementation can perform very close to hand-written CUDA equivalent and improve performance up to 2.18X (compared to the baseline OpenACC.).","","978-1-5090-6152-5","10.1109/WACCPD.2016.009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836580","OpenACC;Cache memory;CUDA;Software-managed cache;Performance","Indexes;Graphics processing units;Arrays;Optimization;Programming;Acceleration;Hardware","cache storage;multi-threading;parallel architectures;program compilers;shared memory systems","open accelerator;control flow minimization;parallelization;write routines;cache fetch;parallel threads;software-managed cache space;CUDA shared memory;CUDA backend;NVIDIA-like GPU;accelerator hardware;code generation;compiler technologies;programmer interface;OpenACC programming model;OpenACC cache directive","","4","","13","","2 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Flexible Linear Algebra Development and Scheduling with Cholesky Factorization","A. Haidar; A. YarKhan; C. Cao; P. Luszczek; S. Tomov; J. Dongarra","Univ. of Tennessee, Knoxville, TN, USA; Univ. of Tennessee, Knoxville, TN, USA; Univ. of Tennessee, Knoxville, TN, USA; Univ. of Tennessee, Knoxville, TN, USA; Univ. of Tennessee, Knoxville, TN, USA; Univ. of Tennessee, Knoxville, TN, USA","2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems","30 Nov 2015","2015","","","861","864","Modern high performance computing environments are composed of networks of compute nodes that often contain a variety of heterogeneous compute resources, such as multicore CPUs and GPUs. One challenge faced by domain scientists ishow to efficiently use all these distributed, heterogeneous resources. Inorder to use the GPUs effectively, the workload parallelism needs to be muchgreater than the parallelism for a multicore-CPU. Additionally, effectivelyusing distributed memory nodes brings out another level of complexity where theworkload must be carefully partitioned over the nodes. In this work we areusing a lightweight runtime environment to handle many of the complexities insuch distributed, heterogeneous systems. The runtime environment usestask-superscalar concepts to enable the developer to write serial code whileproviding parallel execution. The task-programming model allows the developerto write resource-specialization code, so that each resource gets theappropriate sized workload-grain. Our task-programming abstraction enables thedeveloper to write a single algorithm that will execute efficiently across the distributed heterogeneous machine. We demonstrate the effectiveness of ourapproach with performance results for dense linear algebra applications, specifically the Cholesky factorization.","","978-1-4799-8937-9","10.1109/HPCC-CSS-ICESS.2015.285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336271","Cholesky factorization;accelerator-based distributed memory computers;superscalar dataflow scheduling;heterogeneous HPC computing","Multicore processing;Runtime;Hardware;Graphics processing units;Scalability;Linear algebra;Parallel processing","distributed memory systems;graphics processing units;mathematics computing;matrix decomposition;parallel processing;resource allocation;scheduling","flexible linear algebra development;flexible linear algebra scheduling;Cholesky factorization;high performance computing environments;compute nodes;heterogeneous compute resources;distributed resources;GPU;workload parallelism;multicore-CPU;distributed memory nodes;task-superscalar concept;serial code;parallel execution;task-programming model;resource-specialization code;task-programming abstraction;distributed heterogeneous machine","","1","","20","","30 Nov 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Portable data-parallel visualization and analysis in distributed memory environments","C. Sewell; L. Lo; J. Ahrens","CCS-7, Los Alamos National Laboratory, USA; CCS-7, Los Alamos National Laboratory, USA; CCS-7, Los Alamos National Laboratory, USA","2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV)","2 Dec 2013","2013","","","25","33","Data-parallelism is a programming model that maps well to architectures with a high degree of concurrency. Algorithms written using data-parallel primitives can be easily ported to any architecture for which an implementation of these primitives exists, making efficient use of the available parallelism on each. We have previously published results demonstrating our ability to compile the same data-parallel code for several visualization algorithms onto different on-node parallel architectures (GPUs and multi-core CPUs) using our extension of NVIDIA's Thrust library. In this paper, we discuss our extension of Thrust to support concurrency in distributed memory environments across multiple nodes. This enables the application developer to write data-parallel algorithms while viewing the data as single, long vectors, essentially without needing to explicitly take into consideration whether the values are actually distributed across nodes. Our distributed wrapper for Thrust handles the communication in the backend using MPI, while still using the standard Thrust library to take advantage of available on-node parallelism. We describe the details of our distributed implementations of several key data-parallel primitives, including scan, scatter/gather, sort, reduce, and upper/lower bound. We also present two higher-level distributed algorithms developed using these primitives: isosurface and KD-tree construction. Finally, we provide timing results demonstrating the ability of these algorithms to take advantage of available parallelism on nodes and across multiple nodes, and discuss scaling limitations for communication-intensive algorithms such as KD-tree construction.","","978-1-4799-1659-7","10.1109/LDAV.2013.6675155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6675155","","Program processors;Vectors;Algorithm design and analysis;Indexes;Isosurfaces;Computer architecture;Parallel processing","concurrency control;data analysis;data visualisation;distributed memory systems;parallel algorithms","portable data-parallel visualization;portable data-parallel analysis;distributed memory environments;programming model;concurrency degree;data-parallel primitives;GPU;graphics processing unit;multicore CPU;on-node parallel architectures;visualization algorithms;NVIDIA Thrust library;data-parallel algorithms;MPI;message passing interface;Thrust library;scan primitives;scatter-gather primitives;sort primitives;reduce primitives;upper-lower bound primitives;isosurface primitives;KD-tree construction primitives;distributed algorithms","","5","","23","","2 Dec 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Hybrid MPI/OpenMP/OpenACC Implementations for the Solution of Convection-Diffusion Equations with the HOPMOC Method","F. L. Cabral; C. Osthoff; M. Kischinhevsky; D. Brandão","Laboratοrio Nac. de Computacno Cienc., Centro de Computacno de Alto Desempenho, Petrόpolis, Brazil; Laboratοrio Nac. de Computacno Cienc., Centro de Computacno de Alto Desempenho, Petrόpolis, Brazil; Inst. de Comput., Univ. Fed. Fluminense, Niterόi, Brazil; Centro Fed. de Educacno Tecnolοgica, CEFET, Colegiado de Inf., Nova Iguaçu, Brazil","2014 14th International Conference on Computational Science and Its Applications","6 Dec 2014","2014","","","196","199","The need for fast solution of large scientific and industrial problems has long motivated the quest for improvements both in software as well as in hardware, since the inception of computing tools. In this context, vectorization, parallelization of tasks have been important strategies for the improvement of hardware efficiency during the last decades. Operator splitting techniques for the numerical solution of partial differential equations are also an attempt towards the same goal, on the software side. This work presents two parallel implementations of the Hopmoc method to solve parabolic equations with convective dominance on a cluster with multiple multicore nodes or GPUs. The Hopmoc method is based both on the modified method of characteristics and the Hopscotch method. It is implemented through an explicit-implicit operator splitting technique. Hopmoc has been studied on distributed memory machines under MPI. In this work Hopmoc is implemented on clusters of multiple cores or GPUs in one single programming model. Previous results had shown that Hopmoc is a scalable parallel procedure with respect to distributed memory machines. New numerical results of the technique presented herein show performance improvements of up to 300 times when compared with the sequential version.","","978-1-4799-4264-0","10.1109/ICCSA.2014.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976686","Parallel computing;Hopmoc method;Convection-diffusion equation","Mathematical model;Equations;Multicore processing;Message systems;Graphics processing units;Parallel processing","application program interfaces;convection;distributed memory systems;graphics processing units;mathematics computing;message passing;parabolic equations;partial differential equations;public domain software","Hybrid MPI-OpenMP-OpenACC implementation;HOPMOC Method;convection-diffusion equation solution;software improvement;computing tools;task parallelization;task vectorization;hardware efficiency improvement;numerical solution;partial differential equations;parallel implementations;Hopmoc method;parabolic equations;convective dominance;multiple multicore nodes;GPU;explicit-implicit operator splitting technique;distributed memory machines;multiple core clusters;programming model;scalable parallel procedure;performance improvement;numerical analysis","","6","","13","","6 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Comparative Study of SYCL, OpenCL, and OpenMP","H. C. da Silva; F. Pisani; E. Borin","Inst. of Comput., Univ. of Campinas, Campinas, Brazil; Inst. of Comput., Univ. of Campinas, Campinas, Brazil; Inst. of Comput., Univ. of Campinas, Campinas, Brazil","2016 International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)","9 Jan 2017","2016","","","61","66","Recent trends indicate that future computing systems will be composed by a group of heterogeneous computing devices, including CPUs, GPUs, and other hardware accelerators. These devices provide increased processing performance, however, creating efficient code for them may require that programmers manage memory assignments and use specialized APIs, compilers, or runtime systems, thus making their programs dependent on specific tools. In this scenario, SYCL is an emerging C++ programming model for OpenCL that allows developers to write code for heterogeneous computing devices that are compatible with standard C++ compilation frameworks. In this paper, we analyze the performance and programming characteristics of SYCL, OpenMP, and OpenCL using both a benchmark and a real-world application. Our performance results indicate that programs that rely on available SYCL runtimes are not on par with the ones based on OpenMP and OpenCL yet. Nonetheless, the gap is getting smaller if we consider the results reported by previous studies. In terms of programmability, SYCL presents itself as a competitive alternative to OpenCL, requiring fewer lines of code to implement kernels and also fewer calls to essential API functions and methods.","","978-1-5090-4844-1","10.1109/SBAC-PADW.2016.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803697","SYCL;OpenCL;OpenMP;parallel programming;performance evaluation;programmability evaluation","Benchmark testing;Programming;C++ languages;Performance evaluation;Kernel;MOS devices;Program processors","application program interfaces;C++ language;message passing;parallel programming;program compilers","API methods;API functions;programmability;standard C++ compilation frameworks;C++ programming model;runtime systems;compilers;hardware accelerators;GPU;CPU;heterogeneous computing devices;OpenMP;OpenCL;SYCL","","13","","16","","9 Jan 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Comparing performance and energy efficiency of FPGAs and GPUs for high productivity computing","B. Betkaoui; D. B. Thomas; W. Luk","Department of Computing, Imperial College London, United Kingdom; Department of Computing, Imperial College London, United Kingdom; Department of Computing, Imperial College London, United Kingdom","2010 International Conference on Field-Programmable Technology","6 Jan 2011","2010","","","94","101","This paper provides the first comparison of performance and energy efficiency of high productivity computing systems based on FPGA (Field-Programmable Gate Array) and GPU (Graphics Processing Unit) technologies. The search for higher performance compute solutions has recently led to great interest in heterogeneous systems containing FPGA and GPU accelerators. While these accelerators can provide significant performance improvements, they can also require much more design effort than a pure software solution, reducing programmer productivity. The CUDA system has provided a high productivity approach for programming GPUs. This paper evaluates the High-Productivity Reconfigurable Computer (HPRC) approach to FPGA programming, where a commodity CPU instruction set architecture is augmented with instructions which execute on a specialised FPGA co-processor, allowing the CPU and FPGA to co-operate closely while providing a programming model similar to that of traditional software. To compare the GPU and FPGA approaches, we select a set of established benchmarks with different memory access characteristics, and compare their performance and energy efficiency on an FPGA-based Hybrid-Core system with a GPU-based system. Our results show that while GPUs excel at streaming applications, high-productivity reconfigurable computing systems outperform GPUs in applications with poor locality characteristics and low memory bandwidth requirements.","","978-1-4244-8983-1","10.1109/FPT.2010.5681761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681761","","Benchmark testing;Field programmable gate arrays;Coprocessors;Graphics processing unit;Programming;Kernel;Instruction sets","computer graphic equipment;coprocessors;field programmable gate arrays;reconfigurable architectures","high productivity computing system;field-programmable gate array;graphics processing unit;CUDA system;high-productivity reconfigurable computer approach;FPGA programming;CPU instruction set architecture;FPGA-based hybrid-core system;GPU-based system","","37","","27","","6 Jan 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Light-weight API for Portable Multicore Programming","C. G. Baker; M. A. Heroux; H. C. Edwards; A. B. Williams","Comp. Eng. & Energy Sci., Oak Ridge Nat. Lab., Oak Ridge, TN, USA; Scalable Algorithms, Sandia Nat. Labs., Albuquerque, NM, USA; Comput. Simulation Infrastruct., Sandia Nat. Labs., Albuquerque, NM, USA; Comput. Simulation Infrastruct., Sandia Nat. Labs., Albuquerque, NM, USA","2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing","22 Apr 2010","2010","","","601","606","Multicore nodes have become ubiquitous in just a few years. At the same time, writing portable parallel software for multicore nodes is extremely challenging. Widely available programming models such as OpenMP and Pthreads are not useful for devices such as graphics cards, and more flexible programming models such as RapidMind are only available commercially. OpenCL represents the first truly portable standard, but its availability is limited. In the presence of such transition, we have developed a minimal application programming interface (API) for multicore nodes that allows us to write portable parallel linear algebra software that can use any of the aforementioned programming models and any future standard models. We utilize C++ template meta-programming to enable users to write parallel kernels that can be executed on a variety of node types, including Cell, GPUs and multicore CPUs. The support for a parallel node is provided by implementing a Node object, according to the requirements specified by the API. This ability to provide custom support for particular node types gives developers a level of control not allowed by the current slate of proprietary parallel programming APIs. We demonstrate implementations of the API for a simple vector dot-product on sequential CPU, multicore CPU and GPU nodes.","2377-5750","978-1-4244-5673-4","10.1109/PDP.2010.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452412","Parallel programming;multicore architectures","Multicore processing;Parallel programming;Linear programming;Writing;Graphics;Application software;Linear algebra;Software standards;Standards development;Kernel","application program interfaces;C++ language;linear algebra;mathematics computing;metacomputing;multiprocessing systems;parallel programming","portable multicore programming;multicore nodes;application programming interface;portable parallel linear algebra software;programming model;C++ template meta-programming;parallel kernels;multicore CPU;node object;parallel programming;vector dot-product;sequential CPU;GPU node","","7","","9","","22 Apr 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Implementation of XcalableMP Device Acceleration Extention with OpenCL","T. Nomizu; D. Takahashi; J. Lee; T. Boku; M. Sato","Grad. Sch. of Syst. & Inf. Eng., Univ. of Tsukuba, Tsukuba, Japan; Center for Comput. Sci., Univ. of Tsukuba, Tsukuba, Japan; Grad. Sch. of Syst. & Inf. Eng., Univ. of Tsukuba, Tsukuba, Japan; Fac. of Eng., Inf. & Syst., Univ. of Tsukuba, Tsukuba, Japan; Center for Comput. Sci., Univ. of Tsukuba, Tsukuba, Japan","2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum","20 Aug 2012","2012","","","2394","2403","Due to their outstanding computational performance, many acceleration devices, such as GPUs, the Cell Broadband Engine (Cell/B.E.), and multi-core computing are attracting a lot of attention in the field of high-performance computing. Although there are many programming models and languages de-signed for programming accelerators, such as CUDA, AMD Accelerated Parallel Processing (AMD APP), and OpenCL, these models remain difficult and complex. Furthermore, when programming for accelerator-enhanced clusters, we have to use an inter-node programming interface, such as MPI to coordinate the nodes. In order to address these problems and reduce complexity, an extension to XcalableMP (XMP), a PGAS language, for use on accelerator-enhanced clusters, called XcalableMP Device Acceleration Extension (XMP-dev), is proposed. In XMP-dev, a global distributed data is mapped onto distributed memory of each accelerator, and a fragment of codes can be of-floaded to execute in a set of accelerators. It eliminates the complex programming between nodes and accelerators and between nodes. In this paper, we present an implementation of the XMP-dev runtime library with the OpenCL APIs, while the previous implementation targets CUDA-only. Since OpenCL is a standardized interface supported for various kinds of accelerators, it improves the portability of XMP-dev and reduces the cost of development. In the result of performance evaluation, we show that the OpenCL implementation of XMP-dev can generate portable programs that can run on not only NVIDIA GPU-enhanced clusters but also various accelerator-enhanced clusters.","","978-1-4673-0974-5","10.1109/IPDPSW.2012.296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6270611","Cluster;Accelerator;OpenCL","Graphics processing unit;Acceleration;Kernel;Programming;Synchronization;Arrays","application program interfaces;graphics processing units;message passing;multiprocessing systems;parallel architectures;parallel programming","computational performance;acceleration device;Cell Broadband Engine;Cell/BE;multicore computing;high-performance computing;programming model;programming language;programming accelerator;CUDA;AMD Accelerated Parallel Processing;AMD APP;accelerator-enhanced cluster;internode programming interface;MPI;node coordination;complexity reduction;PGAS language;XcalableMP Device Acceleration Extension;global distributed data mapping;distributed memory;code fragment;XMP-dev runtime library;OpenCL API;standardized interface;XMP-dev portability;performance evaluation;OpenCL implementation;NVIDIA GPU-enhanced cluster","","5","","20","","20 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Automatic Resource Scheduling with Latency Hiding for Parallel Stencil Applications on GPGPU Clusters","K. Maeda; M. Murase; M. Doi; H. Komatsu; S. Noda; R. Himeno","IBM Res. - Tokyo, IBM Japan, Ltd., Tokyo, Japan; IBM Res. - Tokyo, IBM Japan, Ltd., Tokyo, Japan; Syst. & Technol. Group, IBM Japan, Ltd., Tokyo, Japan; IBM Res. - Tokyo, IBM Japan, Ltd., Tokyo, Japan; Adv. Center for Comput. & Commun., RIKEN, Wako, Japan; Adv. Center for Comput. & Commun., RIKEN, Wako, Japan","2012 IEEE 26th International Parallel and Distributed Processing Symposium","16 Aug 2012","2012","","","544","556","Overlapping computations and communication is a key to accelerating stencil applications on parallel computers, especially for GPU clusters. However, such programming is a time-consuming part of the stencil application development. To address this problem, we developed an automatic code generation tool to produce a parallel stencil application with latency hiding automatically from its dataflow model. With this tool, users visually construct the workflows of stencil applications in a dataflow programming model. Our dataflow compiler determines a data decomposition policy for each application, and generates source code that overlaps the stencil computations and communication (MPI and PCIe). We demonstrate two types of overlapping models, a CPU-GPU hybrid execution model and a GPU-only model. We use a CFD benchmark computing 19-point 3D stencils to evaluate our scheduling performance, which results in 1.45 TFLOPS in single precision on a cluster with 64 Tesla C1060 GPUs.","1530-2075","978-1-4673-0975-2","10.1109/IPDPS.2012.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6267857","latency hiding;network embedding;resource scheduling;stencil computations","Kernel;Graphics processing unit;Rivers;Hardware;Peer to peer computing;Computational modeling;Jacobian matrices","graphics processing units;parallel processing;partial differential equations;processor scheduling;search problems","automatic resource scheduling;latency hiding;parallel stencil applications;GPGPU Clusters;parallel computers;automatic code generation tool;dataflow programming model;dataflow compiler;data decomposition;source code generation;PDE;partial differential equations","","","","26","","16 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Coordinated static and dynamic cache bypassing for GPUs","X. Xie; Y. Liang; Y. Wang; G. Sun; T. Wang","Center for Energy-Efficient Computing and Applications, School of EECS, Peking University, China; Center for Energy-Efficient Computing and Applications, School of EECS, Peking University, China; Tsinghua National Laboratory for Information Science and Technology, Department of EE, Tsinghua University, China; Center for Energy-Efficient Computing and Applications, School of EECS, Peking University, China; Center for Energy-Efficient Computing and Applications, School of EECS, Peking University, China","2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA)","9 Mar 2015","2015","","","76","88","The massive parallel architecture enables graphics processing units (GPUs) to boost performance for a wide range of applications. Initially, GPUs only employ scratchpad memory as on-chip memory. Recently, to broaden the scope of applications that can be accelerated by GPUs, GPU vendors have used caches in conjunction with scratchpad memory as on-chip memory in the new generations of GPUs. Unfortunately, GPU caches face many performance challenges that arise due to excessive thread contention for cache resource. Cache bypassing, where memory requests can selectively bypass the cache, is one solution that can help to mitigate the cache resource contention problem. In this paper, we propose coordinated static and dynamic cache bypassing to improve application performance. At compile-time, we identify the global loads that indicate strong preferences for caching or bypassing through profiling. For the rest global loads, our dynamic cache bypassing has the flexibility to cache only a fraction of threads. In CUDA programming model, the threads are divided into work units called thread blocks. Our dynamic bypassing technique modulates the ratio of thread blocks that cache or bypass at run-time. We choose to modulate at thread block level in order to avoid the memory divergence problems. Our approach combines compile-time analysis that determines the cache or bypass preferences for global loads with run-time management that adjusts the ratio of thread blocks that cache or bypass. Our coordinated static and dynamic cache bypassing technique achieves up to 2.28X (average I.32X) performance speedup for a variety of GPU applications.","2378-203X","978-1-4799-8930-0","10.1109/HPCA.2015.7056023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056023","","Instruction sets;Graphics processing units;Synchronization;Kernel;Pipelines;Arrays;System-on-chip","cache storage;graphics processing units;multi-threading;parallel architectures","coordinated static cache bypassing;coordinated dynamic cache bypassing;GPUs;parallel architecture;graphics processing units;scratchpad memory;on-chip memory;thread contention;cache resource contention problem;CUDA programming model;thread blocks;dynamic bypassing technique;memory divergence problems;compile-time analysis;bypass preferences;run-time management","","80","1","46","","9 Mar 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Performance characterization of the NAS Parallel Benchmarks in OpenCL","S. Seo; G. Jo; J. Lee","Center for Manycore Programming, School of Computer Science and Engineering, Seoul National University, 151-744, Korea; Center for Manycore Programming, School of Computer Science and Engineering, Seoul National University, 151-744, Korea; Center for Manycore Programming, School of Computer Science and Engineering, Seoul National University, 151-744, Korea","2011 IEEE International Symposium on Workload Characterization (IISWC)","29 Dec 2011","2011","","","137","148","Heterogeneous parallel computing platforms, which are composed of different processors (e.g., CPUs, GPUs, FPGAs, and DSPs), are widening their user base in all computing domains. With this trend, parallel programming models need to achieve portability across different processors as well as high performance with reasonable programming effort. OpenCL (Open Computing Language) is an open standard and emerging parallel programming model to write parallel applications for such heterogeneous platforms. In this paper, we characterize the performance of an OpenCL implementation of the NAS Parallel Benchmark suite (NPB) on a heterogeneous parallel platform that consists of general-purpose CPUs and a GPU. We believe that understanding the performance characteristics of conventional workloads, such as the NPB, with an emerging programming model (i.e., OpenCL) is important for developers and researchers to adopt the programming model. We also compare the performance of the NPB in OpenCL to that of the OpenMP version. We describe the process of implementing the NPB in OpenCL and optimizations applied in our implementation. Experimental results and analysis show that the OpenCL version has different characteristics from the OpenMP version on multicore CPUs and exhibits different performance characteristics depending on different OpenCL compute devices. The results also indicate that the application needs to be rewritten or re-optimized for better performance on a different compute device although OpenCL provides source-code portability.","","978-1-4577-2064-2","10.1109/IISWC.2011.6114174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114174","","Kernel;Graphics processing unit;Multicore processing;Indexes;Computational modeling;Optimization","graphics processing units;high level languages;microprocessor chips;parallel programming","NAS parallel benchmarks;OpenCL;heterogeneous parallel computing platforms;CPU;GPU;FPGA;DSP;parallel programming models;Open Computing Language;open standard;parallel applications;heterogeneous platforms;NAS Parallel Benchmark suite;NPB;heterogeneous parallel platform;source-code portability","","99","","36","","29 Dec 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"The Exploration of Pervasive and Fine-Grained Parallel Model Applied on Intel Xeon Phi Coprocessor","C. Calvin; F. Ye; S. Petiton","DM2S Commissariat a l'Energie Atomique, CEA, France; DM2S Commissariat a l'Energie Atomique, CEA, France; Lab. d'Inf. Fondamentale de Lille, Univ. de Lille 1, Lille, France","2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","12 Dec 2013","2013","","","166","173","In this paper we investigate the dissimilar multithreading programming paradigms on x86 CPU architectures, where the recently released Intel Xeon Phi Coprocessor and commonly used Intel Xeon processors were studied, as well as the NVIDIA K20 GPU, which represents the cutting-edge general purpose graphics processing unit. The relevant numerical algorithm selected to address the problem is power method, which is widely used to compute the dominant eigenvalue of a matrix. This work focuses on dense linear algebra. The frequently used multi-core or many-core processor parallelism techniques include OpenMP, Intel Cilk Plus, Intel Threading Building Blocks, i.e. TBB, along with the optimized computing libraries such as Intel Math Kernel Library(MKL) or the NVIDIA CUDA Basic Linear Algebra Subroutines(cuBLAS) library. Optimized implementations of these techniques were separately applied to the aforementioned architectures. For the reason that a unitary programming model may not satisfy the growing performance demand, we also explored some possible mix of these languages. The study shows that the hybrid pattern of multithreading and data parallelism via explicit vectorization maximizes the performance on x86 architectures, which allows us to obtain 80% of the sustainable peak performance in double precision on the Intel Many Integrated Core(MIC) Architecture. In the case of single precision, this number reaches even 96%. In addition, this approach enables a reasonable performance by requiring least developing time. The numbers of iterations till convergence are roughly the same in both architectures of CPU and GPU. The GPU performs better in small matrix sizes. However, the Intel Xeon Phi coprocessor excels for large sizes with a better scalability.","","978-0-7695-5094-7","10.1109/3PGCIC.2013.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681224","","Coprocessors;Vectors;Kernel;Graphics processing units;Arrays;Computational modeling","graphics processing units;mathematics computing;matrix algebra;multiprocessing systems;multi-threading;ubiquitous computing","fine-grained parallel model;pervasive model;dissimilar multithreading programming paradigms;Intel Xeon Phi coprocessor;NVIDIA K20 GPU;dense linear algebra;many-core processor parallelism techniques;OpenMP;Building Blocks;Intel Cilk Plus;Intel Threading;optimized computing libraries;Intel Math Kernel Library;NVIDIA CUDA basic linear algebra subroutines library;multithreading;data parallelism;iteration method;multicore processor parallelism techniques;general purpose graphics processing unit","","3","","18","","12 Dec 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"TARCAD: A template architecture for reconfigurable accelerator designs","M. Shafiq; M. Pericàs; N. Navarro; E. Ayguadé","Computer Sciences, Barcelona Supercomputing Center, Spain; Computer Sciences, Barcelona Supercomputing Center, Spain; Dept. Arquitectura de Computadors, Universitat Politècnica de Catalunya, Barcelona, Spain; Computer Sciences, Barcelona Supercomputing Center, Spain","2011 IEEE 9th Symposium on Application Specific Processors (SASP)","7 Jul 2011","2011","","","8","15","In the race towards computational efficiency, accelerators are achieving prominence. Among the different types, accelerators built using reconfigurable fabric, such as FPGAs, have a tremendous potential due to the ability to customize the hardware to the application. However, the lack of a standard design methodology hinders the adoption of such devices and makes the portability and reusability across designs difficult. In addition, generation of highly customized circuits does not integrate nicely with high level synthesis tools. In this work, we introduce TARCAD, a template architecture to design reconfigurable accelerators. TARCAD enables high customization in the data management and compute engines while retaining a programming model based on generic programming principles. The template provides generality and scalable performance over a range of FPGAs. We describe the template architecture in detail and show how to implement five important scientific kernels: MxM, Acoustic Wave Equation, FFT, SpMV and Smith Waterman. TARCAD is compared with other High Level Synthesis models and is evaluated against GPUs, a well-known architecture that is far less customizable and, therefore, also easier to target from a simple and portable programming model. We analyze the TARCAD template and compare its efficiency on a large Xilinx Virtex-6 device to that of several recent GPU studies.","","978-1-4577-1213-5","10.1109/SASP.2011.5941071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5941071","","Layout;Kernel;Computer architecture;Field programmable gate arrays;Hardware design languages;Monitoring;Registers","field programmable gate arrays;high level synthesis;reconfigurable architectures","TARCAD;template architecture;reconfigurable accelerator design;reconflgurable fabric;data management;programming model;generic programming;FPGA;acoustic wave equation;Xilinx Virtex-6 device;high level synthesis model","","1","","25","","7 Jul 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Meta-programming and Multi-stage Programming for GPGPUs","I. Masliah; M. Baboulin; J. Falcou","Univ. Paris Sud, Orsay, France; Univ. Paris Sud, Orsay, France; Univ. Paris Sud, Orsay, France","2016 IEEE 10th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSOC)","8 Dec 2016","2016","","","369","376","GPGPUs and other accelerators are becoming a mainstream asset for high-performance computing. Raising the programmability of such hardware is essential to enable users to discover, master and subsequently use accelerators in day-to-day simulations. Furthermore, tools for high-level programming of parallel architectures are becoming a great way to simplify the exploitation of such systems. For this reason, we have extended NT2 - the Numerical Template Toolbox - a C++ scientific computing library which can generate code for SIMD and multithreading systems in a transparent way using a MATLAB like syntax. In this paper, we study how to introduce an accelerator based programming model into this library to allow developers to reap the benefits of such an architecture. After a brief description of the NT2 framework, we explain how our accelerator programming model has been designed and integrated in a pure C++ library. We conclude by showing the applicability and performance of this tool on some practical applications.","","978-1-5090-3531-1","10.1109/MCSoC.2016.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7774460","GPU;Multi-stage;C++","Libraries;C++ languages;Graphics processing units;Programming;Computational modeling;MATLAB;Mathematical model","C++ language;graphics processing units;high level languages;parallel architectures","meta programming;multistage programming;GPGPUs;high-performance computing;accelerators;high-level programming;parallel architectures;numerical template toolbox;C++ scientific library computing;SIMD;multithreading systems;MATLAB","","","","28","","8 Dec 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"SOLAR: Services-Oriented Deep Learning Architectures-Deep Learning as a Service","C. Wang; L. Gong; X. Li; Q. Yu; A. Wang; P. Hung; X. Zhou","University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; Business and Information Technology, University of Ontario Institute of Technology, Oshawa, ON, Canada; University of Science and Technology of China, Hefei, Anhui, China","IEEE Transactions on Services Computing","4 Feb 2021","2021","14","1","262","273","Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data size have posed significant challenge to construct a flexible and high performance implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. To leverage the trade-offs between the metrics among performance, power, energy, and efficiency, we present a multitarget design space exploration. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.","1939-1374","","10.1109/TSC.2017.2777478","NSFC(grant numbers:61379040); Anhui Provincial NSF(grant numbers:1608085QF12); Suzhou Research Foundation(grant numbers:SYG201625); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2017497); Fundamental Research Funds for the Central Universities(grant numbers:WK2150110003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119814","Services-oriented architecture;deep learning;neural network;accelerator","Machine learning;Hardware;Service-oriented architecture;Computer architecture;Field programmable gate arrays;Training","field programmable gate arrays;learning (artificial intelligence);service-oriented architecture","hardware implementation;hardware accelerators;FPGA board;SOLAR;machine learning;large scale data size;flexible performance implementations;high performance implementations;deep learning neural networks;services-oriented deep learning architecture;uniform programming model;deep learning as a service","","2","","35","IEEE","24 Nov 2017","","","IEEE","IEEE Journals"
notebooks/data/ieee_4.csv:"Design consideration of Network Intrusion detection system using Hadoop and GPGPU","S. R. Bandre; J. N. Nandimath","Department of Computer Engineering, Smt. Kashibai Navale College of Engineering, Affiliated to Savitribai Phule Pune University, India; Department of Computer Engineering, Smt.Kashibai Navale College of Engineering, Affiliated to Savitribai Phule Pune University, India","2015 International Conference on Pervasive Computing (ICPC)","16 Apr 2015","2015","","","1","6","Modern computing has primarily shifted towards the distributed environment using commodity resources which results in increase in data and its security concern. This paper deals with design consideration of Network Intrusion Detection System (NIDS) based on the Hadoop framework and acceleration of its performance by using General Purpose Graphical Processing Unit (GPGPU). The large volume of data from an entire infrastructure is assigned to Hadoop framework and intrusion detections are carried out on GPGPU. This approach improves NIDS performance and it enables to provide quick response to various attacks on the network. In order to perform the general purposed computation on the GPU, NVidia provides the Compute Unified Device Architecture (CUDA) which is a parallel programming model which performs high-end complex operations using GPU. In order to process large volumes of data in distributed networks, Hadoop framework has to configure with various supporting ecosystems like Flume, Pig, Hive and HBase. These ecosystems enable the Hadoop framework to handle streaming data on the network and large log files on servers. The proposed system is capable of performing analytics over intrusion pattern and their behavior on the network, which helps a network administrator to configure network security policy and settings. Analytics over intrusion is done by using a Score-Weight approach called as Pattern Frequency Inverse Cluster Frequency (PF-ICF). The design consideration of accelerated NIDS is a solution towards the performance issues of various NIDS that faces due to the large volumes of the network traffic.","","978-1-4799-6272-3","10.1109/PERVASIVE.2015.7087201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087201","CUDA;GPGPU;Hadoop;Network Security;NIDS","Graphics processing units;Intrusion detection;Servers;Ecosystems;Algorithm design and analysis;Telecommunication traffic","data analysis;graphics processing units;parallel architectures;parallel programming;security of data","network intrusion detection system;GPGPU;Hadoop framework;general purpose graphical processing unit;NIDS;NVidia;Compute Unified Device Architecture;CUDA;parallel programming model;Flume;Pig;Hive;HBase;streaming data handling;log files;intrusion pattern analytics;network security policy;score-weight approach;pattern frequency inverse cluster frequency;PF-ICF;network traffic","","8","","15","","16 Apr 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"An Efficient Acceleration of Symmetric Key Cryptography Using General Purpose Graphics Processing Unit","F. Wu; C. -h. Chen; H. Narang","Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA; Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA; Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA","2010 Fourth International Conference on Emerging Security Information, Systems and Technologies","11 Nov 2010","2010","","","228","233","Graphics Processing Units (GPU) have been the extensive research topic in recent years and have been successfully applied to general purpose applications other than computer graphical area. The nVidia CUDA programming model provides a straightforward means of describing inherently parallel computations. In this paper, we present a study of the efficiency of emerging technology in applying General Purpose Graphics Processing Units (GPGPU) in high performance symmetric key cryptographic solutions. We implemented symmetric key cryptography algorithm using the novel CUDA platform on nVidia Geforce 280 GTX and compared its performance with an optimized CPU implementation on a high-end AMD Opteron Dual Core CPU. Our experimental results show that GPGPU can perform as an efficient cryptographic accelerator and the developed GPU based implementation achieve a significant performance improvement over CPU based implementation and the maximum observed speedups are about 100 times.","2162-2116","978-1-4244-7517-9","10.1109/SECURWARE.2010.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5633744","Symmetric Key Cryptography;High Performance Computation;Purpose Graphics Processing Unit;CUDA","Graphics processing unit;Cryptography;Kernel;Instruction sets;Computer architecture;Central Processing Unit","computer graphic equipment;coprocessors;cryptography","efficient acceleration;symmetric key cryptography;general purpose graphics processing unit;computer graphical area;nVidia CUDA programming model;parallel computations;GPGPU;performance symmetric key cryptographic solutions;nVidia Geforce 280 GTX","","1","","12","","11 Nov 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Sparse Matrix Personality for the Convey HC-1","K. K. Nagar; J. D. Bakos","Dept. of Comput. Sci. & Eng., Univ. of South Carolina, Columbia, SC, USA; Dept. of Comput. Sci. & Eng., Univ. of South Carolina, Columbia, SC, USA","2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines","19 May 2011","2011","","","1","8","In this paper we describe a double precision floating point sparse matrix-vector multiplier (SpMV) and its performance as implemented on a Convey HC-1 reconfigurable computer. The primary contributions of this work are a novel streaming reduction architecture for floating point accumulation, a novel on-chip cache optimized for streaming compressed sparse row (CSR) matrices, and end-to-end integration with the HC-1's system, programming model, and runtime environment. The design is composed of 32 parallel processing elements, each connected to the HC-1's coprocessor memory and each containing a streaming multiply-accumulator and local vector cache. When used on the HC-1, each PE has a peak throughput of 300 double precision MFLOP/s, giving a total peak throughput of 9.6 GFLOPS/s. For our test matrices, we demonstrate up to 40% of the peak performance and compare these results with results obtained using the CUSparse library on an NVIDIA Tesla S1070 GPU. In most cases our implementation exceeds the performance of the GPU.","","978-1-61284-277-6","10.1109/FCCM.2011.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5771239","floating point accumulation;reduction;reconfigurable computing;sparse matrix;SpMV","Adders;Coprocessors;Arrays;Sparse matrices;Field programmable gate arrays;Pipelines","cache storage;coprocessors;floating point arithmetic;matrix multiplication;multiplying circuits;parallel processing;reconfigurable architectures;sparse matrices","sparse matrix personality;double precision floating point sparse matrix-vector multiplier;Convey HC-1 reconfigurable computer;streaming reduction architecture;floating point accumulation;on-chip cache;compressed sparse row matrix;end-to-end integration;HC-1 system;programming model;runtime environment;parallel processing;HC-1 coprocessor memory;multiply-accumulator;local vector cache;CUSparse library","","29","","21","","19 May 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Extending OpenACC for Efficient Stencil Code Generation and Execution by Skeleton Frameworks","A. D. Pereira; M. Castro; M. A. R. Dantas; R. C. O. Rocha; L. F. W. Góes","Fed. Univ. of Santa Catarina, Florianopolis, Brazil; Fed. Univ. of Santa Catarina, Florianopolis, Brazil; Fed. Univ. of Santa Catarina, Florianopolis, Brazil; Univ. of Edinburgh, Edinburgh, UK; Pontifical Catholic Univ. of Minas Gerais, Belo Horizonte, Brazil","2017 International Conference on High Performance Computing & Simulation (HPCS)","14 Sep 2017","2017","","","719","726","The OpenACC programming model simplifies the programming for accelerator devices such as GPUs. Its abstract accelerator model defines a least common denominator for accelerator devices, thus it cannot represent architectural specifics of these devices without losing portability. Therefore, this general- purpose approach delivers good performance on average, but it misses optimization opportunities for code generation and execution of specific classes of applications. In this paper, we propose OpenACC extensions to enable efficient code generation and execution of stencil applications by parallel skeleton frameworks such as PSkel. Our results show that our stencil extensions may improve the performance of OpenACC in up to 28% and 45% on GPU and CPU, respectively. Moreover, we show that the work-partitioning mechanism offered by the skeleton framework, which splits the computation across CPU and GPU, may improve even further the performance of the applications in up to 18%.","","978-1-5386-3250-5","10.1109/HPCS.2017.110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8035149","stencil;skeleton frameworks;source-to-source compilation;CUDA;OpenACC","Graphics processing units;Skeleton;Programming;Jacobian matrices;Optimization;Computer architecture;Runtime","graphics processing units;parallel programming;program compilers;software performance evaluation","OpenACC programming model;accelerator devices;abstract accelerator model;OpenACC extensions;stencil applications;parallel skeleton frameworks;stencil extensions;efficient stencil code generation;least common denominator;general-purpose approach;optimization;code execution;performance improvement;work-partitioning","","4","","27","","14 Sep 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Processing of synthetic Aperture Radar data with GPGPU","C. Clemente; M. di Bisceglie; M. Di Santo; N. Ranaldo; M. Spinelli","Università degli Studi del Sannio, Piazza Roma 21, 82100 Benevento, Italy; Università degli Studi del Sannio, Piazza Roma 21, 82100 Benevento, Italy; Università degli Studi del Sannio, Piazza Roma 21, 82100 Benevento, Italy; Università degli Studi del Sannio, Piazza Roma 21, 82100 Benevento, Italy; Università degli Studi del Sannio, Piazza Roma 21, 82100 Benevento, Italy","2009 IEEE Workshop on Signal Processing Systems","17 Nov 2009","2009","","","309","314","Synthetic aperture radar processing is a complex task that involves advanced signal processing techniques and intense computational effort. While the first issue has now reached a mature stage, the question of how to produce accurately focused images in real-time, without mainframe facilities, is still under debate. The recent introduction of general-purpose graphic processing units seems to be quite promising in this view, especially for the decreased per-core cost barrier and for the affordable programming complexity. The authors explain, in this work, the main computational features of a range-Doppler Synthetic Aperture Radar (SAR) processor, trying to disclose the degree of parallelism in the operations at the light of the CUDA programming model. Given the extremely flexible structure of the Single Instruction Multiple Threads (SIMT) model, the authors show that the optimization of a SAR processing unit cannot reduce to an FFT optimization, although this is a quite extensively used kernel. Actually, it is noticeable that the most significant advantage is obtained in the range cell migration correction kernel where a complex interpolation stage is performed very efficiently exploiting the SIMT model. Performance show that, using a single Nvidia Tesla-C1060 GPU board, the obtained processing time is more than fifteen time better than our test workstation.","2162-3570","978-1-4244-4335-2","10.1109/SIPS.2009.5336272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336272","Synthetic Aperture Radar;parallel processing;GPU;CUDA","Synthetic aperture radar;Kernel;Radar signal processing;Focusing;Graphics;Costs;Concurrent computing;Parallel processing;Parallel programming;Flexible structures","computer graphic equipment;Doppler radar;interpolation;synthetic aperture radar","synthetic aperture radar;GPGPU;general-purpose graphic processing unit;range-Doppler SAR;single instruction multiple thread model","","15","1","13","","17 Nov 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Accelerated solution of stiffness matrix for isoparametric elements based on CUDA","H. Binxing; L. Xinguo; Q. Hao; L. Zenghao","Shaanxi Aerospace Flight Vehicle Design Key Laboratory, Northwestern Polytechnical University, Xi'an, PR China; Shaanxi Aerospace Flight Vehicle Design Key Laboratory, Northwestern Polytechnical University, Xi'an, PR China; Shaanxi Aerospace Flight Vehicle Design Key Laboratory, Northwestern Polytechnical University, Xi'an, PR China; School of Astronautics, Northwestern Polytechnical University, Xi'an, PR China","2017 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","1 Jan 2018","2017","","","1","4","High precision results in structural with the shortest time consumption are expected when methods are introduced to solve FEM(Finite element method). Solving of stiffness matrix assembled by isoparametric elements and solving the assembled stiffness matrix are the most time-consuming. In the previous serial algorithms, there is always a time limitation for some applications and it is hard to achieve. However, break-through in programming and feasibility of general-purpose applications executed on GPU (Graph Processing Unit), such as the parallel computing platform and programming model CUDA (Compute Unified Device Architecture) released by NVIDIA corporation, make it possible for some large scale FEM explicit dynamic simulation in real time. Authors present an approach to accelerate calculation in element stiffness matrices, taking the three-dimensional hexahedral isoparametric element in different scale as an example. A speedup of about 15 times is achieved with respect to parallel algorithms using boost on CPU. The results show that the parallel algorithm based on CUDA can satisfy the fast simulation of finite element model of structural problems with certain computational scale.","","978-1-5386-3142-3","10.1109/ICSPCC.2017.8242497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8242497","FEM;CUDA;Conjugate gradient;Parallel Computing;GPU acceleration","Finite element analysis;Computers;Graphics processing units;Indexes;Shape;Hardware","finite element analysis;graphics processing units;mathematics computing;matrix algebra;parallel algorithms;parallel architectures","general-purpose applications;finite element method;graph processing unit;large scale FEM explicit dynamic simulation;assembled stiffness matrix;shortest time consumption;isoparametric elements;accelerated solution;finite element model;CUDA;parallel algorithm;three-dimensional hexahedral isoparametric element;element stiffness matrices;Compute Unified Device Architecture;parallel computing platform","","2","","7","","1 Jan 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"HeTM: Transactional Memory for Heterogeneous Systems","D. Castro; P. Romano; A. Ilic; A. M. Khan","Universidade de Lisboa, Portugal; Universidade de Lisboa, Portugal; Universidade de Lisboa, Portugal; UiT The Arctic University of Norway, Norway","2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)","7 Nov 2019","2019","","","232","244","Modern heterogeneous computing architectures, which couple multi-core CPUs with discrete many-core GPUs (or other specialized hardware accelerators), enable unprecedented peak performance and energy efficiency levels. However, developing applications that can take full advantage of the potential of heterogeneous systems is a notoriously hard task. This work takes a step towards reducing the complexity of programming heterogeneous systems by introducing the abstraction of Heterogeneous Transactional Memory (HeTM). HeTM provides programmers with the illusion of a single memory region, shared among the CPUs and the (discrete) GPU(s) of a heterogeneous system, with support for atomic transactions. Besides introducing the abstract semantics and programming model of HeTM, we present the design and evaluation of a concrete implementation of the proposed abstraction, referred herein as Speculative HeTM (SHeTM). SHeTM makes use of a novel design that leverages speculative techniques, which aims at hiding the inherently large communication latency between CPUs and discrete GPUs and at minimizing inter-device synchronization overhead. We demonstrate the efficiency of the SHeTM via an extensive quantitative study based both on synthetic benchmarks and on a popular object caching system.","2641-7936","978-1-7281-3613-4","10.1109/PACT.2019.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891063","transaction;memory;CPU;GPU;heterogeneous;computing;system","Synchronization;Graphics processing units;Programming;Performance evaluation;Computer architecture;Task analysis","cache storage;graphics processing units;multiprocessing systems;parallel programming;power aware computing","Heterogeneous Transactional Memory;single memory region;Speculative HeTM;modern heterogeneous computing architectures;couple multicore CPUs;many-core GPUs;energy efficiency levels;heterogeneous systems programming;object caching system;SHeTM","","","","59","","7 Nov 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Comparison of Performance Tunabilities between OpenCL and OpenACC","M. Sugawara; S. Hirasawa; K. Komatsu; H. Takizawa; H. Kobayashi","Tohoku Univ., Sendai, Japan; Tohoku Univ., Sendai, Japan; Tohoku Univ., Sendai, Japan; Tohoku Univ., Sendai, Japan; Tohoku Univ., Sendai, Japan","2013 IEEE 7th International Symposium on Embedded Multicore Socs","11 Nov 2013","2013","","","147","152","To design and develop any auto tuning mechanisms for OpenACC, it is important to clarify the differences between conventional GPU programming models and OpenACC in terms of available programming and tuning techniques, called performance tunabilities. This paper hence discusses the performance tunabilities of OpenACC and OpenCL. As OpenACC cannot synchronize threads running on GPUs, some important techniques are not available to OpenACC. Therefore, we also design an additional compiler directive for thread synchronization. Evaluation results show that both OpenCL and OpenACC need architecture-aware optimizations, and similar approaches to performance optimization are effective for both OpenCL and OpenACC. The additional directive can allow OpenACC to describe more tuning techniques in the same approach as OpenCL. As it is obvious that OpenACC is more productive than OpenCL especially for legacy application migration, OpenACC is a very promising programming model if it can achieve the same performance as the conventional GPU programming models such as CUDA and OpenCL.","","978-0-7695-5086-2","10.1109/MCSoC.2013.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6657921","Autotuning;OpenCL;OpenACC","Instruction sets;Kernel;Graphics processing units;Optimization;Programming;Synchronization;Data transfer","graphics processing units;parallel architectures;software maintenance","performance tunabilities;OpenCL;OpenACC;auto tuning mechanisms;GPU programming models;compiler directive;thread synchronization;architecture-aware optimizations;performance optimization;legacy application migration;CUDA","","8","","15","","11 Nov 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Exploring Programming Multi-GPUs Using OpenMP and OpenACC-Based Hybrid Model","R. Xu; S. Chandrasekaran; B. Chapman","Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA","2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum","31 Oct 2013","2013","","","1169","1176","Heterogeneous computing come with tremendous potential and is a leading candidate for scientific applications that are becoming more and more complex. Accelerators such as GPUs whose computing momentum is growing faster than ever offer application performance when compute intensive portions of an application are offloaded to them. It is quite evident that future computing architectures are moving towards hybrid systems consisting of multi-GPUs and multi-core CPUs. A variety of high-level languages and software tools can simplify programming these systems. Directive-based programming models are being embraced since they not only ease programming complex systems but also abstract low-level details from the programmer. We already know that OpenMP has been making programming CPUs easy and portable. Similarly, a directive-based programming model for accelerators is OpenACC that is gaining popularity since the directives play an important role in developing portable software for GPUs. A combination of OpenMP and OpenACC, a hybrid model, is a plausible solution to port scientific applications to heterogeneous architectures especially when there is more than one GPU on a single node to port an application to. However OpenACC meant for accelerators is yet to provide support for multi-GPUs. But using OpenMP we could conveniently exploit features such as for and section to distribute compute intensive kernels to more than one GPU. We demonstrate the effectiveness of this hybrid approach with some case studies in this paper.","","978-0-7695-4979-8","10.1109/IPDPSW.2013.263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651003","GPUs;OpenACC;OpenMP","Graphics processing units;Kernel;Programming;Computational modeling;Computer architecture;Instruction sets;Data transfer","application program interfaces;graphics processing units;high level languages;multiprocessing systems;parallel programming;software tools","heterogeneous architectures;portable software;directive-based programming models;software tools;high-level languages;multicore CPU;heterogeneous computing;OpenMP;OpenACC-based hybrid model;multi-GPU","","11","","20","","31 Oct 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"A Comprehensive Performance Comparison of CUDA and OpenCL","J. Fang; A. L. Varbanescu; H. Sips","Parallel & Distrib. Syst. Group, Delft Univ. of Technol., Delft, Netherlands; Parallel & Distrib. Syst. Group, Delft Univ. of Technol., Delft, Netherlands; Parallel & Distrib. Syst. Group, Delft Univ. of Technol., Delft, Netherlands","2011 International Conference on Parallel Processing","17 Oct 2011","2011","","","216","225","This paper presents a comprehensive performance comparison between CUDA and OpenCL. We have selected 16 benchmarks ranging from synthetic applications to real-world ones. We make an extensive analysis of the performance gaps taking into account programming models, ptimization strategies, architectural details, and underlying compilers. Our results show that, for most applications, CUDA performs at most 30% better than OpenCL. We also show that this difference is due to unfair comparisons: in fact, OpenCL can achieve similar performance to CUDA under a fair comparison. Therefore, we define a fair comparison of the two types of applications, providing guidelines for more potential analyses. We also investigate OpenCL's portability by running the benchmarks on other prevailing platforms with minor modifications. Overall, we conclude that OpenCL's portability does not fundamentally affect its performance, and OpenCL can be a good alternative to CUDA.","2332-5690","978-1-4577-1336-1","10.1109/ICPP.2011.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6047190","Performance Comparison;CUDA;OpenCL","Graphics processing unit;Benchmark testing;Programming;Performance evaluation;Computational modeling;Kernel","benchmark testing;computer graphic equipment;coprocessors;multiprocessing systems;parallel architectures;parallel programming;parallelising compilers","performance comparison;CUDA;performance gap;programming model;optimization strategy;architectural detail;compilers;OpenCL portability;NVIDIA GPU","","121","","30","","17 Oct 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Hippogriff: Efficiently moving data in heterogeneous computing systems","Y. Liu; H. -W. Tseng; M. Gahagan; J. Li; Y. Jin; S. Swanson","Department of Computer Science and Engineering, University of California, San Diego, La Jolla, U.S.A.; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, U.S.A.; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, U.S.A.; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, U.S.A.; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, U.S.A.; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, U.S.A.","2016 IEEE 34th International Conference on Computer Design (ICCD)","24 Nov 2016","2016","","","376","379","Data movement between the compute and the storage (e.g., GPU and SSD) has been a long-neglected problem in heterogeneous systems, while the inefficiency in existing systems does cause significant loss in both performance and energy efficiency. This paper presents Hippogriff to provide a high-level programming model to simplify data movement between the compute and the storage, and to dynamically schedule data transfers based on system load. By eliminating unnecessary data movement, Hippogriff can speedup single program workloads by 1.17×, and save 17% energy. For multi-program workloads, Hippogriff shows 1.25× speedup. Hippogriff also improves the performance of a GPU-based MapReduce framework by 27%.","","978-1-5090-5142-7","10.1109/ICCD.2016.7753307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753307","","Nonvolatile memory;Graphics processing units;Data transfer;Runtime;Discrete wavelet transforms;Peer-to-peer computing;Benchmark testing","data handling;graphics processing units;parallel processing;storage management","Hippogriff;heterogeneous computing systems;data movement;data storage;high-level programming;GPU-based MapReduce","","8","","17","","24 Nov 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Performance Analysis of a Quantum Monte Carlo Application on Multiple Hardware Architectures Using the HPX Runtime","W. Wei; A. Chatterjee; K. Huck; O. Hernandez; H. Kaiser",Louisiana State University; Oak Ridge National Laboratory; University of Oregon; Oak Ridge National Laboratory; Louisiana State University,"2020 IEEE/ACM 11th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems (ScalA)","31 Dec 2020","2020","","","77","84","This paper describes how we successfully used the HPX programming model to port the DCA++ application on multiple architectures that include POWER9, x86, ARM v8, and NVIDIA GPUs. We describe the lessons we can learn from this experience as well as the benefits of enabling the HPX in the application to improve the CPU threading part of the code, which led to an overall 21% improvement across architectures. We also describe how we used HPX-APEX to raise the level of abstraction to understand performance issues and to identify tasking optimization opportunities in the code, and how these relate to CPU/GPU utilization counters, device memory allocation over time, and CPU kernel level context switches on a given architecture.","","978-1-6654-2270-3","10.1109/ScalA51936.2020.00015","U.S. Department of Energy; Office of Science; Advanced Scientific Computing Research; Basic Energy Sciences; Office of Science; U.S. Department of Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308704","Quantum Monte Carlo (QMC);Dynamical Cluster Approximation (DCA);Autonomic Performance Environment for eXascale (APEX);HPX runtime system","Instruction sets;C++ languages;Runtime;Task analysis;Computer architecture;Libraries;Standards","graphics processing units;Monte Carlo methods;multi-threading;parallel architectures;quantum computing;software performance evaluation","x86;POWER9;tasking optimization;CPU threading part;NVIDIA GPUs;ARM v8;DCA++ application;HPX programming model;HPX runtime;hardware architectures;quantum Monte Carlo application;performance analysis;CPU kernel level context;HPX-APEX","","","","33","","31 Dec 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Optimal Bidding Strategies for Thermal and Generic Programming Units in the Day-Ahead Electricity Market","F. -. Heredia; M. J. Rider; C. Corchero","Statistics and Operations Research Department, Universitat Politècnica de Catalunya, Barcelona, Spain; Statistics and Operations Research Department, Universitat Politècnica de Catalunya, Barcelona, Spain; Statistics and Operations Research Department, Universitat Politècnica de Catalunya, Barcelona, Spain","IEEE Transactions on Power Systems","19 Jul 2010","2010","25","3","1504","1518","This study has developed a stochastic programming model that integrates the day-ahead optimal bidding problem with the most recent regulation rules of the Iberian Electricity Market (MIBEL) for bilateral contracts (BC), with a special consideration for the new mechanism to balance the competition of the production market, namely virtual power plant (VPP) auctions. The model allows a price-taking generation company (GenCo) to decide on the unit commitment of the thermal units, the economic dispatch of the BCs between the thermal units and the generic programming unit (GPU), and the optimal sale/purchase bids for all units (thermal and generic), by observing the MIBEL regulation. The uncertainty of the spot prices has been represented through scenario sets built from the most recent real data using scenario reduction techniques. The model has been solved using real data from a Spanish generation company and spot prices, and the results have been reported and analyzed.","1558-0679","","10.1109/TPWRS.2009.2038269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5409525","Bilateral contracts;electricity spot market;optimal bidding strategies;short-term electricity generation planning;stochastic programming;virtual power plant auctions","Electricity supply industry;Power generation;Costs;Marketing and sales;Procurement;Stochastic processes;Contracts;Production;Power system economics;Power generation economics","power markets;pricing;stochastic programming","optimal bidding strategies;generic programming units;thermal programming units;day-ahead electricity market;stochastic programming model;Iberian Electricity Market;bilateral contracts;virtual power plant auctions;production market;price-taking generation company;optimal sale-purchase bids;Spanish generation company;spot prices;scenario reduction techniques","","42","","30","IEEE","8 Feb 2010","","","IEEE","IEEE Journals"
notebooks/data/ieee_4.csv:"Parallelizing Back Propagation Neural Network on Speculative Multicores","Y. Wang; H. An; Z. Liu; T. Liu; D. Zhao","Dept. of Comput. Sci. & Technol., Southwest Univ. of Sci. & Technol., Mianyang, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Southwest Univ. of Sci. & Technol., Mianyang, China; Dept. of Comput. Sci. & Technol., Southwest Univ. of Sci. & Technol., Mianyang, China; Dept. of Comput. Sci. & Technol., Southwest Univ. of Sci. & Technol., Mianyang, China","2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)","19 Jan 2017","2016","","","902","907","Applications typically exhibit extremely different performance characteristics depending on the accelerator. Back propagation neural network (BPNN) has been parallelized into different platforms. However, it has not yet been explored on speculative multicore architecture thoroughly. This paper presents a study of parallelizing BPNN on a speculative multicore architecture, including its speculative execution model, hardware design and programming model. The implementation was analyzed with seven well-known benchmark data sets. Furthermore, it trades off several important design factors in coming speculative multicore architecture. The experimental results show that: (1) the BPNN performs well on speculative multicore platform. It can achieve similar speedup (17.7x to 57.4x) compared with graphics processors (GPU) while provides a more friendly programmability. (2) 64 cores' computing resources can be used efficiently and 4k is the proper speculative buffer capacity in the model.","1521-9097","978-1-5090-4457-3","10.1109/ICPADS.2016.0121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823836","thread level speculation;parallel programming;back propagation;multicore","Multicore processing;Instruction sets;Graphics processing units;Programming;Neural networks;Hardware","backpropagation;multiprocessing systems;neural nets","backpropagation neural network;multicore architecture;speculative execution model;hardware design;programming model;speculative multicore platform;parallelized BPNN","","","","27","","19 Jan 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Task Mapping and Scheduling for OpenVX Applications on Heterogeneous Multi/Many-Core Architectures","F. Lumpp; S. Aldegheri; H. D. Patel; N. Bombieri","Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Computer Science, University of Verona, Verona, Italy","IEEE Transactions on Computers","8 Jul 2021","2021","70","8","1148","1159","Computer vision applications have stringent performance constraints that must be satisfied when they are run at the edge on programmable low-power embedded devices. OpenVX has emerged as the de-facto reference standard to develop such applications. OpenVX uses a primitive-based programming model that results in a directed-acyclic graph (DAG) representation of the application, which can then be used for automatic system-level optimizations and synthesis to heterogeneous multi- and many-core platforms. Although OpenVX has been standardized, its state-of-the-art algorithm for task mapping and scheduling does not deliver the performance necessary for such applications to be deployed on heterogeneous multi-/many-core platforms. This article focuses on addressing this challenge with three main contributions: First, we implemented a static task scheduling and mapping approach for OpenVX using the heterogeneous earliest finish time (HEFT) heuristic. We show that HEFT allows us to improve the system performance up to 70 percent on one of the most widespread smart systems for applying computer vision and intelligent video analytics in general at the edge (i.e., NVIDIA VisionWorks on NVIDIA Jetson TX2). Second, we show that HEFT, in the context of a vision application for edge computing where some primitives may have multiple implementations (e.g., for CPU and GPU), can lead to load imbalance amongst heterogeneous computing elements (CEs), thus suffering from degraded performance. Third, we present an algorithm called exclusive earliest finish time (XEFT) that introduces the notion of exclusive overlap between single implementation primitives to improve the load balancing. We show that XEFT can further improve the system performance up to 33 percent over HEFT, and 82 percent over the native OpenVX scheduler. We present the results on a large set of benchmarks, including a real-world localization and mapping application (ORB-SLAM) combined with an NVIDIA inference application based on convolutional neural networks (CNNs) for object detection.","1557-9956","","10.1109/TC.2021.3059528","Italian Ministry of Education, Univ. and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354946","Embedded vision applications;static mapping and scheduling;OpenVX;heterogeneous architectures","Task analysis;Computer architecture;Computer vision;Graphics processing units;Optimization;System performance;Kernel","computer vision;convolutional neural nets;directed graphs;embedded systems;low-power electronics;metaheuristics;multiprocessing systems;object detection;parallel architectures;processor scheduling;SLAM (robots);video signal processing","automatic system-level optimizations;static task scheduling;heterogeneous earliest finish time heuristic;NVIDIA Jetson TX2;computer vision;edge computing;heterogeneous computing elements;exclusive earliest finish time;native OpenVX scheduler;primitive-based programming model;directed-acyclic graph representation;HEFT heuristic;programmable low-power embedded devices;XEFT;real-world localization and mapping application;ORB-SLAM;convolutional neural networks;CNN;object detection;NVIDIA VisionWorks;DAG representation;heterogeneous multicore architecture;heterogeneous many-core architecture;intelligent video analytics","","","","30","IEEE","16 Feb 2021","","","IEEE","IEEE Journals"
notebooks/data/ieee_4.csv:"Enhancing Performance of Computer Vision Applications on Low-Power Embedded Systems Through Heterogeneous Parallel Programming","S. Aldegheri; S. Manzato; N. Bombieri","Department of Computer Science, University of Verona; Department of Computer Science, University of Verona; Department of Computer Science, University of Verona","2018 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC)","21 Feb 2019","2018","","","119","124","Enabling computer vision applications on low-power embedded systems gives rise to new challenges for embedded SW developers. Such applications implement different functionalities, like image recognition based on deep learning, simultaneous localization and mapping tasks. They are characterized by stringent performance constraints to guarantee real-time behaviors and, at the same time, energy constraints to save battery on the mobile platform. Even though heterogeneous embedded boards are getting pervasive for their high computational power at low power costs, they need a time consuming customization of the whole application (i.e., mapping of application blocks to CPU-GPU processing elements and their synchronization) to efficiently exploit their potentiality. Different languages and environments have been proposed for such an embedded SW customization. Nevertheless, they often find limitations on complex real cases, as their application is mutual exclusive. This paper presents a comprehensive framework that relies on a heterogeneous parallel programming model, which combines OpenMP, PThreads, OpenVX, OpenCV, and CUDA to best exploit different levels of parallelism while guaranteeing a semi-automatic customization. The paper shows how such languages and API platforms have been interfaced, synchronized, and applied to customize an ORB-SLAM application for an NVIDIA Jetson TX2 board.","2324-8440","978-1-5386-4756-1","10.1109/VLSI-SoC.2018.8644937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8644937","","Graphics processing units;Computer vision;Kernel;Task analysis;Computational modeling;Power demand;Libraries","application program interfaces;computer vision;coprocessors;embedded systems;graphics processing units;hardware-software codesign;image recognition;microprocessor chips;multiprocessing systems;parallel architectures;parallel programming;SLAM (robots)","low-power embedded systems;embedded SW developers;real-time behaviors;heterogeneous embedded boards;high computational power;low power costs;application blocks;embedded SW customization;heterogeneous parallel programming model;ORB-SLAM application;computer vision applications;performance constraints;OpenMP;PThreads;OpenVX;OpenCV;CUDA","","3","","12","","21 Feb 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"GasCL: A vertex-centric graph model for GPUs","S. Che","Advanced Micro Devices, USA","2014 IEEE High Performance Extreme Computing Conference (HPEC)","12 Feb 2015","2014","","","1","6","There are increasing research efforts of using GPUs for graph processing. Most prior work on accelerating GPGPU graph algorithms has been focused on algorithm and device-specific optimizations. There is little research on studying high-level programming models and associate run-time systems for graph processing on GPUs, which will be useful to solve diverse real-world problems flexibly. This paper presents a preliminary implementation of a graph framework, GasCL, supporting the well-known “think-like-a-vertex” programming model. The system is built on top of OpenCL and portable across diverse accelerators. We describe our design and use two applications as case studies. The initial performance result shows an average of 2.5× speedup on a GPU compared with a CPU.","","978-1-4799-6233-4","10.1109/HPEC.2014.7040962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7040962","","Graphics processing units;Kernel;Arrays;Runtime;Computational modeling;Programming","graph theory;graphics processing units;optimisation;parallel programming","GasCL;vertex-centric graph model;graph processing;GPGPU graph algorithms;device-specific optimizations;graph framework;think-like-a-vertex programming model;OpenCL;gather-apply-scatter;general purpose graphics processing unit","","15","","25","","12 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"Performance portability of a fluidized bed solver","V. M. Krushnarao Kotteda; V. Kumar; W. Spotz; D. Sunderland","Mechanical Engineering, University of Texas at El Paso, El Paso, USA; Mechanical Engineering, University of Texas at El Paso, El Paso, USA; Multiphysics Applications, Sandia National Laboratories, Albuquerque, USA; Scalable Algorithms, Sandia National Laboratories, Albuquerque, USA","2018 IEEE High Performance extreme Computing Conference (HPEC)","29 Nov 2018","2018","","","1","7","Performance portability is a challenge for application developers as the source code needs to be executed and performant on various hybrid computing architectures. The linear iterative solvers implemented in most applications consume more than 70% of the runtime. This paper presents the results of a linear solver in Trilinos for fluidized bed applications. The linear solver implemented in our code is based on the Kokkos programming model in Trilinos, which uses a library approach to provide performance portability across diverse devices with different memory models. For large scale problems, the numerical experiments on Xeon Phi and Kepler GPU architectures show good performance over the results on Xeon (Haswell) computing architectures.","2377-6943","978-1-5386-5989-2","10.1109/HPEC.2018.8547775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8547775","performance;portability;fluidized bed;Kokkos;Trilinos;MFiX","Mathematical model;Programming;Graphics processing units;Computational modeling;Computer architecture;Message systems;Libraries","fluidised beds;graphics processing units;iterative methods;mathematics computing;multiprocessing systems;parallel architectures","Kokkos programming model;linear iterative solver;source code;application developers;fluidized bed solver;Xeon computing architectures;performance portability;fluidized bed applications;hybrid computing architectures","","","","31","","29 Nov 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_4.csv:"STOIC: Serverless Teleoperable Hybrid Cloud for Machine Learning Applications on Edge Device","M. Zhang; C. Krintz; R. Wolski","University of California,Dept. of Computer Science,Santa Barbara; University of California,Dept. of Computer Science,Santa Barbara; University of California,Dept. of Computer Science,Santa Barbara","2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)","4 Aug 2020","2020","","","1","6","Serverless computing is a promising new event-driven programming model that was designed by cloud vendors to expedite the development and deployment of scalable web services on cloud computing systems. Using the model, developers write applications that consist of simple, independent, stateless functions that the cloud invokes on-demand (i.e. elastically), in response to system-wide events (data arrival, messages, web requests, etc.). In this work, we present STOIC (Serverless TeleOperable HybrId Cloud), an application scheduling and deployment system that extends the serverless model in two ways. First, it uses the model in a distributed setting and schedules application functions across multiple cloud systems. Second, STOIC supports serverless function execution using hardware acceleration (e.g. GPU resources) when available from the underlying cloud system. We overview the design and implementation of STOIC and empirically evaluate it using real-world machine learning applications and multi-tier (e.g. edge-cloud) deployments. We find that STOIC's combined use of edge and cloud resources is able to outperform using either cloud in isolation for the applications and datasets that we consider.","","978-1-7281-4716-1","10.1109/PerComWorkshops48775.2020.9156239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156239","Serverless computing;Edge computing;Image Processing;Internet of Things","Cloud computing;Image edge detection;Runtime;Machine learning;Task analysis;Computer architecture;Graphics processing units","cloud computing;Internet;learning (artificial intelligence);Web services","edge-cloud;STOIC;Serverless teleoperable hybrid Cloud;Serverless computing;event-driven programming model;cloud vendors;scalable web services;cloud computing systems;simple functions;independent functions;stateless functions;system-wide events;Serverless TeleOperable HybrId Cloud;application scheduling;deployment system;serverless model;distributed setting;schedules application functions;multiple cloud systems;serverless function execution;underlying cloud system;real-world machine learning applications","","1","","36","","4 Aug 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Exploring a multi-resolution GPU programming model for Chapel","A. Hayashi; S. Raj Paul; V. Sarkar","Georgia Institute of Technology Atlanta,Georgia,USA; Georgia Institute of Technology Atlanta,Georgia,USA; Georgia Institute of Technology Atlanta,Georgia,USA","2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","28 Jul 2020","2020","","","675","675","There is a growing need to support accelerators, especially GPU accelerators, since they are a common source of performance improvement in HPC clusters. As for GPU programming with Chapel, typically programmers first start with writing forall loops and run these loops on CPUs as a proof-of-concept. If the resulting CPU performance is not sufficient for their needs, their next step could be to try the automatic compiler-based GPU code generation techniques [1], [2]. For portions that remain as performance bottlenecks, even after automatic compilation approaches, the next step is to consider writing GPU kernels using CUDA/HIP/OpenCL and invoking these kernels from the Chapel program using the GPUIterator [3], [4] and Chapel's C interoperability feature.","","978-1-7281-7445-7","10.1109/IPDPSW50202.2020.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150427","","Graphics processing units;Programming;Kernel;Data transfer;Optimization;Conferences;Writing","parallel architectures;parallel programming;program compilers;public domain software","automatic compilation;GPU kernels;Chapel program;multiresolution GPU programming model;GPU accelerators;HPC clusters;forall loops;Chapel C interoperability feature;automatic compiler-based GPU code generation;CUDA;OpenCL;HIP","","","","6","","28 Jul 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU Assist using DSP Pre-processor","M. Mody; H. Hariyani; A. Balagopalakrishnan; J. Jones; A. Jayaraj; Y. A. Prithvishankar","Texas Instruments Inc,Embedded Automotive Processor Business; Texas Instruments Inc,Embedded Automotive Processor Business; Texas Instruments Inc,Embedded Automotive Processor Business; Texas Instruments Inc,Embedded Automotive Processor Business; Texas Instruments Inc,Embedded Automotive Processor Business; Texas Instruments Inc,Embedded Automotive Processor Business","2020 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","16 Sep 2020","2020","","","1","4","There is an ever increasing need for higher GPU performance to render sophisticated User Interface, latest high end 3D games and general purpose compute (GPGPU) applications. GPU SW programming models such as OpenGL have evolved over decades to cater to the unique mixed pipeline 3D GPU architectures. Due to the sticky nature of GPU SW programming model, leveraging other HW blocks to enhance graphics performance has been a most challenging task for SW architects. System designers have usually responded to the GFLOPS demand by increasing the GPU HW specifications. This paper proposes enhancing GPU performance by leveraging DSP transparently in background without impacting GPU software programming model. The proposed solution consists of multiple novel techniques namely ability to offload vertex shader to DSP, 3 stage pipelined execution and ability to re-use GPU internal pipeline. The proposed solution is prototyped in Jacinoto6 Platform from Texas Instruments. The default GPU spec performance is increased by up-to 41% by leveraging dual core C66x DSP in Jacinto6 Platform using proposed solution for different use-cases. The proposed solution is fully transparent to application software stack. In addition, the solution is directly applicable to any GPU + DSP architecture making it attractive approach for cost optimized solutions.","","978-1-7281-6828-9","10.1109/CONECCT50063.2020.9198650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9198650","GPU;GPGPU;GLOPS;Shader;OpenGL;Vulkan DSP;Jacinto","Graphics processing units;Pipeline processing;Pipelines;Programming;Random access memory;Context","digital signal processing chips;graphics processing units;pipeline processing","3D games;general purpose compute applications;GPU SW programming model;graphics performance;GPU HW specifications;GPU software programming model;3 stage pipelined execution;default GPU spec performance;DSP architecture;GPU performance;user interface;GPU internal pipeline;3D GPU architectures;DSP preprocessor;OpenGL;GFLOPS;vertex shader;Jacinoto6 platform;dual core C66x DSP;Jacinto6 platform","","1","","8","","16 Sep 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU Computing Pipeline Inefficiencies and Optimization Opportunities in Heterogeneous CPU-GPU Processors","J. Hestness; S. W. Keckler; D. A. Wood",NA; NA; NA,"2015 IEEE International Symposium on Workload Characterization","2 Nov 2015","2015","","","87","97","Emerging heterogeneous CPU-GPU processors have introduced unified memory spaces and cache coherence. CPU and GPU cores will be able to concurrently access the same memories, eliminating memory copy overheads and potentially changing the application-level optimization targets. To date, little is known about how developers may organize new applications to leverage the available, finer-grained communication in these processors. However, understanding potential application optimizations and adaptations is critical for directing heterogeneous processor programming model and architectural development. This paper quantifies opportunities for applications and architectures to evolve to leverage the new capabilities of heterogeneous processors. To identify these opportunities, we ported and simulated a broad set of benchmarks originally developed for discrete GPUs to remove memory copies, and applied analytical models to quantify their application-level pipeline inefficiencies. For existing benchmarks, GPU bulk-synchronous software pipelines result in considerable core and cache utilization inefficiency. For heterogeneous processors, the results indicate increased opportunity for techniques that provide flexible compute and data granularities, and support for efficient producer-consumer data handling and synchronization within caches.","","978-1-5090-0088-3","10.1109/IISWC.2015.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314150","GPGPU;GPU computing;heterogeneous processors;benchmarking","Graphics processing units;Benchmark testing;Kernel;Optimization;Pipelines;Synchronization","graphics processing units;memory architecture;optimisation;pipeline processing","GPU computing pipeline inefficiency;optimization opportunity;heterogeneous CPU-GPU processor;unified memory space;cache coherence;CPU core;GPU core;memory copy overhead;application-level optimization;finer-grained communication;heterogeneous processor programming model;architectural development;application-level pipeline inefficiency;GPU bulk-synchronous software pipeline","","19","2","38","","2 Nov 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Poster: Acceleration of the BLAST Hydro Code on GPU","T. Dong; T. Kolev; R. Rieben; V. Dobrev","Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., Livermore, USA; Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., Livermore, USA; Lawrence Livermore Nat. Lab., Livermore, USA; Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., Livermore, USA","2012 SC Companion: High Performance Computing, Networking Storage and Analysis","11 Apr 2013","2012","","","1337","1337","The BLAST code implements a high-order numerical algorithm that solves the equations of compressible hydrodynamics using the Finite Element Method in a moving Lagrangian frame. BLAST is coded in C++ and parallelized by MPI. We accelerate the most computationally intensive parts (80%-95%) of BLAST on an NVIDIA GPU with the CUDA programming model. Several 2D and 3D problems were tested and a maximum speedup of 4.3x was delivered. Our results demonstrate the validity and capability of GPU computing.","","978-0-7695-4956-9","10.1109/SC.Companion.2012.172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6495955","GPU;CFD;FEM","","application program interfaces;C++ language;compressible flow;computational fluid dynamics;finite element analysis;graphics processing units;hydrodynamics;message passing;parallel programming","GPU computing;NVIDIA GPU;compute unified device architecture;CUDA programming model;parallelization;message passing interface;MPI;C++ language;moving Lagrangian frame;finite element method;compressible hydrodynamics;high-order numerical algorithm;graphics processing unit;BLAST hydro code","","","","","","11 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Accelerating Kirchhoff Migration on GPU Using Directives","R. Xu; M. Hugues; H. Calandra; S. Chandrasekaran; B. Chapman","Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; TOTAL E&P Res. & Technol. USA, Houston, TX, USA; TOTAL E&P Res. & Technol. USA, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA; Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA","2014 First Workshop on Accelerator Programming using Directives","9 Apr 2015","2014","","","37","46","Accelerators offer the potential to significantly improve the performance of scientific applications when offloading compute intensive portions of programs to the accelerators. However, effectively tapping their full potential is difficult owing to the programmability challenges faced by the users when mapping computation algorithms to the massively parallel architectures such as GPUs.Directive-based programming models offer programmers an option to rapidly create prototype applications by annotating region of code for offloading with hints to the compiler. This is critical to improve the productivity in the production code. In this paper, we study the effectiveness of a high-level directivebased programming model, OpenACC, for parallelizing a seismic migration application called Kirchhoff Migration on GPU architecture. Kirchhoff Migration is a real-world production code in the Oil & Gas industry. Because of its compute intensive property, we focus on the computation part and explore different mechanisms to effectively harness GPU's computation capabilities and memory hierarchy. We also analyze different loop transformation techniques in different OpenACC compilers and compare their performance differences. Compared toone socket (10 CPU cores) on the experimental platform, one GPU achieved a maximum speedup of 20.54x and 6.72x for interpolation and extrapolation kernel functions.","","978-1-4673-6753-0","10.1109/WACCPD.2014.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081676","OpenACC; Kirchhoff Migration; GPU; Directives; Programming Model","Graphics processing units;Interpolation;Kernel;Programming;Extrapolation;Computer architecture;Computational modeling","extrapolation;geophysics computing;graphics processing units;interpolation;parallel architectures;program compilers;seismology","Kirchhoff migration;accelerator;compute intensive portion;programmability challenges;computation algorithm;parallel architecture;directive-based programming model;productivity;high-level directive based programming model;seismic migration application;GPU architecture;real-world production code;oil & gas industry;compute intensive property;GPU computation capability;memory hierarchy;loop transformation technique;OpenACC compiler;interpolation kernel function;extrapolation kernel function","","5","","18","","9 Apr 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU parallel computing architecture and CUDA programming model","J. Nickolls",NA,"2007 IEEE Hot Chips 19 Symposium (HCS)","4 Jul 2016","2007","","","1","12","This article consists of a collection of slides from the author's conference presentation on NVIDIA's CUDA programming model (parallel computing platform and application programming interface) via graphical processing units (GPU). Some of the specific topics discussed include: the special features of GPUs; the importance of GPU computing; system specifications and architectures; processing capabilities; parallel memory sharing; CUDA programming models; transparent scalability; and major applications supported.","","978-1-4673-8869-6","10.1109/HOTCHIPS.2007.7482491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482491","","Instruction sets;Graphics processing units;Parallel processing;Computer architecture;Programming;Computational modeling","application program interfaces;graphics processing units;parallel architectures","GPU parallel computing architecture;NVIDIA CUDA programming models;parallel computing platform;application programming interface;graphical processing units;parallel memory sharing;transparent scalability","","14","1","","","4 Jul 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Kernel Fusion/Decomposition for Automatic GPU-Offloading","A. Mishra; M. Kong; B. Chapman","Stony Brook University, USA; Brookhaven National Laboratory, USA; Stony Brook University, USA","2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)","7 Mar 2019","2019","","","283","284","The massively parallel architecture of GPU accelerators are being harnessed to expedite computational workloads in cutting edge scientific research. Unfortunately writing applications for GPUs requires extensive knowledge of the underlying architecture, the application and the interfacing programming model. Moreover, (re-)writing kernels using lower-level programming models such as CUDA and OpenCL is a burden for application scientists. A more appealing strategy is to leverage a programming model layered on directive-based optimization: OpenMP, whose recent specification significantly extends its accelerator functionalities. Despite this, it is still quite challenging to optimize large scale applications, since “pragmatizing” each kernel is a repetitive and complex task. In large scale applications most of the operations could be small, don't have enough computational work to justify a GPU execution, deeply buried in the library specification, or evenly spread throughout the application. Thus, we seek to design and build a compiler framework that can automatically and profitably offload regions of code with these characteristics. The driving principle of our work resides in generating numerous kernel variants that result from fusing and/or decomposing existing function bodies. We analyze the program's call graph to determine the “proximity” of kernel calls and evaluate the degree of data reuse among adjacent or “close-enough” calls. When such patterns are detected we generate several scenarios, until producing a single variant whose footprint is near the capacity of the GPU. To compare the potential performance among the various kernel variants generated, we are designing an adaptive cost model. The precision of this cost model will depend upon the analyzability of the program. We are also building upon existing cost models like Baghsorkhi et al.'s model which proposed a work flow graph based analytical model and a recent Hong et al.'s model which propose the use of abstract kernel emulations to help identify the performance bottlenecks of a GPU program execution. Along with these we introduce GPU initialization and data transfer cost to the model. Once the profitable kernel variants are detected, we automatically insert pertinent OpenMP directives and provide a newly generated code supporting GPU offloading.","","978-1-7281-1436-1","10.1109/CGO.2019.8661188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661188","","Kernel;Graphics processing units;Adaptation models;Computational modeling;Analytical models;Programming;Libraries","application program interfaces;coprocessors;graphics processing units;message passing;optimisation;parallel architectures;parallel programming;program compilers","lower-level programming models;application scientists;directive-based optimization;accelerator functionalities;repetitive task;complex task;GPU execution;library specification;kernel calls;adaptive cost model;work flow graph;abstract kernel emulations;GPU program execution;data transfer cost;profitable kernel variants;pertinent OpenMP directives;kernel fusion/decomposition;automatic GPU-offloading;massively parallel architecture;GPU accelerators;computational workloads;edge scientific research;interfacing programming model;writing kernels;generated code;automatic GPU offloading","","3","","8","","7 Mar 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Research on Tool Path Planning Method of NURBS Surface Based on CPU-GPU Parallel Computing","W. Yu; Y. Bi; Z. Li","Sch. of Autom., Hangzhou Univ. of Electron. Sci. & Technol., Hangzhou, China; Sch. of Autom., Hangzhou Univ. of Electron. Sci. & Technol., Hangzhou, China; Sch. of Autom., Hangzhou Univ. of Electron. Sci. & Technol., Hangzhou, China","2017 International Conference on Computer Network, Electronic and Automation (ICCNEA)","7 Dec 2017","2017","","","85","88","In order to deal with the inefficiency of trational serial tool path algorithms and incompatibility issues on the heterogeneous hardware platforms, this paper suggests a tool path planning method based on CPU-GPU(Central Processing Unit-Graphic Processing Unit) heterogeneous parallel computing. The method contra poses NURBS(Non-Uniform Rational B-Splines) surface which is abstracted as a matrix multiplication on the principle of isoparametric line tool path planning method. Then a parallel algorithm in accordance with Open CL(Open Computing Language) specification is proposed. Adopting data parallel programming model, the method executes multiple work-items of the GPU on the core under control of the CPU logic, and reconstructs the isoparametric line method as parallel execution instead of traditional serial execution. Simulation results show that this algorithm takes less time to generate tool paths on the CPU-GPU heterogeneous platforms, reduced by 1.5 to 15.9 times compared with traditional serial algorithm and it is of great significance to the tool path planning's real-time or quasi real-time generation.","","978-1-5386-3981-8","10.1109/ICCNEA.2017.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128535","Component;Nurbs surfaces;OpenCL;Parallel computing;Tool path planning;CPU-GPU","Tools;Graphics processing units;Path planning;Parallel processing;Splines (mathematics);Surface topography;Surface reconstruction","graphics processing units;parallel programming;path planning;splines (mathematics)","CPU logic;CPU-GPU heterogeneous platforms;traditional serial algorithm;Nurbs surface;CPU-GPU parallel computing;heterogeneous hardware platforms;parallel algorithm;serial tool path algorithms;Central Processing Unit-Graphic Processing Unit;NonUniform Rational B-Splines surface;isoparametric line tool path planning;Open CL;Open Computing Language;data parallel programming model","","1","","11","","7 Dec 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU programming for EDA with OpenCL","R. O. Topaloglu; B. Gaster","GLOBALFOUNDRIES, 840 N McCarthy Blvd, Milpitas CA 95035; Advanced Micro Devices, 1 AMD Pl, Sunnyvale CA 94085","2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","15 Dec 2011","2011","","","63","66","Graphical processing unit (GPU) computing has been an interesting area of research in the last few years. While initial adapters of the technology have been from image processing domain due to difficulties in programming the GPUs, research on programming languages made it possible for people without the knowledge of low-level programming languages such as OpenGL develop code on GPUs. Two main GPU architectures from AMD (former ATI) and NVIDIA acquired grounds. AMD adapted Stanford's Brook language and made it into an architecture-agnostic programming model. NVIDIA, on the other hand, brought CUDA framework to a wide audience. While the two languages have their pros and cons, such as Brook not being able to scale as well and CUDA having to account for architectural-level decisions, it has not been possible to compile one code on another architecture or across platforms. Another opportunity came with the introduction of the idea of combining one or more CPUs and GPUs on the same die. Eliminating some of the interconnection bandwidth issues, this combination makes it possible to offload tasks with high parallelism to the GPU. The technological direction towards multicores for CPU-only architectures also require a programming methodology change and act as a catalyst for suitable programming languages. Hence, a unified language that can be used both on multiple core CPUs as well as GPUs and their combinations has gained interest. Open Computing Language (OpenCL), developed originally by the Khronos Group of Apple and supported by both AMD and NVIDIA, is seen as the programming language of choice for parallel programming. In this paper, we provide a motivation for our tutorial talk on usage of OpenCL for GPUs and highlight key features of the language. We provide research directions on OpenCL for EDA. In our tutorial talk, we use EDA as our application domain to get the readers started with programming the rising language of parallelism, OpenCL.","1558-2434","978-1-4577-1400-9","10.1109/ICCAD.2011.6105306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6105306","GPU;GPGPU;OpenCL;EDA;CAD;algorithms","Graphics processing unit;Programming;Kernel;Multicore processing;Design automation;Algorithm design and analysis","graphics processing units;parallel programming;programming languages","GPU programming;EDA;OpenCL;graphical processing unit computing;image processing domain;research on programming language;low-level programming languages;OpenGL;GPU architecture;AMD;NVIDIA;Stanford Brook language;architecture-agnostic programming model;CUDA framework;architectural-level decisions;unified language;open computing language;parallel programming","","1","","17","","15 Dec 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Reflection removal using ghosting cues based on GPU via CUDA","M. Liao; C. Lv; G. Li; J. Lin; X. Gao","Software School, Xiamen University, Xiamen, Fujian, P.R. China; Software School, Xiamen University, Xiamen, Fujian, P.R. China; Software School, Xiamen University, Xiamen, Fujian, P.R. China; Software School, Xiamen University, Xiamen, Fujian, P.R. China; Software School, Xiamen University, Xiamen, Fujian, P.R. China","2016 11th International Conference on Computer Science & Education (ICCSE)","6 Oct 2016","2016","","","814","817","Reflections of windows or glass panes always destroy the photograph that we want to take by camera or phone. The purpose of this paper is to study and put forward a reflection removal algorithm based on GPU. The algorithm is not simply transplanted from CPU onto GPU. In order to make it adapted to the GPU architecture and programming model, we improve on the original method and the improved algorithm is more efficient by using GPU resources sufficiently. Experimental results show that the algorithm of this paper is effective and efficient. The GPU-based implementation is faster (up to 18 times) than the CPU-based implementation.","","978-1-5090-2218-2","10.1109/ICCSE.2016.7581687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581687","reflection removal;parallel computation;GPU;CUDA","Reflection;Graphics processing units;Algorithm design and analysis;Windows;Glass;Parallel processing","graphics processing units;image restoration;parallel architectures;reflection","reflection removal algorithm;ghosting cues;GPU architecture;CUDA;window reflections;glass pane reflections;photographs;programming model;image restoration","","1","","22","","6 Oct 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Hybrid Parallel Programming on GPU Clusters","C. Yang; C. Huang; C. Lin; T. Chang","Dept. of Comput. Sci., Tunghai Univ., Taichung, Taiwan; Dept. of Comput. Sci., Tunghai Univ., Taichung, Taiwan; Dept. of Comput. Sci., Tunghai Univ., Taichung, Taiwan; Dept. of Comput. Sci., Tunghai Univ., Taichung, Taiwan","International Symposium on Parallel and Distributed Processing with Applications","11 Nov 2010","2010","","","142","147","Nowadays, NVIDIA's CUDA is a general purpose scalable parallel programming model for writing highly parallel applications. It provides several key abstractions - a hierarchy of thread blocks, shared memory, and barrier synchronization. This model has proven quite successful at programming multithreaded many core GPUs and scales transparently to hundreds of cores: scientists throughout industry and academia are already using CUDA to achieve dramatic speedups on production and research codes. In this paper, we propose a hybrid parallel programming approach using hybrid CUDA and MPI programming, which partition loop iterations according to the number of C1060 GPU nodes in a GPU cluster which consists of one C1060 and one S1070. Loop iterations assigned to one MPI process are processed in parallel by CUDA run by the processor cores in the same computational node.","2158-9208","978-1-4244-8095-1","10.1109/ISPA.2010.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634329","CUDA;GPU;MPI;OpenMP;hybrid;parallel programming","Graphics processing unit;Instruction sets;Parallel processing;Parallel programming;Computational modeling;Linux","computer graphic equipment;coprocessors;message passing;parallel programming","hybrid parallel programming;NVIDIA CUDA programming model;graphics processing units;multithreaded programming;message passing interface;loop iterations;C1060 GPU cluster;S1070 GPU cluster","","4","","18","","11 Nov 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU-accelerated parallel algorithms for map algebra","Jianbo Zhang; Wenxin Yang; Jing Sun; Yonghong Lv","Department of Software Engineering, Faculty of Information Engineering, China University of Geoscience, Wuhan, China; Department of Software Engineering, Faculty of Information Engineering, China University of Geoscience, Wuhan, China; Department of Software Engineering, Faculty of Information Engineering, China University of Geoscience, Wuhan, China; Department of Software Engineering, Faculty of Information Engineering, China University of Geoscience, Wuhan, China","2010 The 2nd Conference on Environmental Science and Information Application Technology","9 Sep 2010","2010","1","","882","885","Aiming at the low efficiency when traditional realization methods of map algebra apply to calculations for gigantic raster data, this paper maps the traditional serial algorithms to GPU parallel processing architecture on a new parallel programming model of GPU named Compute Unified Device Architecture. The paper also aims to discuss the realization mechanism surrounding parallel mapping methods from traditional serial algorithms to parallel algorithms and adaptive-parameter adjustments on computer graphic processor resources.","","978-1-4244-7390-8","10.1109/ESIAT.2010.5567202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567202","Map Algebra;GPU;CUDA;Parallel Computation","Graphics processing unit;Algebra;Instruction sets;Computer architecture;Computational modeling;Hardware;Parallel processing","geographic information systems;mathematics computing;parallel algorithms;parallel architectures;parallel programming","GPU-accelerated parallel algorithms;map algebra;serial algorithms;GPU parallel processing architecture;parallel programming model;Compute Unified Device Architecture;adaptive-parameter adjustments;computer graphic processor","","2","","10","","9 Sep 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Abstract: GPU Accelerated Ultrasonic Tomography Using Propagation and Backpropagation Method","P. D. Bello; Y. Jin; E. Lu","Dept. of Electr. & Comput. Eng., Florida Int. Univ., Miami, FL, USA; Dept. of Eng. & Aviation Sci., Univ. of Maryland Eastern Shore, Princess Anne, MD, USA; Dept. of Math. & Comput. Sci., Salisbury Univ., Salisbury, MD, USA","2012 SC Companion: High Performance Computing, Networking Storage and Analysis","11 Apr 2013","2012","","","1445","1446","This paper develops implementation strategy and method to accelerate the propagation and backpropagation (PBP) tomographic imaging algorithm using Graphic Processing Units (GPUs). The Compute Unified Device Architecture (CUDA) programming model is used to develop our parallelized algorithm since the CUDA model allows the user to interact with the GPU resources more efficiently than traditional shader methods. The results show an improvement of more than 80x when compared to the C/C++ version of the algorithm, and 515x when compared to the MATLAB version while achieving high quality imaging for both cases. We test different CUDA kernel configurations in order to measure changes in the processing-time of our algorithm. By examining the acceleration rate and the image quality, we develop an optimal kernel configuration that maximizes the throughput of CUDA implementation for the PBP method.","","978-0-7695-4956-9","10.1109/SC.Companion.2012.248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6496031","Medical Imaging;Ultrasonic Tomography;GPU;CUDA;Parallel Computing","","acoustic tomography;backpropagation;computerised tomography;graphics processing units;medical image processing;parallel algorithms;parallel architectures;ultrasonic imaging","parallel computing;medical imaging;PBP method;optimal kernel configuration;image quality;acceleration rate;CUDA kernel configuration;MATLAB version;shader method;GPU resource;parallelized algorithm;CUDA programming model;compute unified device architecture;graphic processing unit;PBP tomographic imaging algorithm;propagation and backpropagation tomographic imaging algorithm;GPU accelerated ultrasonic tomography","","","","5","","11 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Extending OpenSHMEM for GPU Computing","S. Potluri; D. Bureddy; H. Wang; H. Subramoni; D. K. Panda","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2013 IEEE 27th International Symposium on Parallel and Distributed Processing","29 Jul 2013","2013","","","1001","1012","Graphics Processing Units (GPUs) are becoming an integral part of modern supercomputer architectures due to their high compute density and performance per watt. In order to maximize utilization, it is imperative that applications running on these clusters have low synchronization and communication overheads. Partitioned Global Address Space (PGAS) models provide an attractive approach for developing parallel scientific applications. Such models simplify programming through the abstraction of a shared memory address space while their one-sided communication primitives allow for efficient implementation of applications with minimum synchronization. OpenSHMEM is a library-based programming model that is gaining popularity. However, the current OpenSHMEM standard does not support direct communication from GPU device buffers. It requires data to be copied to the host memory before OpenSHMEM calls can be made. Similarly, data has to moved to the GPU explicitly by remote processes. This severely limits the programmability and performance of GPU applications. In this paper we provide extensions to the OpenSHMEM model which allow communication calls to be made directly on the GPU memory. The proposed extensions are interoperable with the two most popular GPU programming frameworks: CUDA and OpenCL. We present designs for an efficient OpenSHMEM runtime which transparently provide high-performance communication between GPUs in different inter-node and intra-node configurations. To the best of our knowledge this is the first work that enables GPU-GPU communication using the OpenSHMEM model for both CUDA and OpenCL computing frameworks. The proposed extensions to OpenSHMEM, coupled with the high-performance runtime, improve the latency of GPU-GPU shmem getmem operation by 90%, 40% and 17%, for intra-IOH (I/O Hub), inter-IOH and inter-node configurations. It improves the performance of OpenSHMEM atomics by up to 55% and 52%, for intra-IOH and inter-node GPU configurations respectively. The proposed enhancements improve the performance of Stencil2D kernel by 65% on a cluster of 192 GPUs and the performance of BFS kernel by 12% on a cluster of 96 GPUs.","1530-2075","978-1-4673-6066-1","10.1109/IPDPS.2013.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6569880","PGAS;OpenSHMEM;GPU;CUDA;OpenCL","Graphics processing units;Runtime;Context;Computational modeling;Electronics packaging;Programming;Kernel","graphics processing units;parallel architectures;parallel machines;shared memory systems","OpenSHMEM runtime;high-performance communication;inter-node configurations;intra-node configurations;OpenCL computing frameworks;high-performance runtime;GPU-GPU shmem getmem operation;intra-IOH;I/O hub;OpenSHMEM atomics;GPU computing;graphics processing units;modern supercomputer architectures;high compute density;performance per watt;communication overheads;partitioned global address space models;PGAS models;parallel scientific applications;abstraction;shared memory address space;one-sided communication primitives;minimum synchronization;library-based programming model;direct communication;GPU device buffers;host memory;programmability;OpenSHMEM model;GPU memory;interoperable;GPU programming frameworks;CUDA;OpenCL;Stencil2D kernel","","21","","32","","29 Jul 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Tartan: Evaluating Modern GPU Interconnect via a Multi-GPU Benchmark Suite","A. Li; S. L. Song; J. Chen; X. Liu; N. Tallent; K. Barker",Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory,"2018 IEEE International Symposium on Workload Characterization (IISWC)","13 Dec 2018","2018","","","191","202","High performance multi-GPU computing becomes an inevitable trend due to the ever-increasing demand on computation capability in emerging domains such as deep learning, big data and planet-scale applications. However, the lack of deep understanding on how modern GPUs can be connected and the actual impact of state-of-the-art interconnect on multiGPU application performance becomes a hurdle. Additionally, the absence of a practical multi-GPU benchmark suite poses further obstacles for conducting research in multi-GPU era. In this paper, we fill the gap by proposing a multi-GPU benchmark suite named Tartan, which contains microbenchmarks, scale-up and scale-out applications. We then apply Tartan to evaluate the four latest types of modern GPU interconnects, i.e., PCI-e, NVLink-V1, NVLink-V2 and InfiniBand with GPUDirect-RDMA from two recently released NVIDIA super AI platforms as well as ORNL's exascale prototype system. Based on empirical evaluation, we observe four new types of NUMA effects: three types are triggered by NVLink's topology, connectivity and routing, while one type is caused by PCI-e (i.e., anti-locality). They are very important for performance tuning in multi-GPU environment. Our evaluation results show that, unless the current CPU-GPU master-slave programming model can be replaced, it is difficult for scale-up multi-GPU applications to really benefit from faster intra-node interconnects such as NVLinks; while for inter-node scale-out applications, although interconnect is more crucial to the overall performance, GPUDirect-RDMA appears to be not always the optimal choice. The Tartan benchmark suite including the microbenchmarks are opensource and available athttp://github.com/uuudown/Tartan.","","978-1-5386-6780-4","10.1109/IISWC.2018.8573483","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573483","","Graphics processing units;Bandwidth;Peer-to-peer computing;Benchmark testing;Network topology;Topology;Routing","benchmark testing;computer graphic equipment;graphics processing units;multiprocessing systems","Tartan benchmark suite;modern GPU interconnect;high performance multiGPU computing;planet-scale applications;multiGPU application performance;multiGPU era;NVLink-V1;NVLink-V2;multiGPU environment;scale-up multiGPU applications;modern GPU;CPU-GPU master-slave programming model;multiGPU benchmark suite;intra-node interconnects","","14","","72","","13 Dec 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Integrating Multi-GPU Execution in an OpenACC Compiler","T. Komoda; S. Miwa; H. Nakamura; N. Maruyama","Grad. Sch. of Inf. Sci. & Technol., Univ. of Tokyo, Tokyo, Japan; Grad. Sch. of Inf. Sci. & Technol., Univ. of Tokyo, Tokyo, Japan; Grad. Sch. of Inf. Sci. & Technol., Univ. of Tokyo, Tokyo, Japan; Adv. Inst. for Comput. Sci., RIKEN, Kobe, Japan","2013 42nd International Conference on Parallel Processing","19 Dec 2013","2013","","","260","269","GPUs have become promising computing devices in current and future computer systems due to its high performance, high energy efficiency, and low price. However, lack of high level GPU programming models hinders the wide spread of GPU applications. To resolve this issue, OpenACC is developed as the first industry standard of a directive-based GPU programming model and several implementations are now available. Although early evaluations of the OpenACC systems showed significant performance improvement with modest programming efforts, they also revealed the limitations of the systems. One of the biggest limitations is that the current OpenACC compilers do not automate the utilization of multiple GPUs. In this paper, we present an OpenACC compiler with the capability to execute single GPU OpenACC programs on multiple GPUs. By orchestrating the compiler and the runtime system, the proposed system can efficiently manage the necessary data movements among multiple GPUs memories. To enable advanced communication optimizations in the proposed system, we propose a small set of directives as extensions of OpenACC API. The directives allow programmers to express the patterns of memory accesses in the parallel loops to be offloaded. Inserting a few directives into an OpenACC program can reduce a large amount of unnecessary data movements and thus helps the proposed system drawing great performance from multi-GPU systems. We implemented and evaluated the prototype system on top of CUDA with three data parallel applications. The proposed system achieves up to 6.75x of the performance compared to OpenMP in the 1CPU with 2GPU machine, and up to 2.95x of the performance compared to OpenMP in the 2CPU with 3GPU machine. In addition, in two of the three applications, the multi-GPU OpenACC compiler outperforms the single GPU system where hand-written CUDA programs run.","2332-5690","978-0-7695-5117-3","10.1109/ICPP.2013.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6687359","OpenACC;Multi-GPU","Graphics processing units;Arrays;Kernel;Programming;Runtime;Distributed databases","application program interfaces;graphics processing units;multiprocessing systems;program compilers","multiGPU execution;graphics processing unit;OpenACC compiler;high level GPU programming models;GPU applications;directive-based GPU programming model;GPU OpenACC programs;runtime system;data movements;GPU memories;OpenACC API extension;application program interface;data parallel applications;hand-written CUDA programs;compute unified device architecture","","11","","23","","19 Dec 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Integral image computation on GPU","M. Chouchene; F. E. Sayadi; M. Atri; R. Tourki","Laboratory of Electronics and Microelectronics (EμE), Faculty of Sciences Monastir, Tunisia; Laboratory of Electronics and Microelectronics (EμE), Faculty of Sciences Monastir, Tunisia; Laboratory of Electronics and Microelectronics (EμE), Faculty of Sciences Monastir, Tunisia; Laboratory of Electronics and Microelectronics (EμE), Faculty of Sciences Monastir, Tunisia","10th International Multi-Conferences on Systems, Signals & Devices 2013 (SSD13)","22 Jul 2013","2013","","","1","4","In this paper we present an integral image algorithm that can run in real-time on a Graphics Processing Unit (GPU). Our system exploits the parallelisms in computation via the NVIDA CUDA programming model, which is a software platform for solving non-graphics problems in a massively parallel high performance fashion. We compare the performance of the parallel approach running on the GPU with the sequential CPU implementation across a range of image sizes.","","978-1-4673-6457-7","10.1109/SSD.2013.6564007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6564007","Integral image;GPU;CPU;NVIDIA CUDA","Graphics processing units;Instruction sets;Programming;Computer architecture;Kernel;Computer vision;Laboratories","graphics processing units;parallel architectures;parallel programming","integral image computation;GPU;graphics processing unit;NVIDA;CUDA programming model;software platform;nongraphics problem solving;parallel high performance fashion","","2","","12","","22 Jul 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU-based non-binary LDPC decoder with weighted bit-reliability based algorithm","Z. Liu; R. Liu; L. Zhao","School of Electrical and Information Engineering, Beihang University, Beijing 100191, China; School of Electrical and Information Engineering, Beihang University, Beijing 100191, China; School of Electrical and Information Engineering, Beihang University, Beijing 100191, China","China Communications","29 May 2020","2020","17","5","78","88","In this paper, we present a graphics processing unit (GPU)-based implementation of a weighted bit-reliability based (wBRB) decoder for non-binary LDPC (NB-LDPC) codes. To achieve coalesced memory accesses, an efficient data structure for the wBRB algorithm is proposed. Based on the Single-Instruction Multiple-Threads (SIMT) programming model, a novel mapping strategy with high intra-frame parallelism is presented to improve the latency and throughput performance. Moreover, by using Single-Instruction Multiple-Data (SIMD) intrinsics, four 8-bit message elements are packed into a 32-bit unit and simultaneously processed. Experimental results show that the proposed wBRB decoder provides good tradeoff between error performance and throughput for the codes with relatively large column degrees or high rates.","1673-5447","","10.23919/JCC.2020.05.008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103919","non-binary LDPC;bit-reliability;GPU;SIMT;SIMD","Decoding;Iterative decoding;Complexity theory;Graphics processing units;Memory management;Data structures;Throughput","data structures;decoding;graphics processing units;multi-threading;parity check codes","GPU-based nonbinary LDPC decoder;graphics processing unit-based implementation;weighted bit-reliability based decoder;nonbinary LDPC codes;NB-LDPC;coalesced memory accesses;efficient data structure;wBRB algorithm;high intra-frame parallelism;8-bit message elements;32-bit unit;wBRB decoder;single-instruction multiple-data intrinsics;single-instruction multiple-threads programming model","","","","","","29 May 2020","","","IEEE","IEEE Magazines"
notebooks/data/ieee_1.csv:"GPU implementation of Hertzian Potential Formulation for simulation of nanosensors","D. Tartarini; A. Massaro","Scuola Superiore ISUFI, University of Salento, via Arnesano 16, Lecce 73100, Italy; Center for Bio-Molecular Nanotechnologies (CBN) of IIT, via Barsanti 1, 73010, Arnesano (LE), Italy","2011 Numerical Simulation of Optoelectronic Devices","10 Oct 2011","2011","","","109","110","The time domain modeling and simulation of electromagnetic (EM) waves interaction with nanodevices, at high spatial and time resolution, requires high computational power. In this paper we present an implementation of the Hertzian Potential Formulation (HPF) on the Graphics Processing Units (GPUs) through the NVIDIA's CUDA (Compute Unified Device Architecture)programming model. The results demonstrate that this GPU tool outperforms the CPU based HPF implementation, reaching a speedup from 30× to 70×.","2158-3242","978-1-61284-878-5","10.1109/NUSOD.2011.6041164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041164","GPU Implementation;Nanodevices;Hertzian Potential Formulation","Graphics processing unit;Computational modeling;Time domain analysis;Electromagnetic scattering;Optical waveguides;Nanoscale devices","computer graphics;nanophotonics;nanosensors;optical engineering computing;optical sensors;time-domain analysis","GPU;Hertzian potential formulation;nanosensors;time domain modeling;electromagnetic waves interaction;nanodevices;spatial resolution;time resolution;graphics processing units;compute unified device architecture programming model","","","","14","","10 Oct 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Physis: An implicitly parallel programming model for stencil computations on large-scale GPU-accelerated supercomputers","N. Maruyama; K. Sato; T. Nomura; S. Matsuoka","Tokyo Institute of Technology, JST, CREST 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan; Google, Inc. 6-10-1 Roppongi, Minato-ku, Tokyo, Japan; Tokyo Institute of Technology, JST, CREST & NII, 2-12-1 Ookayama, Meguro-ku, Tokyo, Japan","SC '11: Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis","29 Dec 2011","2011","","","1","12","This paper proposes a compiler-based programming framework that automatically translates user-written structured grid code into scalable parallel implementation code for GPU-equipped clusters. To enable such automatic translations, we design a small set of declarative constructs that allow the user to express stencil computations in a portable and implicitly parallel manner. Our framework translates the user-written code into actual implementation code in CUDA for GPU acceleration and MPI for node-level parallelization with automatic optimizations such as computation and communication overlapping. We demonstrate the feasibility of such automatic translations by implementing several structured grid applications in our framework. Experimental results on the TSUBAME2.0 GPU-based supercomputer show that the performance is comparable as hand-written code and good strong and weak scalability up to 256 GPUs.","2167-4337","978-1-4503-0771-0","10.1145/2063384.2063398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114468","Domain Specific Languages;Application Framework;High Perforamnce Computing","Programming;Computational modeling;DSL;Graphics processing unit;Runtime;Optimization;Indexes","application program interfaces;graphics processing units;grid computing;message passing;parallel architectures;parallel machines;program compilers;program interpreters","Physis;parallel programming model;stencil computations;TSUBAME2.0 GPU-based supercomputer;compiler-based programming framework;user-written structured grid code translation;parallel implementation code;GPU-equipped clusters;CUDA;GPU acceleration;MPI;node-level parallelization;computation overlapping;communication overlapping;structured grid applications","","53","1","30","","29 Dec 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Infiniband-Verbs on GPU: A Case Study of Controlling an Infiniband Network Device from the GPU","L. Oden; H. Fröning; F. Pfreundt","Competence Center High Perfomance Comput., Fraunhofer Inst. for Ind. Math., Kaiserslautern, Germany; Inst. of Comput. Eng., Univ. of Heidelberg, Heidelberg, Germany; Competence Center High Perfomance Comput., Fraunhofer Inst. for Ind. Math., Kaiserslautern, Germany","2014 IEEE International Parallel & Distributed Processing Symposium Workshops","4 Dec 2014","2014","","","976","983","Due to their massive parallelism and high performance per watt GPUs gain high popularity in high performance computing and are a strong candidate for future exacscale systems. But communication and data transfer in GPU accelerated systems remain a challenging problem. Since the GPU normally is not able to control a network device, today a hybrid-programming model is preferred, whereby the GPU is used for calculation and the CPU handles the communication. As a result, communication between distributed GPUs suffers from unnecessary overhead, introduced by switching control flow from GPUs to CPUs and vice versa. In this work, we modify user space libraries and device drivers of GPUs and the Infiniband network device in a way to enable the GPU to control an Infiniband network device to independently source and sink communication requests without any involvements of the CPU. Our performance analysis shows the differences to hybrid communication models in detail, in particular that the CPU's advantage in generating work requests outshines the overhead associated with context switching. In other terms, our results show that complex networking protocols like IBVERBS are better handled by CPUs in spite of time penalties due to context switching, since overhead of work request generation cannot be parallelized and is not suitable with the high parallel programming model of GPUs.","","978-1-4799-4116-2","10.1109/IPDPSW.2014.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969487","GPUs;Communication;Heterogeneous Clusters;Infiniband;RDMA","Graphics processing units;Data transfer;Registers;Performance evaluation;Context;Libraries;Instruction sets","graphics processing units;parallel programming","infiniband-verbs;GPU;infiniband network device;massive parallelism;high performance per watt;high performance computing;exacscale systems;data transfer;hybrid-programming model;IBVERBS;high parallel programming model","","9","2","24","","4 Dec 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Performance Analysis of Benchmarks for GPU-based Linear Programming Problem Solvers","U. A. Shah; S. Yousaf","Department of Computer Science and IT, University of Engineering and Technology, Peshawar, Pakistan; Department of Computer Science and IT, University of Engineering and Technology, Peshawar, Pakistan","2019 2nd International Conference on Communication, Computing and Digital systems (C-CODE)","4 Apr 2019","2019","","","132","136","The single instruction multiple threads (SIMT) architecture of modern graphics processing units (GPUs) shows great potential for efficiently solving compute-intensive linear programming (LP) problems. For benchmarking these GPU-based solutions, speedup is used to measure their relative performance gains with respect to CPU-based implementations. However, a methodological flaw has been observed in benchmarking these GPU-based LP problem solvers, namely, the magnitude of their speedup varies with the choice of CPU-based benchmark. In this paper, we analyze the performance of CPU-based LP problem solvers used to benchmark their GPU-based counterparts. More specifically, we consider benchmarks of two established GPU-based solutions for revised simplex method. The first solution is based on general-purpose computing on GPUs (GPGPU) programming model, and uses a custom-built CPU-based solution as benchmark. The second solution is an OpenGL-based solver, and uses the LP utility in GNU linear programming kit (GLPK) as benchmark. Further, we performed experiments to compare the efficiency of these CPU-based benchmarks with an LP tool present in a commercially available CPU-based software package called CPLEX. Our study reveals that the use of nonstandard benchmarks makes it unfair to quantitatively compare the claims made about speedups achieved by various GPU-based solvers. In order to facilitate decision making process for potential users of GPU-based solutions, we recommend that standard sequential benchmarks be used during any future attempts at developing GPU-based linear optimization tools.","","978-1-5386-9609-5","10.1109/C-CODE.2019.8680981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680981","Graphics processing unit (GPU);General-purpose computing on GPUs (GPGPU);Linear programming (LP);Revised simplex method (RSM)","Benchmark testing;Linear programming;Graphics processing units;Standards;Libraries;Tools;Optimization","decision making;graphics processing units;linear programming;optimisation","compute-intensive linear programming problems;CPU-based implementations;CPU-based benchmark;CPU-based LP problem solvers;GPU-based counterparts;established GPU-based solutions;GPUs programming model;custom-built CPU-based solution;GNU linear programming kit;nonstandard benchmarks;GPU-based solvers;standard sequential benchmarks;GPU-based linear programming problem solvers;single instruction multiple threads architecture;graphics processing units;general-purpose computing;CPU-based software package","","1","","18","","4 Apr 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Accelerating frequency-domain simulations using small shared-memory CPU/GPU cluster","T. Topa; A. Noga; A. Karwowski","Silesian University of Technology, Gliwice, Poland; Silesian University of Technology, Gliwice, Poland; Silesian University of Technology, Gliwice, Poland","2016 21st International Conference on Microwave, Radar and Wireless Communications (MIKON)","16 Jun 2016","2016","","","1","4","Numerical approach to frequency response problems usually requires that the system governing equation is solved repeatedly at many frequencies. The computational efficiency of the overall process can be increased by departing from traditional sequential computing model in favor of utilizing the parallel processing capability commonly offered by modern hardware. In this paper, we consider a hybrid programming pattern, OpenMP + CUDA, from the perspective of a user of a rather typical low-cost multi-core CPU-based workstation that can accommodate up to four GPUs. Such the small-scale heterogeneous platforms have recently gained wide popularity in scientific computing as an inexpensive massively parallel architecture. The relevant programming model issues and performance questions are addressed. Experimental results for the example physics problem, that is, the electromagnetic scattering from perfectly electrically conducting body, show that significant performance improvement can be attained with the OpenMP + CUDA programming model.","","978-1-5090-2214-4","10.1109/MIKON.2016.7492098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492098","GPU;CUDA;milticore CPU;OpenMP;MoM","Graphics processing units;Method of moments;Mathematical model;Kernel;Instruction sets;Computational modeling;Programming","electromagnetic wave scattering;frequency response;frequency-domain analysis;graphics processing units;microprocessor chips;multiprocessing systems;parallel architectures","frequency-domain simulations;graphics processing units;small shared-memory CPU-GPU cluster;frequency response problems;computational efficiency;sequential computing model;parallel processing capability;hybrid programming pattern;multicore CPU-based workstation;electromagnetic scattering;OpenMP + CUDA programming model","","","","11","","16 Jun 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Time-Domain Computational Electromagnetics Algorithms for GPU Based Computers","P. P. M. So","Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada. email: Poman.So@ECE.UVic.CA","EUROCON 2007 - The International Conference on "Computer as a Tool"","26 Dec 2007","2007","","","1","4","Time-domain computational electromagnetic algorithms such as FDTD and TLM require computers with superb processing power and large memory capacity. Grid computing network, cluster computer and massively parallel supercomputers have been the hardware of choices for running powerful modelling tools based on these methods. As a result, high performance modelling tools are only available to elite groups of researchers and big corporations. Stream computing, a new technology that harnesses the tremendous numerical processing power of advanced graphics processing units for general purpose numerical computation, is going to bring high performance time-domain modelling tools to the EM community. This paper reviews the emerging GPU technologies and programming models. Two modelling examples are also used to illustrate the suitability of GPU computing for time-domain electromagnetics.","","978-1-4244-0812-2","10.1109/EURCON.2007.4400480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4400480","CEM;TLM;Time Domain;GPU Computing;Stream Computing","Time domain analysis;Computational electromagnetics;Clustering algorithms;Grid computing;High performance computing;Finite difference methods;Computer networks;Concurrent computing;Supercomputers;Hardware","computational electromagnetics;computer graphic equipment;finite difference time-domain analysis;grid computing;parallel processing","time-domain computational electromagnetics algorithm;GPU based computer;grid computing network;cluster computer;parallel supercomputer;high performance modelling tool;stream computing technology;general purpose numerical computation;graphics processing unit;programming model","","3","","8","","26 Dec 2007","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Scalability of Higher-Order Discontinuous Galerkin FEM Computations for Solving Electromagnetic Wave Propagation Problems on GPU Clusters","N. Gödel; N. Nunn; T. Warburton; M. Clemens","Faculty of Electrical Engineering, Chair for Theory of Electrical Engineering and Computational Electromagnetics, $^{1}$ Helmut-Schmidt-University, University of the Federal Armed Forces Hamburg, Hamburg, Germany; NA; $^{2}$ Computational and Applied Mathematics, Rice University, Houston, TX 77005 , USA; FB E, Chair for Electromagnetic Theory, $^{3}$Bergische Universität Wuppertal, Wuppertal, Germany","IEEE Transactions on Magnetics","19 Jul 2010","2010","46","8","3469","3472","A highly parallel implementation of Maxwell's equations in the time domain using a cluster of Graphics Processing Units (GPUs) is presented. The higher-order Discontinuous Galerkin Finite Element Method (DG-FEM) is used for spatial discretization since its characteristics are matching the parallelization design aspects of the NVIDIA Compute Unified Device Architecture (CUDA) programming model. Asynchronous data transfer is introduced to minimize parallelization overhead and improve parallel efficiency. The implementation is benchmarked with help of a realistic 3-D geometry of an electromagnetic compatibility problem.","1941-0069","","10.1109/TMAG.2010.2046022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5513006","CUDA;discontinuous Galerkin;FEM;GPGPU;GPU-computing;high order","Scalability;Electromagnetic propagation;Maxwell equations;Graphics;Moment methods;Finite element methods;Concurrent computing;Computer architecture;Parallel programming;Geometry","electromagnetic wave propagation;finite element analysis;Galerkin method;Maxwell equations","high-order discontinuous Galerkin FEM computation;electromagnetic wave propagation;GPU clusters;graphics processing units;finite element method;spatial discretization;NVIDIA compute unified device architecture programming model;asynchronous data transfer;realistic 3-D geometry;Maxwell equations","","36","","8","IEEE","19 Jul 2010","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"Improving Utility of GPU in Accelerating Industrial Applications With User-Centered Automatic Code Translation","P. Yang; F. Dong; V. Codreanu; D. Williams; J. B. T. M. Roerdink; B. Liu; A. Anvari-Moghaddam; G. Min","Department of Computer Science, Liverpool John Moores University, Liverpool, U.K.; University of Bedfordshire, Luton, U.K.; SURFsara, Amsterdam, The Netherlands; Faculteit Wiskunde en Natuurwetenschappen, Rijksuniversiteit Groningen, Groningen, The Netherlands; Johann Bernoulli Institute for Mathematics and Computer Science, University of Groningen, Groningen, The Netherlands; Department of Computer Science and Technology, University of Bedfordshire, Luton, U.K.; Department of Energy Technology, Aalborg University, Aalborg, Denmark; Department of Mathematics and Computer Science, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, U.K.","IEEE Transactions on Industrial Informatics","4 Apr 2018","2018","14","4","1347","1360","Small to medium enterprises (SMEs), particularly those whose business is focused on developing innovative produces, are limited by a major bottleneck in the speed of computation in many applications. The recent developments in GPUs have been the marked increase in their versatility in many computational areas. But due to the lack of specialist GPUprogramming skills, the explosion of GPU power has not been fully utilized in general SME applications by inexperienced users. Also, the existing automatic CPU-to-GPU code translators are mainly designed for research purposes with poor user interface design and are hard to use. Little attentions have been paid to the applicability, usability, and learnability of these tools for normal users. In this paper, we present an online automated CPU-to-GPU source translation system (GPSME) for inexperienced users to utilize the GPU capability in accelerating general SME applications. This system designs and implements a directive programming model with a new kernel generation scheme and memory management hierarchy to optimize its performance. A web service interface is designed for inexperienced users to easily and flexibly invoke the automatic resource translator. Our experiments with nonexpert GPU users in four SMEs reflect that a GPSME system can efficiently accelerate real-world applications with at least 4× and have a better applicability, usability, and learnability than the existing automatic CPU-to-GPU source translators.","1941-0050","","10.1109/TII.2017.2731362","European Commission and the Engineering and Physical Sciences Research Council within the iManageCancer(grant numbers:611140); MyHealthAvatar(grant numbers:600929); MyLifeHub(grant numbers:EP/L023830); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990251","Automatic translation;graphics processing unit (GPU);parallel computing;usability","Graphics processing units;Tools;Acceleration;Programming;Usability;C++ languages;Linux","C language;graphics processing units;performance evaluation;service-oriented architecture;small-to-medium enterprises;storage management;user interfaces;Web services","industrial applications;automatic code translation;medium enterprises;SMEs;computational areas;GPU power;general SME applications;inexperienced users;existing automatic CPU-to-GPU code translators;poor user interface design;normal users;CPU-to-GPU source translation system;GPU capability;automatic resource translator;nonexpert GPU users;GPSME system;real-world applications;CPU-to-GPU source translators;specialist GPU programming skills","","","","41","IEEE","24 Jul 2017","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"GPU Accelerated Tensor Computation of Hadamard Product for Machine Learning Applications","K. M. A. Hasan; S. Chakraborty","Khulna University of Engineering & Technology,Computer Science and Engineering Department,Khulna,Bangladesh; Khulna University of Engineering & Technology,Computer Science and Engineering Department,Khulna,Bangladesh","2021 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD)","12 Apr 2021","2021","","","1","5","The computation on Graphics Processing Unit (GPU) has come out as a new cost-effective parallel computing paradigm for high performance computing that makes possible to process large scale data in parallel. GPU is designed to perform complex mathematical and geometric tasks which are primarily used for 3D graphics related functions. It is also possible to use GPU for non-graphics or general-purpose computation, called General Purpose Computing on GPU (GPGPU), a sub-discipline of High-Performance Computing (HPC). The use of GPU, along with CPU to accelerate more complex scientific, engineering and mathematical tasks is known as GPU Accelerated Computing. In this paper, we propose an efficient tensor computation for Hadamard Product (HP) which is directly applied in machine learning applications especially in Long Short-Term Memory (LSTM). The HP computation becomes complex when higher order tensors with millions of data is considered. Therefore, the only CPU-based traditional serial operation becomes tedious and inefficient. The contribution of this paper is in two fold; first we have developed efficient algorithms for higher order tensors by dimension conversion. Then we apply the algorithm in GPU to speed up the computation. To apply in GPU, we develop efficient partitioning scheme of higher order tensors. We have used CUDA (Compute Unified Device Architecture) C programming model developed by NVIDIA to implement the algorithm. We compared these algorithms with Traditional Multidimensional Array (TMA) based algorithm and found improved results.","","978-1-6654-1460-9","10.1109/ICICT4SD50815.2021.9396980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396980","GPU Computing;HPC;Tensor computation;Hadamard Product;CUDA C","Machine learning algorithms;Tensors;Graphics processing units;Machine learning;Partitioning algorithms;Acceleration;Task analysis","C language;graphics processing units;learning (artificial intelligence);mathematics computing;parallel architectures;parallel programming;recurrent neural nets;tensors","higher order tensor partitioning scheme;dimension conversion;LSTM;long short-term memory;HPC;GPGPU;general-purpose computing on GPU;GPU accelerated tensor computation;compute unified device architecture;CUDA C programming model;HP computation;GPU accelerated computing;geometric tasks;complex mathematical tasks;high performance computing;cost-effective parallel computing paradigm;graphics processing unit;machine learning applications;Hadamard Product","","","","17","","12 Apr 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Distributed Interactive Visualization Using GPU-Optimized Spark","S. Hong; J. Choi; W. -K. Jeong","Ulsan National Institute of Science and Technology, Ulsan, South Korea; Ulsan National Institute of Science and Technology, Ulsan, South Korea; Korea University, Seoul, South Korea","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3670","3684","With the advent of advances in imaging and computing technologies, large-scale data acquisition and processing have become commonplace in many science and engineering disciplines. Conventional workflows for large-scale data processing usually rely on in-house or commercial software that are designed for domain-specific computing tasks. Recent advances in MapReduce, which was originally developed for batch processing textual data via a simplified programming model of the map and reduce functions, have expanded its applications to more general tasks in big-data processing, such as scientific computing, and biomedical image processing. However, as shown in previous work, volume rendering and visualization using MapReduce is still considered challenging and impractical owing to the disk-based, batch-processing nature of its computing model. In this article, contrary to this common belief, we show that the MapReduce computing model can be effectively used for interactive visualization. Our proposed system is a novel extension of Spark, one of the most popular open-source MapReduce frameworks, which offers GPU-accelerated MapReduce computing. To minimize CPU-GPU communication and overcome slow, disk-based shuffle performance, the proposed system supports GPU in-memory caching and MPI-based direct communication between compute nodes. To allow for GPU-accelerated in-situ visualization using raster graphics in Spark, we leveraged the CUDA-OpenGL interoperability, resulting in faster processing speeds by several orders of magnitude compared to conventional MapReduce systems. We demonstrate the performance of our system via several volume processing and visualization tasks, such as direct volume rendering, iso-surface extraction, and numerical simulations with in-situ visualization.","1941-0506","","10.1109/TVCG.2020.2990894","National Research Foundation of Korea(grant numbers:NRF-2017R1D1A1A09000841); Ministry of Science and ICT(grant numbers:NRF-2019M3E5D2A01063819,NRF-2014K1A3A1A05034557); Korea Health Industry Development Institute(grant numbers:HI18C0316); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079657","MapReduce;spark;GPU;distributed rendering;in-situ visualization","Data visualization;Sparks;Graphics processing units;Computational modeling;Rendering (computer graphics);Programming;Task analysis","computer graphic equipment;computer graphics;data acquisition;data handling;data visualisation;graphics processing units;medical image processing;message passing;open systems;parallel architectures;parallel processing;public domain software;rendering (computer graphics)","CPU-GPU communication;disk-based shuffle performance;GPU in-memory caching;MPI-based direct communication;compute nodes;GPU-accelerated in-situ visualization;faster processing speeds;conventional MapReduce systems;volume processing;visualization tasks;direct volume rendering;distributed interactive visualization;GPU-optimized Spark;imaging computing technologies;large-scale data acquisition;conventional workflows;large-scale data processing;commercial software;domain-specific computing tasks;batch processing textual data;simplified programming model;general tasks;big-data processing;scientific computing;biomedical image processing;batch-processing nature;MapReduce computing model;popular open-source MapReduce frameworks;GPU-accelerated MapReduce computing","","2","","45","IEEE","27 Apr 2020","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"A GPU-based Fast Solution for Riesz Space Fractional Reaction-Diffusion Equation","Q. Wang; J. Liu; C. Gong; Y. Zhang; Z. Xing","Sci. & Technol. on Parallel & Distrib. Process. Lab., Nat. Univ. of Defense Technol., Changsha, China; Sci. & Technol. on Parallel & Distrib. Process. Lab., Nat. Univ. of Defense Technol., Changsha, China; Sci. & Technol. on Parallel & Distrib. Process. Lab., Nat. Univ. of Defense Technol., Changsha, China; Sci. & Technol. on Parallel & Distrib. Process. Lab., Nat. Univ. of Defense Technol., Changsha, China; Sci. & Technol. on Parallel & Distrib. Process. Lab., Nat. Univ. of Defense Technol., Changsha, China","2015 18th International Conference on Network-Based Information Systems","10 Dec 2015","2015","","","317","323","The fast numerical solutions of Riesz fractional equation have computational cost of O(NMlogM), where M, N are the number of grid points and time steps. In this paper, we present a GPU-based fast solution for Riesz space fractional equation. The GPU-based fast solution, which is based on the fast method using FFT and implemented with CUDA programming model, consists of parallel FFT, vector-vector addition and vector-vector multiplication on GPU. The experimental results show that the GPU-based fast solution compares well with the exact solution. Compared to the known parallel fast solution on 8-core Intel E5-2670 CPU, the overall performance speedup on NVIDIA GTX650 GPU reaches 2.12 times and that on NVIDIA K20C GPU achieves 10.93 times.","","978-1-4799-9942-2","10.1109/NBiS.2015.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350638","Parallel computing;GPU;fractional differential equation;FFT;fast solution","Graphics processing units;Instruction sets;Mathematical model;Arrays;Yttrium;Approximation methods;Parallel processing","differential equations;fast Fourier transforms;graphics processing units;mathematics computing;parallel architectures;reaction-diffusion systems;vectors","GPU-based fast solution;Riesz space fractional reaction-diffusion equation;numerical solutions;Riesz fractional equation;computational cost;CUDA programming model;parallel FFT;vector-vector addition;vector-vector multiplication;NVIDIA GTX650 GPU;NVIDIA K20C GPU;fractional differential equation","","2","","30","","10 Dec 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GCMR: A GPU Cluster-Based MapReduce Framework for Large-Scale Data Processing","Yiru Guo; Weiguo Liu; B. Gong; G. Voss; W. Muller-Wittig","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China; Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China; Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China; Fraunhofer IDM@NTU, Nanyang Technol. Univ., Singapore, Singapore; Fraunhofer IDM@NTU, Nanyang Technol. Univ., Singapore, Singapore","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","12 Jun 2014","2013","","","580","586","MapReduce is a very popular programming model to support parallel and distributed large-scale data processing. There have been a lot of efforts to implement this model on commodity GPU-based systems. However, most of these implementations can only work on a single GPU. And they can not be used to process large-scale datasets. In this paper, we present a new approach to design the MapReduce framework on GPU clusters for handling large-scale data processing. We have used Compute Unified Device Architectures (CUDA) and MPI parallel programming models to implement this framework. To derive an efficient mapping onto GPU clusters, we introduce a two-level parallelization approach: the inter node level and intra node level parallelization. Furthermore in order to improve the overall MapReduce efficiency, a multi-threading scheme is used to overlap the communication and computation on a multi-GPU node. Compared to previous GPU-based MapReduce implementations, our implementation, called GCMR, achieves speedups up to 2.6 on a single node and up to 9.1 on 4 nodes of a Tesla S1060 quad-GPU cluster system for processing small datasets. It also shows very good scalability for processing large-scale datasets on the cluster system.","","978-0-7695-5088-6","10.1109/HPCC.and.EUC.2013.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831970","MapReduce;CUDA;MPI;GPU Cluster","Graphics processing units;Instruction sets;Computational modeling;Computer architecture;Acceleration;Writing;Data processing","application program interfaces;graphics processing units;message passing;parallel programming","GCMR;GPU cluster-based MapReduce framework;distributed large-scale data processing;commodity GPU-based systems;compute unified device architectures;CUDA;MPI parallel programming models;inter node level parallelization;intra node level parallelization;MapReduce efficiency;multithreading scheme;multi-GPU node;GPU-based MapReduce;single node;Tesla S1060 quad-GPU cluster system;large-scale datasets","","2","","15","","12 Jun 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"NVIDIA A100 Tensor Core GPU: Performance and Innovation","J. Choquette; W. Gandhi; O. Giroux; N. Stam; R. Krashinsky","NVIDIA, Singapore; NVIDIA, Singapore; NVIDIA, Singapore; NVIDIA, Singapore; NVIDIA, Singapore","IEEE Micro","29 Mar 2021","2021","41","2","29","35","NVIDIA A100 Tensor Core GPU is NVIDIA's latest flagship GPU. It has been designed with many new innovative features to provide performance and capabilities for HPC, AI, and data analytics workloads. Feature enhancements include a Third-Generation Tensor Core, new asynchronous data movement and programming model, enhanced L2 cache, HBM2 DRAM, and third-generation NVIDIA NVLink I/O.","1937-4143","","10.1109/MM.2021.3061394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361255","GPU;A100;NVLink;Deep Learning;Tensor Core;CUDA;C++20","Graphics processing units;Tensors;Bandwidth;Throughput;Parallel processing;Benchmark testing;Artificial intelligence","cache storage;data analysis;DRAM chips;graphics processing units;multiprocessing systems;parallel architectures;parallel processing;tensors","third-generation NVIDIA NVLink;Third-Generation Tensor Core;innovative features;NVIDIA's latest flagship GPU;NVIDIA A100 Tensor Core GPU","","4","","5","IEEE","23 Feb 2021","","","IEEE","IEEE Magazines"
notebooks/data/ieee_1.csv:"Automatic Parallelization of GPU Applications Using OpenCL","L. D. Solano-Quinde; B. M. Bode; A. K. Somani","Dept. of Electr., Univ. of Cuenca, Cuenca, Ecuador; Nat. Center for Supercomput. Applic., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Electr. & Comput. Eng., Iowa State Univ., Ames, IA, USA","2015 Asia-Pacific Conference on Computer Aided System Engineering","5 Oct 2015","2015","","","276","283","Graphics Processing Units (GPUs) have been successfully used to accelerate scientific applications due to their computation power and the availability of programming languages that make more approachable writing scientific applications for GPUs. However, since the programming model of GPUs requires offloading all the data to the GPU memory, the memory footprint of the application is limited to the size of the GPU memory. Multi-GPU systems can make memory limited problems tractable by parallelizing the computation and data among the available GPUs. Parallelizing applications written for running on single-GPU systems can be done (i) at runtime through an environment that captures the memory operations and kernel calls and distributes among the available GPUs, and (ii) at compile time through a pre-compiler that transforms the application for decomposing the data and computation among the available GPUs. In this paper we propose a framework and implement a tool that transforms an OpenCL application written to run on single-GPU systems into one that runs on multi-GPU systems. Based on data dependencies and data usage analysis, the application is transformed to decompose data and computation among the available GPUs. To reduce the data transfer overhead, computation-communication overlapping techniques are utilized. We tested our tool using two applications with different data transfer requirements, for the application with no data transfer requirements, a linear speedup is achieved, while for the application with data transfers, the computation-communication overlapping reduces the communication overhead by 40%.","","978-1-4799-7588-4","10.1109/APCASE.2015.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7287032","GPU;OpenCL;Program Transformation","Kernel;Arrays;Graphics processing units;Data transfer;Algorithms;XML;Memory management","graphics processing units;parallel processing","automatic parallelization;GPU applications;OpenCL;graphics processing units;scientific applications;computation power;programming languages;programming model;data offloading;GPU memory;memory footprint;multiGPU systems;parallelizing applications;single-GPU systems;memory operations;kernel calls;precompiler;data decomposition;data dependencies;data usage analysis;data transfer overhead;computation-communication overlapping techniques;data transfer requirements;linear speedup;communication overhead","","1","","10","","5 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"An OpenMP-CUDA Implementation of Multilevel Fast Multipole Algorithm for Electromagnetic Simulation on Multi-GPU Computing Systems","J. Guan; S. Yan; J. Jin","Center for Computational Electromagnetics, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Center for Computational Electromagnetics, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Center for Computational Electromagnetics, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA","IEEE Transactions on Antennas and Propagation","2 Jul 2013","2013","61","7","3607","3616","A multi-GPU implementation of the multilevel fast multipole algorithm (MLFMA) based on the hybrid OpenMPCUDA parallel programming model (OpenMP-CUDA-MLFMA) is presented for computing electromagnetic scattering of a three-dimensional conducting object. The proposed hierarchical parallelization strategy ensures a high computational throughput for the GPU calculation. The resulting OpenMP-based multi-GPU implementation is capable of solving real-life problems with over one million unknowns with a remarkable speed-up. The radar cross sections of a few benchmark objects are calculated to demonstrate the accuracy of the solution. The results are compared with those from the CPU-based MLFMA and measurements. The capability and efficiency of the presented method are analyzed through the examples of a sphere, an aerocraft, and a missile-like object. Compared with the 8-threaded CPU-based MLFMA, the OpenMP-CUDA-MLFMA method can achieve from 5 to 20 total speed-up ratios.","1558-2221","","10.1109/TAP.2013.2258882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6504730","CUDA;electromagnetic scattering;hybrid parallel programming model;multi-GPU;multilevel fast multipole algorithm;OpenMP;radar cross section","Graphics processing units;Instruction sets;Method of moments;Computer architecture;Antenna radiation patterns;Computational modeling","computational electromagnetics;electromagnetic wave scattering;graphics processing units;parallel architectures","multilevel fast multipole algorithm;electromagnetic simulation;multi-GPU computing systems;OpenMP-CUDA parallel programming model;electromagnetic scattering;three-dimensional conducting object;radar cross sections;aerocraft;missile-like object","","49","","27","","18 Apr 2013","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"Enhancing Blowfish file encryption algorithm through parallel computing on GPU","T. Mahajan; S. Masih","Devi Ahilya University, Indore, India; Devi Ahilya University, Indore, India","2015 International Conference on Computer, Communication and Control (IC4)","11 Jan 2016","2015","","","1","4","Parallel computing can provide fast execution of the program as compared to sequential computing. Graphical Processing Unit can be used for parallel computing as it gives the advantage of multiple cores. Purpose of parallel implementation of Blowfish cryptography algorithm is to improve the speed up of encryption and decryption so that large files also can be communicated on the network in secure and efficient way. This paper demonstrates the way of implementing Blowfish cryptography algorithm on GPU for improving performance. This implementation uses GPGPU and CUDA. CUDA is used as a programming model for implementing on the GPU. The experiment shows multifold difference in performance of CPU and GPU in encryption-decryption of large files.","","978-1-4799-8164-9","10.1109/IC4.2015.7375604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375604","GPU-Graphical Processing Unit;CPU-Central Processing Unit;CUDA-Computer Unified Device Architecture;GPGPU-General Purpose computation on Graphical Processing Unit","Graphics processing units;Encryption;Programming;Algorithm design and analysis;Conferences","cryptography;graphics processing units;parallel architectures;parallel programming","Blowfish file encryption algorithm;parallel computing;program execution;sequential computing;graphical processing unit;parallel implementation;Blowfish cryptography algorithm;GPGPU;CUDA;programming model;large file encryption-decryption;computer unified device architecture;general purpose computation on graphical processing unit","","2","","10","","11 Jan 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"HPGA: A High-Performance Graph Analytics Framework on the GPU","H. Yang; H. Su; M. Wen; C. Zhang","Department of Computer, National University of Defense Technology, Changsha, 410000, China; Department of Computer, National University of Defense Technology, Changsha, 410000, China; Department of Computer, National University of Defense Technology, Changsha, 410000, China; Department of Computer, National University of Defense Technology, Changsha, 410000, China","2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)","14 Mar 2019","2018","","","488","492","In recent years, the rapidly growing use of graphs has sparked parallel graph analytics frameworks for leveraging the massive hardware resources, specifically graphics processing units (GPUs). However, the issues of the unpredictable control flows, memory divergence, and the complexity of programming have restricted high-level GPU graph libraries. In this work, we present HPGA, a high performance parallel graph analytics framework targeting the GPU. HPGA implements an abstraction which maps vertex programs to generalized sparse matrix operations on GPUs for delivering high performance. HPGA incorporates high-performance GPU computing primitives and optimization strategies with a high-level programming model. We evaluate the performance of HPGA for three graph primitives (BFS, SSSP, PageRank) with large-scale datasets. The experimental results show that HPGA matches or even exceeds the performance of MapGraph and nvGRAPH, two state-of-the-art GPU graph libraries.","","978-1-5386-5738-6","10.1109/ICISCAE.2018.8666877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666877","Graph Analytics;High-performance Computing;GPU","Graphics processing units;Sparse matrices;Programming;Computational modeling;Arrays;Optimization","graph theory;graphics processing units;sparse matrices","HPGA;high-performance graph analytics framework;parallel graph analytics frameworks;massive hardware resources;high-level GPU graph libraries;high performance;generalized sparse matrix operations;high-performance GPU;high-level programming model;GPU graph libraries;vertex programs","","","","20","","14 Mar 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Compiling and Optimizing Java 8 Programs for GPU Execution","K. Ishizaki; A. Hayashi; G. Koblents; V. Sarkar","IBM Res., Tokyo, Japan; NA; IBM Canada, Canada; NA","2015 International Conference on Parallel Architecture and Compilation (PACT)","10 Mar 2016","2015","","","419","431","GPUs can enable significant performance improvements for certain classes of data parallel applications and are widely used in recent computer systems. However, GPU execution currently requires explicit low-level operations such as 1) managing memory allocations and transfers between the host system and the GPU, 2) writing GPU kernels in a low-level programming model such as CUDA or OpenCL, and 3) optimizing the kernels by utilizing appropriate memory types on the GPU. Because of this complexity, in many cases, only expert programmers can exploit the computational capabilities of GPUs through the CUDA/OpenCL languages. This is unfortunate since a large number of programmers use high-level languages, such as Java, due to their advantages of productivity, safety, and platform portability, but would still like to exploit the performance benefits of GPUs. Thus, one challenging problem is how to utilize GPUs while allowing programmers to continue to benefit from the productivity advantages of languages like Java. This paper presents a just-in-time (JIT) compiler that can generate and optimize GPU code from a pure Java program written using lambda expressions with the new parallel streams APIs in Java 8. These APIs allow Java programmers to express data parallelism at a higher level than threads and tasks. Our approach translates lambda expressions with parallel streams APIs in Java 8 into GPU code and automatically generates runtime calls that handle the low-level operations mentioned above. Additionally, our optimization techniques 1) allocate and align the starting address of the Java array body in the GPUs with the memory transaction boundary to increase memory bandwidth, 2) utilize read-only cache for array accesses to increase memory efficiency in GPUs, and 3) eliminate redundant data transfer between the host and the GPU. The compiler also performs loop versioning for eliminating redundant exception checks and for supporting virtual method invocations within GPU kernels. These features and optimizations are supported and automatically performed by a JIT compiler that is built on top of a production version of the IBM Java 8 runtime environment. Our experimental results on an NVIDIA Tesla GPU show significant performance improvements over sequential execution (127.9 × geometric mean) and parallel execution (3.3 × geometric mean) for eight Java 8 benchmark programs running on a 160-thread POWER8 machine. This paper also includes an in-depth analysis of GPU execution to show the impact of our optimization techniques by selectively disabling each optimization. Our experimental results show a geometric-mean speed-up of 1.15 × in the GPU kernel over state-of-the-art approaches. Overall, our JIT compiler can improve the performance of Java 8 programs by automatically leveraging the computational capability of GPUs.","1089-795X","978-1-4673-9524-3","10.1109/PACT.2015.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429325","JIT compiler;GPU;Java 8;Parallel streams","Graphics processing units;Java;Optimization;Kernel;Arrays;Semantics","application program interfaces;cache storage;configuration management;graphics processing units;Java;parallel processing;program compilers","Java 8 programs;GPU execution;data parallel applications;CUDA/OpenCL languages;Java language;just-in-time compiler;JIT compiler;GPU code optimization;lambda expressions;parallel streams API;data parallelism;memory transaction boundary;memory bandwidth;read-only cache;memory efficiency;loop versioning;virtual method invocations;GPU kernels;IBM Java 8 runtime environment;NVIDIA Tesla GPU;thread POWER8 machine;graphics processing unit","","24","3","37","","10 Mar 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"OO-VR: NUMA Friendly Object-Oriented VR Rendering Framework For Future NUMA-Based Multi-GPU Systems","C. Xie; F. Xin; M. Chen; S. L. Song","Pacific Northwest National Lab (PNNL), University of Houston; ECMOS Lab, University of Houston,ECE Department; School of Computer Science and Software Engineering, East China Normal University; Pacific Northwest National Lab (PNNL), University of Houston","2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)","6 Feb 2020","2019","","","53","65","With the strong computation capability, NUMA-based multi-GPU system is a promising candidate to provide sustainable and scalable performance for Virtual Reality (VR) applications and deliver the excellent user experience. However, the entire multi-GPU system is viewed as a single GPU under the single programming model which greatly ignores the data locality among VR rendering tasks during the workload distribution, leading to tremendous remote memory accesses among GPU models (GPMs). The limited inter- GPM link bandwidth (e.g., 64GB/s for NVlink) becomes the major obstacle when executing VR applications in the multi-GPU system. By conducting comprehensive characterizations on different kinds of parallel rendering frameworks, we observe that distributing the rendering object along with its required data per GPM can reduce the inter-GPM memory accesses. However, this object-level rendering still faces two major challenges in NUMA-based multi- GPU system: (1) the large data locality between the left and right views of the same object and the data sharing among different objects and (2) the unbalanced workloads induced by the software- level distribution and composition mechanisms. To tackle these challenges, we propose object-oriented VR rendering framework (OO-VR) that conducts the software and hardware co-optimization to provide a NUMA friendly solution for VR multi-view rendering in NUMA-based multi-GPU systems. We first propose an object-oriented VR programming model to exploit the data sharing between two views of the same object and group objects into batches based on their texture sharing levels. Then, we design an object aware runtime batch distribution engine and distributed hardware composition unit to achieve the balanced workloads among GPMs and further improve the performance of VR rendering. Finally, evaluations on our VR featured simulator show that OO-VR provides 1.58x overall performance improvement and 76% inter-GPM memory traffic reduction over the state-of- the-art multi-GPU systems. In addition, OO-VR provides NUMA friendly performance scalability for the future larger multi-GPU scenarios with ever increasing asymmetric bandwidth between local and remote memory.","2575-713X","978-1-4503-6669-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8980302","","","graphics processing units;multiprocessing systems;object-oriented programming;parallel processing;rendering (computer graphics);virtual reality","VR multiview rendering;NUMA-based multiGPU system;object-oriented VR programming model;data sharing;object aware runtime batch distribution engine;NUMA friendly performance scalability;NUMA friendly object-oriented VR rendering framework;virtual reality applications;single GPU;single programming model;data locality;VR rendering tasks;GPU models;VR applications;parallel rendering frameworks;inter-GPM memory accesses;object-level rendering;composition mechanisms;software-level distribution;inter-GPM link bandwidth;inter-GPM memory traffic reduction;OO-VR framework","","","","44","","6 Feb 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Efficient implementation of apriori algorithm on HDFS using GPU","M. Tiwary; A. K. Sahoo; R. Misra","Department of Information Technology, C.V. Raman College of Engineering, Bhubaneswar, India; Department of Information Technology, C.V. Raman College of Engineering, Bhubaneswar, India; Department of Information Technology, C.V. Raman College of Engineering, Bhubaneswar, India","2014 International Conference on High Performance Computing and Applications (ICHPCA)","19 Feb 2015","2014","","","1","7","A very efficient distributed processing framework is provided by Hadoop. For processing big data, Hadoop uses map-reduce programming model. The proposed technique uses parallel apriori mapreduce algorithm using high performance GPU. The computationally intensive operations of mapping phase are offloaded to GPU. Apriori is a very basic data mining algorithm which is used to determine the frequent item sets in the transactional database. In Hadoop, big transactional database are stored in structured form. When the size of transactional database is big, very fast apriori technique is required to solve the problem. Past researches show a clear view of solving data mining operations in heterogeneous environment which increase the performance with a very high rate than older serial execution techniques. This paper introduces integration of GPU in mapreduce programming model to solve the apriori data mining technique in a very time efficient manner. For our experimental implementation, we use NVIDIA's GPU and for the integration process, we use JCUDA and JNI.","","978-1-4799-5958-7","10.1109/ICHPCA.2014.7045323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045323","Hadoop;Map-reduce;CUDA;GPU;Apriori","Graphics processing units;Acceleration;Computer architecture;Databases;Integrated circuits;Kernel","Big Data;data integration;data mining;graphics processing units;parallel architectures;parallel programming;transaction processing","distributed processing framework;Hadoop;big data processing;Mapreduce programming model;parallel apriori Mapreduce algorithm;high performance GPU;mapping phase;data mining algorithm;big transactional database;data mining operations;heterogeneous environment;apriori data mining technique;NVIDIA's GPU;JCUDA;JNI","","7","","10","","19 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Accelerating FDTD algorithm using GPU computing","Z. Bo; X. Zheng-hui; R. Wu; L. Wei-ming; S. Xin-qing","School of Information and Electronics, Beijing Institute of Technology, Beijing 100081, China; School of Information and Electronics, Beijing Institute of Technology, Beijing 100081, China; School of Information and Electronics, Beijing Institute of Technology, Beijing 100081, China; School of Information and Electronics, Beijing Institute of Technology, Beijing 100081, China; School of Information and Electronics, Beijing Institute of Technology, Beijing 100081, China","2011 IEEE International Conference on Microwave Technology & Computational Electromagnetics","23 Jun 2011","2011","","","410","413","Hardware acceleration of Finite-Difference Time-Domain (FDTD) algorithm has always been an important part of FDTD research. In this essay, we discussed the advantage and feasibility of accelerate FDTD algorithm using Graphics Processing Unit (GPU). With the implement of lattice-threads mapping and other techniques, we proposed a GPU FDTD programming model that is both efficient and accurate. Then we simulated two projects using proposed model, the result shows good agreement with CPU computing while simulation speedup is 20 at minimum, thus proves the efficiency and great potential of GPU accelerating in FDTD research.","","978-1-4244-8559-8","10.1109/ICMTCE.2011.5915546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5915546","FDTD;GPU;Hardware Accelerating","Graphics processing unit;Finite difference methods;Time domain analysis;Acceleration;Instruction sets;Lattices;Computer architecture","coprocessors;finite difference time-domain analysis;mathematics computing","GPU computing;hardware acceleration;finite-difference time-domain algorithm;lattice-threads mapping;FDTD research;FDTD algorithm","","9","","5","","23 Jun 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU based parallel matrix exponential algorithm for large scale power system electromagnetic transient simulation","J. Zhao; J. Liu; P. Li; X. Fu; G. Song; C. Wang","Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China","2016 IEEE Innovative Smart Grid Technologies - Asia (ISGT-Asia)","26 Dec 2016","2016","","","110","114","In order to meet the demand of fast electromagnetic transient simulation for large-scale interconnected power systems, a new method of GPU based parallel matrix exponential algorithm for power system electromagnetic transient simulation is presented in this paper. Firstly, the hardware structure and programming model of GPU are introduced. Then the high data parallelism based on matrix exponential integration algorithm is proposed. Then, a simulation test is carried out for a wind farm system including 17 WTGs. The accuracy and efficiency of the proposed method are verified. The results show that the speed of parallel computing based on GPU is about 2 times faster than that of CPU and Matlab/SimPowerSystems.","2378-8542","978-1-5090-4303-3","10.1109/ISGT-Asia.2016.7796370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796370","matrix exponential;electromagnetic transient simulation;GPU;parallel computation","Graphics processing units;Computational modeling;Parallel processing;Mathematical model;Algorithm design and analysis;Sparse matrices;Power systems","graphics processing units;power engineering computing;power system interconnection;power system simulation;wind power plants","GPU-based parallel matrix exponential integration algorithm;large-scale interconnected power system electromagnetic transient simulation;GPU hardware structure;GPU programming model;data parallelism;wind farm system;WTG;parallel computing;Matlab-SimPower system","","3","","14","","26 Dec 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU Peer-to-Peer Techniques Applied to a Cluster Interconnect","R. Ammendola; M. Bernaschi; A. Biagioni; M. Bisson; M. Fatica; O. Frezza; F. Lo Cicero; A. Lonardo; E. Mastrostefano; P. S. Paolucci; D. Rossetti; F. Simula; L. Tosoratto; P. Vicini","Sezione Roma Tor Vergata, Ist. Naz. di Fis. Nucleare, Rome, Italy; Ist. Applicazioni Calcolo, Consiglio Naz. delle Ric., Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Ist. Applicazioni Calcolo, Consiglio Naz. delle Ric., Rome, Italy; NVIDIA Corp., CA, USA; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Dept. of Comput. Sci., Sapienza Univ., Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy; Sezione Roma, Ist. Naz. di Fis. Nucleare, Rome, Italy","2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum","31 Oct 2013","2013","","","806","815","Modern GPUs support special protocols to exchange data directly across the PCI Express bus. While these protocols could be used to reduce GPU data transmission times, basically by avoiding staging to host memory, they require specific hardware features which are not available on current generation network adapters. In this paper we describe the architectural modifications required to implement peer-to-peer access to NVIDIA Fermi- and Kepler-class GPUs on an FPGA-based cluster interconnect. Besides, the current software implementation, which integrates this feature by minimally extending the RDMA programming model, is discussed, as well as some issues raised while employing it in a higher level API like MPI. Finally, the current limits of the technique are studied by analyzing the performance improvements on low-level benchmarks and on two GPU-accelerated applications, showing when and how they seem to benefit from the GPU peer-to-peer method.","","978-0-7695-4979-8","10.1109/IPDPSW.2013.128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6650959","peer-to-peer;GPU;interconnection network;parallel computing","Graphics processing units;Peer-to-peer computing;Bandwidth;Protocols;Hardware;Benchmark testing;Switches","field programmable gate arrays;graphics processing units;peer-to-peer computing;peripheral interfaces","RDMA programming model;FPGA based cluster interconnect;NVIDIA Fermi- and Kepler class GPU;peer-to-peer access;architectural modifications;hardware features;host memory;GPU data transmission times;PCI express bus;exchange data;GPUs support;GPU peer-to-peer techniques","","24","","17","","31 Oct 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Performance Portability of Molecular Docking Miniapp On Leadership Computing Platforms","M. Thavappiragasam; A. Scheinberg; W. Elwasif; O. Hernandez; A. Sedova","Oak Ridge National Laboratory,Oak Ridge,Tennessee; Jubilee Development,Cambridge,Massachusetts; Oak Ridge National Laboratory,Oak Ridge,Tennessee; Oak Ridge National Laboratory,Oak Ridge,Tennessee; Oak Ridge National Laboratory,Oak Ridge,Tennessee","2020 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","1 Jan 2021","2020","","","36","44","Rapidly changing computer architectures, such as those found at high-performance computing (HPC) facilities, present the need for mini-applications (miniapps) that capture essential algorithms used in large applications to test program performance and portability, aiding transitions to new systems. The COVID-19 pandemic has fueled a flurry of activity in computational drug discovery, including the use of supercomputers and GPU acceleration for massive virtual screens for therapeutics. Recent work targeting COVID-19 at the Oak Ridge Leadership Computing Facility (OLCF) used the GPU-accelerated program AutoDock-GPU to screen billions of compounds on the Summit supercomputer. In this paper we present the development of a new miniapp, miniAutoDock-GPU, that can be used to evaluate the performance and portability of GPU-accelerated protein-ligand docking programs on different computer architectures. These tests are especially relevant as facilities transition from petascale systems and prepare for upcoming exascale systems that will use a variety of GPU vendors. The key calculations, namely, the Lamarckian genetic algorithm combined with a local search using a Solis-Wets based random optimization algorithm, are implemented. We developed versions of the miniapp using several different programming models for GPU acceleration, including a version using the CUDA runtime API for NVIDIA GPUs, and the Kokkos middle-ware API which is facilitated by C++ template libraries. A third version, currently in progress, uses the HIP programming model. These efforts will help facilitate the transition to exascale systems for this important emerging HPC application, as well as its use on a wide range of heterogeneous platforms.","","978-1-6654-2287-1","10.1109/P3HPC51967.2020.00009","Battelle; U.S. Department of Energy; Office of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309044","heterogeneous system;high-performance computing;performance portability;hybrid parallel programming model;molecular docking;drug discovery","Graphics processing units;Proteins;Optimization;Programming;Leadership;Hip;COVID-19","application program interfaces;biology computing;coprocessors;drugs;genetic algorithms;graphics processing units;mainframes;molecular biophysics;parallel architectures;parallel machines;parallel processing;proteins","molecular docking miniapp;Leadership Computing platforms;high-performance computing facilities;COVID-19 pandemic;computational drug discovery;supercomputers;GPU acceleration;Oak Ridge Leadership Computing Facility;GPU-accelerated program AutoDock-GPU;Summit supercomputer;miniAutoDock-GPU;GPU-accelerated protein-ligand docking programs;computer architectures;petascale systems;exascale systems;GPU vendors;Lamarckian genetic algorithm;random optimization algorithm;HIP programming model;HPC application;NVIDIA GPU;Kokkos middleware API","","1","","14","","1 Jan 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A Formal Instruction-level GPU Model for Scalable Verification","Y. Xing; B. Huang; A. Gupta; S. Malik",Princeton University; Princeton University; Princeton University; Princeton University,"2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","3 Jan 2019","2018","","","1","8","GPUs have been widely used to accelerate big-data inference applications and scientific computing through their parallelized hardware resources and programming model. Their extreme parallelism increases the possibility of bugs such as data races and un-coalesced memory accesses, and thus verifying program correctness is critical. State-of-the-art GPU program verification efforts mainly focus on analyzing application-level programs, e.g., in C, and suffer from the following limitations: (1) high false-positive rate due to coarse-grained abstraction of synchronization primitives, (2) high complexity of reasoning about pointer arithmetic, and (3) keeping up with an evolving API for developing application-level programs. In this paper, we address these limitations by modeling GPUs and reasoning about programs at the instruction level. We formally model the Nvidia GPU at the parallel execution thread (PTX) level using the recently proposed Instruction-Level Abstraction (ILA) model for accelerators. PTX is analogous to the Instruction-Set Architecture (ISA) of a general-purpose processor. Our formal ILA model of the GPU includes non-synchronization instructions as well as all synchronization primitives, enabling us to verify multithreaded programs. We demonstrate the applicability of our ILA model in scalable GPU program verification of data-race checking. The evaluation shows that our checker outperforms state-of-the-art GPU data race checkers with fewer false-positives and improved scalability.","1558-2434","978-1-4503-5950-4","10.1145/3240765.3240771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8587727","","Graphics processing units;Instruction sets;Synchronization;Computational modeling;Registers;Programming;Hardware","application program interfaces;graphics processing units;instruction sets;multiprocessing systems;multi-threading;program diagnostics;program verification;reasoning about programs","formal Instruction-level GPU model;scalable verification;big-data inference applications;parallelized hardware resources;programming model;data races;program correctness;application-level programs;coarse-grained abstraction;synchronization primitives;Nvidia GPU;parallel execution thread level;formal ILA model;nonsynchronization instructions;multithreaded programs;scalable GPU program verification;data-race checking;instruction-set architecture;GPU data race checkers;instruction-level abstraction model;GPU program verification efforts","","","","20","","3 Jan 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Unified Execution Mode in a GPU-Style Softcore","P. Thontirawong; P. Chongstitvatana","Dept. of Comput. Eng., Chulalongkorn Univ., Bangkok, Thailand; Dept. of Comput. Eng., Chulalongkorn Univ., Bangkok, Thailand","2013 International Conference on Information Science and Applications (ICISA)","15 Aug 2013","2013","","","1","4","A GPU-style processor has large amount of processing power on a given die compared to a general purpose processor. However, a Graphic Processing Unit must be executed in lock-step where a group of cores execute the same instruction. This constraint puts a real limitation on programming of a GPU. This work proposed a design of a processor that unifies the execution of Graphic Processing Units and a general purpose processor. The discussion of programming model of vectorised instructions and the extension to allow multi-cores to run independently is presented. The proposed design required only 3% additional resource compared to the original design. This design is suitable for embedded applications.","2162-9048","978-1-4799-0604-8","10.1109/ICISA.2013.6579365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579365","","Graphics processing units;Multicore processing;Registers;Logic gates;Programming;Benchmark testing;Process control","embedded systems;graphics processing units;multiprocessing systems;parallel processing;resource allocation","GPU-style softcore;GPU-style processor;processing power;graphic processing unit;lock-step;general purpose processor;programming model;vectorised instructions;multicores;unified execution mode;embedded applications","","","","7","","15 Aug 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Parallel Computing Accelerated Image Inpainting using GPU CUDA, Theano, and Tensorflow","H. T. R. Adie; I. A. Pradana; Pranowo","Department of Informatic Engineering, Universitas Atma Jaya Yogyakarta, Yogyakarta, Indonesia; Department of Informatic Engineering, Universitas Atma Jaya Yogyakarta, Yogyakarta, Indonesia; Department of Informatic Engineering, Universitas Atma Jaya Yogyakarta, Yogyakarta, Indonesia","2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE)","15 Nov 2018","2018","","","621","625","Image inpainting refers to image restoration process that reconstruct damaged image to obtain it lost information based on existing information. PDE-based approach is commonly used for image interpolation especially inpainting. Since PDE process express convolution and continuous change, the approach may take a lot of computational resources and will run slow on standard computer CPU. To overcome that, GPU parallel computing method for PDE-based image inpainting are proposed. These days, some handy platform or frameworks to utilize GPU are already exist like CUDA, Theano and Tensorflow. CUDA is well-known as parallel computing platform and programming model to work with programming language such as C/C++. In other hand Theano and Tensorflow is a bit different thing, both of them is a machine learning framework based on Python that also able to utilize GPU. Although Theano and Tensorflow are specialized for machine learning and deep learning, the system is general enough to applied for computational process like image inpainting. The results of this work show benchmark performance of PDE image inpainting running on CPU using C++, Theano, and Tensorflow and on GPU with CUDA, Theano, and Tensorflow. The benchmark shows that parallel computing accelerated PDE image inpainting can run faster on GPU either with CUDA, Theano, or Tensorflow compared to PDE image inpainting running on CPU.","","978-1-5386-4739-4","10.1109/ICITEED.2018.8534858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8534858","Image Inpainting;PDE;Parallel Computing;GPU;CUDA;Theano;Tensorflow","Graphics processing units;Parallel processing;Mathematical model;Handheld computers;Convolution;Heating systems;Acceleration","computer graphics;graphics processing units;image restoration;interpolation;learning (artificial intelligence);parallel architectures;partial differential equations;Python","parallel computing accelerated image inpainting;GPU CUDA;Theano;Tensorflow;image restoration process;image interpolation;GPU parallel computing method;PDE-based image inpainting;parallel computing platform;programming model;computer CPU;handy platform;machine learning framework;Python;deep learning;C++","","3","","13","","15 Nov 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Efficient data classification by GPU-accelerated linear mean squared slack minimization","G. A. Papakostas; K. I. Diamantaras","EMaTTech, Dept. Computer and Informatics Engineering, Kavala 65404, Greece; TEI of Thessaloniki, Dept. Information Technology, Sindos 57400, Greece","2014 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)","20 Nov 2014","2014","","","1","6","An efficient parallel implementation of the recently proposed Slackmin classification algorithm that minimizes the mean squared slack variables energy is proposed in this paper. The efficacy of the resulted scheme is demonstrated both in terms of accuracy and computation speed. The parallelization of the Slackmin algorithm is achieved in the framework of GPU programming. Based on this framework the “cuLSlackmin” algorithm for linear problems was implemented, by using the CUDA C/C++ programming model and proposed herein. The introduced parallel algorithm is making use of the advantages imposed by the GPU architecture and achieves high classification rates in a short computation time. A set of experiments with some UCI datasets have shown the high performance of the cuLSlackmin algorithm compared to the Slackmin, LIBSVM and GPULIBSVM algorithms. The high performance of cuLSlackmin algorithm makes it appropriate for big data classification problems.","2378-928X","978-1-4799-3694-6","10.1109/MLSP.2014.6958885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6958885","big data classification;machine learning;GPU programming;CUDA;slack minimization","Graphics processing units;Classification algorithms;Big data;Accuracy;Training;Machine learning algorithms;Instruction sets","Big Data;C++ language;graphics processing units;parallel algorithms;parallel architectures;pattern classification","GPU-accelerated linear mean squared slack minimization;parallel implementation;Slackmin classification algorithm;mean squared slack variables energy minimization;computation speed;Slackmin algorithm parallelization;GPU programming;cuLSlackmin algorithm;linear problem;CUDA C/C++ programming model;parallel algorithm;GPU architecture;classification rate;computation time;UCI dataset;GPULIBSVM algorithm;big data classification problem","","1","","22","","20 Nov 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GGAKE: GPU Based Genome Assembly Using K-Mer Extension","A. Garg; A. Jain; K. Paul","Dept. of Comput. Sci. & Eng., IIT Delhi, New Delhi, India; Dept. of Comput. Sci. & Eng., IIT Delhi, New Delhi, India; Dept. of Comput. Sci. & Eng., IIT Delhi, New Delhi, India","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","12 Jun 2014","2013","","","1105","1112","The genome assembly problem involves constructing the complete genome sequence from the reads generated by the sequencers. The Next Generation Sequencing (NGS) platforms produce a large number of short reads at a very low cost. Many assemblers have been developed to work with NGS reads. The assembly process is computation intensive and also requires a large amount of memory to store the reads. Numerous efforts are being made in recent times to parallelize the assembly process in order to reduce computation time. In this paper we present the design and development of a GPU based genome assembler (GGAKE). Our assembler works using the concept of k-mer extension. Prefix and suffix k-mers are spotted out of every read. Suffix k-mers are matched with prefix k-mers and extensions for every read are noted. Contigs are generated by extending the reads. We have implemented GGAKE on Nvidia's GPU using the CUDA programming model and benchmarked it on five bacterial genomes. Our results prove that at high coverage GGAKE is capable of producing good quality assembly in a small amount of time.","","978-0-7695-5088-6","10.1109/HPCC.and.EUC.2013.156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832038","parallel processing;bioinformatics;GPU;genome assembly","Graphics processing units;DNA;Bioinformatics;Assembly;Genomics;Encoding;Sorting","biology computing;cellular biophysics;genomics;graphics processing units;microorganisms;parallel architectures;parallel programming","GGAKE;GPU based genome assembly;genome sequence;next generation sequencing platforms;NGS reads;assembly process parallelization;GPU based genome assembler;k-mer extension;Nvidia's GPU;CUDA programming model;bacterial genomes;contig generation","","3","","21","","12 Jun 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Shared Memory and GPU Parallelization of an Operational Atmospheric Transport and Dispersion Application","F. Yu; P. Strazdins; J. Henrichs; T. Pugh",The Australian National University; The Australian National University; Bureau of Meteorology; Bureau of Meteorology,"2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","29 Jul 2019","2019","","","729","738","The HYSPLIT air concentration model is an operational Lagrangian trajectory and dispersion model that calculates the concentration or the distribution of pollutants by releasing and tracking particles or puffs. It is widely used for tracking and forecasting the release of pollutants such as radioactive material, dust storms and volcanic ash. Due to the massively parallel nature of the particle tracking system, the HYSPLIT model shows potential to be accelerated by multiple CPUs and GPUs. However, porting such a legacy application to a GPU requires non-trivial work to isolate the parallel code regions and correctly adapt the code to a parallel programming model. This paper presents methods to port the current HYSPLIT code to the shared-memory OpenMP and the CUDA programming models. In the OpenMP approach, the original HYSPLIT concentration model is analyzed, profiled and refactored to remove barriers for parallelizing on multi-core CPUs. A linear speed-up with some serial overhead is achieved for the OpenMP version. In the CUDA approach, we utilize the computing power of NVIDIA GTX960 and Tesla P100 GPUs, providing 4-5× faster overall performance than the original. With the help of GPU coarse-grained parallelism, a maximum 12.9× speedup has been measured, compared to the original program running on a CPU. The disturbance of different parallelization approaches to the original code base shows that most of the highly difficult work is in the refactoring, and that CUDA requires extensive, but mostly relatively shallow, changes.","","978-1-7281-3510-6","10.1109/IPDPSW.2019.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778420","Lagrangian trajectory and dispersion model, HYSPLIT, GPU acceleration, CUDA Fortran, OpenMP, MPI, CUDA coarse grained parallelism, High performance computing","Atmospheric modeling;Graphics processing units;Computational modeling;Dispersion;Mathematical model;Meteorology;Parallel processing","computer graphic equipment;graphics processing units;message passing;parallel algorithms;parallel architectures;parallel processing;parallel programming;shared memory systems","shared memory;GPU parallelization;operational atmospheric transport;dispersion application;HYSPLIT air concentration model;dispersion model;tracking particles;puffs;radioactive material;dust storms;volcanic ash;massively parallel nature;particle tracking system;HYSPLIT model;multiple CPUs;legacy application;nontrivial work;parallel code regions;parallel programming model;current HYSPLIT code;shared-memory OpenMP;CUDA programming models;OpenMP approach;original HYSPLIT concentration model;OpenMP version;CUDA approach;GPU coarse-grained parallelism;original program;multicore CPU;parallelization approaches;Tesla P100 GPU;original code base;NVIDIA GTX960","","","","14","","29 Jul 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Architecting Waferscale Processors - A GPU Case Study","S. Pal; D. Petrisko; M. Tomei; P. Gupta; S. S. Iyer; R. Kumar","Dept. of Electr. & Comput. Eng., Univ. of California, Los Angeles, Los Angeles, CA, USA; Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Electr. & Comput. Eng., Univ. of California, Los Angeles, Los Angeles, CA, USA; Dept. of Electr. & Comput. Eng., Univ. of California, Los Angeles, Los Angeles, CA, USA; Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)","28 Mar 2019","2019","","","250","263","Increasing communication overheads are already threatening computer system scaling. One approach to dramatically reduce communication overheads is waferscale processing. However, waferscale processors [1], [2], [3] have been historically deemed impractical due to yield issues [1], [4] inherent to conventional integration technology. Emerging integration technologies such as Silicon-Interconnection Fabric (Si-IF) [5], [6], [7], where pre-manufactured dies are directly bonded on to a silicon wafer, may enable one to build a waferscale system without the corresponding yield issues. As such, waferscalar architectures need to be revisited. In this paper, we study if it is feasible and useful to build today's architectures at waferscale. Using a waferscale GPU as a case study, we show that while a 300 mm wafer can house about 100 GPU modules (GPM), only a much scaled down GPU architecture with about 40 GPMs can be built when physical concerns are considered. We also study the performance and energy implications of waferscale architectures. We show that waferscale GPUs can provide significant performance and energy efficiency advantages (up to 18.9x speedup and 143x EDP benefit compared against equivalent MCM-GPU based implementation on PCB) without any change in the programming model. We also develop thread scheduling and data placement policies for waferscale GPU architectures. Our policies outperform state-of-art scheduling and data placement policies by up to 2.88x (average 1.4x) and 1.62x (average 1.11x) for 24 GPM and 40 GPM cases respectively. Finally, we build the first Si-IF prototype with interconnected dies. We observe 100% of the inter-die interconnects to be successfully connected in our prototype. Coupled with the high yield reported previously for bonding of dies on Si-IF, this demonstrates the technological readiness for building a waferscale GPU architecture.","2378-203X","978-1-7281-1444-6","10.1109/HPCA.2019.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675211","Waferscale Processors;GPU;Silicon Interconnect Fabric","Graphics processing units;Silicon;Integrated circuit interconnections;Copper;Substrates;Computer architecture","cache storage;coprocessors;graphics processing units;integrated circuit interconnections;multiprocessing systems;parallel algorithms;parallel processing;silicon","GPU modules;GPM cases;silicon-interconnection fabric;Si-IF;waferscale processing;threatening computer system scaling;communication overheads;GPU case study;waferscale processors;state-of-art scheduling;waferscale GPU architecture;data placement policies;thread scheduling;equivalent MCM-GPU;energy efficiency advantages;waferscale architectures;waferscalar architectures;corresponding yield issues;waferscale system;silicon wafer;pre-manufactured dies;integration technologies;conventional integration technology;Si","","14","","82","","28 Mar 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"BigKernel -- High Performance CPU-GPU Communication Pipelining for Big Data-Style Applications","R. Mokhtari; M. Stumm","Dept. of Electr. & Comput. Eng., Univ. of Toronto, Toronto, ON, Canada; Dept. of Electr. & Comput. Eng., Univ. of Toronto, Toronto, ON, Canada","2014 IEEE 28th International Parallel and Distributed Processing Symposium","14 Aug 2014","2014","","","819","828","GPUs offer an order of magnitude higher compute power and memory bandwidth than CPUs. GPUs therefore might appear to be well suited to accelerate computations that operate on voluminous data sets in independent ways, e.g., for transformations, filtering, aggregation, partitioning or other ""Big Data"" style processing. Yet experience indicates that it is difficult, and often error-prone, to write GPGPU programs which efficiently process data that does not fit in GPU memory, partly because of the intricacies of GPU hardware architecture and programming models, and partly because of the limited bandwidth available between GPUs and CPUs. In this paper, we propose Big Kernel, a scheme that provides pseudo-virtual memory to GPU applications and is implemented using a 4-stage pipeline with automated prefetching to (i) optimize CPU-GPU communication and (ii) optimize GPU memory accesses. Big Kernel simplifies the programming model by allowing programmers to write kernels using arbitrarily large data structures that can be partitioned into segments where each segment is operated on independently, these kernels are transformed into Big Kernel using straight-forward compiler transformations. Our evaluation on six data-intensive benchmarks shows that Big Kernel achieves an average speedup of 1.7 over state-of-the-art double-buffering techniques and an average speedup of 3.0 over corresponding multi-threaded CPU implementations.","1530-2075","978-1-4799-3800-1","10.1109/IPDPS.2014.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877313","GPU;CPU;communication;optimization;stream processing","Graphics processing units;Kernel;Prefetching;Arrays;Memory management;Pipelines","Big Data;data structures;graphics processing units;pipeline processing;program compilers;storage management","BigKernel scheme;high performance CPU-GPU communication pipelining;Big Data-style processing;memory bandwidth;magnitude higher compute power;voluminous data sets;GPGPU programs;GPU hardware architecture;GPU programming models;pseudovirtual memory;automated prefetching;GPU memory accesses;data structures;straight-forward compiler transformations;double-buffering techniques;multithreaded CPU","","11","2","20","","14 Aug 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Profiling Kernels Behavior to Improve CPU / GPU Interactions","R. Salgado","Pleiad Lab., Univ. of Chile, Santiago, Chile","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","17 Aug 2015","2015","2","","754","756","Most modern computer and mobile devices have a graphical processing unit (GPU) available for any general purpose computation. GPU supports a programming model that is radically different from traditional sequential programming. As such, programming GPU is known to be hard and error prone, despite the large number of available APIs and dedicated programming languages. In this paper we describe a profiling technique that reports on the interaction between a CPU and GPUs. The resulting execution profile may then reveal anomalies and suboptimal situations, in particular due to an improper memory configuration. Our profiler has been effective at identifying suboptimal memory allocation usage in one image processing application.","1558-1225","978-1-4799-1934-5","10.1109/ICSE.2015.239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203060","gpgpu;opencl;memory profiling;profiling","Graphics processing units;Kernel;Programming;Visualization;Central Processing Unit;Computers;Measurement","graphics processing units;storage management","kernel behavior profiling technique;CPU-GPU interactions;mobile devices;graphical processing unit;programming model;improper memory configuration;suboptimal memory allocation usage;image processing application","","","","9","","17 Aug 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Performance improvement of CUDA applications by reducing CPU-GPU data transfer overhead","N. V. Sunitha; K. Raju; N. N. Chiplunkar","Department of CSE, NMAMIT, Nitte; Department of CSE, NMAMIT, Nitte; Department of CSE, NMAMIT, Nitte","2017 International Conference on Inventive Communication and Computational Technologies (ICICCT)","17 Jul 2017","2017","","","211","215","In a CPU-GPU based heterogeneous computing system, the input data to be processed by the kernel resides in the host memory. The host and the device memory address spaces are different. Therefore, the device can not directly access the host memory. In CUDA programming model, the data is moved between the host memory and the device memory. This data transfer is a time consuming task. The communication overhead can be hidden by overlapping the data transfer and the kernel execution. CUDA streams provide a means for overlapping data transfer and the kernel execution. In this paper we explore the effects of overlapping data transfer and the kernel execution on overall execution time of some CUDA applications. The results show that the usage of the different levels of concurrency supported by the streams enhances the performance of the CUDA applications.","","978-1-5090-5297-4","10.1109/ICICCT.2017.7975190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975190","Heterogeneous system;CUDA;Kernel;Stream","Graphics processing units;Kernel;Data transfer;Concurrent computing;Engines;Performance evaluation;Central Processing Unit","concurrency (computers);electronic data interchange;graphics processing units;parallel architectures;parallel programming","performance improvement;CUDA applications;CPU-GPU data transfer overhead reduction;CPU-GPU based heterogeneous computing system;host memory;CUDA programming model;device memory;communication overhead;kernel execution;CUDA streams;overlapping data transfer;overall execution time;concurrency level","","4","","12","","17 Jul 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Selective GPU caches to eliminate CPU-GPU HW cache coherence","N. Agarwal; D. Nellans; E. Ebrahimi; T. F. Wenisch; J. Danskin; S. W. Keckler",University of Michigan; NVIDIA; NVIDIA; University of Michigan; NVIDIA; NVIDIA,"2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)","4 Apr 2016","2016","","","494","506","Cache coherence is ubiquitous in shared memory multiprocessors because it provides a simple, high performance memory abstraction to programmers. Recent work suggests extending hardware cache coherence between CPUs and GPUs to help support programming models with tightly coordinated sharing between CPU and GPU threads. However, implementing hardware cache coherence is particularly challenging in systems with discrete CPUs and GPUs that may not be produced by a single vendor. Instead, we propose, selective caching, wherein we disallow GPU caching of any memory that would require coherence updates to propagate between the CPU and GPU, thereby decoupling the GPU from vendor-specific CPU coherence protocols. We propose several architectural improvements to offset the performance penalty of selective caching: aggressive request coalescing, CPU-side coherent caching for GPU-uncacheable requests, and a CPU-GPU interconnect optimization to support variable-size transfers. Moreover, current GPU workloads access many read-only memory pages; we exploit this property to allow promiscuous GPU caching of these pages, relying on page-level protection, rather than hardware cache coherence, to ensure correctness. These optimizations bring a selective caching GPU implementation to within 93% of a hardware cache-coherent implementation without the need to integrate CPUs and GPUs under a single hardware coherence protocol.","2378-203X","978-1-4673-9211-2","10.1109/HPCA.2016.7446089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7446089","","Graphics processing units;Coherence;Hardware;Memory management;Bandwidth;Protocols;System-on-chip","cache storage;graphics processing units;microprocessor chips;protocols;shared memory systems","HW cache coherence;hardware cache coherence;shared memory multiprocessor;programming model;aggressive request coalescing;CPU-side coherent caching;CPU-GPU interconnect optimization;hardware coherence protocol","","38","7","70","","4 Apr 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"The Unicorn Runtime: Efficient Distributed Shared Memory Programming for Hybrid CPU-GPU Clusters","T. Beri; S. Bansal; S. Kumar","Department of Computer Science and Engineering, Indian Institute of Technology, Delhi, India; Department of Computer Science and Engineering, Indian Institute of Technology, Delhi, India; Department of Computer Science and Engineering, Indian Institute of Technology, Delhi, India","IEEE Transactions on Parallel and Distributed Systems","12 Apr 2017","2017","28","5","1518","1534","Programming hybrid CPU-GPU clusters is hard. This paper addresses this difficulty and presents the design and runtime implementation of Unicorn-a parallel programming model for hybrid CPU-GPU clusters. In particular, this paper proves that efficient distributed shared memory style programing is possible and its simplicity can be retained across CPUs and GPUs in a cluster, minus the frustration of dealing with race conditions. Further, this can be done with a unified abstraction, avoiding much of the complication of dealing with hybrid architectures. This is achieved with the help of transactional semantics (on shared global address spaces), deferred bulk data synchronization, workload pipelining and various communication and computation scheduling optimizations. We describe the said abstraction, our computation and communication scheduling system and report its performance on a few benchmarks like Matrix Multiplication, LU Decomposition and 2D FFT. We find that parallelization of coarse-grained applications like matrix multiplication or 2D FFT using our system requires only about 30 lines of C code to set up the runtime. The rest of the application code is regular single CPU/GPU implementation. This indicates the ease of extending parallel code to a distributed environment. The execution is efficient as well. When multiplying two square matrices of size 65, 536 χ 65,536, Unicornachieves a peak performance of 7.88 TFlop/s when run over a cluster of 14 nodes with each node equipped with two Tesla M2070 GPUs and two 6-core Intel Xeon 2.67 GHz CPUs, connected over a 32Gbps Infiniband network. In this paper, we also demonstrate that the Unicorn programming model can be efficiently used to implement high level abstractions like MapReduce. We use such an extension to implement PageRank and report its performance. For a sample web of 500 million web pages, our implementation completes a page rank iteration in about 18 seconds (on average) on a 14-node cluster.","1558-2183","","10.1109/TPDS.2016.2616314","Ministry of Earth Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7588161","Unicorn runtime;distributed system design;scheduling;load balancing;accelerators;bulk synchronous parallelism","Runtime;Programming;Optimization;Processor scheduling;Kernel;Synchronization;Graphics processing units","distributed shared memory systems;fast Fourier transforms;graphics processing units;information retrieval;Internet;mathematics computing;matrix multiplication;parallel programming;pipeline processing;processor scheduling;programming language semantics;transaction processing","Unicorn runtime;distributed shared memory programming;hybrid CPU-GPU clusters;parallel programming model;unified abstraction;transactional semantics;bulk data synchronization;workload pipelining;computation scheduling optimizations;communication scheduling optimizations;matrix multiplication;LU decomposition;2D FFT;coarse-grained applications;C code;application code;parallel code;Tesla M2070 GPU;6-core Intel Xeon CPU;Infiniband network;Unicorn programming model;PageRank implementation;page rank iteration;Web pages","","6","","40","IEEE","11 Oct 2016","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"PACXX: Towards a Unified Programming Model for Programming Accelerators Using C++14","M. Haidl; S. Gorlatch","Univ. of Muenster, Muenster, Germany; Univ. of Muenster, Muenster, Germany","2014 LLVM Compiler Infrastructure in HPC","30 Mar 2015","2014","","","1","11","We present PACXX -- a unified programming model for programming many-core systems that comprise accelerators like Graphics Processing Units (GPUs). One of the main difficulties of the current GPU programming is that two distinct programming models are required: the host code for the CPU is written in C/C++ with the restricted, C-like API for memory management, while the device code for the GPU has to be written using a device-dependent, explicitly parallel programming model, e.g., OpenCL or CUDA. This leads to long, poorly structured and error-prone codes. In PACXX, both host and device programs are written in the same programming language -- the newest C++14 standard, with all modern features including type inference (auto), variadic templates, generic lambda expressions, as well as STL containers and algorithms. We implement PACXX by a custom compiler (based on the Clang front-end and LLVM IR) and a runtime system, that together perform major tasks of memory management and data synchronization automatically and transparently for the programmer. We evaluate our approach by comparing it to CUDA and OpenCL regarding program size and target performance.","","978-1-4799-7023-0","10.1109/LLVM-HPC.2014.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069296","","Kernel;Graphics processing units;Programming;Vectors;Synchronization;Runtime;Standards","application program interfaces;C++ language;graphics processing units;multiprocessing systems;parallel architectures;parallel programming;program compilers;reasoning about programs;storage management;type theory","PACXX;unified programming model;programming accelerator;many-core system;graphics processing units;GPU programming;C/C++;C-like API;memory management;device code;device-dependent programming model;parallel programming model;OpenCL;CUDA;error-prone code;host program;device program;programming language;C++14 standard;type inference;variadic template;generic lambda expression;STL container;custom compiler;Clang front-end;LLVM IR;runtime system;data synchronization","","19","","15","","30 Mar 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"An Efficient Parallelization Strategy for Dynamic Programming on GPU","K. Berger; F. Galea","LIST Embedded Real Time Syst. Lab., CEA, Gif-sur-Yvette, France; LIST Embedded Real Time Syst. Lab., CEA, Gif-sur-Yvette, France","2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum","31 Oct 2013","2013","","","1797","1806","Optimization methods generally do not fall into the most suitable algorithms for parallelization on a GPU. However, a relatively good efficiency still can be obtained if the method is properly adapted to the GPU programming model, which is the case for dynamic programming. In this article, we propose a parallelization strategy for thread grouping for dynamic programming in CUDA. We show that parametrizing the solver parallelism according to the hardware allows better performance. The strategy provides good acceleration compared to a standard GPU parallel strategy on a dynamic programming-based implementation of the knapsack problem. We show this strategy is helpful in the case of the multi-dimensional knapsack problem, where computing multi-dimensional indices is a costly operation.","","978-0-7695-4979-8","10.1109/IPDPSW.2013.208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651080","dynamic programming;parallelism;knapsack problem;GPU computing;combinatorial optimization;CUDA","Graphics processing units;Instruction sets;Vectors;Dynamic programming;Kernel;Parallel processing;Arrays","dynamic programming;graphics processing units;knapsack problems;parallel architectures","multidimensional indices;multidimensional knapsack problem;dynamic programming based implementation;standard GPU parallel strategy;hardware;solver parallelism;CUDA;GPU programming model;optimization methods;parallelization strategy","","9","","34","","31 Oct 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"CUDA parallel programming model","M. Garland","NVIDIA Research, USA","2008 IEEE Hot Chips 20 Symposium (HCS)","4 Jul 2016","2008","","","1","29","Presents a collection of slides covering the following topics: parallel threads; parallel algorithms; heterogeneous systems; CPU; GPU; concurrent threads; shared memory model; vector addition kernel; block synchronization; thread block; per-block shared memory; parallel reduction; serial SAXPY routine; and parallel SAXPY routine.","","978-1-4673-8871-9","10.1109/HOTCHIPS.2008.7476519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476519","","Instruction sets;Graphics processing units;Tutorials;Parallel programming;Kernel;Parallel algorithms;Synchronization","concurrency control;graphics processing units;multi-threading;parallel algorithms;parallel architectures;shared memory systems","parallel threads;parallel algorithms;CUDA parallel programming model;heterogeneous systems;CPU;GPU;concurrent threads;shared memory model;vector addition kernel;block synchronization;thread block;per-block shared memory;parallel reduction;serial SAXPY routine;parallel SAXPY routine","","1","","","","4 Jul 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"POSTER - collective dynamic parallelism for directive based GPU programming languages and compilers","G. Ozen; E. Ayguade; J. Labarta","Barcelona Supercomputing Center, Universitat Politecnica de Catalunya, Spain; Barcelona Supercomputing Center, Universitat Politecnica de Catalunya, Spain; Barcelona Supercomputing Center, Universitat Politecnica de Catalunya, Spain","2016 International Conference on Parallel Architecture and Compilation Techniques (PACT)","1 Dec 2016","2016","","","423","424","Early programs for GPU (Graphics Processing Units) acceleration were based on a flat, bulk parallel programming model, in which programs had to perform a sequence of kernel launches from the host CPU. In the latest releases of these devices, dynamic (or nested) parallelism is supported, making possible to launch kernels from threads running on the device, without host intervention. Unfortunately, the overhead of launching kernels from the device is higher compared to launching from the host CPU, making the exploitation of dynamic parallelism unprofitable. This paper proposes and evaluates the basic idea behind a user-directed code transformation technique, named collective dynamic parallelism, that targets the effective exploitation of nested parallelism in modern GPUs. The technique dynamically packs dynamic parallelism kernel invocations and postpones their execution until a bunch of them are available. We show that for sparse matrix vector multiplication, CollectiveDP outperforms well optimized libraries, making GPU useful when matrices are highly irregular.","","978-1-4503-4121-9","10.1145/2967938.2974056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7756778","","Kernel;Parallel processing;Graphics processing units;Context;Sparse matrices;Parallel programming;Libraries","graphics processing units;matrix multiplication;microprocessor chips;parallel programming;program compilers;programming languages;vectors","programming languages;program compilers;graphics processing units;GPU;parallel programming model;host CPU;user-directed code transformation;collective dynamic parallelism;sparse matrix vector multiplication","","","","3","","1 Dec 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU accelerated three dimensional unstructured geometric multigrid solver","J. Sebastian; N. Sivadasan; R. Banerjee","Dept. of Computer Science and Engineering, Indian Institute of Technology Hyderabad, India; Dept. of Computer Science and Engineering, Indian Institute of Technology Hyderabad, India; Dept. of Mechanical Engineering, Indian Institute of Technology Hyderabad, India","2014 International Conference on High Performance Computing & Simulation (HPCS)","22 Sep 2014","2014","","","9","16","Graphics processor units (GPUs) have started becoming an integral part of high performance computing. We develop a GPU based 3D-unstructured geometric multigrid solver, which is extensively used in Computational Fluid Dynamics (CFD) applications. Parallelization for GPUs is not straightforward because of the irregularity of the mesh. Using combination of graph coloring and greedy maximal independent set computations, we obtain significant performance improvements in the multigrid solver and its parallelization. We use NVIDIAs CUDA programming model for the implementation. In our experiments, we solve heat conduction problems on unstructured 3D meshes. Different schemes for implementing the multigrid algorithm are evaluated. For a mesh of size 1.6 million, our multigrid GPU implementation gives 24 times speed up compared to multigrid serial implementation and 1630 times speed up compared to non-multigrid serial implementation.","","978-1-4799-5313-4","10.1109/HPCSim.2014.6903663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6903663","GPU Computing;High Performance Computing;Computational Fluid Dynamics;Multigrid Flow Solver","Graphics processing units;Instruction sets;Image color analysis;Iterative methods;Smoothing methods;Computational fluid dynamics;Jacobian matrices","computational fluid dynamics;differential equations;graph colouring;graphics processing units;greedy algorithms;heat conduction;mechanical engineering computing;mesh generation;parallel architectures","GPU accelerated three dimensional unstructured geometric multigrid solver;graphics processor units;high performance computing;GPU based 3D-unstructured geometric multigrid solver;computational fluid dynamics;CFD;mesh irregularity;graph coloring;greedy maximal independent set computations;NVIDIA CUDA programming model;heat conduction problems;unstructured 3D mesh;multigrid serial implementation;nonmultigrid serial implementation","","3","","29","","22 Sep 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Accelerating of color moments and texture features extraction using GPU based parallel computing","H. Heidari; A. Chalechale; A. A. Mohammadabadi","Department of Computer Engineering Razi University Kermanshah, Iran; Department of Computer Engineering Razi University Kermanshah, Iran; Department of Computer Engineering Razi University Kermanshah, Iran","2013 8th Iranian Conference on Machine Vision and Image Processing (MVIP)","31 Mar 2014","2013","","","430","435","Image retrieval tools can assist people in making efficient use of digital image collections; also it has become imperative to find efficient methods for the retrieval of these images. Most image processing algorithms are inherently parallel, so multithreading processors are suitable in such applications. In very big image databases, image processing takes very long time for run on a single core processor because of single thread execution of algorithms. GPU is more common in most image processing applications due to multithread execution of algorithms, programmability and low cost. In this paper we implement color moments and texture based image retrieval (entropy, standard deviation and local range) in parallel using CUDA programming model to run on GPUs. These features are applied to search images from a database which are similar to a query image. We evaluated our retrieval system using recall, precision, and average precision measures. Experimental results showed that parallel implementation led to an average speed up of 144.67×over the serial implementation when running on a NVIDIA GPU GeForce GT610M. Also the average precision and the average recall of proposed method are 61.968% and 55% respectively.","2166-6784","978-1-4673-6184-2","10.1109/IranianMVIP.2013.6780024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6780024","color moment;CUDA;GPU;texture based image retrieval","Feature extraction;Graphics processing units;Image color analysis;Image retrieval;Shape;Instruction sets","feature extraction;graphics processing units;image colour analysis;image retrieval;image texture;multi-threading;parallel architectures","color moments;texture features extraction;GPU based parallel computing;graphics processing unit;image retrieval tools;digital image collections;image processing algorithms;multithreading processors;very big image databases;CUDA programming model;compute unified device architecture;recall measure;precision measure;average precision measure;NVIDIA GPU GeForce GT610M","","2","","23","","31 Mar 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Parallel Monte Carlo Integration Algorithm Based on GPU","H. Zong; R. Hua; J. Zhao; Z. Cao","Huaiyin Institute of Technology,Faculty of Computer and Software Engineering,Huaian,China; Huaiyin Institute of Technology,Faculty of Computer and Software Engineering,Huaian,China; Huaiyin Institute of Technology,Faculty of Computer and Software Engineering,Huaian,China; Nanjing University of Aeronautics and Astronautics,College of Computer Science and Technology,Nanjing,China","2019 IEEE 14th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)","18 Aug 2020","2019","","","790","794","Big data comes with the increasing maturity of computer network technology and its application popularity. How to process big data and mine its potential value is a hot issue today. Artificial intelligence is one of the main sources of algorithms for dealing with big data, while parallel computation is the only choice to improve computing performance. Monte Carlo method plays an important role in the application of artificial intelligence, such as computer game AlphaGo, and it requires a lot of random data to calculate, so we use it, in this paper, to explore the general method of parallel processing big data. According to Monte Carlo method, the calculation time of the algorithm will increase exponentially with the increase of the calculation accuracy. As the calculation accuracy will increase accordingly when the number of points increases. In order to improve the computing performance, a Monte Carlo parallel algorithm based on GPU-CUDA programming model is designed. The quality of the random number generator is the key factor affecting the accuracy of Monte Carlo calculation, so the higher quality Mersenne Twister random number algorithm is chosen. Taking π and e as examples, the experimental results show that the GPU-based Monte Carlo parallel algorithm is effective. This method improves both the calculation performance and the calculation accuracy.","","978-1-7281-2348-6","10.1109/ISKE47853.2019.9170329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170329","GPU;Monte Carlo method;definite integral;parallel computing;random number","","graphics processing units;Monte Carlo methods;parallel algorithms;parallel architectures;parallel processing;random number generation","Monte Carlo calculation;higher quality Mersenne Twister random number algorithm;GPU-based Monte Carlo parallel algorithm;calculation performance;parallel Monte Carlo integration algorithm;increasing maturity;computer network technology;application popularity;artificial intelligence;parallel computation;computing performance;Monte Carlo method;computer game AlphaGo;random data;parallel processing big data;calculation time;points increases;GPU-CUDA programming model;random number generator","","","","7","","18 Aug 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Accelerating gene regulatory networks inference through GPU/CUDA programming","F. F. Borelli; R. Y. Camargo; D. C. Martins; B. Stransky; L. C. S. Rozante","Universidade Federal do ABC, Santo André-SP, Brazil; Universidade Federal do ABC, Santo André-SP, Brazil; Universidade Federal do ABC, Santo André-SP, Brazil; Universidade Federal do ABC, Santo André-SP, Brazil; Universidade Federal do ABC, Santo André-SP, Brazil","2012 IEEE 2nd International Conference on Computational Advances in Bio and medical Sciences (ICCABS)","12 Apr 2012","2012","","","1","6","Gene regulatory networks (GRN) inference is an important bioinformatics problem in which the gene interactions need to be deduced from gene expression data, such as microarray data. Feature selection methods can be applied to this problem. A feature selection technique is composed by two parts: a search algorithm and a criterion function. Among the search algorithms already proposed, there is the exhaustive search where the best feature subset is returned, although its computational complexity is unfeasible in almost all situations. The objective of this work is the development of a low cost parallel solution based on GPU architectures for exhaustive search with a viable cost-benefit. CUDA™ is a general purpose parallel architecture with a new parallel programming model allowing that the NVIDIA<sup>®</sup> GPUs solve complex problems in an efficient way. We developed a parallel algorithm for GRN inference based on the GPU/CUDA and encouraging speedups (60x) were achieved when assuming that each target gene has two predictors. The idea behind the proposed method can be applied considering three or more predictors for each target gene as well.","","978-1-4673-1321-6","10.1109/ICCABS.2012.6182628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182628","GRNs Inference;exhaustive search;mean conditional entropy;GPU Computing;CUDA","Graphics processing unit;Computer architecture;Entropy;Instruction sets;Random access memory;Prediction algorithms;Performance evaluation","bioinformatics;computational complexity;feature extraction;genetics;graphics processing units;inference mechanisms;parallel architectures;parallel programming","gene regulatory network inference;GPU-CUDA programming;bioinformatics;gene interactions;feature selection method;gene expression data;search algorithm;feature subset;computational complexity;GPU architectures;parallel architecture;parallel programming model;parallel algorithm;GRN inference;exhaustive search","","3","","17","","12 Apr 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Comparison of GPU and FPGA based hardware platforms for ultrasonic flaw detection using support vector machines","K. Virupakshappa; E. Oruklu; Y. Jiang; Y. Yuan","ECE Department, Illinois Institute of Technology, Chicago, IL, USA; ECE Department, Illinois Institute of Technology, Chicago, IL, USA; ECE Department, Illinois Institute of Technology, Chicago, IL, USA; ECE Department, Illinois Institute of Technology, Chicago, IL, USA","2017 IEEE International Ultrasonics Symposium (IUS)","2 Nov 2017","2017","","","1","1","Our earlier work on support vector machines (SVM) and ultrasonic flaw detection algorithms demonstrated i) highly accurate classifier performance and ii) the feasibility of the algorithm for real-time implementation on low-cost embedded systems with graphical processing units (GPU) and CUDA library (a parallel computing platform and programming model) support. This works extends the implementation to another programmable hardware platform, FPGA, and also evaluates the performance of a different numerical computation library, TensorFlow by Google.","1948-5727","978-1-5386-3383-0","10.1109/ULTSYM.2017.8091862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8091862","","Graphics processing units;Support vector machines;Field programmable gate arrays;Libraries;Classification algorithms;Hardware;Acoustics","embedded systems;field programmable gate arrays;flaw detection;graphics processing units;parallel architectures;pattern classification;support vector machines","parallel computing;embedded systems;programmable hardware platform;programming model;ultrasonic flaw detection algorithms;support vector machines;FPGA;GPU","","","","","","2 Nov 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU-based Real-time Decoding Technique for High-definition Videos","H. Deng; C. Deng; J. Li","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou, China; Dept. of Comput. Eng., South China Univ. of Technol., Guangzhou, China; Sch. of Software Eng., South China Univ. of Technol., Guangzhou, China","2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","23 Aug 2012","2012","","","186","190","In this paper, we first discussed the video decoding standard and its architecture, and then analyzed the decoding complexity of each process. By using the benefit of the CUDA programming model, and taking advantages of GPU to optimize the decoding process of MC (motion compensation) and CSC(color space conversion) that are very time consuming, we proposed a MC accelerating method based on CUDA, and a CSC accelerating method based on CUDA and OpenGL shader. The experiments show that it is feasible to decode high definition video in real time using GPGPU-CUDA.","","978-1-4673-1741-2","10.1109/IIH-MSP.2012.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6274644","CUDA;real-time decoding;high-definition video;GPGPU;GLSL","Graphics processing unit;Decoding;Videos;Instruction sets;Kernel;Central Processing Unit;Real time systems","graphics processing units;image colour analysis;parallel architectures;video coding","GPU based real-time decoding technique;high definition videos;video decoding;CUDA programming model;motion compensation;MC;color space conversion;CSC;OpenGL shader","","1","","8","","23 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Coordinate strip-mining and kernel fusion to lower power consumption on GPU","G. Wang","National Laboratory for Parallel and Distributed Processing, School of Computer, National University of Defense Technology, Changsha, Hunan, China","2011 Design, Automation & Test in Europe","5 May 2011","2011","","","1","4","Although general purpose GPUs have relatively high computing capacity, they also introduce high power consumption compared with general purpose CPUs. Therefore low-power techniques targeted for GPUs will be one of the most hot topics in the future. On the other hand, in several application domains, users are unwilling to sacrifice performance to save power. In this paper, we propose an effective kernel fusion method to reduce the power consumption for GPUs without performance loss. Different from executing multiple kernels serially, the proposed method fuses several kernels into one larger kernel. Owing to the fact that most consecutive kernels in an application have data dependency and could not be fused directly, we split large kernel into multiple slices with strip-mining method, then fuse independent sliced kernels into one kernel. Based on the CUDA programming model, we propose three different kernel fusion implementations, with each one targeting for a special case. Based on the different strip-ming methods, we also propose two fusion mechanisms, which are called invariant-slice fusion and variant-slice fusion. The latter one could be better adapted to the requirements of the kernels to be fused. The experimental results validate that the proposed kernel fusion method could effectively reduce the power consumption for GPU.","1558-1101","978-3-9810801-8-6","10.1109/DATE.2011.5763317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763317","GPGPV;Kernel Fusion;Strip-mining;Power Efficiency","Kernel;Energy consumption;Graphics processing unit;Power demand;Instruction sets;Programming;Optimization","computer graphic equipment;coprocessors;general purpose computers;low-power electronics;parallel architectures;program slicing","coordinate strip-mining;kernel fusion;power consumption;general purpose GPU;low-power techniques;data dependency;CUDA programming model;invariant-slice fusion;graphics processing unit","","1","","10","","5 May 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A Case Study on the HACCmk Routine in SYCL on Integrated Graphics","Z. Jin; V. Morozov; H. Finkel","Argonne National Laboratory,Leadership Computing Facility,9700 S Cass Ave, Lemont,IL,60439; Argonne National Laboratory,Leadership Computing Facility,9700 S Cass Ave, Lemont,IL,60439; Argonne National Laboratory,Leadership Computing Facility,9700 S Cass Ave, Lemont,IL,60439","2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","28 Jul 2020","2020","","","368","374","As opposed to the Open Computing Language (OpenCL) programming model in which host and device codes are generally written in different languages, the SYCL programming model can combine host and device codes for an application in a type-safe way to improve development productivity. In this paper, we chose the HACCmk routine, a representative compute-bound kernel, as a case study on the performance of the SYCL programming model targeting a heterogeneous computing device. More specifically, we introduced the SYCL programming model, presented the OpenCL and SYCL implementations of the routine, and compared the performance of the two implementations using the offline and online compilation on Intel® IrisTM Pro integrated GPUs. We found that the overhead of online compilation may become significant compared to the execution time of a kernel. Compared to the performance of OpenCL implementations, the SYCL implementation can maintain the performance using the offline compilation. The number of execution units in a GPU are critical to improving the raw performance of a compute-bound kernel.","","978-1-7281-7445-7","10.1109/IPDPSW50202.2020.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150310","Programming model;Compilation modes;Compute-bound kernel;GPU","Kernel;Programming;Graphics processing units;Computational modeling;Performance evaluation;C++ languages","application program interfaces;graphics processing units;parallel processing;program compilers","SYCL programming model;online compilation;OpenCL implementation;SYCL implementation;HACCmk routine;Open Computing Language programming model;representative compute-bound kernel;heterogeneous computing device;Intel IrisTM Pro;GPU","","1","","26","","28 Jul 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Exploring the Suitability of Remote GPGPU Virtualization for the OpenACC Programming Model Using rCUDA","A. Castelló; A. J. Peña; R. Mayo; P. Balaji; E. S. Quintana-Ortí","Univ. Jaume I de Castello, Castello de la Plana, Spain; Argonne Nat. Lab., Argonne, IL, USA; Univ. Jaume I de Castello, Castello de la Plana, Spain; Argonne Nat. Lab., Argonne, IL, USA; Univ. Jaume I de Castello, Castello de la Plana, Spain","2015 IEEE International Conference on Cluster Computing","29 Oct 2015","2015","","","92","95","OpenACC is an application programming interface (API) that aims to unleash the power of heterogeneous systems composed of CPUs and accelerators such as graphic processing units (GPUs) or Intel Xeon Phi coprocessors. This directive-based programming model is intended to enable developers to accelerate their application's execution with much less effort. Coprocessors offer significant computing power but in many cases these devices remain largely underused because not all parts of applications match the accelerator architecture. Remote accelerator virtualization frameworks introduce a means to address this problem. In particular, the remote CUDA virtualization middleware rCUDA provides transparent remote access to any GPU installed in a cluster. Combining these two technologies, OpenACC and rCUDA, in a single scenario is naturally appealing. In this work we explore how the different OpenACC directives behave on top of a remote GPGPU virtualization technology in two different hardware configurations. Our experimental evaluation reveals favorable performance results when the two technologies are combined, showing low overhead and similar scaling factors when executing OpenACC-enabled directives.","2168-9253","978-1-4673-6598-7","10.1109/CLUSTER.2015.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307570","GPUs;OpenACC;remote virtualization;rCUDA","Graphics processing units;Virtualization;Acceleration;Programming;Coprocessors;Kernel","graphics processing units;middleware;parallel architectures;virtualisation","GPGPU virtualization;graphics processing unit;OpenACC programming model;rCUDA;CUDA virtualization middleware;application programming interface;API;directive-based programming model;remote accelerator virtualization framework","","3","","12","","29 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A Performance Prediction Model for Memory-Intensive GPU Kernels","Z. Hu; G. Liu; Z. Hu","Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; NA","2014 IEEE Symposium on Computer Applications and Communications","2 Oct 2014","2014","","","14","18","Commodity graphic processing units (GPUs) have rapidly evolved to become high performance accelerators for data-parallel computing through a large array of processing cores and the CUDA programming model with a C-like interface. However, optimizing an application for maximum performance based on the GPU architecture is not a trivial task for the tremendous change from conventional multi-core to the many-core architectures. Besides, the GPU vendors do not disclose much detail about the characteristics of the GPU's architecture. To provide insights into the performance of memory-intensive kernels, we propose a pipelined global memory model to incorporate the most critical global memory performance related factor, uncoalesced memory access pattern, and provide a basis for predicting performance of memory-intensive kernels. As we will demonstrate, the pipeline throughput is dynamic and sensitive to the memory access patterns. We validated our model on the NVIDIA GPUs using CUDA (Compute Unified Device Architecture). The experiment results show that the pipeline captures performance factors related to global memory and is able to estimate the performance for memory-intensive GPU kernels via the proposed model.","","978-0-7695-5319-1","10.1109/SCAC.2014.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913158","GPU;CUDA;performance prediction;memory-intensive","Graphics processing units;Instruction sets;Kernel;Pipelines;Memory management;Random access memory;Throughput","DRAM chips;graphics processing units;parallel architectures;performance evaluation;pipeline processing","DRAM chips;memory-intensive GPU kernels;global memory;Compute Unified Device Architecture;CUDA;NVIDIA GPU;dynamic sensitive pipeline throughput;uncoalesced memory access pattern;critical global memory performance related factor;pipelined global memory model;memory-intensive kernel performance;GPU architecture;data-parallel computing;high-performance accelerators;graphic processing units;performance prediction model","","","","13","","2 Oct 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"LoSCache: Leveraging Locality Similarity to Build Energy-Efficient GPU L2 Cache","J. Tan; K. Yan; S. L. Song; X. Fu","College of Computer Science and Technology, Jilin University, Changchun, China; College of Communication Engineering, Jilin University, Changchun, China; HPC Group, Pacific Northwest National Laboratory, Richland, USA; ECE Department, University of Houston, Houston, USA","2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)","16 May 2019","2019","","","1190","1195","This paper presents a novel energy-efficient cache design for massively parallel, throughput-oriented architectures like GPUs. Unlike L1 data cache on modern GPUs, L2 cache shared by all the streaming multiprocessors is not the primary performance bottleneck but it does consume a large amount of chip energy. We observe that L2 cache is significantly under-utilized by spending 95.6% of the time storing useless data. If such ""dead time"" on L2 is identified and reduced, L2's energy efficiency can be drastically improved. Fortunately, we discover that the SIMT programming model of GPUs provides a unique feature among threads: instruction-level data locality similarity, which can be used to accurately predict the data re-reference counts at L2 cache block level. We propose a simple design that leverages this Locality Similarity to build an energy-efficient GPU L2 Cache, named LoSCache. Specifically, LoSCache uses the data locality information from a small group of CTAs to dynamically predict the L2-level data re-reference counts of the remaining CTAs. After that, specific L2 cache lines can be powered off if they are predicted to be ""dead"" after certain accesses. Experimental results on a wide range of applications demonstrate that our proposed design can significantly reduce the L2 cache energy by an average of 64% with only 0.5% performance loss.","1558-1101","978-3-9819263-2-3","10.23919/DATE.2019.8714911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8714911","GPU;cache;energy-efficiency;locality similarity","Instruction sets;Graphics processing units;Kernel;Hardware;Programming;Data models;System-on-chip","cache storage;energy conservation;graphics processing units;multi-threading;parallel architectures;power aware computing","energy-efficient GPU L2 cache;L1 data cache;instruction-level data locality similarity;L2 cache block level;L2 cache energy;energy-efficient cache design;SIMT programming model;LoSCache;massively parallel architectures;single instruction multiple thread programming model","","","","20","","16 May 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"dCUDA: Hardware Supported Overlap of Computation and Communication","T. Gysi; J. Bär; T. Hoefler",NA; NA; NA,"SC '16: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","16 Mar 2017","2016","","","609","620","Over the last decade, CUDA and the underlying GPU hardware architecture have continuously gained popularity in various high-performance computing application domains such as climate modeling, computational chemistry, or machine learning. Despite this popularity, we lack a single coherent programming model for GPU clusters. We therefore introduce the dCUDA programming model, which implements device-side remote memory access with target notification. To hide instruction pipeline latencies, CUDA programs over-decompose the problem and over-subscribe the device by running many more threads than there are hardware execution units. Whenever a thread stalls, the hardware scheduler immediately proceeds with the execution of another thread ready for execution. This latency hiding technique is key to make best use of the available hardware resources. With dCUDA, we apply latency hiding at cluster scale to automatically overlap computation and communication. Our benchmarks demonstrate perfect overlap for memory bandwidth-bound tasks and good overlap for compute-bound tasks.","2167-4337","978-1-4673-8815-3","10.1109/SC.2016.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877130","Distributed memory;gpu;latency hiding;programming model;remote memory access","Graphics processing units;Programming;Computational modeling;Hardware;Instruction sets;Kernel","multi-threading;parallel architectures;storage management","hardware supported overlap;computation;communication;GPU hardware architecture;high-performance computing;GPU clusters;dCUDA programming model;device-side remote memory access;instruction pipeline latencies;hardware scheduler;latency hiding;hardware resources;memory bandwidth-bound tasks;compute-bound tasks;threads","","13","1","31","","16 Mar 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU Computing","J. D. Owens; M. Houston; D. Luebke; S. Green; J. E. Stone; J. C. Phillips","Univ. of California, Davis; NA; NA; NA; NA; NA","Proceedings of the IEEE","15 Apr 2008","2008","96","5","879","899","The graphics processing unit (GPU) has become an integral part of today's mainstream computing systems. Over the past six years, there has been a marked increase in the performance and capabilities of GPUs. The modern GPU is not only a powerful graphics engine but also a highly parallel programmable processor featuring peak arithmetic and memory bandwidth that substantially outpaces its CPU counterpart. The GPU's rapid increase in both programmability and capability has spawned a research community that has successfully mapped a broad range of computationally demanding, complex problems to the GPU. This effort in general-purpose computing on the GPU, also known as GPU computing, has positioned the GPU as a compelling alternative to traditional microprocessors in high-performance computer systems of the future. We describe the background, hardware, and programming model for GPU computing, summarize the state of the art in tools and techniques, and present four GPU computing successes in game physics and computational biophysics that deliver order-of-magnitude performance gains over optimized CPU applications.","1558-2256","","10.1109/JPROC.2008.917757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4490127","General-purpose computing on the graphics processing unit (GPGPU);GPU computing;parallel computing","Graphics;Central Processing Unit;Physics computing;Engines;Arithmetic;Bandwidth;Microprocessors;Hardware;Computational biophysics;Performance gain","computer graphic equipment;microcomputers;parallel programming","GPU computing;graphics processing unit;graphics engine;parallel programmable processor;peak arithmetic;memory bandwidth;general-purpose computing;microprocessor;high-performance computer system;programming model;game physics;computational biophysics;parallel computing","","1060","30","32","","15 Apr 2008","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"Data Parallel Programming Model for Many-Core Architectures","Y. Zhang","North Carolina State Univ., Raleigh, NC, USA","2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum","1 Sep 2011","2011","","","2065","2068","Emerging accelerating architectures, such as GPUs, have proved successful in providing significant performance gains to various application domains. This is done by exploiting data parallelism in existing algorithms. However, programming in a data-parallel fashion imposes extra burdens to programmers, who are used to writing sequential programs. New programming models and frameworks are needed to reach a balance between programmability, portability and performance. We start from stream processing domain and propose GStream, a general-purpose, scalable data streaming framework on GPUs. The contributions of GStream are as follows: (1) We provide powerful, yet concise language abstractions suitable to describe conventional algorithms as streaming problems. (2) We project these abstractions onto GPUs to fully exploit their inherent massive data-parallelism. (3) We demonstrate the viability of streaming on accelerators. Experiments show that the proposed framework provides flexibility, programmability and performance gains for various benchmarks from a collection of domains, including but not limited to data streaming, data parallel problems, numerical codes and text search. This work lays a foundation to our future work to develop more general data parallel programming models for many-core architectures.","1530-2075","978-1-61284-425-1","10.1109/IPDPS.2011.378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6009018","","Graphics processing unit;Parallel processing;Benchmark testing;Libraries;Kernel;Computer architecture","computer graphic equipment;multiprocessing systems;parallel programming","data parallel programming model;many-core architectures;GPU;GStream;general-purpose scalable data streaming framework;language abstractions;massive data-parallelism","","","","22","","1 Sep 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A Unified Programming Model for Heterogeneous Computing with CPU and Accelerator Technologies","Y. Xiong","Shanghai Institute of Technology,Computer Science Department,Shanghai,China,201418","2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","23 Jan 2020","2019","","","1","4","This paper provides a unified programming model for heterogeneous computing with CPU and accelerator (like GPU, FPGA, Google TPU, and more) technologies. This new programming model provides a clean interface to application developers and to some extent makes programming across CPUs and accelerators turn into usual programming tasks with common programming languages. Thus it can contribute to improve software productivity for computing across CPUs and accelerators. It can be achieved by extending file managements in common programming languages, such as C/C++, Fortran, Python, MPI, etc., to cover GPUs, FPGAs, and other accelerators (such as Google TPU, etc.) as I/O devices. The programming model can be applied to a number of different computing systems equipped with accelerators, ranging from embedded systems, to mobile computing systems, to HPC systems, and to cloud computing systems.","","978-1-7281-4852-6","10.1109/CISP-BMEI48845.2019.8965946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965946","","Graphics processing units;Programming;Field programmable gate arrays;Computer languages;Printers;Task analysis;Deep learning","cloud computing;embedded systems;message passing;mobile computing;parallel programming;programming languages","unified programming model;heterogeneous computing;Google TPU;CPUs;programming tasks;programming languages;mobile computing systems","","","","50","","23 Jan 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A graphical dataflow programming model for on-line signal processing on parallel architectures","Yongsen Jiang","Beihua University, Jilin, China","2010 Third International Symposium on Knowledge Acquisition and Modeling","29 Nov 2010","2010","","","107","110","Many real-world signal processing applications require an enormous amount of computational power. When these applications are deployed in on-line settings, many hurdles including stringent timing constraints must be overcome. Additionally, the number of channels feeding mathematical DSP routines is growing rapidly, easily reaching 1,000 to 100,000 channels. These applications have increasingly demanding performance requirements for generating control outputs which interact with real-world processes, where 1ms loop times are not uncommon. In this paper, we describe a graphical dataflow approach capable of yielding the necessary computational power and meeting aggressive timing constraints. We combine this methodology with strategies for targeting a combination of processors including CPUs, FPGAs, and GPUs deployed on standard PCs, workstations, and real-time systems. We demonstrate this approach through case studies on adaptive mirror control for an extremely large telescope and plasma measurement via soft X-ray tomography.","","978-1-4244-8007-4","10.1109/KAM.2010.5646310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5646310","Software Engineering;Parallel Programming;Program Design;Graphical Dataflow","Real time systems;Mirrors;Communities","computer graphic equipment;computerised tomography;coprocessors;data flow computing;field programmable gate arrays;parallel architectures;signal processing;X-ray microscopy","graphical dataflow programming model;online signal processing;parallel architectures;stringent timing constraints;mathematical DSP routines;computational power;aggressive timing constraints;CPU;FPGA;GPU;adaptive mirror control;extremely large telescope;plasma measurement;soft X-ray tomography","","","","6","","29 Nov 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Study on Transient Temperature Field Parallel Computing in Cooling Control Based on a GPU Fourier Method","L. Wang; Y. -s. Zhang","State Key Lab. of Mater. Process. & Die & Mould Technol., Huazhong Univ. of Sci. & Technol. Wuhan, Wuhan, China; State Key Lab. of Mater. Process. & Die & Mould Technol., Huazhong Univ. of Sci. & Technol. Wuhan, Wuhan, China","2010 International Conference on Computational Intelligence and Software Engineering","30 Dec 2010","2010","","","1","4","With the evolution of graphics processing units (GPUs) in floating point operations and programmability, GPU has increasingly become powerful and cost-efficient computing architectures, its range of application has expanded tremendously, especially in the area of computational simulation. In this article, the Fourier method combined with GPU acceleration techniques is applied to simulate large-scale transient temperature field in cooling control. Although it is possible to perform temperature field simulation on a personal computer through Fourier method, when grids are huge, a tremendous CPU calculating time is required which is unacceptable. Thus GPU accelerating technique is used for the parallel processing of Fourier method and a significant speedup can be observed. Following the programming model of compute unified device architecture (CUDA), the iteration process of Fourier method is improved into several kernel functions by the single instruction multiple thread (SIMT) mode and multiple processors of the GPU execute these kernel functions. Numerical results with over 13 speedups demonstrate the efficiency of GPU computing technique of the Fourier method. The absolute error between GPU and CPU is less than 10-12 in double-precision.","","978-1-4244-5391-7","10.1109/CISE.2010.5676712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676712","","Graphics processing unit;Mathematical model;Instruction sets;Equations;Transient analysis;Parallel processing;Computational modeling","computer architecture;control engineering computing;cooling;coprocessors;heat systems","transient temperature field parallel computing;cooling control;GPU Fourier method;graphics processing units;floating point operations;programmability;cost-efficient computing architecture;computational simulation;GPU acceleration;large-scale transient temperature field;compute unified device architecture;single instruction multiple thread mode","","1","","6","","30 Dec 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Towards high performance and usability programming model for heterogeneous HPC platforms","Myungho Lee; Heeseung Jo; Dong Hoon Choi","Dept of Computer Science and Engineering, Myongji University, 38-2 San Namdong, Cheo-In Gu, Yong In, Kyung Ki Do, Korea 449-728; Department of Information Technology, Chonbuk National University, Jeonju, Jeonbuk, Korea 561-756; Korea Institute of Science and Technology Information (KISTI), 245 Dae Hak Ro, Yu Seong Gu, Daejeon, Korea 305-806","2012 8th International Conference on Computing Technology and Information Management (NCM and ICNIT)","16 Aug 2012","2012","1","","51","57","Latest High Performance Computing (HPC) platforms are built with heterogeneous chips such as multicore microprocessors and multicore GPUs (Graphic Processing units), thus they are commonly called as Heterogeneous High Performance Computing (HPC) platforms. Various programming models have been developed and proposed for heterogeneous platforms. However, their wide adoption in the user community is predicted to be limited, because of low performance, low usability due to revealing architectural details in the program which burdens the programmers, and most importantly the limited SIMD execution model which relies on the GPU for most of the computations in the program which can limit the performance. Thus a more general programming model beyond SIMD which is easy to use and leads to high performance needs to be developed. In this paper, we propose methods to achieve this goal by considering all types of parallelism according to Flynn's classification (SIMD, MIMD, MISD). Our proposed methods incorporate these parallelisms in the existing high usability programming models and can lead to significant performance improvements.","","978-89-88678-68-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268469","Heterogenesou HP platformC;programming model;OpenMP;CUDA;OpenACC","Graphics processing unit;Programming;Computational modeling;Registers;Levee;Engines","graphics processing units;multiprocessing systems;parallel processing","heterogeneous HPC platforms;usability programming model;high performance computing;multicore microprocessors;multicore GPU;graphic processing units;SIMD execution model;Flynn classification","","1","","20","","16 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"2D-FMFI SAR application on HPC architectures with OmpSs parallel programming model","F. Kraja; A. Bode; X. Martorell","Chair of Computer Architecture, Department of Informatics, Technische Universität München, Munich, Germany; Chair of Computer Architecture, Department of Informatics, Technische Universität München, Munich, Germany; Computer Architecture Department, Universitat Politecnica de Catalunya, Barcelona Supercomputing Center, Barcelona, Spain","2012 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)","16 Aug 2012","2012","","","115","121","Spacecraft on-board platforms will soon contain high performance off-the-shelf computing components, as the only way to deal with applications which require High Performance Computing (HPC) capabilities. Heterogeneous architectures, give the possibility to profit from specific features of such components, by combining them on the same computing platform. Such architectures integrate different multicore CPUs with many-core accelerators (GPGPUs) so that parts of the same application can efficiently execute on the CPU while other parts can profit more from the GPU features. The problem stands in the way how to program these heterogeneous architectures. In this paper we introduce the OmpSs Programming Model as a framework to program heterogeneous architectures. For benchmarking purposes, we use a Synthetic Aperture Radar (SAR) application, which we parallelized with OmpSs for Symmetric Multi-Processor (SMP) architectures and for hybrid SMP/GPU environments. We also compare the results obtained with OmpSs with the ones obtained with OpenMP in SMP environments and it turns out that OmpSs outperforms OpenMP. When applying OmpSs to the SAR code for hybrid architectures, OmpSs does not offer better performance than CUDA, but it offers support for heterogeneous architectures and it also increases programmer's productivity.","","978-1-4673-1916-4","10.1109/AHS.2012.6268638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268638","OmpSs;OpenMP;CUDA;Space Applications;SAR;SMP;GPU","Graphics processing unit;Computer architecture;Synthetic aperture radar;Image reconstruction;Runtime;Interpolation;Programming","aerospace engineering;aerospace instrumentation;graphics processing units;multiprocessing systems;parallel programming;software packages;space vehicles;synthetic aperture radar","2D-FMFI SAR application;HPC architectures;OmpSs parallel programming model;spacecraft on-board platforms;high performance computing;HPC;heterogeneous architectures;multicore CPU;GPGPU;many-core accelerators;synthetic aperture radar;symmetric multiprocessor architectures;SMP/GPU environments;OpenMP","","","","18","","16 Aug 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Heterogeneous Habanero-C (H2C): A Portable Programming Model for Heterogeneous Processors","D. Majeti; V. Sarkar",NA; NA,"2015 IEEE International Parallel and Distributed Processing Symposium Workshop","1 Oct 2015","2015","","","708","717","Heterogeneous architectures with their diverse architectural features impose significant programmability challenges. Existing programming systems involve non-trivial learning and are not productive, not portable, and are challenging to tune for performance. In this paper, we introduce Heterogeneous Habanero-C (H2C), which is an implementation of the Habanero execution model for modern heterogeneous (CPU + GPU) architectures. The H2C language provides high-level constructs to specify the computation, communication, and synchronization in a given application. H2C also implements novel constructs for task partitioning and locality. The H2C (source-to-source) compiler and runtime framework efficiently map these high-level constructs onto the underlying heterogeneous platform, which can include multiple CPU cores and multiple GPU devices, possibly from different vendors. Experimental evaluations of four applications show significant improvements in productivity, portability, and performance.","","978-1-4673-7684-6","10.1109/IPDPSW.2015.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284378","heterogeneous architectures;programming model;automatic data distribution;OpenCL;event management","Runtime;Graphics processing units;Computer architecture;Optimization;Kernel;Programming","graphics processing units;multiprocessing systems;program compilers","portable programming model;heterogeneous processors;programming systems;Heterogeneous Habanero-C;Habanero execution model;modern heterogeneous architectures;compiler;runtime framework;multiple CPU cores;multiple GPU devices","","6","","20","","1 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"High-speed parallel wavelet algorithm based on CUDA and its application in three-dimensional surface texture analysis","Wang Jianjun; Lu Wenlong; Liu Xiaojun; Jiang Xiangqian","The State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China; The State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China; The State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China; The State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China","2011 International Conference on Electric Information and Control Engineering","27 May 2011","2011","","","2249","2252","A new efficient parallel wavelet algorithm was presented in order to speed up wavelet transform in three dimensional surface texture analysis. It is based NVIDIA's CUDA (Compute Unified Device Architecture), a new general purpose parallel programming model and instruction set architecture that leverage computational problems on GPU more efficient than CPU. Compared with CPU, GPU has evolved into a highly parallel, multithread, multicore processor with tremendous computational horsepower and very high memory bandwidth. GPU is well-suited to address data-parallel computation problems rather than flow controlled problems. Wavelet transform can use data-parallel programming model so data elements will be mapped to parallel processing threads to speed up the computations. CUDA wavelet decomposition and reconstruction algorithms were realized based on the analysis above. Experiments show that the parallelization of the fast wavelet decomposition transform for GPU speedup 34×-38× over CPU, reconstruction transform speedup 29x-33x over CPU.","","978-1-4244-8039-5","10.1109/ICEICE.2011.5778225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5778225","CUDA;GPU;Wavelet;surface texture","Graphics processing unit;Wavelet transforms;Convolution;Surface waves;Wavelet analysis;Instruction sets","computer graphic equipment;computer graphics;coprocessors;general purpose computers;instruction sets;multiprocessing systems;multi-threading;parallel algorithms;parallel architectures;wavelet transforms","high-speed parallel wavelet algorithm;CUDA;three-dimensional surface texture analysis;NVIDIA;compute unified device architecture;general purpose parallel programming model;instruction set architecture;GPU;multithread processor;parallel processor;multicore processor;computational horsepower;memory bandwidth;data-parallel computation problems;data-parallel programming model;reconstruction transform speedup","","2","","13","","27 May 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Gdarts: A GPU-Based Runtime System for Dataflow Task Programming on Dependency Applications","M. Li; Q. Jiang; H. Lin; H. An","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China","2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","26 Mar 2020","2019","","","547","552","Massively multithreaded GPUs achieve considerable performance improvements by thousands of processing cores running simultaneously for compute-intensive applications. However, present parallel programming model suffers significant performance degradation on dependency scenarios, where tasks are assigned into multiple thread blocks and the parallelism is limited by inter-block dependencies. Massively multithreaded GPUs achieve considerable performance improvements by thousands of processing cores running simultaneously for compute-intensive applications. However, present parallel programming model suffers significant performance degradation on dependency scenarios, where tasks are assigned into multiple thread blocks and the parallelism is limited by inter-block dependencies. This paper proposes Gdarts, a dataflow runtime system for GPU workloads with data dependencies. Employing asynchronous task programming, Gdarts builds Stream Multiprocessors (SM) as standalone workers towards fine-granular and independent kernels. Meanwhile, it designs a two-level task scheduler to adapt GPU's hierarchical memory environment. Such a scheme, leveraging the hybrid memory resources, fulfills requirements for workload balancing across SMs, as well as flexible priority scheduling. Based on the improved controllability and flexible support fosr kernel scheduling, Gdarts complements the existing GPU with insights of dataflow diagram by two heuristic schedule approaches, node-degree and data-driven priority.","","978-1-7281-4328-6","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9047478","task based execution;dataflow runtime system;schedule;GPU programming","Task analysis;Graphics processing units;Runtime;Programming;Parallel processing;Schedules;Kernel","coprocessors;graphics processing units;multiprocessing systems;multi-threading;parallel programming;scheduling","Gdarts;GPU-based runtime system;dataflow task programming;GPUs;processing cores;compute-intensive applications;parallel programming model;parallelism;dataflow runtime system;data dependencies;asynchronous task programming;two-level task scheduler;kernel scheduling","","","","20","","26 Mar 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Divide and conquer skeleton on GPU","F. Baghayeri; H. Deldari; D. Bahrepour","Department of Computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran; Department of Computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran; Department of Computer Engineering, Mashhad Branch Islamic Azad University, Mashhad, Iran","2014 International Congress on Technology, Communication and Knowledge (ICTCK)","9 Feb 2015","2014","","","1","6","Parallelism is a suitable approach for speeding up the massive computations of applications, but parallel programming is difficult yet. Algorithmic skeleton is a parallel programming model that provides a high level of abstraction for programmers. This approach uses the pre-defined components to facilitate easier parallel programming. Divide and conquer (DC) is an appropriate parallel pattern for implementation as a skeleton. The solution of the original problem is obtained by dividing it into smaller sub-problems and solving them in parallel. Today, graphics processor unit (GPU) is an attractive computational processor for doing tasks in parallel, because it has a large number of process units. In this paper, divide and conquer skeleton on GPU has been proposed and named OC_GFV.DC_GPU is a divide and conquer skeleton that is implemented on GPU that using a consistent programming interface in C++ for easier parallel programming. Performance of this skeleton has been evaluated by mergesort and sobeledge detection. The results show that obtained speedup at this skeleton is more than 2 on GPU.","","978-1-4799-8021-5","10.1109/ICTCK.2014.7033531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033531","Algorithmic Skeleton;Divide and Conquer Skeleton;Graphics Processor Unit(GPU);Programming Interface in C++;Mergesort;Sobel Edge Detection","Skeleton;Graphics processing units;Parallel processing;Parallel programming;Libraries;Computational modeling","C++ language;divide and conquer methods;edge detection;graphics processing units;parallel programming","parallel programming model;parallel pattern;graphics processor unit;computational processor;divide and conquer skeleton;DC_GPU;consistent programming interface;C++;mergesort;sobeledge skeleton","","1","","12","","9 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Task Scheduling Greedy Heuristics for GPU Heterogeneous Cluster Involving the Weights of the Processor","K. Zhang; B. Wu","Sch. of Comput. Sci., Fudan Univ., Shanghai, China; Sch. of Comput. Sci., Fudan Univ., Shanghai, China","2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum","31 Oct 2013","2013","","","1817","1827","Modern GPUs are gradually used by more and more cluster computing systems as the high performance computing units due to their outstanding computational power, whereas bringing system-level (among different nodes) architectural heterogeneity to cluster. In this paper, based on MPI and CUDA programming model, we aim to investigate task scheduling for GPU heterogeneous cluster by taking into account the system-level heterogeneous characteristics and also involving the weights of the processor (both CPUs and GPUs). At first, based on our GPU heterogeneous cluster, we classify executing tasks to six major classifications according to their parallelism degrees, input data sizes, and processing workloads. Then, aiming to realize the approximately optimal mapping between tasks and computing resources, a task scheduling strategy is presented. In this paper, we present the WSLSA greedy heuristic which can involve the weights of the processor. Besides, we also define two measurement factors for the task assignments. One is the maximum value of total workloads for all task assignments to consider the maximum workloads for the GPU heterogeneity cluster. The other is the distribution of task assignments which can determine the load balance of the task assignments for the GPU heterogeneity cluster. The other is the distribution of task assignments which can determine the load balance of the task assignments for the GPU heterogeneity cluster.","","978-0-7695-4979-8","10.1109/IPDPSW.2013.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651082","Task Scheduling;Greedy Heuristics;GPU Heterogeneous Cluster;WSLSA Greedy Heuristic","Graphics processing units;Kernel;Processor scheduling;Computer architecture;Scheduling;Clustering algorithms","application program interfaces;graphics processing units;greedy algorithms;parallel architectures;scheduling;task analysis;workstation clusters","task scheduling greedy heuristics;GPU heterogeneous cluster;cluster computing systems;high performance computing units;computational power;system-level architectural heterogeneity;MPI;CUDA programming model;system-level heterogeneous characteristics;executing tasks classify;parallelism degrees;data sizes;processing workloads;computing resources;WSLSA greedy heuristic;task assignments;load balance","","2","","27","","31 Oct 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Mini-Gunrock: A Lightweight Graph Analytics Framework on the GPU","Yangzihao Wang; S. Baxter; J. D. Owens",NA; NA; NA,"2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","24 Aug 2017","2017","","","616","626","Existing GPU graph analytics frameworks are typically built from specialized, bottom-up implementations of graph operators that are customized to graph computation. In this work we describe Mini-Gunrock, a lightweight graph analytics framework on the GPU. Unlike existing frameworks, Mini-Gunrock is built from graph operators implemented with generic transform-based data-parallel primitives. Using this method to bridge the gap between programmability and high performance for GPU graph analytics, we demonstrate operator performance on scale-free graphs with an average 1.5x speedup compared to Gunrock's corresponding operator performance. Mini-Gunrock's graph operators, optimizations, and applications code have 10x smaller code size and comparable overall performance vs. Gunrock.","","978-1-5386-3408-0","10.1109/IPDPSW.2017.116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965101","GPU computing;Graph analytics;Programming model;Runtime system","Transforms;Graphics processing units;Kernel;Libraries;Programming;Optimization;Computational modeling","graph theory;graphics processing units;mathematics computing;optimisation;parallel processing","miniGunrock;lightweight graph analytics framework;GPU graph analytics frameworks;graph operators;graph computation;generic transform-based data-parallel primitives;scale-free graphs;optimizations","","","","11","","24 Aug 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Programming GPU Clusters with Shared Memory Abstraction in Software","K. I. Karantasis; E. D. Polychronopoulos","Dept. of Comput. Eng. & Inf., Univ. of Patras, Rio, Greece; Dept. of Comput. Eng. & Inf., Univ. of Patras, Rio, Greece","2011 19th International Euromicro Conference on Parallel, Distributed and Network-Based Processing","24 Mar 2011","2011","","","223","230","As many-core graphics processors gain an increasingly important position concerning the advancements on modern highly concurrent processors, we are experiencing the deployment of the first heterogeneous clusters that are based on GPUs. The attempts to match future expectations in computational power and energy saving with hybrid - GPU-based - clusters are expected to grow in the next years, and much of their success will depend on the provision of the appropriate programming tools. In the current paper we propose a programming model for GPU clusters that is based on shared memory abstraction. We give evidence for the applicability of the proposed model under two cases. In the first case we describe an implementation procedure that involves the utilization of Intel Cluster OpenMP, a cluster-enabled OpenMP implementation. Subsequently, we present an extended version of Pleiad, a cluster middleware which is based on the Java platform. The evaluation of these schemes under two characteristic computationally intensive applications on a 4-node multi-GPU cluster, reveals that such approaches can easily enhance existing GPU software development tools, such as CUDA, and they can lead to a significant acceleration of applications that can benefit from many-core GPU clusters.","2377-5750","978-1-4244-9682-2","10.1109/PDP.2011.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5739005","GPU Clusters;Software DSM;CUDA;OpenMP;Pleiad","Graphics processing unit;Programming;Middleware;Benchmark testing;Computational modeling;Kernel;Multicore processing","computer graphic equipment;coprocessors;Java;middleware;multiprocessing programs;power aware computing;shared memory systems;software tools","GPU cluster programming;shared memory abstraction;many-core graphics processors;energy saving;programming tools;Intel Cluster OpenMP;cluster middleware;Pleiad;Java platform;4-node multiGPU cluster;GPU software development tools","","8","","27","","24 Mar 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Matrix multiplication beyond auto-tuning: Rewrite-based GPU code generation","M. Steuwer; T. Remmelg; C. Dubach","University of Edinburgh, United Kingdom; University of Edinburgh, United Kingdom; University of Edinburgh, United Kingdom","2016 International Conference on Compliers, Architectures, and Sythesis of Embedded Systems (CASES)","17 Nov 2016","2016","","","1","10","Graphics Processing Units (GPUs) are used as general purpose parallel accelerators in a wide range of applications. They are found in most computing systems, and mobile devices are no exception. The recent availability of programming APIs such as OpenCL for mobile GPUs promises to open up new types of applications on these devices. However, producing high performance GPU code is extremely difficult. Subtle differences in device characteristics can lead to large performance variations when different optimizations are applied. As we will see, this is especially true for a mobile GPU such as the ARM Mali GPU which has a very different architecture than desktop-class GPUs. Code optimized and tuned for one type of GPUs is unlikely to achieve the performance potential on another type of GPUs. Auto-tuners have traditionally been an answer to this performance portability challenge. For instance, they have been successful on CPUs for matrix operations, which are used as building blocks in many high-performance applications. However, they are much harder to design for different classes of GPUs, given the wide variety of hardware characteristics. In this paper, we take a different perspective and show how performance portability for matrix multiplication is achieved using a compiler approach. This approach is based on a recently developed generic technique that combines a high-level programming model with a system of rewrite rules. Programs are automatically rewritten in successive steps, where optimizations decision are made.This approach is truly performance portable, resulting in high-performance code for very different types of architectures such as desktop and mobile GPUs. In particular, we achieve a speedup of 1.7x over a state-of-the-art auto-tuner on the ARM Mali GPU.","","978-1-4503-4482-1","10.1145/2968455.2968521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745278","","Graphics processing units;Optimization;Mobile communication;Hardware;Instruction sets;Performance evaluation;Registers","graphics processing units;mathematics computing;matrix multiplication;optimising compilers;rewriting systems;software portability","matrix multiplication;rewrite-based GPU code generation;graphics processing units;general purpose parallel accelerators;programming APIs;OpenCL;mobile GPUs;high performance GPU code;ARM Mali GPU;code optimization;auto-tuners;performance portability;compiler approach;high-level programming model;optimizations decision","","4","","25","","17 Nov 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"GPU-Accelerated Computations for Supersonic Flow Modeling on Hybrid Grids","Z. Tian; J. Lai; F. Yang; H. Li","College of Aerospace Science and Engineering, National University of Defense Technology,Changsha,China; College of Aerospace Science and Engineering, National University of Defense Technology,Changsha,China; College of Aerospace Science and Engineering, National University of Defense Technology,Changsha,China; College of Aerospace Science and Engineering, National University of Defense Technology,Changsha,China","2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)","13 May 2021","2020","","","1391","1397","With its strong floating-point operation capability and high memory bandwidth in data parallelism, the graphics processing unit (GPU) has been widely used in general-purpose computing. GPU-based computations have been extensively applied in the field of computational fluid dynamics (CFD). This paper aims to design an extremely efficient double-precision GPU-accelerated parallel algorithm for supersonic flow computations on hybrid grids. Compute unified device architecture (CUDA) is used as a general-purpose parallel computing platform and programming model to perform parallel computing codes on GPUs. The cell-centered finite volume method based on unstructured grids is used in the spatial discretization of governing equations, whereas the three-stage explicit Runge-Kutta scheme with second-order accuracy is used for temporal discretization. The turbulence is solved by using the K-ω SST two-equation model. Three test cases are studied to validate the computational accuracy of the proposed algorithm. The numerical results agree well with the experiment data, thereby suggesting that the GPU-accelerated parallel algorithm has good accuracy.","","978-1-6654-2314-4","10.1109/ICMCCE51767.2020.00305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421767","graphics processing unit;compute unified device architecture;supersonic flow;hybrid grids;parallel algorithm","Performance evaluation;Computational modeling;Computational fluid dynamics;Graphics processing units;Process control;Life estimation;Programming","computational fluid dynamics;finite volume methods;graphics processing units;grid computing;parallel algorithms;parallel architectures;Runge-Kutta methods;supersonic flow","GPU-accelerated computations;hybrid grids;floating-point operation capability;high memory bandwidth;data parallelism;graphics processing unit;GPU-based computations;computational fluid dynamics;double-precision GPU-accelerated parallel algorithm;supersonic flow computations;compute unified device architecture;programming model;parallel computing codes;cell-centered finite volume method;unstructured grids;three-stage explicit Runge-Kutta scheme;K-ω SST two-equation model;supersonic flow modeling;general-purpose parallel computing platform","","","","30","","13 May 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Multimobile Robot Cooperative Localization Using Ultrawideband Sensor and GPU Acceleration","J. Xin; G. Xie; B. Yan; M. Shan; P. Li; K. Gao","Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an 710048, China.; Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an 710048, China (e-mail: guoxie@xaut.edu.cn); Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an 710048, China.; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW 2006, Australia.; Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an 710048, China.; Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an 710048, China.","IEEE Transactions on Automation Science and Engineering","","2021","PP","99","1","12","To tackle the poor localization accuracy of multimobile robots caused by non-line-of-sight (NLOS) errors in a complex indoor environment and to meet the real-time requirement, this article proposes a multimobile robot cooperative localization system using ultrawideband (UWB) sensor and GPU hardware acceleration. First, a UWB multinode ranging network is established to obtain the relative distance information between robots and anchors. Then, the line-of-sight (LOS) and NLOS errors in distance information are effectively mitigated by using the proposed UWB ranging error mitigation algorithm based on the Bayesian filter. A cooperative particle filter (PF) localization algorithm based on the Gibbs sampling is designed to estimate the position information of each robot at any time. Finally, in order to improve the real-time performance of the collaborative localization system, a parallel Gibbs collaborative localization algorithm that can be accelerated by GPU is proposed considering the characteristics of GPU hardware and CUDA programming model. The experimental results of three TurtleBot2 mobile robots in real scene show that the proposed multimobile robot cooperative localization system using UWB technology can estimate the position information of each robot robustly and accurately, and the localization accuracy is superior to that of the popular extended Kalman filter (EKF) and PF algorithms. It is shown through further evaluations that the proposed parallel algorithm achieves about 3.2 times acceleration effect in the scenarios of three mobile robots. The speed gain is found more significant with more robots, which substantially improves the real-time performance of the cooperative localization system. In the test with seven mobile robots, the speedup is as high as 11.9, that is, the execution time of the algorithm is only 8.39% of that of the original algorithm.","1558-3783","","10.1109/TASE.2021.3117949","National Natural Science Foundation of China(grant numbers:61873200,61873201,U20A20225,61833013); National Key Research and Development Program of China(grant numbers:2018YFB1201500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576116","Cooperative localization;GPU acceleration;multimobile robot systems;real scene;real time","Location awareness;Robots;Robot sensing systems;Distance measurement;Real-time systems;Graphics processing units;Wireless sensor networks","","","","","","","IEEE","15 Oct 2021","","","IEEE","IEEE Early Access Articles"
notebooks/data/ieee_1.csv:"Vispark: GPU-accelerated distributed visual computing using spark","W. Choi; W. Jeong","School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea; School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea","2015 IEEE 5th Symposium on Large Data Analysis and Visualization (LDAV)","7 Dec 2015","2015","","","125","126","With the growing need of big data processing in diverse application domains, MapReduce (e.g., Hadoop) becomes one of the standard computing paradigms for large-scale computing on a cluster system. Despite of its popularity, the current MapReduce framework suffers from inflexibility and inefficiency inherent from its programming model and system architecture. In order to address these problems, we propose Vispark, a novel extension of Spark for GPU-accelerated MapReduce processing on array-based scientific computing and image processing tasks. Vispark provides an easy-to-use, Python-like high-level language syntax and a novel data abstraction for MapReduce programming on a GPU cluster system. Vispark introduces a programming abstraction for accessing neighbor data in the mapper function, which greatly simplifies many image processing tasks using MapReduce by reducing memory footprints and bypassing the reduce stage. We demonstrate the performance of our prototype system on several visual computing tasks, such as image processing, and K-means clustering.","","978-1-4673-8517-6","10.1109/LDAV.2015.7348080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7348080","","Graphics processing units;Sparks;Kernel;Programming;Visualization;Arrays;Image processing","Big Data;computer vision;graphics processing units;parallel programming;pattern clustering;software architecture;visual programming","Vispark;GPU-accelerated distributed visual computing;big data processing;Hadoop;large-scale computing;GPU cluster system;system architecture;Spark;GPU-accelerated MapReduce processing;array-based scientific computing;image processing tasks;Python-like high-level language syntax;data abstraction;MapReduce programming;programming abstraction;neighbor data access;memory footprints reduction;K-means clustering","","2","","3","","7 Dec 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A Data Communication Scheduler for Stream Programs on CPU-GPU Platform","T. Tang; X. Xu; Y. Lin","Nat. Lab. for Parallel & Distrib. Process., Nat. Univ. of Defense Technol., Changsha, China; Nat. Lab. for Parallel & Distrib. Process., Nat. Univ. of Defense Technol., Changsha, China; Nat. Lab. for Parallel & Distrib. Process., Nat. Univ. of Defense Technol., Changsha, China","2010 10th IEEE International Conference on Computer and Information Technology","16 Sep 2010","2010","","","139","146","In recent years, heterogeneous parallel system have become a focus research area in high performance computing field. Generally, in a heterogeneous parallel system, CPU provides the basic computing environment and special purpose accelerator (GPU in this paper) provides high computing performance. However, the overall performance of the system is prone to be limited by the data communication between the CPU and the GPU. Data communication is typically used to synchronize the array on the CPU and the stream (in AMD's terminology) on the GPU. In many cases, programmers just add data synchronization for each GPU invoking independently. It is easy to program in this manner but much redundant communication may be introduced, which will dramatically degrade the overall performance. To alleviate this problem, based on the stream programming model, we propose a heuristic data communication schedule approach in this paper. By analyzing the state transition of stream/array data pair, relaxing the synchronization strategy conditionally and considering optimization for branch and loop control structure, our approach can significantly reduce the redundant data communication in most cases.","","978-1-4244-7548-3","10.1109/CIT.2010.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578445","GPU;data communication schedule;structural analysis","Graphics processing unit;Data communication;Arrays;Kernel;Streaming media;Schedules","computer graphic equipment;coprocessors;data communication;scheduling","data communication scheduler;stream programs;CPU-GPU platform;heterogeneous parallel system;high performance computing field;stream programming model;synchronization strategy;loop control structure","","","","18","","16 Sep 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Performance Analysis of Parallel Programming Paradigms on CPU-GPU Clusters","B. N. Chandrashekhar; H. A. Sanjay; T. Srinivas","Nitte meenakshi Institute of Technology,Department of Information science and Engineering,Benagluru,India,64; Nitte meenakshi Institute of Technology,Department of Information science and Engineering,Benagluru,India,64; Nitte meenakshi Institute of Technology,Department of Information science and Engineering,Benagluru,India,64","2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)","12 Apr 2021","2021","","","646","651","CPU-GPU based cluster computing in today's modern world encompasses the domain of complex and high-intensity computation. To exploit the efficient resource utilization of a cluster, traditional programming paradigm is not sufficient. Therefore, in this article, the performance parallel programming paradigms like OpenMP on CPU cluster and CUDA on GPU cluster using BFS and DFS graph algorithms is analyzed. This article analyzes the time efficiency to traverse the graphs with the given number of nodes in two different processors. Here, CPU with OpenMP platform and GPU with CUDA platform support multi-thread processing to yield results for various nodes. From the experimental results, it is observed that parallelization with the OpenMP programming model using the graph algorithm does not boost the performance of the CPU processors, instead, it decreases the performance by adding overheads like idling time, inter-thread communication, and excess computation. On the other hand, the CUDA parallel programming paradigm on GPU yields better results. The implementation achieves a speed-up of 187 to 240 times over the CPU implementation. This comparative study assists the programmers provocatively and select the optimum choice among OpenMP and CUDA parallel programming paradigms.","","978-1-7281-9537-7","10.1109/ICAIS50930.2021.9395977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395977","Breadth First Search(BFS);Central Processing Unit(CPU);CUDA;Depth First Search(DFS);Graphics Processing Unit(GPU) OpenMP;Performance analysis","Parallel programming;Computational modeling;Graphics processing units;Clustering algorithms;Cluster computing;Performance analysis;Resource management","cluster computing;graph theory;graphics processing units;message passing;multi-threading;parallel architectures;performance evaluation","multithread processing;DFS graph algorithm;BFS graph algorithm;resource utilization;cluster computing;CUDA parallel programming paradigms;CPU processors;OpenMP programming model;parallelization;time efficiency;CPU-GPU clusters;performance analysis","","","","17","","12 Apr 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Towards a parallelization and performance optimization of Viola and Jones algorithm in heterogeneous CPU-GPU mobile system","A. Ghorbel; N. Ben Amor; M. Jallouli","Computer and Embedded Systems Laboratory, Ecole Nationale d'Ingénieurs de Sfax (ENIS), Tunisia; Computer and Embedded Systems Laboratory, Ecole Nationale d'Ingénieurs de Sfax (ENIS), Tunisia; Computer and Embedded Systems Laboratory, Ecole Nationale d'Ingénieurs de Sfax (ENIS), Tunisia","2015 15th International Conference on Intelligent Systems Design and Applications (ISDA)","13 Jun 2016","2015","","","528","532","Parallel computing on heterogeneous multiprocessor architecture is a new technique used to tackle the complexity of actual media applications. Such technique is used on an embedded architecture composed of 2ARMs coupled to a GPU. In this paper, an approach for real time Viola and Jones face detection algorithm using CPU-GPU based platform is presented. First, the application is implemented and parallelized on two identical ARM CortexA9 CPUs using tasks and data levels parallelism. This technique does not achieve the timing objectives. To ensure greater performance while reducing energy ratio, we extend our parallelization technique to support a GPU as an accelerator to perform non graphical tasks. OpenCL, the heterogeneous parallel programming model, is used to ensure communication between CPU and GPU.","2164-7151","978-1-4673-8709-5","10.1109/ISDA.2015.7489172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489172","Parallel computing;GPU;mobile device","Computer architecture;Neon;Graphics processing units;Acceleration;Hardware;Synchronization;Gray-scale","face recognition;graphics processing units;microprocessor chips;mobile computing;parallel programming","Viola algorithm performance optimization;Jones algorithm performance optimization;heterogeneous CPU-GPU mobile system;parallel computing;heterogeneous multiprocessor architecture;media applications;embedded architecture;face detection algorithm;identical ARM CortexA9 CPU;data level parallelism;task level parallelism;energy ratio reduction;parallelization technique;OpenCL;heterogeneous parallel programming model","","1","","14","","13 Jun 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A GPU implementation of tiled belief propagation on Markov Random Fields","H. Eslami; T. Kasampalis; M. Kotsifakou","Department of Computer Science University of Illinois at Urbana-Champaign Urbana, Illinois 61801; Department of Computer Science University of Illinois at Urbana-Champaign Urbana, Illinois 61801; Department of Computer Science University of Illinois at Urbana-Champaign Urbana, Illinois 61801","2013 Eleventh ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE 2013)","21 Nov 2013","2013","","","143","146","In the MEMOCODE Design Contest 2013, we are participating with a parallelized version of tiled belief propagation method for stereo matching. The proposed algorithm is implemented in CUDA programming model to leverage parallel processing capabilities of GPUs. In our solution, the original tiled belief propagation algorithm is combined with a number of novel optimizations specific to parallel programs in CUDA. For the given test inputs, the proposed solution runs in 7.96 milliseconds on Nvidia Tesla C2050, achieving acceptable accuracy with respect to the reference code. To the best of authors' knowledge, there is no prior work in optimizing a parallelized version of the tiled belief propagation algorithm.","","978-1-4799-0905-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6670953","","Message systems;Tiles;Belief propagation;Graphics processing units;Synchronization;Stereo vision;Parallel processing","belief maintenance;graphics processing units;image matching;Markov processes;optimisation;parallel architectures;stereo image processing","GPU implementation;tiled belief propagation;Markov random fields;MEMOCODE design contest 2013;stereo matching;CUDA programming model;parallel processing capabilities;optimizations;parallel programs;Nvidia Tesla C2050","","","","5","","21 Nov 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Exploiting GPUDirect RDMA in Designing High Performance OpenSHMEM for NVIDIA GPU Clusters","K. Hamidouche; A. Venkatesh; A. A. Awan; H. Subramoni; C. -H. Chu; D. K. Panda","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2015 IEEE International Conference on Cluster Computing","29 Oct 2015","2015","","","78","87","GPUDirect RDMA (GDR) brings the high-performance communication capabilities of RDMA networks like InfiniBand (IB) to GPUs (referred to as ""Device""). It enables IB network adapters to directly write/read data to/from GPU memory. Partitioned Global Address Space (PGAS) programming models, such as OpenSHMEM, provide an attractive approach for developing scientific applications with irregular communication characteristics by providing shared memory address space abstractions, along with one-sided communication semantics. However, current approaches and designs of OpenSHMEM on GPU clusters do not take advantage of the GDR features leading to inefficiencies and sub-optimal performance. In this paper, we analyze the performance of various OpenSHMEM operations with different inter-node and intra-node communication configurations (Host-to-Device, Device-to-Device, and Device-to-Host) on GPU based systems. We propose novel designs that ensure ""truly one-sided"" communication for the different inter-/intra-node configurations identified above while working around the hardware limitations. To the best of our knowledge, this is the first work that investigates GDR-aware designs for OpenSHMEM communication operations. Experimental evaluations indicate 2.5X and 7X improvement in point-point communication for intra-node and inter-node, respectively. The proposed framework achieves 2.2µs for an intra-node 8 byte put operation from Host-to-Device, and 3.13µs for an inter-node 8 byte put operation from GPU to remote GPU. With Stencil2D application kernel from SHOC benchmark suite, we observe a 19% reduction in execution time on 64 GPU nodes. Further, for GPULBM application, we are able to improve the performance of the evolution phase by 53% and 45% on 32 and 64 GPU nodes, respectively.","2168-9253","978-1-4673-6598-7","10.1109/CLUSTER.2015.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307568","PGAS;OpenSHMEM;GPU Direct RDMA;CUDA","Graphics processing units;Performance evaluation;Peer-to-peer computing;Runtime;Electronics packaging;Programming;Pipeline processing","application program interfaces;graphics processing units;parallel architectures;shared memory systems","GPUDirect RDMA;GDR;high performance OpenSHMEM;NVIDIA GPU cluster;InfiniBand;IB network;partitioned global address space;PGAS programming model;shared memory address space abstraction;CUDA API","","8","","32","","29 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Designing a unified programming model for heterogeneous machines","M. Garland; M. Kudlur; Y. Zheng","NA; NA; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA","SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis","25 Feb 2013","2012","","","1","11","While high-efficiency machines are increasingly embracing heterogeneous architectures and massive multithreading, contemporary mainstream programming languages reflect a mental model in which processing elements are homogeneous, concurrency is limited, and memory is a flat undifferentiated pool of storage. Moreover, the current state of the art in programming heterogeneous machines tends towards using separate programming models, such as OpenMP and CUDA, for different portions of the machine. Both of these factors make programming emerging heterogeneous machines unnecessarily difficult. We describe the design of the Phalanx programming model, which seeks to provide a unified programming model for heterogeneous machines. It provides constructs for bulk parallelism, synchronization, and data placement which operate across the entire machine. Our prototype implementation is able to launch and coordinate work on both CPU and GPU processors within a single node, and by leveraging the GASNet runtime, is able to run across all the nodes of a distributed-memory machine.","2167-4337","978-1-4673-0806-9","10.1109/SC.2012.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6468503","","Graphics processing units;Programming;Instruction sets;Runtime;Message systems;Parallel processing","distributed memory systems;multi-threading;programming languages","distributed memory machine;GASNet runtime;GPU processors;CPU processors;data placement;Phalanx programming model;CUDA;OpenMP;undifferentiated pool;mental model;contemporary mainstream programming languages;massive multithreading;heterogeneous architectures;high efficiency machines;heterogeneous machines;unified programming model","","19","","25","","25 Feb 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"A case study of OpenCL on an Android mobile GPU","J. A. Ross; D. A. Richie; S. J. Park; D. R. Shires; L. L. Pollock","Engility Corporation, Chantilly, VA, USA; Brown Deer Technology, Forest Hill, MD, USA; U.S. Army Research Laboratory, APG, MD, USA; U.S. Army Research Laboratory, APG, MD, USA; University of Delaware, Newark, USA","2014 IEEE High Performance Extreme Computing Conference (HPEC)","12 Feb 2015","2014","","","1","6","An observation in supercomputing in the past decade illustrates the transition of pervasive commodity products being integrated with the world's fastest system. Given today's exploding popularity of mobile devices, we investigate the possibilities for high performance mobile computing. Because parallel processing on mobile devices will be the key element in developing a mobile and computationally powerful system, this study was designed to assess the computational capability of a GPU on a low-power, ARM-based mobile device. The methodology for executing computationally intensive benchmarks on a handheld mobile GPU is presented, including the practical aspects of working with the existing Android-based software stack and leveraging the OpenCL-based parallel programming model. The empirical results provide the performance of an OpenCL N-body benchmark and an auto-tuning kernel parameterization strategy. The achieved computational performance of the low-power mobile Adreno GPU is compared with a quad-core ARM, an ×86 Intel processor, and a discrete AMD GPU.","","978-1-4799-6233-4","10.1109/HPEC.2014.7040987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7040987","handheld GPU;OpenCL;Android;N-body","Graphics processing units;Mobile communication;Androids;Humanoid robots;Performance evaluation;Benchmark testing;Computer architecture","Android (operating system);graphics processing units;mobile computing;parallel programming","Android mobile GPU;supercomputing;pervasive commodity product;mobile computing;parallel processing;mobile device;ARM;handheld mobile GPU;Android-based software stack;parallel programming;OpenCL N-body benchmark;autotuning kernel parameterization","","7","","25","","12 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Pro++: A Profiling Framework for Primitive-Based GPU Programming","N. Bombieri; F. Busato; F. Fummi","Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy","IEEE Transactions on Emerging Topics in Computing","2 Sep 2018","2018","6","3","382","394","Parallelizing software applications through the use of existing optimized primitives is a common trend that mediates the complexity of manual parallelization and the use of less efficient directivebased programming models. Parallel primitive libraries allow software engineers to map any sequential code to a target many-core architecture by identifying the most computational intensive code sections and mapping them into one or more existing primitives. On the other hand, the spreading of such a primitivebased programming model and the different graphic processing unit (GPU) architectures has led to a large and increasing number of third-party libraries, which often provide different implementations of the same primitive, each one optimized for a specific architecture. From the developer point of view, this moves the actual problem of parallelizing the software application to selecting, among the several implementations, the most efficient primitives for the target platform. This paper presents Pro++, a profiling framework for GPU primitives that allows measuring the implementation quality of a given primitive by considering the target architecture characteristics. The framework collects the information provided by a standard GPU profiler and combines them into optimization criteria. The criteria evaluations are weighed to distinguish the impact of each optimization on the overall quality of the primitive implementation. This paper shows how the tuning of the different weights has been conducted through the analysis of five of the most widespread existing primitive libraries and how the framework has been eventually applied to improve the implementation performance of two standard and widespread primitives.","2168-6750","","10.1109/TETC.2016.2546554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447754","GPUs;performance model;parallel applications","Graphics processing units;Computational modeling;Instruction sets;Computer architecture;Optimization;Measurement;Libraries","graphics processing units;parallel programming;program diagnostics;software architecture;software libraries","third-party libraries;software application;profiling framework;GPU primitives;optimization criteria;primitive-based GPU programming;parallel primitive libraries;computational intensive code sections;parallelization;directive-based programming models;many-core architecture;Pro++;GPU profiler;primitive-based programming model;graphic processing unit architectures","","","","40","IEEE","5 Apr 2016","","","IEEE","IEEE Journals"
notebooks/data/ieee_1.csv:"Atmospheric Model Cluster Performance Evaluation on Hybrid MPI/OpenMP/Cuda Programming Model Platform","C. Osthoff; R. P. Souto; P. L. S. Dias; J. Panetta; P. Lopes","LNCC (Nat. Lab. for Sci. Comput.), Petropolis, Brazil; LNCC (Nat. Lab. for Sci. Comput.), Petropolis, Brazil; LNCC (Nat. Lab. for Sci. Comput.), Petropolis, Brazil; Nat. Lab. for Space Res., INPE, Sao Jose dos Campos, Brazil; Nat. Lab. for Space Res., INPE, Sao Jose dos Campos, Brazil","2012 31st International Conference of the Chilean Computer Science Society","2 Jan 2014","2012","","","216","222","This work discuss the parallel performance of a global numerical simulation model, Ocean-Land-Atmosphere Model (OLAM), on a hybrid multicore/GPU cluster environment, under the following programming models: 1) OLAM MPI implementation, on the multicore system, 2) OLAM hybrid MPI/OpenMP, which starts one MPI process on each node of the platform and one OpenMP thread on each core of the node, 3) OLAM hybrid MPI/OpenMP/Cuda implementation, which starts one MPI process on each node of the platform, one OpenMP threads on each core of the node and Cuda kernels on the GPUs. The results shows that the adopted programming model impacts significantly the performance of the application. We show that as we increase the number of cores, the OLAM MPI parallel implementation running one process on each cluster core executes faster than the other implementations.","1522-4902","978-1-4799-2938-2","10.1109/SCCC.2012.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694092","Cluster;Multicore;GPU;Atmospheric Numerical Simulation Model;High Performance Computing","Atmospheric modeling;Graphics processing units;Computational modeling;Numerical models;Multicore processing;Kernel;Performance evaluation","atmospheric techniques;geophysics computing;graphics processing units;message passing;multiprocessing systems;multi-threading;parallel architectures","atmospheric model cluster performance evaluation;hybrid MPI/OpenMP/Cuda programming model platform;parallel performance;global numerical simulation model;ocean-land-atmosphere model;hybrid multicore/GPU cluster environment;programming models;multicore system;MPI process;OpenMP thread;Cuda kernels;OLAM MPI parallel implementation;cluster core","","1","","14","","2 Jan 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Performance and Power Efficiency Analysis of the Symmetric Cryptograph on Two Stream Processor Architectures","G. Xu; H. An; G. Liu; P. Yao; M. Xu; W. Han; X. Li; X. Hao","Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","17 Nov 2009","2009","","","917","920","Multimedia and some scientific applications have achieved good performance on the stream processor architecture by employing the stream programming model. In order to find out the way to accelerate the symmetric cryptograph on stream processor, we implement and analyze cryptograph algorithms on different stream processors in this paper. Four cipher algorithms including RC5, AES, TWOFISH and 3DES in ECB model are implemented on three platforms, which are stream processor SPI Storm SP16-G160, NVIDIA GeForce 9800GTX, Intel Core2 dual-core processor E7300. The difference of architecture between two stream processors and the character of programming model are described. When we compare throughput rate of these applications, 9800GTX is shown with 4-30x performance improvement over E7300, SP16 achieves the highest power efficiency and obtains 15-20x increase over E7300 in Gops/Watt.","","978-1-4244-4717-6","10.1109/IIH-MSP.2009.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337159","cryptograph;stream processor;GPU;stream programming model;accelerate;power efficiency","Performance analysis;Cryptography;Streaming media;Computer architecture;Acceleration;Signal processing algorithms;Storms;Multimedia systems;High performance computing;Hardware","computer architecture;cryptography;microcomputers;parallel processing;performance evaluation","performance analysis;power efficiency analysis;symmetric cryptograph;stream processor architecture;multimedia application;scientific application;stream programming model;cryptograph algorithms;cipher algorithms;RC5;AES;TWOFISH;3DES;SPI Storm SP16-G160;NVIDIA GeForce 9800GTX;Intel Core2 dual-core processor E7300","","1","","7","","17 Nov 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"Dense linear algebra solvers for multicore with GPU accelerators","S. Tomov; R. Nath; H. Ltaief; J. Dongarra","Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA","2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)","24 May 2010","2010","","","1","8","Solving dense linear systems of equations is a fundamental problem in scientific computing. Numerical simulations involving complex systems represented in terms of unknown variables and relations between them often lead to linear systems of equations that must be solved as fast as possible. We describe current efforts toward the development of these critical solvers in the area of dense linear algebra (DLA) for multicore with GPU accelerators. We describe how to code/develop solvers to effectively use the high computing power available in these new and emerging hybrid architectures. The approach taken is based on hybridization techniques in the context of Cholesky, LU, and QR factorizations. We use a high-level parallel programming model and leverage existing software infrastructure, e.g. optimized BLAS for CPU and GPU, and LAPACK for sequential CPU processing. Included also are architecture and algorithm-specific optimizations for standard solvers as well as mixed-precision iterative refinement solvers. The new algorithms, depending on the hardware configuration and routine parameters, can lead to orders of magnitude acceleration when compared to the same algorithms on standard multicore architectures that do not contain GPU accelerators. The newly developed DLA solvers are integrated and freely available through the MAGMA library.","","978-1-4244-6534-7","10.1109/IPDPSW.2010.5470941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470941","Dense Linear Algebra Solvers;GPU Accelerators;Multicore;MAGMA;Hybrid Algorithms","Linear algebra;Multicore processing;Acceleration;Iterative algorithms;Linear accelerators;Linear systems;Equations;Computer architecture;Scientific computing;Numerical simulation","coprocessors;linear algebra;mathematics computing;matrix decomposition;multiprocessing systems;optimisation;parallel programming","dense linear algebra solvers;multicore systems;GPU accelerators;graphics processing unit;hybridization techniques;Cholesky factorization;LU factorization;QR factorization;parallel programming model;optimized BLAS software;LAPACK software;architecture-specific optimization;algorithm-specific optimization;MAGMA library","","117","2","14","","24 May 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_1.csv:"An Efficient GPU Implementation for Large Scale Individual-Based Simulation of Collective Behavior","U. Erra; B. Frola; V. Scarano; I. Couzin","Dipt. di Mat. e Inf., Univ. della Basilicata, Italy; Dipt. di Mat. e Applicazioni, Univ. di Salerno, Salerno, Italy; Dipt. di Mat. e Applicazioni, Univ. di Salerno, Salerno, Italy; Dept. of Ecology & Evolutionary Biol., Princeton Univ., Princeton, NJ, USA","2009 International Workshop on High Performance Computational Systems Biology","30 Oct 2009","2009","","","51","58","In this work we describe a GPU implementation for an individual-based model for fish schooling. In this model each fish aligns its position and orientation with an appropriate average of its neighbors' positions and orientations. This carries a very high computational cost in the so-called nearest neighbors search. By leveraging the GPU processing power and the new programming model called CUDA we implement an efficient framework which permits to simulate the collective motion of high-density individual groups. In particular we present as a case study a simulation of motion of millions of fishes. We describe our implementation and present extensive experiments which demonstrate the effectiveness of our GPU implementation.","","978-0-7695-3809-9","10.1109/HiBi.2009.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5298705","gpu;individual-based model;large scale simulation","Large-scale systems;Biological system modeling;Computational modeling;Marine animals;Educational institutions;Computational systems biology;Birds;Organisms;Graphics;Sorting","artificial life;C language;computer graphics;digital simulation;search problems","large scale individual-based simulation;collective behavior;fish schooling;computational cost;nearest neighbor search;GPU processing power;CUDA programming model;graphics processing unit;collective motion;fish motion simulation","","15","","25","","30 Oct 2009","","","IEEE","IEEE Conferences"
notebooks/data/exclude.ris:TI  - Integral image computation on GPU
notebooks/data/ieee_3.csv:"MR-Graph: A Customizable GPU MapReduce","Z. Qiao; S. Liang; H. Jiang; S. Fu","Dept. of Comput. Sci. & Eng., Univ. of North Texas, Denton, TX, USA; Dept. of Comput. Sci. & Eng., Univ. of North Texas, Denton, TX, USA; Dept. of Comput. Sci., Arkansas State Univ., AR, USA; NA","2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing","7 Jan 2016","2015","","","417","422","The MapReduce programming model has been widely used in Big Data and Cloud applications. Criticism on its inflexibility when being applied to complicated scientific applications recently emerges. Several techniques have been proposed to enhance its flexibility. However, some of them exert special requirements on applications, while others fail to support the increasingly popular coprocessors, such as Graphics Processing Unit (GPU). In this paper, we propose MR-Graph, a customizable and unified framework for GPU-based MapReduce, which aims to improve the flexibility, scalability and performance of MapReduce. MR-Graph addresses the limitations and restrictions of the traditional MapReduce execution paradigm. The three execution modes integrated in MR-Graph facilitates users to write their applications in a more flexible fashion by defining a Map and Reduce function call graph. MR-Graph efficiently explores the memory hierarchy in GPUs to reduce the data transfer overhead between execution stages and accommodate big data applications. We have implemented a prototype of MR-Graph and experimental results show the effectiveness of using MR-Graph for flexible and scalable GPU-based MapReduce computing.","","978-1-4673-9300-3","10.1109/CSCloud.2015.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371516","MapReduce;GPU;Configurable;Flexible;Iterative;Recursive","Graphics processing units;Programming;Parallel processing;Computational modeling;Big data;Cloud computing;Data models","graphics processing units;parallel programming","MR-Graph framework;GPU MapReduce;MapReduce programming model;graphics processing unit;MapReduce execution paradigm;memory hierarchy;Big Data applications","","","","15","","7 Jan 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Performance Optimization of Top-k Queries on GPU","T. Luo; G. -Z. Sun; G. Chen","Key Lab. on High Performance Comput., Anhui Province Univ. of Sci. & Technol. of China, Hefei, China; Key Lab. on High Performance Comput., Anhui Province Univ. of Sci. & Technol. of China, Hefei, China; Key Lab. on High Performance Comput., Anhui Province Univ. of Sci. & Technol. of China, Hefei, China","2011 Fourth International Symposium on Parallel Architectures, Algorithms and Programming","12 Jan 2012","2011","","","9","13","With the development of web search engines, the concern on real-time performance of Top-k queries has attracted more and more attention. The author studies implement of classic algorithm - No Random Access Algorithm in order to optimize performance of Top-k queries on GPU. We give a novel GPU algorithm by using the features of CUDA's programming model. Experiment results show that an implementation of the algorithm on one GPU runs more than 7000 times faster than a single core implementation on a latest CPU.","2168-3042","978-1-4577-1808-3","10.1109/PAAP.2011.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128467","GPU;performance optimization;top-k queries","Graphics processing unit;Instruction sets;Upper bound;Programming;Algorithm design and analysis;Optimization;Vectors","graphics processing units;optimisation;parallel architectures;parallel programming;performance evaluation;query processing","performance optimization;top-k queries;GPU;Web search engines;classic algorithm;no random access algorithm;CUDA programming model","","1","","15","","12 Jan 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Towards an Effective Unified Programming Model for Many-Cores","A. L. Varbanescu; P. Hijma; R. van Nieuwpoort; H. Bal","Comput. Syst. Group, Vrije Univ. Amsterdam, Amsterdam, Netherlands; Comput. Syst. Group, Vrije Univ. Amsterdam, Amsterdam, Netherlands; Comput. Syst. Group, Vrije Univ. Amsterdam, Amsterdam, Netherlands; Comput. Syst. Group, Vrije Univ. Amsterdam, Amsterdam, Netherlands","2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum","1 Sep 2011","2011","","","681","692","Building an effective programming model for many-core processors is challenging. On the one hand, the increasing variety of platforms and their specific programming models force users to take a hardware-centric approach not only for implementing parallel applications, but also for designing them. This approach diminishes portability and, eventually, limits performance. On the other hand, to effectively cope with the increased number of large-scale workloads that require parallelization, a portable, application-centric programming model is desirable. Such a model enables programmers to focus first on extracting and exploiting parallelism from their applications, as opposed to generating parallelism for specific hardware, and only second on platform-specific implementation and optimizations. In this paper, we first present a survey of programming models designed for programming three families of many-cores: general purpose many-cores (GPMCs), graphics processing units (GPUs), and the Cell/B.E.. We analyze the usability of these models, their ability to improve platform programmability, and the specific features that contribute to this improvement. Next, we also discuss two types of generic models: parallelism-centric and application-centric. We also analyze their features and impact on platform programmability. Based on this analysis, we recommend two application-centric models (OmpSs and OpenCL) as promising candidates for a unified programming model for many-cores and we discuss potential enhancements for them.","1530-2075","978-1-61284-425-1","10.1109/IPDPS.2011.210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6008837","","Programming;Parallel processing;Computer architecture;Data models;Concurrent computing;Computational modeling;Productivity","application program interfaces;computer graphic equipment;coprocessors;multiprocessing systems","unified programming model;many-core processors;application-centric programming model;parallelism generation;general purpose many-cores;GPMC;graphics processing units;GPU;Cell/B.E;parallelism-centric model;OmpS;OpenCL;multicore processors;many-core accelerators","","7","","26","","1 Sep 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Lit: A high performance massive data computing framework based on CPU/GPU cluster","Y. Zhai; E. Mbarushimana; W. Li; J. Zhang; Y. Guo","Beijing Engineering Research Center of Massive Language Information Processing and Cloud Computing Application, School of Computer Science, Beijing Institute of Technology, China 100081; Beijing Engineering Research Center of Massive Language Information Processing and Cloud Computing Application, School of Computer Science, Beijing Institute of Technology, China 100081; Science and Technology on Complex Systems Simulation Laboratory, Beijing, China; Science and Technology on Complex Systems Simulation Laboratory, Beijing, China; Beijing Engineering Research Center of Massive Language Information Processing and Cloud Computing Application, School of Computer Science, Beijing Institute of Technology, China 100081","2013 IEEE International Conference on Cluster Computing (CLUSTER)","9 Jan 2014","2013","","","1","8","Big data processing is receiving significant amount of interest as an important technology to reveal the information behind the data, such as trends, characteristics, etc. MapReduce is considered as the most efficient distributed parallel data processing framework. However, some high-end applications, especially some scientific analyses have both data-intensive and computation-intensive features. Current big data processing techniques like Hadoop are not designed for computation-intensive applications, thus have insufficient computation power. In this paper, we presented Lit, a high performance massive data computing framework based on CPU/GPU cluster. Lit integrated GPU with Hadoop to improve the computational power of each node in the cluster. Since the architecture and programming model of GPU is different from CPU, Lit provided an annotation based approach to automatically generate CUDA codes from Hadoop codes. Lit hided the complexity of programming on CPU/GPU cluster by providing extended compiler and optimizer. To utilize the simplified programming, scalability and fault tolerance benefits of Hadoop and combine them with the high performance computation power of GPU, Lit extended the Hadoop by applying a GPUClassloader to detect the GPU, generate and compile CUDA codes, and invoke the shared library. Our experimental results show that Lit can achieve an average speedup of 1x to 3x on three typical applications over Hadoop.","2168-9253","978-1-4799-0898-1","10.1109/CLUSTER.2013.6702614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702614","","Graphics processing units;Computational modeling;Handheld computers;Data models;Load modeling;Semantics","Big Data;fault tolerant computing;graphics processing units;parallel architectures;program compilers","Lit;high performance massive data computing framework;CPU cluster;GPU cluster;Big Data processing;MapReduce;distributed parallel data processing framework;data-intensive feature;computation-intensive feature;programming model;annotation based approach;CUDA code generation;Hadoop codes;extended compiler;extended optimizer;fault tolerance;high performance computation power;GPUClassloader;GPU detection;CUDA code compiling","","6","1","19","","9 Jan 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"LOOG: Improving GPU Efficiency With Light-Weight Out-Of-Order Execution","K. Iliakis; S. Xydis; D. Soudris","National Technical University of Athens, Zografou, Greece; National Technical University of Athens, Zografou, Greece; National Technical University of Athens, Zografou, Greece","IEEE Computer Architecture Letters","10 Jan 2020","2019","18","2","166","169","GPUs are one of the most prevalent platforms for accelerating general-purpose workloads due to their intuitive programming model, computing capacity, and cost-effectiveness. GPUs rely on massive multi-threading and fast context switching to overlap computations with memory operations. Among the diverse GPU workloads, there exists a class of kernels that fail to maintain a sufficient number of active warps to hide the latency of memory operations, and thus suffer from frequent stalling. We observe that these kernels will benefit from increased levels of Instruction-Level Parallelism and we propose a novel architecture with lightweight Out-Of-Order execution capability. To minimize hardware overheads, we carefully design our extension to highly re-use the existing micro-architectural structures. We show that the proposed architecture outperforms traditional platforms by 15 to 46 percent on average for low occupancy kernels, with an area overhead of 0.74 to 3.94 percent. Finally, we prove the potential of our proposal as a GPU u-arch alternative, by providing a 5 percent speedup over a wide collection of 63 general-purpose kernels with as little as 0.74 percent area overhead.","1556-6064","","10.1109/LCA.2019.2951161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890662","GPGPU;Out-of-Order execution;micro-architecture","Graphics processing units;Kernel;Registers;Radio access technologies;Copper;Radio frequency;Out of order","graphics processing units;multi-threading;parallel architectures;storage management","light-weight out-of-order execution;out-of-order execution capability;GPU u-arch;general-purpose kernels;area overhead;low occupancy kernels;hardware overheads;instruction-level parallelism;stalling;active warps;GPU workloads;memory operations;massive multithreading;cost-effectiveness;intuitive programming model;general-purpose workloads;GPU efficiency;LOOG","","","","18","IEEE","4 Nov 2019","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Template matching of aerial images using GPU","N. Nazneen; M. Shafiq; A. Hameed","KICSIT, Rawalpindi, Pakistan; CESAT, Islamabad, Pakistan; CESAT, Islamabad, Pakistan","2016 13th International Bhurban Conference on Applied Sciences and Technology (IBCAST)","10 Mar 2016","2016","","","206","212","During the last decade, processor architectures have emerged with hundreds and thousands of high speed processing cores in a single chip. These cores can work in parallel to share a work load for faster execution. This paper presents performance evaluations on such multicore and many-core devices by mapping a computationally expensive correlation kernel of a template matching process using various programming models. The work builds a base performance case by a sequential mapping of the algorithm on an Intel processor. In the second step, the performance of the algorithm is enhanced by parallel mapping of the kernel on a shared memory multicore machine using OpenMP programming model. Finally, the Normalized Cross-Correlation (NCC) kernel is scaled to map on a many-core K20 GPU using CUDA programming model. In all steps, the correctness of the implementation of algorithm is taken care by comparing computed data with reference results from a high level implementation in MATLAB. The performance results are presented with various optimization techniques for MATLAB, Sequential, OpenMP and CUDA based implementations. The results show that GPU based implementation achieves 32x and 5x speed-ups respectively to the base case and multicore implementations respectively. Moreover, using inter-block sub-sampling on an 8-bit 4000×4000 reference gray-scale image achieves the execution time upto 2.8sec with an error growth less than 20% for the selected templates of size 96×96.","2151-1411","978-1-4673-9127-6","10.1109/IBCAST.2016.7429878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429878","","Graphics processing units;MATLAB;Kernel;Computational modeling;Correlation;Instruction sets;Multicore processing","graphics processing units;image matching;parallel programming;shared memory systems","template matching;aerial image matching;graphics processing unit;multicore devices;many-core devices;correlation kernel mapping;sequential mapping;parallel mapping;shared memory multicore machine;OpenMP programming model;normalized cross-correlation kernel;NCC kernel;many-core K20 GPU;CUDA programming model;Compute Unified Device Architecture;Matlab;inter-block sub-sampling","","","","13","","10 Mar 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Sparse Matrix Formats Evaluation and Optimization on a GPU","M. R. Hugues; S. G. Petiton","TOTAL Exploration & Production, Pau, France; Lab. d'Inf. Fondamentale de Lille, CNRS/LIFL, Lille, France","2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC)","27 Sep 2010","2010","","","122","129","The data parallel programming model comes back with massive multicore architectures. The GPU is one of these and offers important possibilities to accelerate linear algebra. However, the irregular structure of sparse matrix operations generates problems with this programming model to obtain efficient performance. This depends on the used format to store values and the matrix structure. The sparse matrix-vector product (SpMV) is one of the most used kernel in scientific computing and is the main performance source of iterative methods. We propose an evaluation and optimization of several sparse formats for the SpMV kernel which have succeeded at the time of data parallel computer. This study is realized by analyzing the performances following the distribution of the non zeros values in the matrix to determine the best and the worst reachable value. The results show that all sparse formats converge to the same efficiency and perform poorly with a strong distribution of elements.","","978-1-4244-8335-8","10.1109/HPCC.2010.85","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581446","Sparse Format;SpMV;GPU;Many-Core;Data Parallel Programming","Arrays;Sparse matrices;Graphics processing unit;Indexes;Instruction sets;Artificial neural networks;Finite element methods","computer graphic equipment;coprocessors;iterative methods;multiprocessing systems;parallel programming;sparse matrices","sparse matrix format evaluation;GPU;sparse matrix format optimization;data parallel programming model;massive multicore;linear algebra;sparse matrix vector product;iterative method;SpMV kernel","","10","","14","","27 Sep 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Beyond the Socket: NUMA-Aware GPUs","U. Milic; O. Villa; E. Bolotin; A. Arunkumar; E. Ebrahimi; A. Jaleel; A. Ramirez; D. Nellans","Barcelona Supercomputing Center (BSC), Universitat Politècnica de Catalunya (UPC); NVIDIA; NVIDIA; Arizona State University; NVIDIA; NVIDIA; Google; NVIDIA","2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)","11 Apr 2019","2017","","","123","135","GPUs achieve high throughput and power efficiency by employing many small single instruction multiple thread (SIMT) cores. To minimize scheduling logic and performance variance they utilize a uniform memory system and leverage strong data parallelism exposed via the programming model. With Moore’s law slowing, for GPUs to continue scaling performance (which largely depends on SIMT core count) they are likely to embrace multi-socket designs where transistors are more readily available. However when moving to such designs, maintaining the illusion of a uniform memory system is increasingly difficult. In this work we investigate multi-socket non-uniform memory access (NUMA) GPU designs and show that significant changes are needed to both the GPU interconnect and cache architectures to achieve performance scalability. We show that application phase effects can be exploited allowing GPU sockets to dynamically optimize their individual interconnect and cache policies, minimizing the impact of NUMA effects. Our NUMA-aware GPU outperforms a single GPU by $1.5 \times, 2.3 \times$, and $3.2 \times$ while achieving 89%, 84%, and 76% of theoretical application scalability in 2, 4, and 8 sockets designs respectively. Implementable today, NUMA-aware multi-socket GPUs may be a promising candidate for scaling GPU performance beyond a single socket.CCS CONCEPTS• Computing methodologies → Graphics processors; • Computer systems organization → Single instruction, multiple data;","2379-3155","978-1-4503-4952-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686671","Graphics Processing Units;Multi-socket GPUs;NUMA Systems","Graphics processing units;Bandwidth;Programming;Runtime;Sockets;Transistors;Throughput","cache storage;graphics processing units;integrated circuit design;multiprocessing systems;multi-threading;power aware computing","multisocket nonuniform memory access GPU designs;cache architectures;performance scalability;application phase effects;GPU sockets;individual interconnect;cache policies;NUMA effects;single GPU;scaling GPU performance;single socket;high throughput;power efficiency;single instruction multiple thread cores;scheduling logic;performance variance;uniform memory system;programming model;Moore's law slowing;scaling performance;SIMT core count;multisocket designs;NUMA-aware multisocket GPU;strong data parallelism","","","","63","","11 Apr 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A Branch-and-Bound algorithm using multiple GPU-based LP solvers","X. Meyer; B. Chopard; P. Albuquerque","Dept. of Computer Science, University of Geneva, Switzerland; Dept. of Computer Science, University of Geneva, Switzerland; Institute for Informatics & Telecommunications, University of Applied Sciences of Western Switzerland, Geneva, Switzerland","20th Annual International Conference on High Performance Computing","17 Apr 2014","2013","","","129","138","The Branch-and-Bound (B&B) method is a well-known optimization algorithm for solving integer linear programming (ILP) models in the field of operations research. It is part of software often employed by businesses for finding solutions to problems such as airline scheduling problems. It operates according to a divide-and-conquer principle by building a tree-like structure with nodes that represent linear programming (LP) problems. A LP solver commonly used to process the nodes is the simplex method. Nowadays its sequential implementation can be found in almost all commercial ILP solvers. In this paper, we present a hybrid CPU-GPU implementation of the B&B algorithm. The B&B tree is managed by the CPU, while the revised simplex method is mainly a GPU implementation, relying on the CUDA technology of NVIDIA. The CPU manages concurrently multiple instances of the LP solver. The principal difference with a sequential implementation of the B&B algorithm pertains to the LP solver, provided that the B&B tree is managed with the same strategy. We thus compared our GPU-based implementation of the revised simplex to a well-known open-source sequential solver, named CLP, of the COIN-OR project. For given problem densities, we measured a size threshhold beyond which our GPU implementation outperformed its sequential counterpart.","1094-7256","978-1-4799-0730-4","10.1109/HiPC.2013.6799105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799105","","Graphics processing units;Linear programming;Indexes;Mathematical model;Standards;Central Processing Unit;Equations","graphics processing units;integer programming;linear programming;public domain software;scheduling;travel industry;tree searching","branch-and-bound algorithm;multiple GPU-based LP solver;B&B method;optimization algorithm;integer linear programming model;ILP model;operations research;airline scheduling problem;divide-and-conquer principle;tree-like structure;LP problem;hybrid CPU-GPU implementation;B&B algorithm;B&B tree;simplex method;CUDA technology;NVIDIA;sequential implementation;GPU-based implementation;open-source sequential solver;CLP;COIN-OR project","","4","","33","","17 Apr 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Early evaluation of directive-based GPU programming models for productive exascale computing","S. Lee; J. S. Vetter","Oak Ridge Nat. Lab., Oak Ridge, TN, USA; Oak Ridge Nat. Lab., Georgia Inst. of Technol., Atlanta, GA, USA","SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis","25 Feb 2013","2012","","","1","11","Graphics Processing Unit (GPU)-based parallel computer architectures have shown increased popularity as a building block for high performance computing, and possibly for future Exascale computing. However, their programming complexity remains as a major hurdle for their widespread adoption. To provide better abstractions for programming GPU architectures, researchers and vendors have proposed several directive-based GPU programming models. These directive-based models provide different levels of abstraction, and required different levels of programming effort to port and optimize applications. Understanding these differences among these new models provides valuable insights on their applicability and performance potential. In this paper, we evaluate existing directive-based models by porting thirteen application kernels from various scientific domains to use CUDA GPUs, which, in turn, allows us to identify important issues in the functionality, scalability, tunability, and debuggability of the existing models. Our evaluation shows that directive-based models can achieve reasonable performance, compared to hand-written GPU codes.","2167-4337","978-1-4673-0806-9","10.1109/SC.2012.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6468490","","Graphics processing units;Programming;Computational modeling;Optimization;Data models;Computer architecture;Kernel","graphics processing units;parallel architectures;parallel programming;software performance evaluation","directive-based GPU programming model early evaluation;productive exascale computing;graphics processing unit-based parallel computer architectures;high performance computing;exascale computing;programming complexity;GPU architecture programming;abstraction levels;performance potential;programming effort levels;CUDA GPUs;hand-written GPU codes;program scalability;program functionality;program tunability;program debuggability","","40","","25","","25 Feb 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GAGM: Genome assembly on GPU using mate pairs","A. Jain; A. Garg; K. Paul","Dept. of Computer Science and Engineering, IIT Delhi, New Delhi, India; Dept. of Computer Science and Engineering, IIT Delhi, New Delhi, India; Dept. of Computer Science and Engineering, IIT Delhi, New Delhi, India","20th Annual International Conference on High Performance Computing","17 Apr 2014","2013","","","176","185","Genome fragment assembly has long been a time and computation intensive problem in the field of bioinformatics. Many parallel assemblers have been proposed to accelerate the process but there hasn't been any effective approach proposed for GPUs. Also with the increasing power of GPUs, applications from various research fields are being parallelized to take advantage of the massive number of “cores” available in GPUs. In this paper we present the design and development of a GPU based assembler (GAGM) for sequence assembly using Nvidia's GPUs with the CUDA programming model. Our assembler utilizes the mate pair reads produced by the current NGS technologies to build paired de Bruijn graph. Every paired read is broken into paired k-mers and l-mers. Every paired k-mer represents a vertex and paired l-mers are mapped as edges. Contigs are formed by grouping the regions of graph which can be unambiguously connected. We present parallel algorithms for k - mer extraction, paired de Bruijn graph construction and grouping of edges. We have benchmarked GAGM on four bacterial genomes. Our results show that the design on GPU is effective in terms of time as well as the quality of assembly produced.","1094-7256","978-1-4799-0730-4","10.1109/HiPC.2013.6799107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799107","parallel processing;bioinformatics;GPU;genome assembly","Graphics processing units;Genomics;Bioinformatics;Benchmark testing;DNA;Encoding","biocomputing;graph theory;graphics processing units;parallel algorithms;parallel architectures;program assemblers","GAGM;mate pairs;genome fragment assembly;bioinformatics;parallel assemblers;GPU based assembler;sequence assembly;CUDA programming model;NGS technologies;paired read;paired k-mers;paired l-mers;vertex;parallel algorithms;k-mer extraction;paired de Bruijn graph construction;edge grouping;bacterial genomes","","6","","31","","17 Apr 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Task Scheduling for GPU Heterogeneous Cluster","K. Zhang; B. Wu","Sch. of Comput. Sci., Fudan Univ., Shanghai, China; Sch. of Comput. Sci., Fudan Univ., Shanghai, China","2012 IEEE International Conference on Cluster Computing Workshops","20 Nov 2012","2012","","","161","169","Modern GPUs are gradually used by more and more cluster computing systems as the high performance computing units due to their outstanding computational power, whereas bringing node-level architectural heterogeneity to cluster. In this paper, based on MPI and CUDA programming model, we aim to investigate task scheduling for GPU heterogeneous cluster by taking into account the node-level heterogeneous characteristics. At first, based on our GPU heterogeneous cluster, we classify executing tasks to six major classifications according to their parallelism degrees, input data sizes, and processing workloads. Then, aiming to realize optimal mapping between tasks and computing resources, a task scheduling strategy is presented. The strategy consists of two key algorithms. The first is packing task algorithm (PTA) used to pack multiple tasks into a single task, such packing provides us a way of task classification converting according to the characteristic of computing resources. The second is system-level scheduling algorithm(SLSA) used to distribute parallel and sequential tasks to corresponding nodes, to maintain the load balance.","","978-0-7695-4844-9","10.1109/ClusterW.2012.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6355860","Task Scheduling;GPU Heterogeneous Cluster;PTA Algorithm;SLSA Algorithm","Graphics processing units;Kernel;Processor scheduling;Scheduling;Clustering algorithms;Computer architecture","application program interfaces;graphics processing units;message passing;parallel architectures;pattern classification;pattern clustering;resource allocation;scheduling","task scheduling strategy;GPU heterogeneous cluster;cluster computing systems;high performance computing units;node-level architectural heterogeneity;MPI;CUDA programming model;node-level heterogeneous characteristics;parallelism degrees;input data sizes;processing workloads;packing task algorithm;PTA;task classification;system-level scheduling algorithm;SLSA;parallel tasks;sequential tasks;load balance","","4","2","25","","20 Nov 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Parallelized computation for Edge Histogram Descriptor using CUDA on the Graphics Processing Units (GPU)","A. A. Mohammadabadi; A. Chalechale; H. Heidari","Department of Computer Engineering, Razi University, Kermanshah, Iran; Department of Computer Engineering, Razi University, Kermanshah, Iran; Department of Computer Engineering, Razi University, Kermanshah, Iran","The 17th CSI International Symposium on Computer Architecture & Digital Systems (CADS 2013)","20 Jan 2014","2013","","","9","14","Most image processing algorithms are inherently parallel, so multithreading processors are suitable in such applications. In huge image databases, image processing takes very long time for run on a single core processor because of single thread execution of algorithms. GPU is more common in most image processing applications due to multithread execution of algorithms, programmability and low cost. In this paper we show how to implement the MPRG-7 Edge Histogram Descriptor in parallel using CUDA programming model on a GPU. The Edge Histogram Descriptor describes the distribution of various types of edges with a histogram that can be a tool for image matching. This feature is applied to search images from a database which are similar to a query image. We evaluated the retrieval of the proposed technique using recall, precision, and average precision measures. Experimental results showed that parallel implementation led to an average speed up of 14.74×over the serial implementation. The average precision and the average recall of presented method are 67.02% and 55.00% respectively.","2325-937X","978-1-4799-0565-2","10.1109/CADS.2013.6714231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714231","content based image retrieval;CUDA;edge histogram descriptor;GPU","Image edge detection;Graphics processing units;Instruction sets;Feature extraction;Histograms;Image retrieval;Kernel","edge detection;graphics processing units;image matching;image retrieval;multi-threading;parallel architectures;visual databases","parallelized computation;MPRG-7 edge histogram descriptor;CUDA programming model;graphics processing unit;GPU;image processing algorithm;multithreading processors;image database;image matching;image searching;query image;recall measures;average precision measures","","","","11","","20 Jan 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Implementation and Performance Analysis of a Parallel Oil Reservoir Simulator Tool Using a CG Method on a GPU-Based System","L. Ismail; J. Abou-Kassem; B. Qamar","Comput. & Software Eng., UAE Univ., Al-Ain, United Arab Emirates; Dept. of Chem. & Pet. Eng., UAE Univ., Al-Ain, United Arab Emirates; HPGCL Res. Lab., UAE Univ., Al-Ain, United Arab Emirates","2014 UKSim-AMSS 16th International Conference on Computer Modelling and Simulation","23 Feb 2015","2014","","","375","380","An oil reservoir simulator is a crucial tool used by petroleum engineering to analyze reservoir conditions. To increase its performance, we implement a parallel version of the tool on a Graphic Processing Unit (GPU), using Computer Unified Device Architecture (CUDA) programming model and the Single Instruction Multiple Threads (SIMT). This paper presents our parallel implementation and performance analysis for 1-D, 2-D, and 3-D oil-phase reservoirs. The implementation and the performance evaluation reveal the gains and the losses achieved by the parallelization of a reservoir simulator on a Graphics Processing Unite (GPU) system. The performance results show that despite the interdependency between the different computational parts of the Conjugate Gradient (CG) method used as a linear solver in the parallel reservoirs, a speedup of 26 can be easily obtained for an oil reservoir simulator using 15 streaming multiprocessors (SMs), compared to a sequential CPU execution. The parallel execution scales well with grid dimensionality.","","978-1-4799-4922-9","10.1109/UKSim.2014.113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7046095","Oil Reservoir Simulator; Conjugate Gradient (CG) Method; GPU; High Performance Computing","Reservoirs;Graphics processing units;Sparse matrices;Vectors;Instruction sets;Memory management;Clustering algorithms","conjugate gradient methods;graphics processing units;hydrocarbon reservoirs;multiprocessing systems;parallel programming","parallel oil reservoir simulator tool;CG method;conjugate gradient method;GPU based system;graphics processing unit;computer unified device architecture;CUDA programming model;single instruction multiple threads;SIMT;linear solver;streaming multiprocessors;sequential CPU execution;grid dimensionality","","1","","40","","23 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPU accelerate parallel Odd-Even merge sort: An OpenCL method","K. Zhang; J. Li; G. Chen; B. Wu","School of Computer Science, Fudan University, Shanghai 201203, China; School of Computer Science, Fudan University, Shanghai 201203, China; School of Computer Science, Fudan University, Shanghai 201203, China; School of Computer Science, Fudan University, Shanghai 201203, China","Proceedings of the 2011 15th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","21 Jul 2011","2011","","","76","83","Odd-Even merge sort is a basic problem in computer supported cooperative work in design area. However, it is not effective because of the high complexity O(nlg<sup>2</sup>n) in CPU platform. In this paper, we present a novel implementation based on the OpenCL programming model on recent GPU (Graphic Processing Unit). Our implementation was based on Knuth's algorithm and do some change. Due to limitations of OpenCL, we utilize a flag variable to make it avoid the direct backward control flow. As results, our implementation achieves 18× speedups compared with the CPU C++ STL quick sort. And it gets almost linear speedup for next generations of GPU because of the complete parallelism in each iteration process. Meanwhile, our approach makes the odd-even merge sort effectively in practice because of the high performance. Furthermore, the approach used in this paper for cooperating thousands of processing units to parallel process can also be used in other cooperation areas.","","978-1-4577-0387-4","10.1109/CSCWD.2011.5960058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5960058","GPGPU;GPU;Odd-Even Merge Sort;OpenCL","Graphics processing unit;Sorting;Arrays;Computational modeling;Complexity theory;Instruction sets","computer graphic equipment;coprocessors;iterative methods","GPU accelerate parallel odd even merge sort;computer supported cooperative work;OpenCL programming model;graphic processing unit;Knuth algorithm;direct backward control flow;CPU C++ STL quick sort;parallel process;processing units;iteration process","","5","2","35","","21 Jul 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPU Acceleration of Clustered DPCM for Lossless Compression of Hyperspectral Images","J. Li; J. Wu; G. Jeon","School of Electronic Engineering, Xidian University, Xi'an, China; School of Electronic Engineering, Xidian University, Xi'an, China; School of Electronic Engineering, Xidian University, Xi'an, China","IEEE Transactions on Industrial Informatics","14 Feb 2020","2020","16","5","2906","2916","With the development of remote sensing technology, spatial and spectral resolutions of hyperspectral images have become increasingly dense. In order to overcome difficulties in the storage, transmission, and manipulation of hyperspectral images, an effective compression algorithm is requisite. The clustered differential pulse code modulation (C-DPCM), which is a prediction-based hyperspectral image lossless compression algorithm, can achieve a relatively high compression ratio, but its efficiency still requires improvement. This paper presents a parallel implementation of the C-DPCM algorithm on graphics processing units (GPUs) with the compute unified device architecture, which is a parallel computing platform and programming model developed by NVIDIA. Three optimization strategies are utilized to implement the C-DPCM algorithm in parallel, including a version that uses shared memory and registers, a version that employs multistream, and a version that uses multi-GPU. In addition, we studied how to assign all classes to each GPU to minimize the processing time. Finally, we reduced the compression time from approximately half an hour to an hour to several seconds, with almost no loss in accuracy.","1941-0050","","10.1109/TII.2019.2893437","National Natural Science Foundation of China(grant numbers:61775175,61771378); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613877","Clustered differential pulse code modulation (C-DPCM);compute unified device architecture (CUDA);graphics processing unit (GPU);hyperspectral image lossless compression","Image coding;Hyperspectral imaging;Prediction algorithms;Graphics processing units;Correlation;Bit rate","data compression;differential pulse code modulation;geophysical image processing;graphics processing units;image coding;parallel architectures;remote sensing","hyperspectral images;remote sensing technology;spatial resolutions;spectral resolutions;effective compression algorithm;clustered differential pulse code modulation;prediction-based hyperspectral image lossless compression;compression ratio;parallel implementation;C-DPCM algorithm;compute unified device architecture;parallel computing platform;programming model;compression time;GPU acceleration;clustered DPCM","","4","","30","IEEE","16 Jan 2019","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"A parallel design of computer Go engine on CUDA-enabled GPU","Q. Zhang; Z. Liu","School of Software Beijing University of Posts and Telecommunications, Beijing, China; School of Software Beijing University of Posts and Telecommunications, Beijing, China","2011 IEEE International Conference on Cloud Computing and Intelligence Systems","13 Oct 2011","2011","","","85","88","With the rapid growth of Graphics Processing Unit (GPU) processing capability, using GPU as a coprocessor to assist the CPU in parallel computing has become indispensable. CUDA (Compute Unified Device Architecture) programming model also gives C/C++ language support which makes programming easily. This paper details how to design an engine of computer Go with Monte-Carlo algorithm which is based on GPU with Fermi architecture. We analyze the characteristics of Monte-Carlo algorithm, combined with the CUDA architecture features, divide the algorithm into various sub-modules for GPU computing fast and easily.","2376-595X","978-1-61284-204-2","10.1109/CCIS.2011.6045037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045037","Parallelization;CUDA;Monte-Carlo","Graphics processing unit;Games;Monte Carlo methods;Computers;Instruction sets;Engines;Computational modeling","C++ language;computer graphic equipment;coprocessors;Monte Carlo methods;parallel processing","parallel design;computer Go engine;CUDA enabled GPU;graphics processing unit;parallel computing;compute unified device architecture;C++ language support;C language support;Monte-Carlo algorithm;Fermi architecture","","","","7","","13 Oct 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Advanced genetic algorithm to solve MINLP problems over GPU","A. Munawar; M. Wahib; M. Munetomo; K. Akama","Graduate School of Information, Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information, Science and Technology, Hokkaido University, Sapporo, Japan; Information Systems Design Laboratory, Information Initiative Center, Hokkaido University, Sapporo, Japan; Information Systems Design Laboratory, Information Initiative Center, Hokkaido University, Sapporo, Japan","2011 IEEE Congress of Evolutionary Computation (CEC)","14 Jul 2011","2011","","","318","325","In this paper we propose a many-core implementation of evolutionary computation for GPGPU (General-Purpose Graphic Processing Unit) to solve non-convex Mixed Integer Non-Linear Programming (MINLP) and non-convex Non Linear Programming (NLP) problems using a stochastic algorithm. Stochastic algorithms being random in their behavior are difficult to implement over GPU like architectures. In this paper we not only succeed in implementation of a stochastic algorithm over GPU but show considerable speedups over CPU implementations. The stochastic algorithm considered for this paper is an adaptive resolution approach to genetic algorithm (arGA), developed by the authors of this paper. The technique uses the entropy measure of each variable to adjust the intensity of the genetic search around promising individuals. Performance is further improved by hybridization with adaptive resolution local search (arLS) operator. In this paper, we describe the challenges and design choices involved in parallelization of this algorithm to solve complex MINLPs over a commodity GPU using Compute Unified Device Architecture (CUDA) programming model. Results section shows several numerical tests and performance measurements obtained by running the algorithm over an nVidia Fermi GPU. We show that for difficult problems we can obtain a speedup of up to 20x with double precision and up to 42x with single precision.","1941-0026","978-1-4244-7835-4","10.1109/CEC.2011.5949635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949635","Adaptive Resolution Genetic Algorithm;Parallel Genetic Algorithms;General-Purpose computation on Graphics Processing Units (GPGPU);Compute Unified Device Architecture (CUDA)","Graphics processing unit;Genetic algorithms;Kernel;Stochastic processes;Entropy;Algorithm design and analysis;Genetics","computer graphic equipment;coprocessors;genetic algorithms;integer programming;nonlinear programming;parallel algorithms;parallel architectures;stochastic processes","advanced genetic algorithm;MINLP problems;evolutionary computation;GPGPU;general-purpose graphic processing unit;many-core implementation;nonconvex mixed integer nonlinear programming;stochastic algorithm;GPU like architectures;CPU implementations;adaptive resolution local search operator;parallelization;compute unified device architecture programming model;nVidia Fermi GPU","","10","","28","","14 Jul 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Hybrid CPU and GPU Computation to Detect Lung Nodule in Computed Tomography Images","I. W. B. Sentana; N. Jawas; A. E. Wardani","Department of Information, Systems Bali State Polytechnic, J1. Raya Bukit Jimbaran, Badung, Bali, Indonesia; Department of Computer, System STMIK STIKOM, Bali Jalan Raya Puputan No. 86, Renon, Denpasar, Indonesia; Radiology Unit, Airlangga university, Hospital Jalan Mayjen Dr. Moestopo No. 6–8, Surabaya, Indonesia","2018 Third International Conference on Informatics and Computing (ICIC)","1 Aug 2019","2018","","","1","6","Lung Nodule is a white patch on the thorax medical image, usually used as an early marker of lung cancer. Although there were some research deals with lung nodule detection, but none of those researches tailoring Graphical Processing Unit (GPU) to assist the computing process. This research aims to produce algorithms that can detect lung nodules automatically in CT images, by utilizing a combination of hybrid computing between Central Processing Unit (CPU) and Graphical Processing Unit. The framework used is Compute Unified Device Architecture, which consists of platform and programming model. The algorithm consists of several steps: read dicom and data normalization, lung segmentation, candidate nodule extraction, and classification. Normalization is required to facilitate calculation by changing the data type ui16 to ui8. Furthermore, segmentation is used to separate the lung parts with other organs, where at this stage the Otsu Algorithm and Moore Neighborhood Tracing (MNT) are used. The next step is Lung Nodule Extraction, which aims to find the nodule candidate. The last step is a classification that utilizes the Support Vector Machine (SVM) to distinguish which one is nodule or not. The algorithm successfully detects near round nodules that are free-standing or not attached to other parts of organs. After undergoing ground truth tests, it was found that under some conditions, the algorithm has not been able to distinguish nodules and other strokes that resemble nodules. While in terms of computing speed is found a very surprising result because overall single CPU computing provides better results compared to hybrid CPU and GPU computing.","","978-1-5386-6921-1","10.1109/IAC.2018.8780573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780573","Lung Nodule;Hybrid Computing;GPU and CPU;CT images","Lung;Graphics processing units;Support vector machines;Computed tomography;Central Processing Unit;Kernel;Classification algorithms","cancer;computerised tomography;image segmentation;lung;medical image processing;support vector machines","compute unified device architecture;Otsu algorithm;graphical processing unit;central processing unit;hybrid CPU computing;lung nodule extraction;hybrid computing;CT images;lung nodules;computing process;lung nodule detection;lung cancer;thorax medical image;computed tomography;GPU computation;GPU computing;round nodules;lung segmentation;data normalization","","1","","18","","1 Aug 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPU-Accelerated High-Throughput Online Stream Data Processing","Z. Chen; J. Xu; J. Tang; K. A. Kwiat; C. A. Kamhoua; C. Wang","Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; US Air Force Research Lab (AFRL), Rome, NY; US Air Force Research Lab (AFRL), Rome, NY; InterDigital, Inc, King of Prussia, PA","IEEE Transactions on Big Data","1 Jun 2018","2018","4","2","191","202","The Single Instruction Multiple Data (SIMD) architecture of Graphic Processing Units (GPUs) makes them perfect for parallel processing of big data. In this paper, we present the design, implementation and evaluation of G-Storm, a GPU-enabled parallel system based on Storm, which harnesses the massively parallel computing power of GPUs for high-throughput online stream data processing. G-Storm has the following desirable features: 1) G-Storm is designed to be a general data processing platform as Storm, which can handle various applications and data types. 2) G-Storm exposes GPUs to Storm applications while preserving its easy-to-use programming model. 3) G-Storm achieves high-throughput and low-overhead data processing with GPUs. 4) G-Storm accelerates data processing further by enabling Direct Data Transfer (DDT), between two executors that process data at a common GPU. We implemented G-Storm based on Storm 0.9.2 and tested it using three different applications, including continuous query, matrix multiplication and image resizing. Extensive experimental results show that 1) Compared to Storm, G-Storm achieves over 7χ improvement on throughput for continuous query, while maintaining reasonable average tuple processing time. It also leads to 2.3χ and 1.3χ throughput improvements on the other two applications, respectively. 2) DDT significantly reduces data processing time.","2332-7790","","10.1109/TBDATA.2016.2616116","Air Force Office of Scientific Research(grant numbers:FA9550-16-1-0077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7587437","Stream data processing;GPU;parallel computing;big data infrastructure","Graphics processing units;Storms;Fasteners;Programming;Computer architecture;Big data","Big Data;graphics processing units;matrix multiplication;parallel architectures;query processing","low-overhead data processing;parallel processing;big data;image resizing;matrix multiplication;continuous query;easy-to-use programming;GPU-enabled parallel system;G-Storm;storm applications;direct data transfer;tuple processing time;online stream data processing;GPU-accelerated high-throughput;parallel computing;graphic processing units;single instruction multiple data architecture","","7","","37","IEEE","10 Oct 2016","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Poster: GPU Accelerated Ultrasonic Tomography Using Propagation and Backpropagation Method","P. D. Bello; Y. Jin; E. Lu",NA; NA; NA,"2012 SC Companion: High Performance Computing, Networking Storage and Analysis","11 Apr 2013","2012","","","1447","1447","This paper develops implementation strategy and method to accelerate the propagation and backpropagation (PBP) tomographic imaging algorithm using Graphic Processing Units (GPUs). The Compute Unified Device Architecture (CUDA) programming model is used to develop our parallelized algorithm since the CUDA model allows the user to interact with the GPU resources more efficiently than traditional shader methods. The results show an improvement of more than 80x when compared to the C/C++ version of the algorithm, and 515x when compared to the MATLAB version while achieving high quality imaging for both cases. We test different CUDA kernel configurations in order to measure changes in the processing-time of our algorithm. By examining the acceleration rate and the image quality, we develop an optimal kernel configuration that maximizes the throughput of CUDA implementation for the PBP method.","","978-0-7695-4956-9","10.1109/SC.Companion.2012.249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6496032","Medical Imaging;Ultrasonic Tomography;GPU;CUDA;Parallel Computing","","","","","","","","","11 Apr 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A Compute Unified System Architecture for Graphics Clusters Incorporating Data Locality","C. Muller; S. Frey; M. Strengert; C. Dachsbacher; T. Ertl",Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart,"IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","605","617","We present a development environment for distributed GPU computing targeted for multi-GPU systems, as well as graphics clusters. Our system is based on CUDA and logically extends its parallel programming model for graphics processors to higher levels of parallelism, namely, the PCI bus and network interconnects. While the extended API mimics the full function set of current graphics hardware-including the concept of global memory-on all distribution layers, the underlying communication mechanisms are handled transparently for the application developer. To allow for high scalability, in particular for network-interconnected environments, we introduce an automatic GPU-accelerated scheduling mechanism that is aware of data locality. This way, the overall amount of transmitted data can be heavily reduced, which leads to better GPU utilization and faster execution. We evaluate the performance and scalability of our system for bus and especially network-level parallelism on typical multi-GPU systems and graphics clusters.","1941-0506","","10.1109/TVCG.2008.188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4653488","GPU computing;graphics clusters;parallel programming.;Distributed/network graphics;Graphics Systems;Computer Graphics;Computing Methodologies;Concurrent Programming;Programming Techniques;Software/Software Engineering;Concurrent;distributed;and parallel languages;Language Classifications;Programming Languages Software;Graphics processors;Hardware Architecture;Computing Methodologies","Computer architecture;Graphics;Parallel processing;Concurrent computing;Distributed computing;Hardware;Parallel programming;Scalability;Power generation;Rendering (computer graphics)","computer graphics;coprocessors;parallel programming","compute unified system architecture;graphics clusters;data locality;distributed GPU computing;multi-GPU systems;parallel programming model;graphics processors;PCI bus;network interconnects;graphics hardware;communication mechanism;network-interconnected environment;automatic GPU-accelerated scheduling;GPU utilization;network-level parallelism","","17","","23","","17 Oct 2008","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Exploring Compiler Optimization Opportunities for the OpenMP 4.× Accelerator Model on a POWER8+GPU Platform","A. Hayashi; J. Shirako; E. Tiotto; R. Ho; V. Sarkar",NA; NA; NA; NA; NA,"2016 Third Workshop on Accelerator Programming Using Directives (WACCPD)","2 Feb 2017","2016","","","68","78","While GPUs are increasingly popular for high-performance computing, optimizing the performance of GPU programs is a time-consuming and non-trivial process in general. This complexity stems from the low abstraction level of standard GPU programming models such as CUDA and OpenCL: programmers are required to orchestrate low-level operations in order to exploit the full capability of GPUs. In terms of software productivity and portability, a more attractive approach would be to facilitate GPU programming by providing high-level abstractions for expressing parallel algorithms.OpenMP is a directive-based shared memory parallel programming model and has been widely used for many years. From OpenMP 4.0 onwards, GPU platforms are supported by extending OpenMP's high-level parallel abstractions with accelerator programming. This extension allows programmers to write GPU programs in standard C/C++ or Fortran languages, without exposing too many details of GPU architectures.However, such high-level parallel programming strategies generally impose additional program optimizations on compilers, which could result in lower performance than fully hand-tuned code with low-level programming models. To study potential performance improvements by compiling and optimizing high-level GPU programs, in this paper, we 1) evaluate a set of OpenMP 4.× benchmarks on an IBM POWER8 and NVIDIA Tesla GPU platform and 2) conduct a comparable performance analysis among hand-written CUDA and automatically-generated GPU programs by the IBM XL and clang/LLVM compilers.","","978-1-5090-6152-5","10.1109/WACCPD.2016.011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836582","Parallel programming","Graphics processing units;Optimization;Kernel;Instruction sets;Programming;Performance evaluation","C++ language;FORTRAN;graphics processing units;optimisation;parallel algorithms;parallel architectures;parallel programming;program compilers;shared memory systems;software portability","clang/LLVM compilers;IBM XL compilers;NVIDIA Tesla GPU platform;IBM POWER8 platform;FORTRAN languages;C/C++ languages;accelerator programming;directive-based shared memory parallel programming;parallel algorithms;high-level abstractions;software portability;software productivity;OpenCL;CUDA;GPU programming models;high-performance computing;POWER8+GPU platform;OpenMP 4.x accelerator model;compiler optimization","","4","1","26","","2 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPu-based framework for interactive visualization of SAR data","M. Lambers; A. Kolb; H. Nies; M. Kalkuhl","Institute for Vision and Graphics, University of Siegen, Germany; Institute for Vision and Graphics, University of Siegen, Germany; Center for Sensorsystems (ZESS), University of Siegen, Germany; Department of Simulation, University of Siegen, Germany","2007 IEEE International Geoscience and Remote Sensing Symposium","7 Jan 2008","2007","","","4076","4079","Synthetic aperture radar data presents specific problems for interactive visualization. The high amount of multiplicative speckle noise has to be reduced. The high dynamic range of the amplitude data must be mapped to the lower dynamic range of display devices in a way that makes image features appropriately visible. In addition to interactive navigation in the data, it is desirable to allow interactive selection of despeckling and dynamic range reduction methods and adjustment of their parameters. Graphics processing units (GPUs) can be seen as ubiquitous parallel coprocessors with extreme computational power. In this paper, we propose a GPU-based framework for interactive visualization of SAR data. Data management techniques are used to make full use of the GPU. We reworked well-known despeckling and dynamic range reduction techniques for the GPU programming model and implemented them in our framework. Both navigation in large data sets and adjustment of processing parameters are fully interactive.","2153-7003","978-1-4244-1211-2","10.1109/IGARSS.2007.4423745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4423745","","Data visualization;Dynamic range;Navigation;Speckle;Noise reduction;Displays;Graphics;Coprocessors;Concurrent computing;Pervasive computing","coprocessors;data visualisation;geophysical signal processing;image denoising;interactive systems;radar signal processing;speckle;synthetic aperture radar","GPU based framework;interactive SAR data visualization;synthetic aperture radar;multiplicative speckle noise reduction;interactive despeckling selection;dynamic range reduction;graphics processing unit;parallel coprocessors;data management techniques;GPU programming model;large dataset navigation;processing parameter adjustment","","4","1","8","","7 Jan 2008","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A Dynamically Balanced OpenMP-CUDA Implementation of PDE-Based Contrast Source Inversion for Microwave Imaging","N. Geddert; I. Jeffrey","Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, Canada; Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, Canada","2018 18th International Symposium on Antenna Technology and Applied Electromagnetics (ANTEM)","13 Dec 2018","2018","","","1","2","An implementation of a PDE-based Contrast Source Inversion (CSI) algorithm using a hybrid Open MP-CUDA parallel programming model is presented for the acceleration of microwave imaging. The CSI algorithm uses a time-harmonic discontinuous Galerkin method forward solver. The programming model ensures high computational throughput by dynamically balancing the amount of work performed on the GPU and CPU. The resulting implementation is capable of substantial speed-up, bringing the computational performance to near real-time. Implementation and optimization details are discussed; results show GPU acceleration alone gives a speedup of at least 5 times.","2473-3555","978-1-5386-1338-2","10.1109/ANTEM.2018.8572994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8572994","Graphics processing unit (GPU);Open MP;hybrid parallel programming;contrast source inversion;microwave imaging","Graphics processing units;Acceleration;Programming;Computational modeling;Magnetic resonance imaging;Magnetic domains","Galerkin method;graphics processing units;Maxwell equations;microwave imaging;parallel architectures;parallel programming","microwave imaging;CSI algorithm;time-harmonic discontinuous Galerkin method;high computational throughput;computational performance;GPU acceleration;dynamically balanced OpenMP-CUDA implementation;PDE-based Contrast Source Inversion algorithm;hybrid Open MP-CUDA parallel programming model","","1","","9","","13 Dec 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Using graphics devices in reverse: GPU-based Image Processing and Computer Vision","J. Fung; S. Mann","NVIDIA Corporation, 2701 San Tomas Expressway, Santa Clara, California, USA; University of Toronto, Dept. of Electrical and Computer Engineering, 10 King's College Road, Mailstop. B540, Ontario, Canada","2008 IEEE International Conference on Multimedia and Expo","26 Aug 2008","2008","","","9","12","Graphics and vision are approximate inverses of each other: ordinarily graphics processing units (GPUs) are used to convert ldquonumbers into picturesrdquo (i.e. computer graphics). In this paper, we discuss the use of GPUs in approximately the reverse way: to assist in ldquoconverting pictures into numbersrdquo (i.e. computer vision). For graphical operations, GPUs currently provide many hundreds of gigaflops of processing power. This paper discusses how this processing power is being harnessed for image processing and computer vision, thereby providing dramatic speedups on commodity, readily available graphics hardware. A brief review of algorithms mapped to the GPU by using the graphics API for vision is presented. The NVIDIA CUDA programming model is then introduced as a way of expressing program parallelism without the need for graphics expertise.","1945-788X","978-1-4244-2570-9","10.1109/ICME.2008.4607358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4607358","GPU;Graphics Processing Unit;Computer Vision;Image Processing","Graphics;Hardware;Computer architecture;Computer vision;Programming;Acceleration;Pattern recognition","application program interfaces;computer graphics;computer vision;coprocessors;image processing equipment","computer vision;graphics processing units;computer graphics;graphics API;NVIDIA CUDA programming model;program parallelism;GPU-based image processing","","49","","32","","26 Aug 2008","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Parallel AMG solver for three dimensional unstructured grids using GPU","K. R. Tej; N. Sivadasan; V. Sharma; R. Banerjee","Dept. of Computer Science and Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India; Dept. of Computer Science and Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India; Dept. of Mechanical Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India; Dept. of Mechanical Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India","2014 21st International Conference on High Performance Computing (HiPC)","4 Jun 2015","2014","","","1","10","Graphics Processing Units (GPUs) have evolved over the years from being graphics accelerator to scalable coprocessor. We implement an algebraic multigrid solver for three dimensional unstructured grids using GPU. Such a solver has extensive applications in Computational Fluid Dynamics (CFD). Using a combination of vertex coloring, optimized memory representations, multi-grid and improved coarsening techniques, we obtain considerable speedup in our parallel implementation. Our solver provides significant acceleration for solving pressure Poisson equations, which is the most time consuming part while solving Navier-Stokes equations. In our experimental study, we solve pressure Poisson equations for flow over lid driven cavity and for laminar flow past square cylinder. Our implementation achieves 915 times speed up for the lid driven cavity problem on a grid of size 2.6 million and a speed up of 1020 times for the laminar flow past square cylinder problem on a grid of size 1.7 million, compared to serial non-multigrid implementations. For our implementation, we used NVIDIA's CUDA programming model.","1094-7256","978-1-4799-5976-1","10.1109/HiPC.2014.7116899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116899","GPU Computing;Computational Fluid Dynamics;Multigrid Flow Solver;Gauss-Seidel;Navier-Stokes","Graphics processing units;Image color analysis;Instruction sets;Smoothing methods;Kernel;Mathematical model;Computational fluid dynamics","computational fluid dynamics;external flows;graphics processing units;laminar flow;Navier-Stokes equations;parallel architectures;parallel programming;Poisson equation","parallel AMG solver;three-dimensional unstructured grids;GPU;graphics processing units;graphics accelerator;scalable co-processor;algebraic multigrid solver;computational fluid dynamics;CFD;vertex coloring;optimized memory representations;improved coarsening techniques;parallel implementation;pressure Poisson equations;Navier-Stokes equations;laminar flow;lid driven cavity problem;square cylinder problem;NVIDIA CUDA programming model","","1","","37","","4 Jun 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Evaluation of GPU Architectures Using Spiking Neural Networks","V. K. Pallipuram; M. A. Bhuiyan; M. C. Smith","Dept. of Electr. & Comput. Eng., Clemson Univ., Clemson, SC, USA; Dept. of Electr. & Comput. Eng., Clemson Univ., Clemson, SC, USA; Dept. of Electr. & Comput. Eng., Clemson Univ., Clemson, SC, USA","2011 Symposium on Application Accelerators in High-Performance Computing","29 Sep 2011","2011","","","93","102","During recent years General-Purpose Graphical Processing Units (GP-GPUs) have entered the field of High-Performance Computing (HPC) as one of the primary architectural focuses for many research groups working with complex scientific applications. Nvidia's Tesla C2050, codenamed Fermi, and AMD's Radeon 5870 are two devices positioned to meet the computationally demanding needs of supercomputing research groups across the globe. Though Nvidia GPUs powered by CUDA have been the frequent choices of the performance centric research groups, the introduction and growth of OpenCL has promoted AMD GP-GPUs as potential accelerator candidates that can challenge Nvidia's stronghold. These architectures not only offer a plethora of features for application developers to explore, but their radically different architectures calls for a detailed study that weighs their merits and evaluates their potential to accelerate complex scientific applications. In this paper, we present our performance analysis research comparing Nvidia's Fermi and AMD's Radeon 5870 using OpenCL as the common programming model. We have chosen four different neuron models for Spiking Neural Networks (SNNs), each with different communication and computation requirements, namely the Izhikevich, Wilson, Morris Lecar (ML), and the Hodgkin Huxley (HH) models. We compare the runtime performance of the Fermi and Radeon GPUs with an implementation that exhausts all optimization techniques available with OpenCL. Several equivalent architectural parameters of the two GPUs are studied and correlated with the application performance. In addition to the comparative study effort, our implementations were able to achieve a speed-up of 857.3x and 658.51x on the Fermi and Radeon architectures respectively for the most compute intensive HH model with a dense network containing 9.72 million neurons. The final outcome of this research is a detailed architectural comparison of the two GPU architectures with a common programming platform.","2166-515X","978-1-4577-0635-6","10.1109/SAAHPC.2011.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031572","Fermi;AMD;OpenCL;GPU Architecture Comparison;Profiler Counters;SNNs;speed-up","Graphics processing unit;Computer architecture;Neurons;Computational modeling;Mathematical model;Optimization;Firing","computer graphic equipment;coprocessors;neural nets","GPU architectures;spiking neural networks;general-purpose graphical processing units;high-performance computing;Nvidia Tesla C2050;Fermi;AMD Radeon 5870;supercomputing research groups;CUDA;performance centric research groups;OpenCL;application developers;programming model;Morris Lecar models;Hodgkin Huxley models;optimization techniques","","5","","27","","29 Sep 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"CUKNN: A parallel implementation of K-nearest neighbor on CUDA-enabled GPU","Shenshen Liang; Cheng Wang; Ying Liu; Liheng Jian","Graduate University of Chinese Academy of Sciences, Beijing, China 100190; Agilent Technologies Co. Ltd., Beijing, China 100102; Graduate University of Chinese Academy of Sciences, Beijing, China 100190; Graduate University of Chinese Academy of Sciences, Beijing, China 100190","2009 IEEE Youth Conference on Information, Computing and Telecommunication","15 Jan 2010","2009","","","415","418","Recent development in Graphics Processing Units (GPUs) has enabled inexpensive high performance computing for general-purpose applications. Due to GPU's tremendous computing capability, it has emerged as the co-processor of the CPU to achieve a high overall throughput. CUDA programming model provides the programmers adequate C language like APIs to better exploit the parallel power of the GPU. K-nearest neighbor is a widely used classification technique and has significant applications in various domains. The computational-intensive nature of KNN requires a high performance implementation. In this paper, we present a CUDA-based parallel implementation of KNN, CUKNN, using CUDA multi-thread model. Various CUDA optimization techniques are applied to maximize the utilization of the GPU. CUKNN outperforms significantly and achieve up to 15.2X speedup. It also shows good scalability when varying the dimension of the training dataset and the number of records in training dataset.","","978-1-4244-5074-9","10.1109/YCICT.2009.5382329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5382329","KNN;classification;CUDA;parallel computing","High performance computing;Graphics;Coprocessors;Central Processing Unit;Throughput;Parallel programming;Programming profession;Scalability","C language;computer graphics;coprocessors;multi-threading;parallel architectures","CUDA-enabled GPU;graphics processing units;C language;CUDA multi-thread model;k-nearest neighbor parallel implementation;coprocessor;compute unified device architecture;high performance computing","","8","","6","","15 Jan 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPU Accelerated Krylov Subspace Methods for Computational Electromagnetics","S. Velamparambil; S. MacKinnon-Cormier; J. Perry; R. Lemos; M. Okoniewski; J. Leon","Acceleware Corporation, 1600 37th St. SW, Calgary, Alberta-T3E 3P1, Canada. sanjay.velamparambil@acceleware.com; Acceleware Corporation, 1600 37th St. SW, Calgary, Alberta-T3E 3P1, Canada; Acceleware Corporation, 1600 37th St. SW, Calgary, Alberta-T3E 3P1, Canada; Acceleware Corporation, 1600 37th St. SW, Calgary, Alberta-T3E 3P1, Canada; Dept. Elect. & Comp. Engg., University of Calgary, Calgary, Canada. michal.okoniewski@acceleware.com; Faculty of Engineering, Dalhousie University, Halifax, Canada. Joshua.Leon@dal.ca","2008 38th European Microwave Conference","19 Jan 2009","2008","","","1312","1314","Programmable graphics processor units (GPU), such as the NVIDIA<sup>R</sup> Geforce 8800 series, offer a raw computing power that is often an order of magnitude larger than even the most modern multicore CPUs, making them a relatively inexpensive platform for high performance computing. In this paper, we report the development of two Krylov subspace solvers, the generalized minimal residual (GMRES) and the quasi-minimal residual (QMR) algorithms, on the GPU using the NVIDIA CUDA<sup>R</sup> programming model. The algorithms have been implemented as a stand-alone library. We report a speed-up of up to 13 times, on a single GPU, in our preliminary experiments with the classic problem of computing the capacitance of conductors using an integral equation method.","","978-2-87487-006-4","10.1109/EUMC.2008.4751704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4751704","","Acceleration;Computational electromagnetics;Integral equations;Computer interfaces;Graphics;High performance computing;Multicore processing;Libraries;Concurrent computing;Kernel","capacitance;computational electromagnetics;computer graphics;integral equations","programmable graphics processor units;Krylov subspace methods;computational electromagnetics;NVIDIA Geforce 8800 series;generalized minimal residual algorithm;quasiminimal residual algorithm;stand-alone library;single GPU;integral equation;capacitance;conductors;high performance computing;multicore CPUs","","6","","7","","19 Jan 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"DDGSim: GPU based simulator for large multicore with bufferless NoC","N. Kumar; A. Sahu","Deptt. of Comp. Sc. and Engg., Indian Institute of Technology Guwahati, Assam, India, 781039; Deptt. of Comp. Sc. and Engg., Indian Institute of Technology Guwahati, Assam, India, 781039","2014 Annual IEEE India Conference (INDICON)","5 Feb 2015","2014","","","1","6","In large scale chip multicore, last level cache management and core interconnection network play important roles in performance and power consumption. And in large scale chip multicore, mesh interconnect is used widely due to scalability and simplicity of design. As interconnection network occupied significant area and consumes significant percent of system power, bufferless network is an appealing alternative design to reduce power consumption and hardware cost. We have designed and implemented a simulator for simulation of distributed cache management of large chip multicore where cores are connected using bufferless interconnection network. Also, we have redesigned and implemented the DDGSim, which is a GPU compatible parallel version of the same simulator using CUDA programming model. We have simulated target large chip multicore with up to 43,000 cores and achieved up to 25 times speedup on NVIDIA GeForce GTX 690 GPU over serial simulation.","2325-9418","978-1-4799-5364-6","10.1109/INDICON.2014.7030460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030460","","Multicore processing;Graphics processing units;Ports (Computers);Instruction sets;Kernel;Routing;Radiation detectors","cache storage;digital simulation;multiprocessing systems;network-on-chip;parallel architectures","DDGSim;GPU based simulator;bufferless NoC;distributed cache management;bufferless interconnection network;CUDA programming model;NVIDIA GeForce GTX 690 GPU;large scale chip multicore;LCMP","","","","35","","5 Feb 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Analyzing CUDA workloads using a detailed GPU simulator","A. Bakhoda; G. L. Yuan; W. W. L. Fung; H. Wong; T. M. Aamodt","University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada","2009 IEEE International Symposium on Performance Analysis of Systems and Software","12 May 2009","2009","","","163","174","Modern graphic processing units (GPUs) provide sufficiently flexible programming models that understanding their performance can provide insight in designing tomorrow's manycore processors, whether those are GPUs or otherwise. The combination of multiple, multithreaded, SIMD cores makes studying these GPUs useful in understanding tradeoffs among memory, data, and thread level parallelism. While modern GPUs offer orders of magnitude more raw computing power than contemporary CPUs, many important applications, even those with abundant data level parallelism, do not achieve peak performance. This paper characterizes several non-graphics applications written in NVIDIA's CUDA programming model by running them on a novel detailed microarchitecture performance simulator that runs NVIDIA's parallel thread execution (PTX) virtual instruction set. For this study, we selected twelve non-trivial CUDA applications demonstrating varying levels of performance improvement on GPU hardware (versus a CPU-only sequential version of the application). We study the performance of these applications on our GPU performance simulator with configurations comparable to contemporary high-end graphics cards. We characterize the performance impact of several microarchitecture design choices including choice of interconnect topology, use of caches, design of memory controller, parallel workload distribution mechanisms, and memory request coalescing hardware. Two observations we make are (1) that for the applications we study, performance is more sensitive to interconnect bisection bandwidth rather than latency, and (2) that, for some applications, running fewer threads concurrently than on-chip resources might otherwise allow can improve performance by reducing contention in the memory system.","","978-1-4244-4184-6","10.1109/ISPASS.2009.4919648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4919648","","Analytical models;Yarn;Graphics;Parallel processing;Microarchitecture;Hardware;Process design;Concurrent computing;Parallel programming;Computational modeling","cache storage;computer graphic equipment;instruction sets;multiprocessing systems;multi-threading;parallel architectures","CUDA workload;GPU simulator;graphic processing unit;flexible programming model;CUDA programming;microarchitecture performance simulator;parallel thread execution;virtual instruction set;GPU hardware;high-end graphics card;microarchitecture design;interconnect topology;caches;memory controller;parallel workload distribution;memory request coalescing hardware","","890","4","46","","12 May 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"SMGuard: A Flexible and Fine-Grained Resource Management Framework for GPUs","C. Yu; Y. Bai; H. Yang; K. Cheng; Y. Gu; Z. Luan; D. Qian","Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China; Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China; Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China; Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China; Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China; Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China; Sino-German Joint Software Institute, School of Computer Science, Beihang University, Beijing, China","IEEE Transactions on Parallel and Distributed Systems","11 Nov 2018","2018","29","12","2849","2862","GPUs have been becoming an indispensable computing platform in data centers, and co-locating multiple applications on the same GPU is widely used to improve resource utilization. However, performance interference due to uncontrolled resource contention severely degrades the performance of co-locating applications and fails to deliver satisfactory user experience. In this paper, we present SMGuard, a software approach to flexibly manage the GPU resource usage of multiple applications under co-location. We also propose a capacity based GPU resource model CapSM, which provisions the GPU resources in a fine-grained granularity among co-locating applications. When co-locating latency-sensitive applications with batch applications, SMGuard can prevent batch applications from occupying resources without constraint using quota based mechanism, and guarantee the resource usage of latency-sensitive applications with reservation based mechanism. In addition, SMGuard supports dynamic resource adjustment through evicting the running thread blocks of batch applications to release the occupied resources and remapping the uncompleted thread blocks to the remaining resources, which avoids the relaunch of the preempted kernel. The SMGuard is a pure software solution that does not rely on special GPU hardware or programming model, which is easy to adopt on commodity GPUs in data centers. Our evaluation shows that SMGuard improves the average performance of latency-sensitive applications by 9.8× when co-located with batch applications. In the meanwhile, the GPU utilization can be improved by 35 percent on average.","1558-2183","","10.1109/TPDS.2018.2848621","National Key Research and Development Program of China(grant numbers:2016YFB1000503); National Science Foundation of China(grant numbers:61572062,61502019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388218","GPU;parallel computing;resource management;application co-location","Graphics processing units;Task analysis;Instruction sets;Resource management;Quality of service;Data centers","computer centres;graphics processing units;resource allocation","SMGuard;data centers;co-locating multiple applications;resource utilization;uncontrolled resource contention;GPU resource usage;GPU resource model CapSM;fine-grained granularity;latency-sensitive applications;batch applications;quota based mechanism;reservation based mechanism;dynamic resource adjustment;programming model;GPU utilization;flexible resource management framework;fine-grained resource management framework;performance interference","","4","","42","IEEE","19 Jun 2018","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"LU, QR, and Cholesky factorizations: Programming model, performance analysis and optimization techniques for the Intel Knights Landing Xeon Phi","A. Haidar; S. Tomov; K. Arturov; M. Guney; S. Story; J. Dongarra","University of Tennessee, Knoxville, 37916, USA; University of Tennessee, Knoxville, 37916, USA; Intel Corporation, Novosibirsk, Russia; Intel Corporation, Hillsboro, OR 97124, USA; Intel Corporation, Hillsboro, OR 97124, USA; University of Tennessee, Knoxville, Oak Ridge National Laboratory, USA","2016 IEEE High Performance Extreme Computing Conference (HPEC)","1 Dec 2016","2016","","","1","7","A wide variety of heterogeneous compute resources, ranging from multicore CPUs to GPUs and coprocessors, are available to modern computers, making it challenging to design unified numerical libraries that efficiently and productively use all these varied resources. For example, in order to efficiently use Intel's Knights Landing (KNL) processor, the next-generation of Xeon Phi architectures, one must design and schedule an application in multiple degrees of parallelism and task grain sizes in order to obtain efficient performance. We propose a productive and portable programming model that allows us to write a serial-looking code, which, however, achieves parallelism and scalability by using a lightweight runtime environment to manage the resource-specific workload, and to control the dataflow and the parallel execution. This is done through multiple techniques ranging from multi-level data partitioning to adaptive task grain sizes, and dynamic task scheduling. In addition, our task abstractions enable unified algorithmic development across all the heterogeneous resources. Finally, we outline the strengths and the effectiveness of this approach - especially in regards to hardware trends and ease of programming high-performance numerical software that current applications need - in order to motivate current work and future directions for the next generation of parallel programming models for high-performance linear algebra libraries on heterogeneous systems.","","978-1-5090-3525-0","10.1109/HPEC.2016.7761591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7761591","","Hardware;Programming;Libraries;Multicore processing;Parallel processing;Software","data flow computing;data handling;graphics processing units;linear algebra;mathematics computing;multiprocessing systems;parallel programming;processor scheduling;software libraries","LU factorization;QR factorization;Cholesky factorization;performance analysis;optimization technique;Intel Knights Landing Xeon Phi;heterogeneous compute resources;multicore CPU;GPU;coprocessors;unified numerical libraries;Intel KNL processor;Xeon Phi architecture;productive portable programming model;serial-looking code;scalability;lightweight runtime environment;resource-specific workload management;dataflow control;parallel execution;multilevel data partitioning;adaptive task grain size;dynamic task scheduling;task abstraction;unified algorithmic development;high-performance numerical software programming;parallel programming model;high-performance linear algebra libraries;heterogeneous systems","","7","","24","","1 Dec 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Designing a Profiling and Visualization Tool for Scalable and In-depth Analysis of High-Performance GPU Clusters","P. Kousha; B. Ramesh; K. Kandadi Suresh; C. Chu; A. Jain; N. Sarkauskas; H. Subramoni; D. K. Panda",The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University,"2019 IEEE 26th International Conference on High Performance Computing, Data, and Analytics (HiPC)","13 Feb 2020","2019","","","93","102","The recent advent of advanced fabrics like NVIDIA NVLink is enabling the deployment of dense Graphics Processing Unit (GPU) systems, e.g., DGX-2 and Summit. The Message Passing Interface (MPI) has been the dominant programming model to design distributed applications on such clusters. The MPI Tools Interface (MPI_T) provides an opportunity for performance tools and external software to introspect and understand MPI runtime behavior at a deeper level to detect performance and scalability issues. However, the lack of low-overhead and scalable monitoring tools have thus far prevented a comprehensive study of efficiency and utilization of high-performance interconnects such as NVLinks on high-performance GPU-enabled clusters. In this paper, we address this deficiency by proposing and designing an in-depth, real-time analysis, profiling, and visualization tool for high-performance GPU-enabled clusters with NVLinks. The proposed tool builds on the top of the OSU InfiniBand Network Analysis and Monitoring Tool (INAM). It provides insights into the efficiency of different communication patterns by examining the utilization of underlying GPU interconnects. The contributions of the proposed tool are two-fold: 1) domain scientists and system administrators can understand how applications and runtime libraries interact with underlying high-performance interconnects, and 2)Proposed tool enables designers of high-performance communication libraries to gain low-level knowledge to optimize existing designs and develop new algorithms to optimally utilize cutting-edge interconnects on GPU clusters. To the best of our knowledge, this is the first such tool which is capable of presenting a unified and holistic view of MPI-level and fabric level information for emerging NVLink-enabled high-performance GPU clusters.","2640-0316","978-1-7281-4535-8","10.1109/HiPC.2019.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8990500","MPI;MPI_T;NVLINK;GPU;Profiling","Graphics processing units;Tools;Libraries;Measurement;Fabrics;Topology;Bandwidth","application program interfaces;data visualisation;graphics processing units;message passing;parallel processing;software libraries","visualization tool;high-performance interconnects;high-performance communication libraries;MPI-level;NVLink-enabled high-performance GPU clusters;in-depth analysis;message passing interface;performance tools;MPI runtime behavior;scalable monitoring tools;NVIDIA NVLink;graphics processing unit;MPI tools interface;low-overhead tools;infiniband network analysis and monitoring tool;cutting-edge interconnects;fabric level information;runtime libraries","","6","","30","","13 Feb 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Code Complexity versus Performance for GPU-accelerated Scientific Applications","A. W. U. Munipala; S. V. Moore","University of Texas at El Paso, TX, USA; Oak Ridge Nat. Lab., Oak Ridge, TN, USA","2016 Fourth International Workshop on Software Engineering for High Performance Computing in Computational Science and Engineering (SE-HPCCSE)","2 Feb 2017","2016","","","50","50","Summary form only given. Graphics Processing Units (GPUs) are becoming widely used as parallel accelerators in high-performance computing. GPU programming until recently, has been done by using low-level programming models such as CUDA and OpenCL. The directive-based OpenACC programming model has been growing in popularity due to its higher level of abstraction. This technique, which uses “directive” or “pragma” statements to annotate source code written in traditional high-level languages such as Fortran, C, and C++, is intended to allow a single code base to work across multiple computational platforms. We attempt to compare code complexity and performance of CUDA, OpenCL, and OpenACC implementations for three benchmark codes - the Game of Life (GOL) example code, the LULESH hydrodynamics proxy application, and the CloverLeaf mini-app from the Mantevo suite For the GOL C, CUDA C, and OpenCL codes and the LULESH C++, CUDA, and OpenCL codes, we measured source lines of code (SLOC) and cyclomatic complexity using the Oxbow toolkit static analysis tools. We ran the commercial McCabe IQ tool on the CloverLeaf Fortran90, Fortran90 + OpenACC, and Fortran portion of CloverLeaf_CUDA to measure cyclomatic complexity, design complexity, and essential complexity. We found that the CUDA and OpenCL implementations have significantly more lines of code than the corresponding OpenACC implementations but that the measured cyclomatic complexity is not always higher. The CUDA and OpenCL implementations generally have better performance, but there is not a drastic difference if the OpenACC code is optimized. We conclude that the available metrics and tools for measuring complexity of GPU programs are inadequate, since they do not quantify the portability and maintainability of the codes, and that specialization and extensions are needed.","","978-1-5090-5224-0","10.1109/SE-HPCCSE.2016.012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7839472","","Complexity theory;Graphics processing units;Programming;Measurement;Software engineering;Computational modeling;C++ languages","C++ language;graphics processing units;parallel architectures;software metrics;software performance evaluation;source code (software)","code complexity;GPU-accelerated scientific applications;graphics processing units;game of life;GOL;LULESH hydrodynamics proxy application;CloverLeaf mini-app;Mantevo suite;GOL C;CUDA C;OpenCL codes;LULESH C++;source lines of code;SLOC;cyclomatic complexity;Oxbow toolkit static analysis tools;McCabe IQ tool;CloverLeaf Fortran90;Fortran90 + OpenACC;design complexity;essential complexity","","2","","","","2 Feb 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPU acceleration of the iterative physical optics (IPO) method","Kan Xu; Z. W. Liu; D. Z. Ding; R. S. Chen","Department of Electronic Engineering, Nanjing University of Science and Technology, China; Department of Electronic Engineering, Nanjing University of Science and Technology, China; Department of Electronic Engineering, Nanjing University of Science and Technology, China; Department of Electronic Engineering, Nanjing University of Science and Technology, China","2008 8th International Symposium on Antennas, Propagation and EM Theory","16 Mar 2009","2008","","","733","735","In this paper, we employ the Programmable Graphics Processing Unit (GPU) to accelerate the IPO computation for analyzing the scattering of open cavities. Since the iterative strategy accounts for multiple reflections on the inner wall, the IPO method provides a more accurate solution than the other high frequency asymptotic methods. However, it suffers from a large requirement of simulation time. To date, the GPU featuring inherent parallelism and powerful floating-point capability has become an attractive alternative to the central processing unit (CPU) for some of computation tasks. Therefore, we map the time-consuming parts of IPO into the graphics hardware following the stream programming model, and the CPU carries out the computation of the far field scattering. In addition, the numerical results demonstrate the accuracy and effectiveness of our proposed method.","","978-1-4244-2192-3","10.1109/ISAPE.2008.4735319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4735319","","Acceleration;Iterative methods;Physical optics;Central Processing Unit;Graphics;Optical scattering;Optical reflection;Frequency;Computational modeling;Parallel processing","computational electromagnetics;electromagnetic wave scattering;iterative methods;parallel programming;physical optics","GPU acceleration;programmable graphics processing unit;multiple reflections;central processing unit;inherent parallelism;floating-point capability;time-consuming parts;iterative physical optics method","","","","8","","16 Mar 2009","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GraphReduce: Large-Scale Graph Analytics on Accelerator-Based HPC Systems","D. Sengupta; K. Agarwal; S. L. Song; K. Schwan","Georgia Inst. of Technol., Atlanta, GA, USA; Georgia Inst. of Technol., Atlanta, GA, USA; Pacific Northwest Nat. Lab., Richland, WA, USA; Georgia Inst. of Technol., Atlanta, GA, USA","2015 IEEE International Parallel and Distributed Processing Symposium Workshop","1 Oct 2015","2015","","","604","609","Recent work on graph analytics has sought to leverage the high performance offered by GPU devices, but challenges remain due to the inherent irregularity of graph algorithm and limitations in GPU-resident memory for storing large graphs. The Graph Reduce methods presented in this paper permit a GPU-based accelerator to operate on graphs that exceed its internal memory capacity. Graph Reduce operates with a combination of both edge- and vertex-centric implementations of the Gather-Apply-Scatter programming model, to achieve high degrees of parallelism supported by methods that partition graphs across GPU and host memories and efficiently move graph data between both. Graph Reduce-based programming is performed via device functions that include gather map, gather reduce, apply, and scatter, implemented by programmers for the graph algorithms they wish to realize. Experimental evaluations for a wide variety of graph inputs, algorithms, and system configuration demonstrate that Graph Reduce outperforms other competing approaches.","","978-1-4673-7684-6","10.1109/IPDPSW.2015.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284365","graph processing;big data;GPU;CUDA","Graphics processing units;Computational modeling;Programming;Parallel processing;Algorithm design and analysis;Hardware;Data structures","graph theory;graphics processing units;storage management","GraphReduce;large-scale graph analytics;accelerator-based HPC systems;GPU devices;graph algorithm irregularity;GPU-resident memory;GPU-based accelerator;internal memory capacity;edge-centric implementations;vertex-centric implementations;gather-apply-scatter programming model;partition graphs;gather_map;gather_reduce","","3","","22","","1 Oct 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Automatic Code Tuning for Improving GPU Resource Utilization","R. Takeshima; T. Tsumura","Nagoya Inst. of Technol., Nagoya, Japan; Nagoya Inst. of Technol., Nagoya, Japan","2014 Second International Symposium on Computing and Networking","2 Mar 2015","2014","","","419","425","Utilizing a GPU to perform general purpose computation is called GPGPU. The high theoretical performance of GPU draws attention to GPGPU. CUDA supplies a platform for the developers of GPU applications. In CUDA programming model, massive threads are allocated to GPU's calculation units. Besides, CUDA has various kinds of memories on GPU. These memories have different features of access latency, capacity, and so on. Therefore, to produce high-performance GPU programs, developers should consider how to allocate the massive threads to cores and which memory should be used for storing data. Hence, developers should have deep understanding of the GPU architecture and CUDA APIs. To address this problem, we propose an auto tuning framework for GPU programs, and explain an implementation of a preprocessor for the framework, in this paper.","2379-1896","978-1-4799-4152-0","10.1109/CANDAR.2014.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7052220","","Graphics processing units;Kernel;Message systems;Instruction sets;Registers;Tuning","application program interfaces;graphics processing units;parallel architectures;resource allocation","code tuning;GPU resource utilization;general purpose graphics processing unit;GPGPU;Compute Unified Device Architecture;high-performance GPU program;CUDA API;application program interface","","1","","11","","2 Mar 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Multi-Level Graph Layout on the GPU","Y. Frishman; A. Tal","Technion, Israel Institute of Technology; Technion, Israel Institute of Technology","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1310","1319","This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.","1941-0506","","10.1109/TVCG.2007.70580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376155","Graph layout;GPU;graph partitioning.","Partitioning algorithms;Acceleration;Application software;Visualization;High performance computing;Parallel programming;Computer architecture;Quality management;Network topology;Web and internet services","computer graphics;graph theory;parallel programming","multi-level graph layout;directed graph layout;general multi-level scheme;spectral partitioning;data parallel programming model;naturally unstructured graph;multi-core architectures;Internet service provider;graph partitioning","","70","1","41","","5 Nov 2007","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"On the Portability of the OpenCL Dwarfs on Fixed and Reconfigurable Parallel Platforms","K. Krommydas; M. Owaida; C. D. Antonopoulos; N. Bellas; W. -C. Feng",NA; NA; NA; NA; NA,"2013 International Conference on Parallel and Distributed Systems","1 May 2014","2013","","","432","433","The proliferation of heterogeneous computing systems presents the parallel computing community with the challenge of porting legacy and emerging applications to multiple processors with diverse programming abstractions. OpenCL is a vendor-agnostic and industry-supported programming model that offers code portability on heterogeneous platforms, allowing applications to be developed once and deployed ""anywhere."" In this paper, we use the OpenCL implementation of the Open Dwarfs, a benchmark suite that captures patterns of computation and communication common to classes of important applications, as delineated by Berkeley's Dwarfs. We evaluate portability across multicore CPU, GPU, APU (CPUs+GPUs on a die), the Intel Xeon Phi co-processor, and the FPGA. To realize FPGA portability, we exploit SOpenCL (Silicon OpenCL), a CAD tool that automatically converts OpenCL kernels to customizable hardware accelerators. We show that a single, unmodified OpenCL code base, i.e., Open Dwarfs, can be effectively used to target multiple, architecturally diverse platforms.","1521-9097","978-1-4799-2081-5","10.1109/ICPADS.2013.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808208","OpenCL;CPU;GPU;APU;Xeon Phi;FPGA;dwarfs;portability","Field programmable gate arrays;Graphics processing units;Hardware;Hardware design languages;Kernel;Programming;Parallel processing","parallel processing","OpenCL Dwarfs;reconfigurable parallel platforms;heterogeneous computing systems;parallel computing community;porting legacy;diverse programming abstractions;industry-supported programming model;code portability;heterogeneous platforms;multicore CPU;GPU;APU;Intel Xeon Phi coprocessor;FPGA portability;SOpenCL;Silicon OpenCL;CAD tool;OpenCL kernels;OpenCL code base","","4","","5","","1 May 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Using CUDA GPU to Accelerate the Ant Colony Optimization Algorithm","K. Wei; C. Wu; C. Wu","Comput. Sci. & Inf. Eng., Nat. Changhua Univ. of Educ., Changhua, Taiwan; Comput. Sci. & Inf. Eng., Nat. Changhua Univ. of Educ., Changhua, Taiwan; Comput. Sci. & Inf. Eng., Nat. Changhua Univ. of Educ., Changhua, Taiwan","2013 International Conference on Parallel and Distributed Computing, Applications and Technologies","22 Sep 2014","2013","","","90","95","Graph Processing Units (GPUs) have recently evolved into a super multi-core and a fully programmable architecture. In the CUDA programming model, the programmers can simply implement parallelism ideas of a task on GPUs. The purpose of this paper is to accelerate Ant Colony Optimization (ACO) for Traveling Salesman Problems (TSP) with GPUs. In this paper, we propose a new parallel method, which is called the Transition Condition Method. Experimental results are extensively compared and evaluated on the performance side and the solution quality side. The TSP problems are used as a standard benchmark for our experiments. In terms of experimental results, our new parallel method achieves the maximal speed-up factor of 4.74 than the previous parallel method. On the other hand, the quality of solutions is similar to the original sequential ACO algorithm. It proves that the quality of solutions does not be sacrificed in the cause of speed-up.","2379-5352","978-1-4799-2419-6","10.1109/PDCAT.2013.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6904238","GPU;CUDA;Ant Colony Optimization;ACO;TSP","Cities and towns;Graphics processing units;Instruction sets;Arrays;Wheels;Memory management","ant colony optimisation;graphics processing units;parallel architectures;parallel programming;travelling salesman problems","CUDA GPU;ant colony optimization algorithm;graph processing units;programmable architecture;ant colony optimization;traveling salesman problems;TSP;Transition Condition Method;parallel method;super multi-core;CUDA programming model","","2","","14","","22 Sep 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Comparison of Xeon Phi and Kepler GPU Performance for Finite Element Numerical Integration","K. Banas; F. Kruzel","Dept. of Appl. Comput. Sci. & Modelling, AGH Univ. of Sci. & Technol., Krakόw, Poland; Inst. of Comput. Sci., Cracow Univ. of Technol., Krakόw, Poland","2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)","12 Mar 2015","2014","","","145","148","We consider two recently introduced massively multi-core architectures designed for high performance computing, the Xeon Phi coprocessor and Kepler graphics processor. We discuss the OpenCL programming model, as one that allows to look at the platforms in a unified way and to construct efficient algorithms for both of them. As an example application we investigate a typical algorithm employed in finite element codes for numerical integration. We create kernels implementing the algorithm for the two considered platforms and compare the performance obtained.","","978-1-4799-6123-8","10.1109/HPCC.2014.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056730","OpenCL;performance analysis;Xeon Phi coprocessor;GPU;Kepler architecture;finite elements;numerical integration","Finite element analysis;Registers;Instruction sets;Computer architecture;Kernel;Graphics processing units;Numerical models","finite element analysis;graphics processing units;integration;multiprocessing systems;parallel processing","Xeon Phi coprocessor;Kepler GPU graphics processor;finite element numerical integration;massively multicore architectures;high performance computing;OpenCL programming model","","2","","8","","12 Mar 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Evaluating Optimization Strategies for HMMer Acceleration on GPU","S. Ferraz; N. Moreano","Sch. of Comput., Fed. Univ. of Mato Grosso do Sul, Campo Grande, Brazil; Sch. of Comput., Fed. Univ. of Mato Grosso do Sul, Campo Grande, Brazil","2013 International Conference on Parallel and Distributed Systems","1 May 2014","2013","","","59","68","Comparing a biological sequence to a family of sequences is an important task in Bioinformatics, commonly performed using tools such as HMMer. The Viterbi algorithm is applied as HMMer main step to compute the similarity between the sequence and the family. Due to the exponential growth of biological sequence databases, implementations of the Viterbi algorithm on several high performance platforms have been proposed. Nevertheless, few implementations of the Viterbi algorithm use GPUs as main platform. In this paper, we present the development and optimization of an accelerator for the Viterbi algorithm applied to biological sequence analysis on GPUs. Some of the optimizations analyzed are applied to the sequence comparison problem for the first time in the literature and others are evaluated in more depth than in related works. Our main contributions are: (a) an accelerator that achieves speedups up to 102.90 and 60.46, with respect to HMMer2 and HMMer3 execution on a general purpose computer, respectively, (b) the use of the multi-platform OpenCL programming model for the accelerator, (c) a detailed evaluation of several optimizations such as memory, control flow, execution space, instruction scheduling, and loop optimizations, and (d) a methodology of optimizations and evaluation that can also be applied to other sequence comparison algorithms, such as the HMMer3 MSV.","1521-9097","978-1-4799-2081-5","10.1109/ICPADS.2013.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808158","Sequence-profile alignment;Viterbi algorithm;GPU;Accelerator;Optimization;OpenCL","Hidden Markov models;Graphics processing units;Viterbi algorithm;Memory management;Optimization;Databases;Parallel processing","bioinformatics;graphics processing units;hidden Markov models;optimisation;scheduling","optimization strategies;HMMer acceleration;GPU;bioinformatics;Viterbi algorithm;biological sequence databases;HMMer2;general purpose computer;multiplatform OpenCL programming model;accelerator;control flow;execution space;instruction scheduling;loop optimizations;HMMer3 MSV;sequence comparison algorithms","","1","15","26","","1 May 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"The Heterogeneous System Architecture: It's beyond the GPU","P. Blinzer","Advanced Micro Devices, Inc., United States","2014 International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS XIV)","8 Sep 2014","2014","","","iii","iii","Summary form only given. The use of GPUs in computation intensive tasks has an ever increasing impact across all platforms - including embedded - sometimes even used to create new forms of currency (Bitcoin, Litecoin, ...). And the exponential improvements in Performance per Watt gains are still ongoing unabated. At the same time, due to their “design heritage” as primarily 3D accelerators, GPUs have several properties that make it a SW challenge to unlock their full benefit in many real-world application scenarios, be it due to limiting API's (proprietary or limited functionality) or properties that require an advanced understanding of the platform architecture and managing the memory and other system resources, beyond the reach of the “average programmer”. The Heterogeneous System Architecture is established by the HSA Foundation to address many of the current shortcomings at a system architecture and programming model level while providing a great foundation for already established SW models, and in addition to the GPU allow extending the architecture to other specialty processors like DSPs, FPGAs and others to interoperate within the SW framework, a main task for the next level of work in the HSA Foundation. The HSA Foundation, a not-for-profit consortium of SOC and SOC IP vendors, OEMs, academia, OSVs and ISVs defining a consistent heterogeneous platform architecture to make it dramatically easier to program heterogeneous parallel devices like GPUs and other accelerators. The presentation gives the audience a high-level understanding of the goals of HSA, the HSA system architecture properties and its use models by system software, tools and applications.","","978-1-4799-3770-7","10.1109/SAMOS.2014.6893187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893187","","Computer architecture;Computational modeling;Graphics processing units;System-on-chip;Graphics;Computers","application program interfaces;computer architecture;graphics processing units","heterogeneous system architecture;GPU;computation intensive tasks;performance per watt gains;design heritage;3D accelerators;SW challenge;API;HSA foundation;DSP;FPGA;SOC IP vendors;OEM;OSV;ISV","","","","","","8 Sep 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Detailed Performance Analysis of Distributed Tensorflow on a GPU Cluster using Deep Learning Algorithms","A. Malik; M. Lu; N. Wang; Y. Lin; S. Yoo","Computer Science Initiative, Brookhaven National Laboratory; Computer Science Initiative, Brookhaven National Laboratory; Computer Science Initiative, Brookhaven National Laboratory; Computer Science Initiative, Brookhaven National Laboratory; Computer Science Initiative, Brookhaven National Laboratory","2018 New York Scientific Data Summit (NYSDS)","18 Nov 2018","2018","","","1","8","Long training times for building a high accuracy deep neural networks (DNNs) is impeding research for new DNN architectures. For example, time for training GoogleNet with the ImageNet dataset on a single Nvidia K20 GPU almost takes 25 days. Therefore, there is a great need in the AI community to speed up the training phase, especially when using a large dataset. For this, we need Distributed Deep Neural Networks (DDNNs) that can scale well with more computation resources. However, this involves two challenges.First, the deep learning framework or training library must support inter-node communication. Second, the user must modify the code to take advantage of the inter-node communication. The changes to the code can be minimal to significant depending upon the user expertize in the distributed systems. Current DNN frameworks support distributed learning using MPI. However, these frameworks come with poorly understood overheads associated with communication and data management. Tensorflow provides APIs for distributed learning using MPI programming model and gRPC. These APIs are not easy to use for a domain expert for designing an efficient distributed learning model. Recently, Uber Inc. provides the Horovod Framework which gives a fast and easy way to support distributed learning using Tensorflow, Pytorach, and Keras. In this paper we provide a detailed performance analysis of distributed Tensorflow using Horovod. We implemented distributed learning for AlexNet, GoogleNet, and ResNet50 using Horovod. We used Nvidia K 40,K80, and P100 GPUs for our experimentation. We used synthetic image data with different runtime variables (batch size and number of GPUs). Our results shows that the Horovod framework gives almost linear throughput (images/sec) scalability up to 256 GPUs.","","978-1-5386-7933-3","10.1109/NYSDS.2018.8538946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538946","High Performance Computing;Tensorflow;Deep Learning;Distributed Learning;Performance Analysis","Training;Neural networks;Parallel processing;Computer architecture;Graphics processing units;Computational modeling","application program interfaces;graphics processing units;learning (artificial intelligence);message passing;neural nets;parallel architectures","computation resources;deep learning framework;inter-node communication;distributed systems;current DNN frameworks;data management;MPI programming model;domain expert;distributed learning model;Horovod Framework;distributed tensorflow;Horovod framework;GPU cluster;deep learning algorithms;high accuracy deep neural networks;DNN architectures;training GoogleNet;ImageNet dataset;single Nvidia K20 GPU;AI community;API","","","","28","","18 Nov 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"An improved vision-based wastewater velocity measurement system using discontinuity-preserving smoothing and GPU acceleration","C. Cao Pham; T. Tuong Nguyen; J. Jae Wook","School of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea; School of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea; School of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea","2011 11th International Conference on Control, Automation and Systems","19 Dec 2011","2011","","","1303","1308","Automatic long-term measuring wastewater velocity is an important and challenging task in hydraulic systems. This paper proposed a vision-based wastewater velocity measurement method using Bilateral filter that is a discontinuity-preserving smoothing as a prior-processing step. Experimental results showed that using Bilateral filter can improve estimation accuracy over existing methods. An effective background creation algorithm and simple floating waste tracking algorithm based on binary blob properties are also discussed in this paper. Furthermore, by implementing the proposed method on massively parallel GPU (graphics processing units) using the CUDA (compute unified device architecture) programming model, we can achieve a satisfactory acceleration to apply in real-time applications. Memory usage optimization methods are discussed and analyzed for effective implementation in graphics hardware.","2093-7121","978-89-93215-03-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106126","Water flow measurement;image processing;graphics processing units","Graphics processing unit;Particle measurements;Atmospheric measurements;Velocity measurement;Accuracy;Smoothing methods;Noise","computer vision;filtering theory;flow measurement;graphics processing units;object tracking;parallel architectures;storage management;velocity measurement;wastewater","vision-based wastewater velocity measurement system;discontinuity-preserving smoothing;GPU acceleration;hydraulic system;bilateral filter;background creation algorithm;floating waste tracking algorithm;binary blob properties;massively parallel GPU;graphics processing units;CUDA programming model;compute unified device architecture;real-time application;memory usage optimization;graphics hardware","","","","16","","19 Dec 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Porting LASG/ IAP Climate System Ocean Model to Gpus Using OpenAcc","J. Jiang; P. Lin; J. Wang; H. Liu; X. Chi; H. Hao; Y. Wang; W. Wang; L. Zhang","Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; LASG, Institute of Atmospheric Physics, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; NVIDIA, Beijing, China; LASG, Institute of Atmospheric Physics, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; School of Information Engineering, China University of Geosciences (Beijing), Beijing, China; Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China","IEEE Access","30 Oct 2019","2019","7","","154490","154501","GPUs have become important solutions for accelerating scientific applications. Most of the existing work on climate models now use code rewritten using CUDA to achieve a limited speedup. This restriction also greatly limits followup development and applications. In this paper, we designed and implemented a GPU-based acceleration of the LASG/IAP climate system ocean model (LICOM) version 2, called LICOM2-GPU. Considering the extremely large codebase of the model and the occasional need to modify the code, we implemented the model completely in OpenACC. Several accelerated methods, including OpenACC data locality optimization, loop optimization, and interprocess communication optimization are presented. Developing for GPUs using OpenACC is substantially simpler than using the CUDA port. Thus, the OpenACC is a suitable GPU programming model for complex systems, such as the earth system model and its components. Our experimental results using 4 NVIDIA K80 cards achieved up to a 6.6$ \times $ speedup compared with 4 Intel(R) Xeon(R) CPU E5-2690 v2 GPUs.","2169-3536","","10.1109/ACCESS.2019.2932443","National Basic Research Program of China (973 Program)(grant numbers:2016YFB0200800); National Natural Science Foundation of China(grant numbers:61602477,61432018); Strategic Priority Research Programme(grant numbers:XDC01040000); Chinese Academy of Sciences(grant numbers:XXH13506-402,XXH13506-302); Open Research Project of the Key Laboratory of Geological Information Technology of Ministry of Natural Resources; Open Research Project of the Hubei Key Laboratory of Intelligent Geo-Information Processing(grant numbers:KLIGIP-2017A04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784044","High performance computing;parallel algorithm;GPU;LICOM;parallel acceleration","Graphics processing units;Acceleration;Computational modeling;Meteorology;Atmospheric modeling;Optimization;Oceans","geophysics computing;graphics processing units;parallel architectures","accelerated methods;OpenACC data locality optimization;interprocess communication optimization;CUDA port;suitable GPU programming model;complex systems;earth system model;scientific applications;climate models;code rewritten;GPU-based acceleration;LICOM2-GPU","","2","","25","CCBY","1 Aug 2019","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Hybrid Map Task Scheduling for GPU-Based Heterogeneous Clusters","K. Shirahata; H. Sato; S. Matsuoka","Tokyo Inst. of Technol., Tokyo, Japan; Tokyo Inst. of Technol., Tokyo, Japan; Tokyo Inst. of Technol., Tokyo, Japan","2010 IEEE Second International Conference on Cloud Computing Technology and Science","4 Feb 2011","2010","","","733","740","MapReduce is a programming model that enables efficient massive data processing in large-scale computing environments such as supercomputers and clouds. Such large-scale computers employ GPUs to enjoy its good peak performance and high memory bandwidth. Since the performance of each job is depending on running application characteristics and underlying computing environments, scheduling MapReduce tasks onto CPU cores and GPU devices for efficient execution is difficult. To address this problem, we have proposed a hybrid scheduling technique for GPU-based computer clusters, which minimizes the execution time of a submitted job using dynamic profiles of Map tasks running on CPU cores and GPU devices. We have implemented a prototype of our proposed scheduling technique by extending MapReduce framework, Hadoop. We have conducted some experiments for this prototype by using a K-means application as a benchmark on a supercomputer. The results show that the proposed technique achieves 1.93 times faster than the Hadoop original scheduling algorithm at 64 nodes (1024 CPU cores and 128 GPU devices). The results also indicate that the performance of map tasks, including both CPU and GPU tasks, is significantly affected by the overhead of map task invocation in the Hadoop framework.","","978-1-4244-9405-7","10.1109/CloudCom.2010.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708524","Large-scale data processing;MapReduce;GPGPU;Job Scheduling","Graphics processing unit;Java;Performance evaluation;Processor scheduling;Prototypes;Central Processing Unit;Computers","computer graphic equipment;coprocessors;microcomputers;parallel machines;pattern clustering","hybrid map task scheduling;MapReduce model;programming model;data processing;memory bandwidth;hybrid scheduling technique;GPU-based computer clusters;K-means application;supercomputer;Hadoop original scheduling algorithm","","50","1","15","","4 Feb 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Efficient Fork-Join on GPUs Through Warp Specialization","A. C. Jacob; A. E. Eichenberger; H. Sung; S. F. Antao; G. -T. Bercea; C. Bertolli; A. Bataev; T. Jin; T. Chen; Z. Sura; G. Rokos; K. O'Brien","IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA","2017 IEEE 24th International Conference on High Performance Computing (HiPC)","8 Feb 2018","2017","","","358","367","Graphics Processing Units (GPUs) are increasingly used to accelerate portions of general-purpose applications. Higher level language extensions have been proposed to help non-experts bridge the gap between a host and the GPU's threading model. Recent updates to the OpenMP standard allow a user to parallelize code on a GPU using the well known fork-join programming model for CPUs. Mapping this model to the architecturally visible threading model of typical GPUs has been challenging. In this work we propose a novel approach using the technique of Warp Specialization. We show how to specialize one warp (a unit of 32 GPU threads) to handle sequential code on a GPU. When this master warp reaches a user-specified parallel region, it awakens unused GPU warps to collectively execute the parallel code. Based on this method, we have implemented a Clang-based, OpenMP 4.5 compliant, open source compiler for GPUs. Our work achieves a 3.6x (and up to 32x) performance improvement over a baseline that does not exploit fork-join parallelism on an NVIDIA k40m GPU across a set of 25 kernels. Compared to state-of-the-art compilers (Clang-ykt, GCC-OpenMP, GCC-OpenACC) our work is 2.1 - 7.6x faster. Our proposed technique is simpler to implement, robust, and performant.","","978-1-5386-2293-3","10.1109/HiPC.2017.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8287767","OpenMP;Fork-Join;GPU;Warp Specialization","Graphics processing units;Parallel processing;Kernel;Programming;Benchmark testing;Hardware;Data models","graphics processing units;multiprocessing systems;parallel programming;sequential codes","parallelism;GCC-OpenMP;Warp Specialization;Graphics Processing Units;higher level language extensions;GPU's threading model;OpenMP standard;programming model;architecturally visible threading model;sequential code;unused GPU warps;parallel code;Fork-join","","9","","29","","8 Feb 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"How Well do CPU, GPU and Hybrid Graph Processing Frameworks Perform?","T. K. Aasawat; T. Reza; M. Ripeanu","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","6 Aug 2018","2018","","","458","466","The importance of high-performance graph processing to solve big data problems targeting high-impact applications is greater than ever before. Recent graph processing frameworks target different hardware platforms (e.g., shared memory systems, accelerators such as GPUs, and distributed systems) and differ with respect to the programming model they adopt (e.g., based on linear algebra formulations of graph algorithms or enabling direct access to the graph structure). To better understand the impact of these choices, this paper, presents a comparative study of five state-of-the-art graph processing frameworks: two CPU-only frameworks - GraphMat and Galois, two GPU-based frameworks - Nvgraph and Gunrock; and Totem, a hybrid (CPU+GPU) framework. We use three popular graph algorithms (PageRank, Single Source Shortest Path, and Breadth-First Search), and massive scale graphs with up to billions of edges. Our evaluation focuses on three performance metrics: (i) execution time, (ii) scalability and (iii) energy consumption.","","978-1-5386-5555-9","10.1109/IPDPSW.2018.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425449","Graph Processing;CPU;GPU;Hybrid Systems;Performance Evaluation;PageRank;SSSP;BFS","Computational modeling;Graphics processing units;Programming;Linear algebra;Measurement;Sparse matrices;Instruction sets","Big Data;graph theory;graphics processing units;mathematics computing;parallel processing","graph processing frameworks;Nvgraph;GraphMat;Galois;Gunrock;Totem;hybrid graph;massive scale graphs;graph structure;linear algebra formulations;programming model;high-impact applications;big data problems;high-performance graph","","2","","35","","6 Aug 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Overlapping Data Transfers with Computation on GPU with Tiles","B. Bastem; D. Unat; W. Zhang; A. Almgren; J. Shalf","Koc Univ., Istanbul, Turkey; Koc Univ., Istanbul, Turkey; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA","2017 46th International Conference on Parallel Processing (ICPP)","7 Sep 2017","2017","","","171","180","GPUs are employed to accelerate scientific applications however they require much more programming effort from the programmers particularly because of the disjoint address spaces between the host and the device. OpenACC and OpenMP 4.0 provide directive based programming solutions to alleviate the programming burden however synchronous data movement can create a performance bottleneck in fully taking advantage of GPUs. We propose a tiling based programming model and its library that simplifies the development of GPU programs and overlaps the data movement with computation. The programming model decomposes the data and computation into tiles and treats them as the main data transfer and execution units, which enables pipelining the transfers to hide the transfer latency. Moreover, partitioning application data into tiles allows the programmer to still take advantage of GPU even though application data cannot fit into the device memory. The library leverages C++ lambda functions, OpenACC directives, CUDA streams and tiling API from TiDA to support both productivity and performance. We show the performance of the library on a data transfer-intensive and a compute-intensive kernels and compare its speedup against OpenACC and CUDA. The results indicate that the library can hide the transfer latency, handle the cases where there is no sufficient device memory, and achieves reasonable performance.","2332-5690","978-1-5386-1042-8","10.1109/ICPP.2017.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8025291","GPUs;Tiles;Programming Models;Overlapping communication with computation;Library;OpenACC;CUDA","Graphics processing units;Kernel;Programming;Data transfer;Performance evaluation;Libraries;Memory management","data handling;graphics processing units;parallel architectures","compute-intensive kernels;data transfer-intensive kernels;TiDA;API;CUDA streams;OpenACC directives;C++ lambda functions;device memory;application data;transfer latency;GPU programs;tiling based programming model;synchronous data movement;directive based programming solutions;OpenMP 4.0;programmers;programming effort;scientific applications;overlapping data transfers","","4","","34","","7 Sep 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"AES finalists implementation for GPU and multi-core CPU based on OpenCL","Xingliang Wang; Xiaochao Li; Mei Zou; Jun Zhou","Department of Electronic Engineering, Xiamen University, China, 361005; Department of Electronic Engineering, Xiamen University, China, 361005; Department of Electronic Engineering, Xiamen University, China, 361005; Department of Electronic Engineering, Xiamen University, China, 361005","2011 IEEE International Conference on Anti-Counterfeiting, Security and Identification","28 Jul 2011","2011","","","38","42","Benefit from the OpenCL (Open Computing Language), applications can be easily transplanted among different GPUs, multi-core CPUs, and other processors. In this paper, we present implementation of AES finalists (Rijndael, Serpent, Twofish) in XTS mode, based on OpenCL. Benchmark testing is performed on 4 mainstream GPUs and multi-core CPUs. The results are also compared with implementations based on traditional serial programming model and CUDA. The resulting data shows that throughputs based on OpenCL are higher than serial programming model, while a little lower than CUDA. Which demonstrates that OpenCL promises a portable language for GPU programming, while entail a performance penalty.","2163-5056","978-1-61284-632-3","10.1109/ASID.2011.5967411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967411","OpenCL;GPU;Rijndael;Serpent;Twofish;XTS","Graphics processing unit;Programming;Encryption;Throughput;Kernel;Performance evaluation","computer graphic equipment;coprocessors;cryptography;multiprocessing systems","AES finalists implementation;multicore CPU;OpenCL;open computing language;XTS mode;GPU programming;advanced encryption standard","","5","","16","","28 Jul 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Computing 2D Constrained Delaunay Triangulation Using the GPU","M. Qi; T. Cao; T. Tan","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore","IEEE Transactions on Visualization and Computer Graphics","19 Mar 2013","2013","19","5","736","748","We propose the first graphics processing unit (GPU) solution to compute the 2D constrained Delaunay triangulation (CDT) of a planar straight line graph (PSLG) consisting of points and edges. There are many existing CPU algorithms to solve the CDT problem in computational geometry, yet there has been no prior approach to solve this problem efficiently using the parallel computing power of the GPU. For the special case of the CDT problem where the PSLG consists of just points, which is simply the normal Delaunay triangulation (DT) problem, a hybrid approach using the GPU together with the CPU to partially speed up the computation has already been presented in the literature. Our work, on the other hand, accelerates the entire computation on the GPU. Our implementation using the CUDA programming model on NVIDIA GPUs is numerically robust, and runs up to an order of magnitude faster than the best sequential implementations on the CPU. This result is reflected in our experiment with both randomly generated PSLGs and real-world GIS data having millions of points and edges.","1941-0506","","10.1109/TVCG.2012.307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6361389","GPGPU;parallel computation;computational geometry;Voronoi diagram;image vectorization","Graphics processing units;Instruction sets;Arrays;Strips;Standards;Color","graphics processing units;mesh generation;parallel architectures","computing 2D constrained Delaunay triangulation;graphics processing unit;CDT;planar straight line graph;PSLG;computational geometry;parallel computing power;CUDA programming model;NVIDIA GPU","Algorithms;Computer Graphics;Image Enhancement;Image Enhancement;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted","17","","30","","26 Nov 2012","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Kernel Fusion: An Effective Method for Better Power Efficiency on Multithreaded GPU","G. Wang; Y. Lin; W. Yi","Nat. Lab. for Parallel & Distrib. Process. Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Nat. Lab. for Parallel & Distrib. Process. Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Nat. Lab. for Parallel & Distrib. Process. Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2010 IEEE/ACM Int'l Conference on Green Computing and Communications & Int'l Conference on Cyber, Physical and Social Computing","7 Mar 2011","2010","","","344","350","As one of the most popular accelerators, Graphics Processing Unit (GPU) has demonstrated high computing power in several application fields. On the other hand, GPU also produces high power consumption and has been one of the most largest power consumers in desktop and supercomputer systems. However, software power optimization method targeted for GPU has not been well studied. In this work, we propose kernel fusion method to reduce energy consumption and improve power efficiency on GPU architecture. Through fusing two or more independent kernels, kernel fusion method achieves higher utilization and much more balanced demand for hardware resources, which provides much more potential for power optimization, such as dynamic voltage and frequency scaling (DVFS). Basing on the CUDA programming model, this paper also gives several different fusion methods targeted for different situations. In order to make judicious fusion strategy, we deduce the process of fusing multiple independent kernels as a dynamic programming problem, which could be well solved with many existing tools and be simply embedded into compiler or runtime system. To reduce the overhead introduced by kernel fusion, we also propose effective method to reduce the usage of shared memory and coordinate the thread space of the kernels to be fused. Detailed experimental evaluation validates that the proposed kernel fusion method could reduce energy consumption without performance loss for several typical kernels.","","978-1-4244-9779-9","10.1109/GreenCom-CPSCom.2010.102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5724850","Kernel Fusion;Power Efficiency;Power Optimization;GPGPU","Kernel;Instruction sets;Graphics processing unit;Energy consumption;Hardware;Mathematical model;Dynamic programming","computer graphic equipment;coprocessors;energy conservation;power aware computing","kernel fusion;multithreaded GPU;power efficiency;graphics processing unit;desktop systems;supercomputer systems;dynamic voltage and frequency scaling;CUDA programming model","","59","1","21","","7 Mar 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"HLanc: Heterogeneous Parallel Implementation of the Implicitly Restarted Lanczos Method","S. Zhang; T. Li; X. Jiao; Y. Wang; Y. Yang","Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China; Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China","2014 43rd International Conference on Parallel Processing Workshops","11 May 2015","2014","","","403","410","Graphics Processing Unit (GPU) has been used as a ubiquitous accelerator for general purpose computing, such as linear algebra routines and numerical methods. The implicitly restarted Lanczos method (IRLM) is well suited for solving the partial eigenvalue problem for large symmetric sparse matrices, which is important in many real world applications. In this paper, we present the HLanc library, a parallel implementation of IRLM on the heterogeneous CPU-GPU architecture employing the CUDA programming model. The HLanc library is designed with separated heterogeneous parallel IRLM solvers and sparse matrix-vector multiplication (SPMV) operators. The SPMV operators hide the details about the storage of sparse matrices from the IRLM solvers, so the solvers can work with any spare matrix formats. Especially the SPMV operators and IRLM solvers can be combined arbitrarily for achieving the best performance of CPU-GPU heterogeneous system. The HLanc is evaluated using eight sparse matrices with the NVIDIA GTX 480 and GTX TITAN Black GPUs. The results show that HLanc achieves 15 times speedup than the ARPACK library and scales well across different GPU generations.","2332-5690","978-1-4799-5615-9","10.1109/ICPPW.2014.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103478","GPU;CUDA;symmetric sparse matrix;IRLM;SPMV;HLanc","Sparse matrices;Graphics processing units;Eigenvalues and eigenfunctions;Libraries;Computer architecture;Symmetric matrices;Hardware","eigenvalues and eigenfunctions;graphics processing units;mathematics computing;matrix multiplication;parallel architectures;parallel programming;software libraries;sparse matrices;vectors","heterogeneous parallel implementation;implicitly restarted Lanczos method;graphics processing unit;ubiquitous accelerator;general purpose computing;linear algebra routines;numerical methods;partial eigenvalue problem;symmetric sparse matrices;HLanc library;heterogeneous CPU-GPU architecture;CUDA programming model;heterogeneous parallel IRLM solvers;sparse matrix-vector multiplication operators;SPMV operators;CPU-GPU heterogeneous system;NVIDIA GTX 480;GTX TITAN Black GPUs","","2","","26","","11 May 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Stargazer: Automated regression-based GPU design space exploration","W. Jia; K. A. Shaw; M. Martonosi","Princeton University, USA; University of Richmond, USA; Princeton University, USA","2012 IEEE International Symposium on Performance Analysis of Systems & Software","26 Apr 2012","2012","","","2","13","Graphics processing units (GPUs) are of increasing interest because they offer massive parallelism for high-throughput computing. While GPUs promise high peak performance, their challenge is a less-familiar programming model with more complex and irregular performance trade-offs than traditional CPUs or CMPs. In particular, modest changes in software or hardware characteristics can lead to large or unpredictable changes in performance. In response to these challenges, our work proposes, evaluates, and offers usage examples of Stargazer<sup>1</sup>, an automated GPU performance exploration framework based on stepwise regression modeling. Stargazer sparsely and randomly samples parameter values from a full GPU design space and simulates these designs. Then, our automated stepwise algorithm uses these sampled simulations to build a performance estimator that identifies the most significant architectural parameters and their interactions. The result is an application-specific performance model which can accurately predict program runtime for any point in the design space. Because very few initial performance samples are required relative to the extremely large design space, our method can drastically reduce simulation time in GPU studies. For example, we used Stargazer to explore a design space of nearly 1 million possibilities by sampling only 300 designs. For 11 GPU applications, we were able to estimate their runtime with less than 1.1% average error. In addition, we demonstrate several usage scenarios of Stargazer.","","978-1-4673-1146-5","10.1109/ISPASS.2012.6189201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189201","","Graphics processing unit;Instruction sets;Mathematical model;Hardware;Space exploration;Runtime;Concurrent computing","computer architecture;graphics processing units;regression analysis","Stargazer;automated regression;GPU design space exploration;graphics processing unit;automated GPU performance exploration framework;stepwise regression modeling","","44","","28","","26 Apr 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"DART-CUDA: A PGAS Runtime System for Multi-GPU Systems","L. Zhou; K. Fuerlinger","Dept. of Comput. Sci., Ludwig-Maximilians-Univ. (LMU) Munchen, Munich, Germany; Dept. of Comput. Sci., Ludwig-Maximilians-Univ. (LMU) Munchen, Munich, Germany","2015 14th International Symposium on Parallel and Distributed Computing","23 Jul 2015","2015","","","110","119","The Partitioned Global Address Space (PGAS) approach is a promising programming model in high performance parallel computing that combines the advantages of distributed memory systems and shared memory systems. The PGAS model has been used on a variety of hardware platforms in the form of PGAS programming languages like Unified Parallel C (UPC), Chapel and Fortress. However, in spite of the increasing adoption in distributed and shared memory systems, the extension of the PGAS model to accelerator platforms is still not well supported. To exploit the immense computational power of multi-GPU systems, this work is concerned with the design and implementation of a Partitioned Global Address Space model for multi-GPU systems. Several issues related to the combination of logically separate GPU memories on multiple graphic cards are addressed. Furthermore, the execution model of modern GPU architectures is studied and a task creation mechanism with load balancing is proposed. Our work is implemented in the context of the DASH project, a C++ template library that realizes PGAS semantics through operator overloading. Experimental results suggest promising performance of the design and its implementation.","2379-5352","978-1-4673-7148-3","10.1109/ISPDC.2015.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165137","PGAS;Partitioned Global Address Space;MultiGPU systems;CUDA;Heterogeneous computing","Graphics processing units;Resource management;Electronics packaging;Runtime;Programming;Computational modeling;Kernel","C++ language;distributed memory systems;graphics processing units;parallel processing;resource allocation;software libraries","C++ template library;DASH project;load balancing;task creation mechanism;GPU architecture;multiple graphic card;GPU memories;PGAS programming language;Chapel;UPC;unified parallel C;shared memory system;distributed memory system;high performance parallel computing;PGAS approach;partitioned global address space approach;multiGPU system;PGAS runtime system;DART-CUDA","","2","","11","","23 Jul 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GPU acceleration of the dynamics routine in the HIRLAM weather forecast model","V. T. Vu; G. Cats; L. Wolters","Leiden Institute of Advanced Computer Science, Leiden University, 2333 CA, The Netherlands; Royal Netherlands, Meteorological Institute, 3730 AE De Bilt, The Netherlands; Leiden Institute of Advanced Computer Science, Leiden University, 2333 CA, The Netherlands","2010 International Conference on High Performance Computing & Simulation","12 Aug 2010","2010","","","31","38","Programmable graphics processing units (GPUs) nowadays offer very high performance computing power at relatively low hardware cost and power consumption. In this paper, we present the implementation of the dynamics routine of the HIRLAM weather forecast model on the NVIDIA GeForce 9800 GX2 GPU card using the Compute Unified Device Architecture (CUDA) as parallel programming model. We converted the original Fortran to C and CUDA by hand, straightforwardly, without much concern about optimization. On a single GPU, we observe speed-ups by an order of magnitude over our hosting CPU (Intel quad core, 1998 MHz). This includes the relatively very costly copying of data between GPU and CPU memories. Calculation times proper decreased by a factor of 2000. A single GPU, however, has not enough memory for practical use. Therefore, we investigated a parallel implementation on 4 GPUs. We found a parallel speed-up of 3.6, which is not very promising if memory limitations force the use of many GPUs in parallel. We discuss several options to solve this issue.","","978-1-4244-6830-0","10.1109/HPCS.2010.5547152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5547152","GPGPU;Large Scale Scientific Computing;Parallelization of Simulation;CUDA;Numerical Weather Prediction model;Dynamics","Graphics processing unit;Kernel;Weather forecasting;Predictive models","computer graphic equipment;coprocessors;geophysics computing;parallel programming;weather forecasting","GPU acceleration;dynamics routine;programmable graphics processing unit;high performance computing power;HIRLAM weather forecast model;NVIDIA GeForce 9800 GX2 GPU card;Compute Unified Device Architecture;CUDA;parallel programming;Intel quad core","","6","","18","","12 Aug 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"CUDA-Based Computation for Visual Odometry","S. -H. Liu; C. -C. Hsu; W. -Y. Wang; C. -H. Lin","Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan; Department of Mechatronic Engineering, National Taiwan Normal University, Taipei, Taiwan; Department of Mechatronic Engineering, National Taiwan Normal University, Taipei, Taiwan","2018 IEEE 7th Global Conference on Consumer Electronics (GCCE)","13 Dec 2018","2018","","","64","65","An enhanced visual odometry (VO) system is proposed to improve the accuracy of pose estimation based on a corrected model, and the matching algorithm is implemented on graphical processing units (GPUs) so that the computation can be accelerated in parallel and in real-time using the compute unified device architecture (CUDA) programming model. To evaluate the performance of the proposed approach, an ASUS Xtion 3D camera, laptop, and NVIDIA TX2 are employed to conduct extensive experiments. The experimental results show that compared with the traditional VO algorithm, the proposed approach gives better results over the traditional VO algorithm.","2378-8143","978-1-5386-6309-7","10.1109/GCCE.2018.8574869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574869","Visual odometry;GPU;CUDA","Graphics processing units;Cameras;Feature extraction;Pose estimation;Computational modeling;Visual odometry;Computational efficiency","cameras;computerised instrumentation;distance measurement;graphics processing units;parallel architectures;pose estimation;robot vision","graphical processing units;compute unified device architecture programming model;ASUS Xtion 3D camera;NVIDIA TX2;CUDA-based computation;matching algorithm;visual odometry system;VO algorithm;GPU","","","","6","","13 Dec 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Empowering Visual Categorization With the GPU","K. E. A. van de Sande; T. Gevers; C. G. M. Snoek","Intelligent Systems Lab Amsterdam, Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands; Intelligent Systems Lab Amsterdam, Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands; Intelligent Systems Lab Amsterdam, Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands","IEEE Transactions on Multimedia","17 Jan 2011","2011","13","1","60","70","Visual categorization is important to manage large collections of digital images and video, where textual metadata is often incomplete or simply unavailable. The bag-of-words model has become the most powerful method for visual categorization of images and video. Despite its high accuracy, a severe drawback of this model is its high computational cost. As the trend to increase computational power in newer CPU and GPU architectures is to increase their level of parallelism, exploiting this parallelism becomes an important direction to handle the computational cost of the bag-of-words approach. When optimizing a system based on the bag-of-words approach, the goal is to minimize the time it takes to process batches of images. this paper, we analyze the bag-of-words model for visual categorization in terms of computational cost and identify two major bottlenecks: the quantization step and the classification step. We address these two bottlenecks by proposing two efficient algorithms for quantization and classification by exploiting the GPU hardware and the CUDA parallel programming model. The algorithms are designed to (1) keep categorization accuracy intact, (2) decompose the problem, and (3) give the same numerical results. In the experiments on large scale datasets, it is shown that, by using a parallel implementation on the Geforce GTX260 GPU, classifying unseen images is 4.8 times faster than a quad-core CPU version on the Core i7 920, while giving the exact same numerical results. In addition, we show how the algorithms can be generalized to other applications, such as text retrieval and video retrieval. Moreover, when the obtained speedup is used to process extra video frames in a video retrieval benchmark, the accuracy of visual categorization is improved by 29%.","1941-0077","","10.1109/TMM.2010.2091400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5625914","Bag-of-words;computational efficiency;General-Purpose computation on Graphics Processing Units (GPGPU);image classification;image/video retrieval;multicore processing;parallel processing;support vector machines","Visualization;Graphics processing unit;Kernel;Computational modeling;Feature extraction;Vector quantization;Acceleration","computer graphic equipment;coprocessors;image classification;image segmentation;meta data;parallel programming;video signal processing","visual categorization;GPU;digital image;digital video;textual metadata;parallel architecture;quantization step;classification step;CUDA;parallel programming model;Geforce GTX260;image classification;Core i7 920;computational efficiency;graphics processing unit;general purpose computation","","51","5","51","IEEE","11 Nov 2010","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Parallelization and Optimization of SIFT on GPU Using CUDA","Z. Yonglong; M. Kuizhi; J. Xiang; D. Peixiang","NA; NA; Xian Jiaotong Univ., Xian, China; NA","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","12 Jun 2014","2013","","","1351","1358","Scale-invariant feature transform (SIFT) based feature extraction algorithm is widely applied to extract features from images, and it is very attractive to accelerate these SIFT based algorithms on GPU. In this paper, we present several parallel computing strategies, implement and optimize the SIFT algorithm using CUDA programming model on GPU. Each stage of SIFT is analyzed in detail to choose the parallel strategy. On the basis of the elementary CUDA-SIFT and CUDA architecture, we optimize the implementation from several aspects to speedup the CUDA-SIFT. Experimental results demonstrate that our implementation after optimization is 2.5 times faster than previous optimization, and our CUDA based SIFT can run at the speed of 20 frames per second on most images with 1280x 960 resolution in the test. Using 1920 x1440 image to test, we have obtained a speed of 11 frames per second on average, which is about 60 times faster than the CPU implementation of SIFT. In short, our implementation obtains appropriate accuracy and higher efficiency compared to CPU implementations and other GPU implementations, which is attributed to our dedicated optimization strategies.","","978-0-7695-5088-6","10.1109/HPCC.and.EUC.2013.192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832074","","Graphics processing units;Instruction sets;Feature extraction;Convolution;Histograms;Optimization;Vectors","graphics processing units;parallel architectures;parallel processing;transforms","GPU;SIFT optimization;SIFT parallelization;scale invariant feature transform;feature extraction algorithm;parallel computing strategies;CUDA programming model;parallel strategy;CUDA architecture;CUDA-SIFT;CPU implementation","","5","","13","","12 Jun 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Simplifying the multi-GPU programming of a hyperspectral image registration algorithm","J. Fernàndez-Fabeiro; A. Gonzalez-Escribano; D. R. Llanos","Universidad de Valladolid,Departamento de Informaticá,Valladolid,Spain; Universidad de Valladolid,Departamento de Informaticá,Valladolid,Spain; Universidad de Valladolid,Departamento de Informaticá,Valladolid,Spain","2019 International Conference on High Performance Computing & Simulation (HPCS)","9 Sep 2020","2019","","","11","18","Hyperspectral image registration is a relevant task for real-time applications like environmental disasters management or search and rescue scenarios. Traditional algorithms for this problem were not really devoted to real-time performance. The HYFMGPU algorithm arose as a high-performance GPU-based solution to solve such a lack. Nevertheless, a single-GPU solution is not enough, as sensors are evolving and then generating images with finer resolutions and wider wavelength ranges. An MPI+CUDA multi-GPU implementation of HYFMGPU was previously presented. However, this solution shows the programming complexity of combining MPI with an accelerator programming model. In this paper we present a new and more abstract programming approach for this type of applications, which provides a high efficiency while simplifying the programming of the multi-device parts of the code. The solution uses Hitmap, a library to ease the programming of parallel applications based on distributed arrays. It uses a more algorithm-oriented approach than MPI, including abstractions for the automatic partition and mapping of arrays at runtime with arbitrary granularity, as well as techniques to build flexible communication patterns that transparently adapt to the data partitions. We show how these abstractions apply to this application class. We present a comparison of development effort metrics between the original MPI implementation and the one based on Hitmap, with reductions of up to 95% for the Halstead score in specific work redistribution steps. We finally present experimental results showing that these abstractions are internally implemented in a high efficient way that can reduce the overall performance time in up to 37% comparing with the original MPI implementation.","","978-1-7281-4484-9","10.1109/HPCS48598.2019.9188064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188064","Hyperspectral imaging;image registration;parallel libraries;distributed arrays;MPI;CUDA;GPGPU","Programming;Graphics processing units;Hyperspectral imaging;Real-time systems;Libraries;Principal component analysis","application program interfaces;emergency management;graphics processing units;hyperspectral imaging;image registration;message passing;parallel architectures","multiGPU programming;hyperspectral image registration algorithm;real-time applications;environmental disasters management;search and rescue scenario;real-time performance;HYFMGPU algorithm;high-performance GPU-based solution;programming complexity;accelerator programming model;abstract programming approach;multidevice parts;Hitmap;parallel applications;distributed arrays;algorithm-oriented approach;application class;performance time","","","","29","","9 Sep 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Two-stage Asynchronous Iterative Solvers for multi-GPU Clusters","P. Nayak; T. Cojean; H. Anzt","Karlsruhe Institute of Technology,Germany; Karlsruhe Institute of Technology,Germany; Karlsruhe Institute of Technology,Germany","2020 IEEE/ACM 11th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems (ScalA)","31 Dec 2020","2020","","","9","18","Given the trend of supercomputers accumulating much of their compute power in GPU accelerators composed of thousands of cores and operating in streaming mode, global synchronization points become a bottleneck, severely confining the performance of applications. In consequence, asynchronous methods breaking up the bulk-synchronous programming model are becoming increasingly attractive. In this paper, we study a GPU-focused asynchronous version of the Restricted Additive Schwarz (RAS) method that employs preconditioned Krylov subspace methods as subdomain solvers. We analyze the method for various parameters such as local solver tolerance and iteration counts. Leveraging the multi-GPU architecture on Summit, we show that these two-stage methods are more memory and time efficient than asynchronous RAS using direct solvers. We also demonstrate the superiority over synchronous counterparts, and present results using one-sided CUDA-aware MPI on up to 36 NVIDIA V100 GPUs.","","978-1-6654-2270-3","10.1109/ScalA51936.2020.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308758","Asynchronous iterative methods;Schwarz methods;GPUs;Krylov subspace solvers","Iterative methods;Convergence;Synchronization;Additives;Symmetric matrices;Sparse matrices;Programming","graphics processing units;hardware accelerators;iterative methods;multiprocessing systems;parallel architectures;parallel machines","multiGPU clusters;GPU accelerators;global synchronization points;GPU-focused asynchronous version;restricted additive Schwarz method;preconditioned Krylov subspace methods;subdomain solvers;local solver tolerance;iteration counts;multiGPU architecture;two-stage asynchronous iterative solvers;supercomputers;Summit;asynchronous RAS;one-sided CUDA-aware MPI;NVIDIA V100 GPUs","","","","14","","31 Dec 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Parallel Fast Pencil Drawing Generation Algorithm Based on GPU","J. Qiu; B. Liu; J. He; C. Liu; Y. Li","College of Information Engineering, Northwest A&F University, Yangling, China; College of Information Engineering, Northwest A&F University, Yangling, China; College of Mathematics and Computer Science, Yan’an University, Yan’an, China; College of Information Engineering, Northwest A&F University, Yangling, China; School of Computer Science and Technology, Xi’an University of Science and Technology, Xi’an, China","IEEE Access","5 Jul 2019","2019","7","","83543","83555","With the development of image processing technology, pencil drawing has been widely used in video games and mobile phone applications. However, the existing pencil drawing algorithms require a large amount of time to convert a real picture into a pencil drawing; hence, it is difficult to apply them to real-time systems. This paper proposes a parallel fast pencil drawing generation algorithm based on the graphics processing unit (GPU) to accelerate the real-time rendering process of sketch painting. The parallelism of the pencil drawing generation algorithm is identified via a theoretical analysis at first. Then, sub-algorithms of the sequential algorithm are designed in parallel using the compute unified device architecture (CUDA) programming model and executed via thread-level parallel techniques. Furthermore, an optimal cache pattern of data that reduce the access time of the most frequently used data is structured using shared memory and constant memory. Finally, task-level parallelism is achieved by the CUDA stream technology, which overlaps independent sub-tasks for further acceleration. On the CUDA platform, the experimental results demonstrate that the proposed parallel algorithm can achieve a significant increase in speedup. The proposed algorithm achieves a performance improvement of 448.59 times compared with the sequential algorithm, on 2560×1920-resolution images, and maintains a high degree of similarity with the real pencil paintings. Hence, the proposed algorithm is suitable for real-time pencil drawing rendering and has promising application prospects in non-photorealistic rendering.","2169-3536","","10.1109/ACCESS.2019.2924658","National Natural Science Foundation of China(grant numbers:61602388); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2017JM6059); Fundamental Research Funds for the Central Universities(grant numbers:2452019064); Postdoctoral Science Foundation of Shaanxi Province of China(grant numbers:2016BSHEDZZ121); China Postdoctoral Science Foundation(grant numbers:2017M613216,2018M633585); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2018JQ6060); Key Program of the National Natural Science Foundation of China(grant numbers:61834005); Fundamental Research Funds for the Central Universities(grant numbers:2452016081); Doctoral Starting up Foundation of Yan’an University(grant numbers:YDBK2019-06); Northwest A and F University(grant numbers:2201810712307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744506","Non-photorealistic rendering;pencil drawing;parallel algorithm;GPU platform;convolution operation;CUDA","Graphics processing units;Rendering (computer graphics);Instruction sets;Histograms;Parallel processing;STEM;Real-time systems","graphics processing units;image resolution;parallel architectures;real-time systems;rendering (computer graphics)","parallel algorithm;sequential algorithm;parallel fast pencil drawing generation algorithm;image processing technology;real-time rendering process;thread-level parallel techniques;task-level parallelism;CUDA programming model;compute unified device architecture;real-time pencil drawing rendering;pencil drawing algorithms","","3","","37","CCBY","24 Jun 2019","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"An Asynchronous Parallel Implementation of Multilevel Fast Multipole Algorithm on GPU Cluster for 3D Electromagnetic Scattering Problems","R. -P. Xi; W. -J. He; M. -L. Yang; X. -Q. Sheng","Center for Electromagnetic Simulation, School of Information and Electronics, Beijing Institute of Technology,Beijing,China,100081; Center for Electromagnetic Simulation, School of Information and Electronics, Beijing Institute of Technology,Beijing,China,100081; Center for Electromagnetic Simulation, School of Information and Electronics, Beijing Institute of Technology,Beijing,China,100081; Center for Electromagnetic Simulation, School of Information and Electronics, Beijing Institute of Technology,Beijing,China,100081","2021 International Applied Computational Electromagnetics Society (ACES-China) Symposium","8 Nov 2021","2021","","","1","2","This paper presents a CPU/GPU asynchronous computing pattern based improved parallel multilevel fast multipole algorithm (MLFMA) for 3D electromagnetic scattering problems on GPU Cluster. In the presented parallel implementation, the matrix assembly process of the MLFMA is decomposed into CPU execution and GPU execution two parts. The former is performed on CPU using OpenMP multi-threading programming model, while the latter is performed on GPU with CUDA programming model. The execution time between the two parts is overlapped by using the feature of asynchronous execution between CPU and GPU. The performance of the proposed parallel implementation is investigated in terms of accuracy and efficiency. Numerical results show that, with the proposed parallel approach, over 10% speed-up can be attained, compared with the original parallel implementation.","","978-1-7335096-1-9","10.23919/ACES-China52398.2021.9581392","National Key R&D Program of China(grant numbers:2017YFB0202500); NSFC(grant numbers:61971034); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581392","Multilevel fast multipole algorithm;OpenMP;CUDA;Asynchronous Computing;scattering","Three-dimensional displays;Runtime;Computational modeling;Electromagnetic scattering;Graphics processing units;Programming;Computational electromagnetics","","","","","","4","","8 Nov 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Accelerating DNN Inference with GraphBLAS and the GPU","X. Wang; Z. Lin; C. Yang; J. D. Owens","University of California, Davis,Department of Computer Science,Davis,California,95616; University of California, Davis,Department of Electrical & Computer Engineering,Davis,California,95616; University of California, Davis,Department of Electrical & Computer Engineering,Davis,California,95616; University of California, Davis,Department of Electrical & Computer Engineering,Davis,California,95616","2019 IEEE High Performance Extreme Computing Conference (HPEC)","28 Nov 2019","2019","","","1","6","This work addresses the 2019 Sparse Deep Neural Network Graph Challenge with an implementation of this challenge using the GraphBLAS programming model. We demonstrate our solution to this challenge with GraphBLAST, a GraphBLAS implementation on the GPU, and compare it to SuiteSparse, a GraphBLAS implementation on the CPU. The GraphBLAST implementation is 1.94 × faster than Suite-Sparse; the primary opportunity to increase performance on the GPU is a higher-performance sparse-matrix-times-sparse-matrix (SpGEMM) kernel.","2643-1971","978-1-7281-5020-8","10.1109/HPEC.2019.8916498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8916498","","Sparse matrices;Graphics processing units;Neurons;Matlab;Runtime;Neural networks;Memory management","graph theory;graphics processing units;inference mechanisms;multiprocessing systems;neural nets;sparse matrices","GraphBLAS implementation;GPU;GraphBLAST implementation;Suite-Sparse;DNN Inference;2019 Sparse Deep Neural Network Graph Challenge;GraphBLAS programming model;sparse-matrix-times-sparse-matrix kernel","","4","","14","","28 Nov 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"CNN based high performance computing for real time image processing on GPU","S. Potluri; A. Fasih; L. K. Vutukuru; F. A. Machot; K. Kyamakya","Transportation Informatics Group, Alpen-Adria University of Klagenfurt, Klagenfurt, Austria; Transportation Informatics Group, Alpen-Adria University of Klagenfurt, Klagenfurt, Austria; Transportation Informatics Group, Alpen-Adria University of Klagenfurt, Klagenfurt, Austria; Transportation Informatics Group, Alpen-Adria University of Klagenfurt, Klagenfurt, Austria; Transportation Informatics Group, Alpen-Adria University of Klagenfurt, Klagenfurt, Austria","Proceedings of the Joint INDS'11 & ISTET'11","22 Sep 2011","2011","","","1","7","Many of the basic image processing tasks suffer from processing overhead to operate over the whole image. In real time applications the processing time is considered as a big obstacle for its implementations. A High Performance Computing (HPC) platform is necessary in order to solve this problem. The usage of hardware accelerator make the processing time low. In recent developments, the Graphics Processing Unit (GPU) is being used in many applications. Along with the hardware accelerator a proper choice of the computing algorithm makes it an added advantage for fast processing of images. The Cellular Neural Network (CNN) is a large-scale nonlinear analog circuit able to process signals in real time [1]. In this paper, we develop a new design in evaluation of image processing algorithms on the massively parallel GPUs with CNN implementation using Open Computing Language (OpenCL) programming model. This implementation uses the Discrete Time CNN (DT-CNN) model which is derived from originally proposed CNN model. The inherent massive parallelism of CNN along with GPUs makes it an advantage for high performance computing platform [2]. The advantage of OpenCL makes the design to be portable on all the available graphics processing devices and multi core processors. Performance evaluation is done in terms of execution time with both device (i.e. GPU) and host (i.e. CPU).","2324-8335","978-1-4577-0762-9","10.1109/INDS.2011.6024781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6024781","Image processing;Hardware accelerators;Cellular Neural Networks;GPUs;High Performance Computing;OpenCL","Graphics processing unit;Mathematical model;Kernel;Image processing;Equations;Computer architecture","analogue circuits;cellular neural nets;computer graphic equipment;coprocessors;image processing;multiprocessing systems;parallel programming","CNN based high performance computing;real time image processing;hardware accelerator;graphical processing unit;cellular neural network;large-scale nonlinear analog circuit;signal processing;parallel GPU;open computing language programming model;discrete time CNN model;DT-CNN model;OpenCL;multicore processor;performance evaluation","","23","","17","","22 Sep 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Accelerating scientific applications using GPU's","M. Taher","Ain Shams University, Cairo, Egypt","2009 4th International Design and Test Workshop (IDT)","2 Feb 2010","2009","","","1","6","Graphics processing units (GPUs) have emerged as a powerful platform for high-performance computation. They have been successfully used to accelerate many scientific workloads. Typically, the computationally intensive parts of the application are offloaded to the GPU, which serves as the CPU's parallel coprocessor. The key to effective utilization of GPUs for scientific computing is the design and implementation of efficient data-parallel algorithms that can scale to hundreds of tightly coupled processing units. Many compute intensive scientific applications are well suited to GPUs, due to their extensive computational requirements, and because they lend themselves to parallel processing implementations. The use of multiple GPUs can bring even more computational power to bear on highly parallelizable computational problems. This paper discusses performance results for some fundamental cores of scientific applications such as fft, smith-waterman sequence alignment algorithm, and data encryption standard (DES) on the Nvidia GPUs using the CUDA programming model. Results have demonstrated acceleration up to 25 times speedup using a single G80 Nvidia GPU.","2162-061X","978-1-4244-5750-2","10.1109/IDT.2009.5404114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5404114","","Acceleration;Yarn;Graphics;Concurrent computing;Hardware;Parallel processing;Computer architecture;Coprocessors;Computer applications;Cryptography","computer graphic equipment;coprocessors","graphics processing units;CPU parallel coprocessor;scientific computing;efficient data parallel algorithms;parallel processing;smith-waterman sequence alignment algorithm;data encryption standard;CUDA programming model;Nvidia GPU","","2","","11","","2 Feb 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A large-scale cross-architecture evaluation of thread-coarsening","A. Magni; C. Dubach; M. F. P. O'Boyle","University of Edinburgh, UK; University of Edinburgh, UK; University of Edinburgh, UK","SC '13: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis","14 Aug 2014","2013","","","1","11","OpenCL has become the de-facto data parallel programming model for parallel devices in today's high-performance supercomputers. OpenCL was designed with the goal of guaranteeing program portability across hardware from different vendors. However, achieving good performance is hard, requiring manual tuning of the program and expert knowledge of each target device. In this paper we consider a data parallel compiler transformation - thread-coarsening - and evaluate its effects across a range of devices by developing a source-to-source OpenCL compiler based on LLVM. We thoroughly evaluate this transformation on 17 benchmarks and five platforms with different coarsening parameters giving over 43,000 different experiments. We achieve speedups over 9x on individual applications and average speedups ranging from 1.15x on the Nvidia Kepler GPU to 1.50x on the AMD Cypress GPU. Finally, we use statistical regression to analyse and explain program performance in terms of hardware-based performance counters.","2167-4337","978-1-4503-2378-9","10.1145/2503210.2503268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877444","GPU;OpenCL;Thread coarsening;Regression trees","Instruction sets;Performance evaluation;Kernel;Hardware;Benchmark testing;Graphics processing units;Multicore processing","graphics processing units;multi-threading;program compilers;regression analysis;software architecture;software performance evaluation;software portability","large-scale cross-architecture evaluation;thread-coarsening parameters;de-facto data parallel programming model;high-performance supercomputers;program portability;data parallel compiler trans- formation;source-to-source OpenCL compiler;LLVM;Nvidia Kepler GPU;AMD Cypress GPU;statistical regression;program performance;hardware-based performance counters","","24","","28","","14 Aug 2014","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"StreamMR: An Optimized MapReduce Framework for AMD GPUs","M. Elteir; H. Lin; W. Feng; T. Scogland","City of Sci. Researches & Technol. Applic., Egypt; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA","2011 IEEE 17th International Conference on Parallel and Distributed Systems","2 Jan 2012","2011","","","364","371","MapReduce is a programming model from Google that facilitates parallel processing on a cluster of thousands of commodity computers. The success of MapReduce in cluster environments has motivated several studies of implementing MapReduce on a graphics processing unit (GPU), but generally focusing on the NVIDIA GPU. Our investigation reveals that the design and mapping of the MapReduce framework needs to be revisited for AMD GPUs due to their notable architectural differences from NVIDIA GPUs. For instance, current state-of-the-art MapReduce implementations employ atomic operations to coordinate the execution of different threads. However, atomic operations can implicitly cause inefficient memory access, and in turn, severely impact performance. In this paper, we propose Streamer, an OpenCL MapReduce framework optimized for AMD GPUs. With efficient atomic-free algorithms for output handling and intermediate result shuffling, Stream MR is superior to atomic-based MapReduce designs and can outperform existing atomic-free MapReduce implementations by nearly five-fold on an AMD Radeon HD 5870.","1521-9097","978-0-7695-4576-9","10.1109/ICPADS.2011.131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121299","atomics;parallel computing;AMD GPU;GPGPU;MapReduce;Mars;MapCG;OpenCL","Instruction sets;Kernel;Mars;Graphics processing unit;Programming;High definition video;Optimization","graphics processing units;parallel processing;workstation clusters","StreamMR;optimized MapReduce framework;AMD GPU;programming model;parallel processing;commodity computers;cluster environments;graphics processing unit;NVIDIA GPU;OpenCL MapReduce framework;atomic-free algorithm","","20","1","19","","2 Jan 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Evaluating OpenMP 4.0's Effectiveness as a Heterogeneous Parallel Programming Model","M. Martineau; S. McIntosh-Smith; W. Gaudin","HPC Group, Univ. of Bristol, Bristol, UK; HPC Group, Univ. of Bristol, Bristol, UK; Atomic Weapons Establ., Aldermaston, UK","2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","4 Aug 2016","2016","","","338","347","Although the OpenMP 4.0 standard has been available since 2013, support for GPUs has been absent up until very recently, with only a handful of experimental compilers available. In this work we evaluate the performance of Cray's new NVIDIA GPU targeting implementation of OpenMP 4.0, with the mini-apps TeaLeaf, CloverLeaf and BUDE. We successfully port each of the applications, using a simple and consistent design throughout, and achieve performance on an NVIDIA K20X that is comparable to Cray's OpenACC in all cases. BUDE, a compute bound code, required 2.2x the runtime of an equivalently optimised CUDA code, which we believe is caused by an inflated frequency of control flow operations and less efficient arithmetic optimisation. Impressively, both TeaLeaf and CloverLeaf, memory bandwidth bound codes, only required 1.3x the runtime of hand-optimised CUDA implementations. Overall, we find that OpenMP 4.0 is a highly usable open standard capable of performant heterogeneous execution, making it a promising option for scientific application developers.","","978-1-5090-3682-0","10.1109/IPDPSW.2016.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529889","high performance computing;parallel computing;application programming interfaces;OpenMP;performance portability","Standards;Graphics processing units;Performance evaluation;Complexity theory;Parallel processing;Parallel programming;Runtime","application program interfaces;graphics processing units;optimising compilers;parallel architectures;parallel programming;software performance evaluation","OpenMP 4.0 effectiveness evaluation;heterogeneous parallel programming model;OpenMP 4.0 standard;compilers;NVIDIA GPU targeting implementation;mini-apps;TeaLeaf;CloverLeaf;BUDE;NVIDIA K20X;OpenACC;BUDE;compute bound code;equivalently optimised CUDA code;control flow operations;arithmetic optimisation;memory bandwidth bound codes;hand-optimised CUDA implementations;heterogeneous execution;scientific application developers","","18","","19","","4 Aug 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"The Research on Parallel Optimization of SAR Imaging R-D Algorithm Based on CUDA","P. Wei; J. Du; S. Sui; Y. Chen","Luoyang Electronic Equipment Test Center,LEETC, Luoyang, China; Luoyang Electronic Equipment Test Center,LEETC, Luoyang, China; Luoyang Electronic Equipment Test Center,LEETC, Luoyang, China; Luoyang Electronic Equipment Test Center,LEETC, Luoyang, China","2018 10th International Conference on Communication Software and Networks (ICCSN)","11 Oct 2018","2018","","","526","530","Synthetic Aperture Radar (SAR) imaging technology is widely used in the field of remote sensing observation, navigation positioning and so on, SAR imaging is large in data scale and long in operating time. Based on the Compute Unified Device Architecture (CUDA) programming model, the SAR imaging R-D algorithm is designed and implemented for parallel optimization on the CPU-GPU heterogeneous platform and tested on the GPU Tesla K20. The test shows that the efficiency of the core steps of R-D algorithm has been greatly improved.","2472-8489","978-1-5386-7223-5","10.1109/ICCSN.2018.8488250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488250","SAR;parallel optimization;CUDA programming model","Graphics processing units;Azimuth;Imaging;Instruction sets;Radar polarimetry;Radar imaging;Programming","graphics processing units;microprocessor chips;parallel architectures;radar imaging;synthetic aperture radar","parallel optimization;R-D algorithm;CUDA;Synthetic Aperture Radar imaging technology;remote sensing observation;navigation positioning;SAR imaging;data scale;Compute Unified Device Architecture;CPU-GPU heterogeneous platform","","","","13","","11 Oct 2018","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Exploiting Task-Parallelism on GPU Clusters via OmpSs and rCUDA Virtualization","A. Castelló; R. Mayo; J. Planas; E. S. Quintana-Ortí","Dept. de Ing. y Cienc. de Comput., Univ. Jaume I, Castellon, Spain; Dept. de Ing. y Cienc. de Comput., Univ. Jaume I, Castellon, Spain; Barcelona Supercomput. Center, Barcelona, Spain; Dept. de Ing. y Cienc. de Comput., Univ. Jaume I, Castellon, Spain","2015 IEEE Trustcom/BigDataSE/ISPA","3 Dec 2015","2015","3","","160","165","OmpSs is a task-parallel programming model consisting of a reduced collection of OpenMP-like directives, a front-end compiler, and a runtime system. This directive-based programming interface helps developers accelerate their application's execution, e.g. in a cluster equipped with graphics processing units (GPUs), with a low programming effort. On the other hand, the virtualization package rCUDA provides seamless and transparent remote access to any CUDA GPU in a cluster, via the CUDA Driver and Runtime programming interfaces. In this paper we investigate the hurdles and practical advantages of combining these two technologies. Our experimental study targets two cluster configurations: a system where all the GPUs are located into a single cluster node, and a cluster with the GPUs distributed among the nodes. Two applications, the N-body particle simulation and the Cholesky factorization of a dense matrix, are employed to expose the bottlenecks and performance of a remote virtualization solution applied to these two OmpSs task-parallel codes.","","978-1-4673-7952-6","10.1109/Trustcom.2015.626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345642","Task parallelism;graphics processing units (GPUs);OmpSs;CUDA;remote virtualization","Graphics processing units;Servers;Virtualization;Runtime;Message systems;Programming;Instruction sets","device drivers;graphics processing units;matrix decomposition;parallel architectures;parallel programming;pattern clustering;program compilers;task analysis;virtualisation","OmpSs task parallel code;task parallel programming model;OpenMP-like directive;frontend compiler;runtime system;directive-based programming interface;application execution;graphics processing unit;GPU;rCUDA;CUDA driver;runtime programming interface;cluster configuration;single cluster node;N-body particle simulation;Cholesky factorization;dense matrix;remote virtualization package","","1","","20","","3 Dec 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A Translation Framework for Virtual Execution Environment on CPU/GPU Architecture","G. Dong; K. Chen; E. Zhu; Y. Zhang; Z. Qi; H. Guan","Sch. of Software, Shanghai Jiaotong Univ., Shanghai, China; Sch. of Inf. Security Eng., Shanghai Jiaotong Univ., Shanghai, China; Dept. of Comput. Sci. & Eng., Shanghai Jiaotong Univ., Shanghai, China; Sch. of Software, Shanghai Jiaotong Univ., Shanghai, China; Sch. of Software, Shanghai Jiaotong Univ., Shanghai, China; Dept. of Comput. Sci. & Eng., Shanghai Jiaotong Univ., Shanghai, China","2010 3rd International Symposium on Parallel Architectures, Algorithms and Programming","17 Feb 2011","2010","","","130","137","GPUs are many-core processors with tremendous computational power. However, as automatic parallelization has not been realized yet, developing high-performance parallel code for GPUs is still very challenging. The paper presents a novel translation framework designed for virtual execution environment based on CPU/GPU architecture. It addresses two major challenges of taking advantage of general purpose computation on graphics processing units (GPGPU) to improve performance: no rewriting the existing source code and resolving binary compatibility issues between different GPUs. The translation framework uses semi-automatic parallelization technology to port existing code to explicitly parallel programming models. It not only offers a mapping strategy from X86 platform to CUDA programming model, but also synchronizes the execution between the CPU and the GPUs. The input to our translation framework is parallelizable part of the program within binary code. With an additional information related to the parallelizable part, the translation framework transforms the sequential code into PTX code and execute it on GPUs. Experimental results on several programs from CUDA SDK Code Samples and Parboil Benchmark Suite show that our translation framework could achieve very high performance, even up to several tens of times speedup over the X86 native version.","2168-3042","978-1-4244-9482-8","10.1109/PAAP.2010.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715074","GPGPU;Parallelization;Translator;CUDA","Graphics processing unit;Registers;Kernel;Instruction sets;Driver circuits;Programming;Computer architecture","computer graphic equipment;coprocessors;multiprocessing systems;parallel architectures","virtual execution environment;CPU-GPU Architecture;many core processors;X86 platform;CUDA programming model;CUDA SDK code samples;Parboil benchmark suite","","","1","25","","17 Feb 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Parallel quantum computer simulation on the GPU","A. Amariutei; S. Caraiman","Faculty of Automatic Control and Computer Engineering, Technical University of Iasi, Romania; Faculty of Automatic Control and Computer Engineering, Technical University of Iasi, Romania","15th International Conference on System Theory, Control and Computing","28 Nov 2011","2011","","","1","6","Simulation of quantum computers using classical computers is a hard problem with high memory and computational requirements. Parallelization can alleviate this problem, allowing the simulation of more qubits at the same time or the same number of qubits to be simulated in less time. A promising approach is to exploit the high performance computing capabilities provided by the latest graphical processing units. In this paper we present a parallel implementation of the QC-lib quantum computer simulator on the GPU using the CUDA programming model. The proposed scheme for partitioning the terms that describe the state of a quantum register takes advantage of the specific characteristics of the CUDA memory spaces and allows for an efficient parallelization of the general singe qubit operator. Experimental results indicate that very good speed-ups can be obtained in contrast with the sequential implementation.","","978-973-621-321-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6085728","","Quantum computing;Graphics processing unit;Computational modeling;Registers;Computers;Instruction sets;Quantum cascade lasers","computer graphic equipment;coprocessors;parallel programming;quantum computing","parallel quantum computer simulation;GPU;high performance computing capability;graphical processing unit;parallel implementation;QC-lib quantum computer simulator;CUDA programming model;quantum register","","","","33","","28 Nov 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Solving N-Queens problem on GPU architecture using OpenCL with special reference to synchronization issues","K. Thouti; S. R. Sathe","Dept. of Computer Science & Engg., Visvesvaraya National Institute of Technology, Nagpur, India; Dept. of Computer Science & Engg., Visvesvaraya National Institute of Technology, Nagpur, India","2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing","7 Feb 2013","2012","","","806","810","The N-Queens problem is to place N queens on an N × N chessboard such that no two queens attack each other. General purpose computing on graphics processing units (GPGPU) is fast becoming a common feature of high performance computing. This paper investigates cost of finding the solutions to N-Queens problem on GPGPU architecture using OpenCL programming model. We extensively analyze the N-Queen problem with respect to local, global memory parameters and atomicity and synchronization issues in OpenCL and its effects on performance. Experimental results are shown on NVidia Quadro FX 3800 GPU. Using Queens between 16 and 21, we observed average speedup of 20x.","","978-1-4673-2925-5","10.1109/PDGC.2012.6449926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6449926","GPGPU;OpenCL;N-Queen problem;Parallel copmuting;Graphical processors","Performance evaluation;Graphics processing units;Artificial neural networks;Synchronization","application program interfaces;game theory;graphics processing units;multiprocessing systems;parallel architectures","many-core processor;NVidia Quadro FX 3800 GPU;synchronization issues;atomicity issues;global memory parameters;local memory parameters;OpenCL programming model;general purpose computing-on-graphics processing units;GPGPU architecture;N-queens problem","","6","","26","","7 Feb 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Efficient Parallel Preconditioned Conjugate Gradient Solver on GPU for FE Modeling of Electromagnetic Fields in Highly Dissipative Media","A. F. P. de Camargos; V. C. Silva; J. Guichon; G. Munier","Escola Politécnica da Universidade de São Paulo, São Paulo, Brazil; V. C. Silva is with the Escola Politécnica da Universidade de São Paulo, São Paulo, SP, 05508-010, Brazil; Laboratoire de Génie Electrique de Grenoble, CNRS, Saint Martin d'Hères, France; Laboratoire de Génie Electrique de Grenoble, CNRS, Saint Martin d'Hères, France","IEEE Transactions on Magnetics","26 Feb 2014","2014","50","2","569","572","We present a performance analysis of a parallel implementation of preconditioned conjugate gradient solvers using graphic processing units with compute unified device architecture programming model. The solvers were optimized for the solution of sparse systems of equations arising from finite-element analysis of electromagnetic phenomena involved in the diffusion of underground currents in both steady state and under time-harmonic current excitation. We used both shifted incomplete Cholesky factorization and incomplete LU factorization as preconditioners. The results show a significant speedup using the graphics processing unit compared with a serial CPU implementation.","1941-0069","","10.1109/TMAG.2013.2285091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6749203","FEMs;graphic processing unit (GPU);linear systems;performance analysis","Graphics processing units;Linear systems;Mathematical model;Convergence;Silicon carbide;Computer architecture;Sparse matrices","absorbing media;electromagnetic fields;finite element analysis;graphics processing units;matrix decomposition","parallel preconditioned conjugate gradient solver;graphic processing units;GPU;electromagnetic fields;dissipative media;unified device architecture programming;sparse systems;finite element analysis;electromagnetic phenomena;underground currents;time-harmonic current excitation;Cholesky factorization;graphics processing unit","","12","","15","IEEE","26 Feb 2014","","","IEEE","IEEE Journals"
notebooks/data/ieee_3.csv:"Unlocking bandwidth for GPUs in CC-NUMA systems","N. Agarwal; D. Nellans; M. O'Connor; S. W. Keckler; T. F. Wenisch",University of Michigan; NVIDIA; NVIDIA; NVIDIA; University of Michigan,"2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA)","9 Mar 2015","2015","","","354","365","Historically, GPU-based HPC applications have had a substantial memory bandwidth advantage over CPU-based workloads due to using GDDR rather than DDR memory. However, past GPUs required a restricted programming model where application data was allocated up front and explicitly copied into GPU memory before launching a GPU kernel by the programmer. Recently, GPUs have eased this requirement and now can employ on-demand software page migration between CPU and GPU memory to obviate explicit copying. In the near future, CC-NUMA GPU-CPU systems will appear where software page migration is an optional choice and hardware cache-coherence can also support the GPU accessing CPU memory directly. In this work, we describe the trade-offs and considerations in relying on hardware cache-coherence mechanisms versus using software page migration to optimize the performance of memory-intensive GPU workloads. We show that page migration decisions based on page access frequency alone are a poor solution and that a broader solution using virtual address-based program locality to enable aggressive memory prefetching combined with bandwidth balancing is required to maximize performance. We present a software runtime system requiring minimal hardware support that, on average, outperforms CC-NUMA-based accesses by 1.95 ×, performs 6% better than the legacy CPU to GPU memcpy regime by intelligently using both CPU and GPU memory bandwidth, and comes within 28% of oracular page placement, all while maintaining the relaxed memory semantics of modern GPUs.","2378-203X","978-1-4799-8930-0","10.1109/HPCA.2015.7056046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056046","","Graphics processing units;Bandwidth;Memory management;Hardware;Runtime;Random access memory","cache storage;graphics processing units;parallel processing;storage management","GPU-based HPC applications;GDDR memory;GPU kernel;on-demand software page migration;CC-NUMA GPU-CPU systems;hardware cache-coherence;memory-intensive GPU workloads;virtual address-based program locality;aggressive memory prefetching;bandwidth balancing;software runtime system;minimal hardware support;CPU memory bandwidth;GPU memory bandwidth;oracular page placement;GPU relaxed memory semantics","","54","1","44","","9 Mar 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Design evaluation of OpenCL compiler framework for Coarse-Grained Reconfigurable Arrays","H. Kim; M. Ahn; J. A. Stratton; W. W. Hwu","Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, USA; Samsung Advanced Institute of Technology, San 14-1, Nongseo-dong, Giheung-gu, Yongin-si, Geyonggi-do, Korea; Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, USA; Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, USA","2012 International Conference on Field-Programmable Technology","17 Jan 2013","2012","","","313","320","OpenCL is undoubtedly becoming one of the most popular parallel programming languages as it provides a standardized and portable programming model. However, adopting OpenCL for Coarse-Grained Reconfigurable Arrays (CGRA) is challenging due to divergent architecture capability compared to GPUs. In particular, CGRAs are designed to accelerate loop execution by software pipelining on a grid of functional units exploiting instruction-level parallelism. This is vastly different from a GPU in that it executes data parallel kernels using a large number of parallel threads. Therefore, an OpenCL compiler and runtime for CGRAs must map the threaded parallel programming model to a loop-parallel execution model so that the architecture can best utilize its resources. In this paper, we propose and evaluate a design for an OpenCL compiler framework for CGRAs. The proposed design is composed of a serializer and post optimizer. The serializer transforms parallel execution of work-items to an equivalent loop-based iterative execution in order to avoid expensive multithreading on CGRAs. The resulting code is further optimized by the post optimizer to maximize the coverage of software-pipelinable innermost loops. In order to achieve the goal, various loop-level optimizations can take place in the post optimizer using the loops introduced by the serializer for iterative execution of OpenCL kernels. We provide an analysis of the propose framework from a set of well-studied standard OpenCL kernels by comparing performance of various implementations of benchmarks.","","978-1-4673-2845-6","10.1109/FPT.2012.6412155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412155","OpenCL;GPU;Coarse-Grained Reconfigurable Arrays;CGRA;Samsung Reconfigurable Processor;SRP;RP","Kernel;Computer architecture;Graphics processing units;Optimization;Programming;Hardware","multi-threading;optimising compilers;parallel languages;pipeline processing;reconfigurable architectures;software performance evaluation","design evaluation;OpenCL compiler framework;coarse-grained reconfigurable arrays;parallel programming languages;standardized programming model;portable programming model;CGRA;software pipelining;functional unit grid;instruction-level parallelism;parallel kernels;data execution;parallel threads;threaded parallel programming model;loop-parallel execution model;serializer;post optimizer;loop-based iterative execution;multithreading;innermost loop coverage maximization;loop-level optimizations;iterative OpenCL kernel execution","","6","","19","","17 Jan 2013","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A programming model and runtime system for approximation-aware heterogeneous computing","I. Parnassos; N. Bellas; N. Katsaros; N. Patsiatzis; A. Gkaras; K. Kanellis; C. D. Antonopoulos; M. Spyrou; M. Maroudas","Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece; Electrical and Computer Engineering Department, University of Thessaly, Volos, Greece","2017 27th International Conference on Field Programmable Logic and Applications (FPL)","5 Oct 2017","2017","","","1","4","Heterogeneous platforms that include diverse architectures such as multicore CPUs, FPGAs and GPUs are becoming very popular due to their superior performance and energy efficiency. Besides heterogeneity, a promising approach for minimizing energy consumption is through approximate computing which relaxes the requirement that all parts of a program are considered equally important to the output quality, thus, all should be executed at full accuracy. Our work extends a traditional OpenMP-like programming model and runtime system to support seamless execution on hybrid architectures with approximation semantics. Starting from a common application code, annotated with our programming model, the programmer can not only target heterogeneous architectures comprising CPU, FPGA and GPU components, but can also regulate the amount of approximation. We evaluate our framework on a number of large-scale applications and demonstrate that the combination of heterogeneous and approximate computing can provide a powerful dynamic interplay between performance and output quality.","1946-1488","978-9-0903-0428-1","10.23919/FPL.2017.8056774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8056774","","Field programmable gate arrays;Kernel;Runtime;Graphics processing units;Programming;Histograms","multiprocessing systems;parallel architectures;parallel programming;power aware computing","energy consumption;approximate computing;runtime system;hybrid architectures;approximation semantics;heterogeneous architectures;approximation-aware heterogeneous computing;energy efficiency;OpenMP-like programming model","","1","","8","","5 Oct 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Performance Models for Hybrid Programs Accelerated by GPUs","A. Sasidharan","Ansys, Inc,Lebanon,NH,USA","2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","24 Jun 2021","2021","","","641","651","This paper describes the use of statistical tools to model the performance of mixed device (hosts and devices) programs where hosts are CPUs and devices are GPUs. The purpose of GPUs is to accelerate compute-intensive sections of a program, thereby reducing total execution time, with side-effects including reduced machine usage and energy consumption. To model major and minor factors that affect the execution time of offloaded programs, we used a compute-intensive program with several GPU kernels. We have abstracted the hybrid program as a sequence of computations that access various types of memories (device caches, device shared memory, memory of other devices and host memory). In the programming model discussed, the role of a host is reduced to scheduling and coordinating execution of kernels across devices and communicating with other hosts. It can be extended to models where hosts perform computations or are obliterated. Experiments were designed to include a range of memory sizes and types. The performance models were trained, and their predictions were verified using test data.","","978-1-6654-3577-2","10.1109/IPDPSW52791.2021.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460650","Hybrid Programming Models;Multi-GPU architectures;Unified Memory;Performance Models;Statistics","Performance evaluation;Processor scheduling;Multiprocessor interconnection;Computational modeling;Graphics processing units;Programming;Tools","cache storage;graphics processing units;mathematics computing;message passing;multiprocessing systems;scheduling","offloaded programs;compute-intensive program;GPU kernels;hybrid program;device caches;host memory;programming model;scheduling;memory sizes;performance models;hybrid programs;GPU;statistical tools;mixed device;compute-intensive sections;total execution time;reduced machine usage;energy consumption","","","","37","","24 Jun 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A GPU-inspired soft processor for high-throughput acceleration","J. Kingyens; J. Gregory Steffan","Department of Electrical and Computer Engineering, University of Toronto, Canada; Department of Electrical and Computer Engineering, University of Toronto, Canada","2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)","24 May 2010","2010","","","1","8","There is building interest in using FPGAs as accelerators for high-performance computing, but existing systems for programming them are so far inadequate. In this paper we propose a soft processor programming model and architecture inspired by graphics processing units (GPUs) that are well-matched to the strengths of FPGAs, namely highly-parallel and pipelinable computation. In particular, our soft processor architecture exploits multithreading and vector operations to supply a floating-point pipeline of 64 stages via hardware support for up to 256 concurrent thread contexts. The key new contributions of our architecture are mechanisms for managing threads and register files that maximize data-level and instruction-level parallelism while overcoming the challenges of port limitations of FPGA block memories, as well as memory and pipeline latency. Through simulation of a system that (i) supports AMD's CTM r5xx GPU ISA [1], and (ii) is realizable on an XtremeData XD1000 FPGA-based accelerator system, we demonstrate that our soft processor can achieve 100% utilization of the deeply-pipelined floating-point datapath.","","978-1-4244-6534-7","10.1109/IPDPSW.2010.5470679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470679","","Acceleration;Field programmable gate arrays;Computer architecture;Memory management;Graphics processing unit;Multithreading;Hardware","computer graphic equipment;coprocessors;field programmable gate arrays;multi-threading;parallel processing;pipeline processing","high-throughput acceleration;soft processor programming;graphics processing units;pipelinable computation;highly-parallel computation;floating-point pipeline;multithreading process;instruction-level parallelism;AMD CTM r5xx GPU ISA;XtremeData XD1000 FPGA-based accelerator system;GPU","","7","","15","","24 May 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"DistributedCL: A Framework for Transparent Distributed GPU Processing Using the OpenCL API","A. Tupinambá; A. Sztajnberg","Programa de Eng. Eletron. - PEL, Univ. do Estado do Rio de Janeiro - UERJ, Rio de Janeiro, Brazil; Dept. de Inf. e Cienc. da Comput., Univ. do Estado do Rio de Janeiro - UERJ, Rio de Janeiro, Brazil","2012 13th Symposium on Computer Systems","24 Dec 2012","2012","","","187","193","This paper presents the DistributedCL, a framework that provides the applications developed using the OpenCL interface location-transparent GPU processing. The application can explore distributed processing with no modification. The architecture of the framework and the programming model are presented, and the possible performance bottlenecks are discussed.","","978-1-4673-4468-5","10.1109/WSCAD-SSC.2012.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6391781","OpenCL;GPGPU;framework;distributed systems","Graphics processing units;Kernel;Computational modeling;Electronic mail;Linux;Distributed processing;Computer architecture","application program interfaces;graphics processing units","transparent distributed GPU processing;OpenCL API;DistributedCL;OpenCL interface location-transparent GPU processing;performance bottlenecks","","1","","20","","24 Dec 2012","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Performance Analysis of Sequential and Parallel Programming Paradigms on CPU-GPUs Cluster","B. N. Chandrashekhar; H. A. Sanjay","Nitte Meenakshi Institute of Technology,Department of ISE,Bangalore,India,560064; Nitte Meenakshi Institute of Technology,Department of ISE,Bangalore,India,560064","2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)","31 Mar 2021","2021","","","1205","1213","The entire world of parallel computing endured a change when accelerators are gradually embraced in today's high-performance computing cluster. A hybrid CPU-GPU cluster is required to speed up the complex computations by using parallel programming paradigms. This paper deals with performance evaluation of sequential, parallel and hybrid programming paradigms on the hybrid CPU-GPU cluster using the sorting strategies such as quick sort, heap sort and merge sort. In this research work performance comparison of C, MPI, and hybrid [MPI+CUDA] on CPU-GPUs hybrid systems are performed by using the sorting strategies. From the analysis it is observed that, the performance of parallel programming paradigm MPI is better when compared against sequential programming model. Also, research work evaluates the performance of CUDA on GPUs and hybrid programming model [MPI+CUDA] on CPU+GPU cluster using merge sort strategies and noticed that hybrid programming model [MPI+CUDA] has better performance against traditional approach and parallel programming paradigms MPI and CUDA When the overall performance of all three programming paradigms are compared, MPI+CUDA based on CPU+GPU environment gives the best speedup.","","978-1-6654-1960-4","10.1109/ICICV50876.2021.9388469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388469","Parallel programming pardigms;Performance model;hybrid parallel computing models;Central Processing Unit;compute unified device architecture;Graphics Processing Unit;message passing interface","Performance evaluation;Parallel programming;Computational modeling;Graphics processing units;Programming;Parallel processing;Sorting","application program interfaces;graphics processing units;merging;message passing;parallel architectures;parallel programming;pattern clustering;software performance evaluation;sorting","sorting strategies;quick sort;heap sort;parallel programming paradigm MPI;sequential programming model;hybrid programming model;performance analysis;parallel computing;high performance computing cluster;hybrid CPU GPU cluster;CUDA performance evaluation;merge sort strategies","","","","21","","31 Mar 2021","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"An MPI/GPU parallelization of an interior penalty discontinuous Galerkin time domain method for Maxwell's equations","S. Dosopoulos; J. D. Gardiner; J. Lee","Electrical and Computer Engineering Department, Ohio State University, Columbus, Ohio, USA.; Ohio Supercomputer Center, Columbus, Ohio, USA.; Electrical and Computer Engineering Department, Ohio State University, Columbus, Ohio, USA.","Radio Science","9 Dec 2016","2011","46","03","1","10","In this paper we discuss our approach to the MPI/GPU implementation of an Interior Penalty Discontinuous Galerkin Time domain (IPDGTD) method to solve the time dependent Maxwell's equations. In our approach, we exploit the inherent DGTD parallelism and describe a combined MPI/GPU and local time stepping implementation. This combination is aimed at increasing efficiency and reducing computational time, especially for multiscale applications. The CUDA programming model was used, together with non-blocking MPI calls to overlap communications across the network. A 10X speedup compared to CPU clusters is observed for double precision arithmetic. Finally, for p = 1 basis functions, a good scalability with parallelization efficiency of 85% for up to 40 GPUs and 80% for up to 160 CPU cores was achieved on the Ohio Supercomputer Center's Glenn cluster.","1944-799X","","10.1029/2011RS004689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776116","","Graphics processing units;Finite element analysis;Time-domain analysis;Scalability;Method of moments;Mathematical model;Hardware","","","","4","","","","9 Dec 2016","","","AGU","AGU Journals"
notebooks/data/ieee_3.csv:"Parallel implementation of Multi-dimensional Ensemble Empirical Mode Decomposition","L. Chang; M. Lo; N. Anssari; K. Hsu; N. E. Huang; W. W. Hwu","University of Illinois at Urbana-Champaign, USA 61801; National Central University, Chungli, Taiwan 32001; University of Illinois at Urbana-Champaign, USA 61801; National Central University, Chungli, Taiwan 32001; National Central University, Chungli, Taiwan 32001; University of Illinois at Urbana-Champaign, USA 61801","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","11 Jul 2011","2011","","","1621","1624","In this paper, we propose and evaluate two parallel implementations of Multi-dimensional Ensemble Empirical Mode Decomposition (MEEMD) for multi-core (CPU) and many-core (GPU) architectures. Relative to a sequential C implementation, our double precision GPU implementation, using the CUDA programming model, achieves up to 48.6x speedup on NVIDIA Tesla C2050. Our multi-core CPU implementation, using the OpenMP programming model, achieves up to 11.3x speedup on two octal-core Intel Xeon x7550 CPUs.","2379-190X","978-1-4577-0539-7","10.1109/ICASSP.2011.5946808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946808","Multi-dimensional Ensemble Empirical Mode Decomposition;GPGPU;OpenMP;CUDA","Graphics processing unit;Parallel processing;Instruction sets;Spline;Interpolation;Programming","computer graphic equipment;coprocessors;multiprocessing systems;parallel architectures;parallel programming","parallel implementation;multidimensional ensemble empirical mode decomposition;multicore architecture;many-core architecture;sequential C implementation;double precision GPU implementation;CUDA programming model;NVIDIA Tesla C2050;multicore CPU implementation;OpenMP programming model;octal-core Intel Xeon CPU","","15","","17","","11 Jul 2011","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"OpenCL - An effective programming model for data parallel computations at the Cell Broadband Engine","J. Breitbart; C. Fohry","Research Group Programming Languages / Methodologies, Universität Kassel, Germany; Research Group Programming Languages / Methodologies, Universität Kassel, Germany","2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)","24 May 2010","2010","","","1","8","Current processor architectures are diverse and heterogeneous. Examples include multicore chips, CPUs and the Cell Broadband Engine (CBE). The recent Open Compute Language (OpenCL) standard aims at efficiency and portability. This paper explores its efficiency when implemented on the CBE, without using CBE-specific features such as explicit asynchronous memory transfers. We based our experiments on two applications: matrix multiplication, and the client side of the Einstein@Home distributed computing project. Both were programmed in OpenCL, and then translated to the CBE. For matrix multiplication, we deployed different levels of OpenCL performance optimization, and observed that they pay off on the CBE. For the Einstein@Home application, our translated OpenCL version achieves almost the same speed as a native CBE version. Another main contribution of the paper is a proposal for an additional memory level in OpenCL, called static local memory. With little programming expense, it can lead to significant speedups such as factor seven for reduction. Finally, we studied two versions of the OpenCL to CBE mapping, in which the PPE component of the CBE does or does not take the role of a compute unit.","","978-1-4244-6534-7","10.1109/IPDPSW.2010.5470823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470823","","Parallel programming;Concurrent computing;Engines;Computer architecture;Multicore processing;Hardware;Computer languages;Distributed computing;Optimization;Proposals","computer graphics;coprocessors;matrix multiplication;parallel programming","programming model;data parallel computations;cell broadband engine;multicore chips;GPU;open compute language;explicit asynchronous memory transfers;matrix multiplication;Einstein@Home distributed computing project;static local memory","","7","","12","","24 May 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"GraphReduce: processing large-scale graphs on accelerator-based systems","D. Sengupta; S. L. Song; K. Agarwal; K. Schwan",NA; NA; NA; NA,"SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","26 Jan 2017","2015","","","1","12","Recent work on real-world graph analytics has sought to leverage the massive amount of parallelism offered by GPU devices, but challenges remain due to the inherent irregularity of graph algorithms and limitations in GPU-resident memory for storing large graphs. We present GraphReduce, a highly efficient and scalable GPU-based framework that operates on graphs that exceed the device's internal memory capacity. GraphReduce adopts a combination of edge- and vertex-centric implementations of the Gather-Apply-Scatter programming model and operates on multiple asynchronous GPU streams to fully exploit the high degrees of parallelism in GPUs with efficient graph data movement between the host and device. GraphReduce-based programming is performed via device functions that include gatherMap, gatherReduce, apply, and scatter, implemented by programmers for the graph algorithms they wish to realize. Extensive experimental evaluations for a wide variety of graph inputs and algorithms demonstrate that GraphReduce significantly outperforms other competing out-of-memory approaches.","2167-4337","978-1-4503-3723-6","10.1145/2807591.2807655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832802","","Graphics processing units;Parallel processing;Programming;Memory management;Computational modeling;Acceleration;Partitioning algorithms","data handling;graph theory;parallel processing","GraphReduce;large-scale graphs processing;accelerator-based systems;graph analytics;parallelism;GPU devices;GPU-based framework;internal memory capacity;edge-centric implementations;vertex-centric implementations;gather-apply-scatter programming model;multiple asynchronous GPU streams;graph data movement;device functions;gatherMap;gatherReduce","","12","1","43","","26 Jan 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Student Session: Practical Insights on Acceleration for 3D Lidar Data Processing","I. Baek; K. Fuseini; R. R. Rajkumar",Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,"2020 IEEE 26th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)","22 Sep 2020","2020","","","1","2","3D Lidar has become a widely used sensor technology in autonomous vehicles by providing accurate distance information. However, lidar pointcloud processing often involves sophisticated algorithms, and takes a lot of computational power. Many prior approaches relied on a GPU-based parallel programming model, such as CUDA, to accelerate these computations. However, little attention has been given to comparing different methods for selecting the most-suited programming and parallelization approaches for a given computing system. We present our findings and insights identified by implementing various parallel approaches considering both CPUs and GPUs. We also demonstrate significant acceleration results using a real-world perception algorithm developed to detect road boundaries. Finally, we compare the pros and cons of each method in terms of system architecture, programming model, and resource utilization to yield a better understanding of choosing the best parallelization approach for a given optimization objective.","2325-1301","978-1-7281-4403-0","10.1109/RTCSA50079.2020.9203651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203651","","Graphics processing units;Data structures;Acceleration;Laser radar;Runtime;Sorting;Kernel","data structures;graphics processing units;optical information processing;optical radar;parallel programming","sensor technology;autonomous vehicles;accurate distance information;computational power;GPU-based parallel programming model;system architecture;parallelization approach;optimization objective;lidar point cloud processing;real-world perception algorithm;CUDA;CPUs;road boundaries detection;programming model;resource utilization;3D Lidar data processing acceleration","","","","2","","22 Sep 2020","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Connecting the dots: Triangle completion and related problems on large data sets using GPUs","A. Chatterjee; S. Radhakrishnan; C. N. Sekharan","School of Computer Science, University of Oklahoma, Norman, USA; School of Computer Science, University of Oklahoma, Norman, USA; Department of Computer Science, Loyola University Chicago, Chicago, IL, USA","2014 IEEE International Conference on Big Data (Big Data)","8 Jan 2015","2014","","","1","8","Studying the properties of Online Social Networks (OSNs) and other real world graphs have gained importance due to the large amount of information available from them. These large graphs contain data that can be analyzed and effectively used in advertising, security and improving the overall experience of the users of these networks. However, the analysis of these graphs for studying specific properties requires combinatorially explosive number of computations. Compute Unified Device Architecture (CUDA) is a programming model available from Nvidia for solving general-purpose problems using the massively parallel and highly multi-threaded Graphics Processing Units (GPUs). Therefore, using GPUs to solve these types of problems is appropriate. In addition, due to the properties of real-world data, the graphs being considered are sparse and have irregular data dependencies. Hence, using efficient techniques to store the graph data for initial preprocessing and final computation by taking advantage of heterogeneous CPU-GPU systems can address these issues. In this paper, we are interested in studying different properties of these real-world entities that transform into the following graph problems: a) identifying a missing edge, which when added would result in maximum increase in the number of triangles, b) identifying an existing edge whose removal would result in the maximum decrease in the number of triangles, c) identifying an existing edge whose removal would increase the number of connected components in the graph. In this paper, we develop and implement algorithms to solve the above problems using both CPU and GPU. Specifically, given a graph G = (V, E), we provide algorithms for the following: a) find (v<sub>i</sub>, V<sub>j</sub>) ∉ E, such that Δ<sub>f</sub> - Δ<sub>c</sub> is maximized, where Δ<sub>f</sub> and Δ<sub>c</sub> are the number of triangles in G<sub>m</sub> = (V, E ∪(v<sub>i</sub>, V<sub>j</sub>)) and G, respectively, b) find a (v<sub>i</sub>, V<sub>j</sub>) ϵ E, such that Δ<sub>c</sub> - Δ<sub>f</sub> is maximized, where Δ<sub>f</sub> and Δ<sub>c</sub> are the number of triangles in G<sub>m</sub> = (V, E \ (v<sub>i</sub>, V<sub>j</sub>)) and G = (V, E), respectively, c) find a (v<sub>i</sub>, V<sub>j</sub>) ϵ E, such that Φ<sub>c</sub> > Φ<sub>c</sub>, where Φ<sub>c</sub> and Φ<sub>c</sub> are the number of connected components in G<sub>m</sub> = (V, E \ (v<sub>i</sub>, V<sub>j</sub>)) and G = (V, E), respectively. We implement the algorithms using a GPU and achieve a 10 × speedup as compared to a sequential implementation. Thereafter, we design a heuristic for finding an edge whose existence would result in the maximum increase in the number of triangles. The heuristic is implemented and the results are reported and compared to those of the regular algorithm on the GPU.","","978-1-4799-5666-1","10.1109/BigData.2014.7004365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004365","Graph problems;Online Social Networks;Triangle completion;CUDA;GPU","Joining processes;Graphics processing units;Algorithm design and analysis;Social network services;Testing;Educational institutions;Advertising","computer graphics;graphics processing units;Internet","triangle completion;large data sets;online social networks;OSN;compute unified device architecture;CUDA;programming model;Nvidia;general-purpose problems;multithreaded graphics processing units;irregular data dependencies;graph data;heterogeneous CPU-GPU systems","","3","","18","","8 Jan 2015","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Speculative execution on multi-GPU systems","G. Diamos; S. Yalamanchili","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia 30332-0250; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia 30332-0250","2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)","24 May 2010","2010","","","1","12","The lag of parallel programming models and languages behind the advance of heterogeneous many-core processors has left a gap between the computational capability of modern systems and the ability of applications to exploit them. Emerging programming models, such as CUDA and OpenCL, force developers to explicitly partition applications into components (kernels) and assign them to accelerators in order to utilize them effectively. An accelerator is a processor with a different ISA and micro-architecture than the main CPU. These static partitioning schemes are effective when targeting a system with only a single accelerator. However, they are not robust to changes in the number of accelerators or the performance characteristics of future generations of accelerators. In previous work, we presented the Harmony execution model for computing on heterogeneous systems with several CPUs and accelerators. In this paper, we extend Harmony to target systems with multiple accelerators using control speculation to expose parallelism. We refer to this technique as Kernel Level Speculation (KLS). We argue that dynamic parallelization techniques such as KLS are sufficient to scale applications across several accelerators based on the intuition that there will be fewer distinct accelerators than cores within each accelerator. In this paper, we use a complete prototype of the Harmony runtime that we developed to explore the design decisions and trade-offs in the implementation of KLS. We show that KLS improves parallelism to a sufficient degree while retaining a sequential programming model. We accomplish this by demonstrating good scaling of KLS on a highly heterogeneous system with three distinct accelerator types and ten processors.","1530-2075","978-1-4244-6443-2","10.1109/IPDPS.2010.5470427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470427","","Parallel programming;Kernel;Parallel processing;Concurrent computing;Instruction sets;Robustness;Character generation;Control systems;Prototypes;Runtime","coprocessors;multiprocessing systems;parallel programming","speculative execution;multi-GPU systems;parallel programming models;parallel programming languages;heterogeneous many-core processors;computational capability;CUDA;OpenCL;application partitioning;components;accelerator;ISA;micro-architecture;Harmony execution model;kernel level speculation;dynamic parallelization techniques;Harmony runtime;sequential programming model;heterogeneous system","","12","","28","","24 May 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"A GPU-Accelerated SVD Algorithm, Based on QR Factorization and Givens Rotations, for DWI Denoising","L. Marcellino; G. Navarra","Dept. of Sci. & Technol., Univ. of Naples Parthenope, Naples, Italy; Dept. of Sci. & Technol., Univ. of Naples Parthenope, Naples, Italy","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","24 Apr 2017","2016","","","699","704","In this work, we present a parallel implementation of the Singular Value Decomposition (SVD) method on Graphics Processing Units (GPUs) using CUDA programming model. Our approach is based on an iterative parallel version of the QR factorization by means Givens plane rotations using the Sameh and Kuck scheme. The parallel algorithm is driven by an outer loop executed on the CPU. Therefore, threads and blocks configuration is organized in order to use the shared memory and avoid multiple accesses to global memory. However, the main kernel provides coalesced accesses to global memory using contiguous indices. As case study, we consider the application of the SVD in the Overcomplete Local Principal Component Analysis (OLPCA) algorithm for the Diffusion Weighted Imaging (DWI) denoising process. Our results show significant improvements in terms of performances with respect to the CPU version that encourage its usability for this expensive application.","","978-1-5090-5698-9","10.1109/SITIS.2016.117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907544","SVD;QR factorization;Givens Rotations;GPGPU;PCA;DWI denoising","Matrix decomposition;Graphics processing units;Central Processing Unit;Noise reduction;Principal component analysis;Parallel algorithms;Image processing","biomedical MRI;graphics processing units;image denoising;matrix decomposition;medical image processing;parallel architectures;parallel programming;principal component analysis;singular value decomposition","GPU-accelerated SVD algorithm;DWI denoising;singular value decomposition;SVD method;graphics processing units;CUDA programming model;iterative parallel QR factorization;Givens plane rotations;Sameh-and-Kuck scheme;parallel algorithm;outer loop;thread configuration;block configuration;shared memory;global memory;contiguous indices;SVD;overcomplete local principal component analysis;OLPCA algorithm;diffusion weighted imaging denoising process;DWI denoising process;performance improvement;diffusion tensor imaging","","1","","24","","24 Apr 2017","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Game developer's perspective on OpenCL","E. Schenk","EA, USA","2009 IEEE Hot Chips 21 Symposium (HCS)","26 May 2016","2009","","","1","44","Presents a collection of slides covering the following topics: game development; OpenCL; concurrent programming model; Amdahl's law; game experiences; memory objects; data flow; command queue; vectorization; scalar integrator; vector integrator; parallelism; GPU memory; and GPU device performance.","","978-1-4673-8873-3","10.1109/HOTCHIPS.2009.7478347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7478347","","Art;Open systems;Data models;Games;Computer platforms;Concurrent computing;Standards;Computer graphics;Videos","computer games;concurrency control;graphics processing units;parallel programming;specification languages;storage management","game development;OpenCL;concurrent programming model;Amdahl law;game experience;memory objects;data flow;command queue;vectorization;scalar integrator;vector integrator;parallelism;GPU memory;GPU device performance;graphics processing unit","","","","","","26 May 2016","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Efficient Data Communication between CPU and GPU through Transparent Partial-Page Migration","S. Zhang; Y. Yang; L. Shen; Z. Wang","Dept. of Comput. Sci. & Technol., Nat. Univ. of Defense Technol., Changsha, China; Dept. of Comput. Sci. & Technol., Nat. Univ. of Defense Technol., Changsha, China; Dept. of Comput. Sci. & Technol., Nat. Univ. of Defense Technol., Changsha, China; Dept. of Comput. Sci. & Technol., Nat. Univ. of Defense Technol., Changsha, China","2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)","24 Jan 2019","2018","","","618","625","Despite the increasing investment in integrated GPUs and next-generation interconnect research, discrete GPUs connected by PCI Express still account for the dominant position of the market, the management of data communication between CPU and GPU continues to evolve. Initially, the programmer controls the data transfer between CPU and GPU explicitly. To simplify programming and enable system-wide atomic memory operations, GPU vendors have developed a programming model that provides a single virtual address space. The page migration engine in this model migrates pages between CPU and GPU on demand automatically. To meet the needs of high-performance workloads, the page size tends to be larger. Limited by low bandwidth and high latency interconnects, larger page migration has longer delay, which may reduce the overlap of computation and transmission and cause serious performance decline. In this paper, we propose partial-page migration that only migrates the requested part of a page to shorten the migration latency and avoid the performance degradation of the whole-page migration when the page becomes larger. Experiments show that partial-page migration is possible to significantly hide the performance overheads of whole-page migration when the page size is 2MB and the PCI Express bandwidth is 16GB/sec, converting an average 72.72× slowdown to a 1.29× speedup when compared with programmers controlled data transmission. Additionally, we examine the impact of page size on TLB miss rate and the performance impact of migration unit size on execution time, enabling designers to make informed decisions.","","978-1-5386-6614-2","10.1109/HPCC/SmartCity/DSS.2018.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622850","Unified Memory, Data Communication, Partial Page Migration","Graphics processing units;Data communication;Memory management;Bandwidth;Programming;Delays;Central Processing Unit","data communication;graphics processing units;paged storage","whole-page migration;PCI Express bandwidth;data transmission;transparent partial-page migration;next-generation interconnect research;system-wide atomic memory operations;GPU vendors;high-performance workloads;data communication","","1","","23","","24 Jan 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Acceleration of regular grid traversals using extended chessboard distance transformation on GPU","A. Es; V. Isler","Tubitak-Bilten, METU, Turkey; NA","Ninth International Conference on Computer Aided Design and Computer Graphics (CAD-CG'05)","13 Mar 2006","2005","","","8 pp.","","In the recent years graphics processing units (GPU) have evolved into general purpose programmable streaming parallel processors. This evolution makes it possible to implement high quality photo realistic rendering techniques on graphics processors. There have been a few studies to show how to map ray tracing to the GPU. Since graphics processors are not designed to process complex data structures, it is crucial to explore data structures and algorithms for efficient stream processing. In particular ray traversal is one of the most time consuming parts of ray tracing methods. In this work we focus on the efficient ray traversals on GPU. Several known techniques have been redesigned and adapted to the GPU programming model. Also a new traversal method based on extended anisotropic chessboard distance metric has been introduced.","","0-7695-2473-7","10.1109/CAD-CG.2005.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1604672","","Acceleration;Data structures;Ray tracing;Computer graphics;Anisotropic magnetoresistance;Concurrent computing;Rendering (computer graphics);Process design;Algorithm design and analysis;Parallel processing","coprocessors;parallel processing;rendering (computer graphics);ray tracing","regular grid traversals;chessboard distance transformation;GPU;graphics processing units;general purpose programmable streaming parallel processors;photo realistic rendering;ray tracing;ray traversals;anisotropic chessboard distance metric","","2","","18","","13 Mar 2006","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Achieving High Performance on Supercomputers with a Sequential Task-based Programming Model","E. Agullo; O. Aumage; M. Faverge; N. Furmento; F. Pruvost; M. Sergent; S. P. Thibault","HiePACS, Inria Centre de recherche Bordeaux Sud-Ouest, 113923 Talence, Aquitaine France (e-mail: emmanuel.agullo@inria.fr); STORM, Inria Centre de recherche Bordeaux Sud-Ouest, 113923 Talence, Aquitaine France (e-mail: olivier.aumage@inria.fr); HiePACS, Bordeaux INP, Talence, Aquitaine France (e-mail: mathieu.faverge@inria.fr); STORM, LaBRI, TALENCE, Aquitaine France (e-mail: nathalie.furmento@labri.fr); HiePACS, Inria Centre de recherche Bordeaux Sud-Ouest, 113923 Talence, Aquitaine France (e-mail: florent.pruvost@inria.fr); STORM, Inria Centre de recherche Bordeaux Sud-Ouest, 113923 Talence, Aquitaine France (e-mail: marc.sergent@inria.fr); Computer science, LaBRI, TALENCE, - France 33405 (e-mail: samuel.thibault@u-bordeaux.fr)","IEEE Transactions on Parallel and Distributed Systems","","2017","PP","99","1","1","The emergence of accelerators as standard computing resources on supercomputers and the subsequent architectural complexity increase revived the need for high-level parallel programming paradigms. Sequential task-based programming model has been shown to efficiently meet this challenge on a single multicore node possibly enhanced with accelerators, which motivated its support in the OpenMP 4.0 standard. In this paper, we show that this paradigm can also be employed to achieve high performance on modern supercomputers composed of multiple such nodes, with extremely limited changes in the user code. To prove this claim, we have extended the StarPU runtime system with an advanced inter-node data management layer that supports this model by posting communications automatically. We illustrate our discussion with the task-based tile Cholesky algorithm that we implemented on top of this new runtime system layer. We show that it allows for very high productivity while achieving a performance competitive with both the pure Message Passing Interface (MPI)-based ScaLAPACK Cholesky reference implementation and the DPLASMA Cholesky code, which implements another (non sequential) task-based programming paradigm.","1558-2183","","10.1109/TPDS.2017.2766064","ANR SOLHAR(grant numbers:ANR-13-MONU-0007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8226789","runtime system;sequential task flow;task-based programming;heterogeneous computing;distributed computing;multicore;GPU;Cholesky factorization","Runtime;Programming;Supercomputers;Libraries;Algorithm design and analysis;Productivity","","","","12","","","IEEE","19 Dec 2017","","","IEEE","IEEE Early Access Articles"
notebooks/data/ieee_3.csv:"Asynchronous Task-Based Execution of the Reverse Time Migration for the Oil and Gas Industry","A. AlOnazi; H. Ltaief; D. Keyes; I. Said; S. Thibault","King Abdullah University of Science and Technology,Extreme Computing Research Center,Thuwal,Jeddah 23955,Saudi Arabia; King Abdullah University of Science and Technology,Extreme Computing Research Center,Thuwal,Jeddah 23955,Saudi Arabia; King Abdullah University of Science and Technology,Extreme Computing Research Center,Thuwal,Jeddah 23955,Saudi Arabia; NVIDIA,Oil and Gas Department,Paris,France; Univ. Bordeaux,Talence,33400 France","2019 IEEE International Conference on Cluster Computing (CLUSTER)","7 Nov 2019","2019","","","1","11","We propose a new framework for deploying Reverse Time Migration (RTM) simulations on distributed-memory systems equipped with multiple GPUs. Our software, TB-RTM, infrastructure engine relies on the StarPU dynamic runtime system to orchestrate the asynchronous scheduling of RTM computational tasks on the underlying resources. Besides dealing with the challenging hardware heterogeneity, TB-RTM supports tasks with different workload characteristics, which stress disparate components of the hardware system. RTM is challenging in that it operates intensively at both ends of the memory hierarchy, with compute kernels running at the highest level of the memory system, possibly in GPU main memory, while I/O kernels are saving solution data to fast storage. We consider how to span the wide performance gap between the two extreme ends of the memory system, i.e., GPU memory and fast storage, on which large-scale RTM simulations routinely execute. To maximize hardware occupancy while maintaining high memory bandwidth throughout the memory subsystem, our framework presents the new-of-core (OOC) feature from StarPU to prefetch data solutions in and out not only from/to the GPU/CPU main memory but also from/to the fast storage system. The OOC technique may trigger opportunities for overlapping expensive data movement with computations. TB-RTM framework addresses this challenging problem of heterogeneity with a systematic approach that is oblivious to the targeted hardware architectures. Our resulting RTM framework can effectively be deployed on massively parallel GPU-based systems, while delivering performance scalability up to 500 GPUs.","2168-9253","978-1-7281-4734-5","10.1109/CLUSTER.2019.8891054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891054","Reverse Time Migration;Task-Based Programming Model;Out-Of-Core Algorithms;Asynchronous Executions;Overlapping I/O with Computation;STARPU OOC","Task analysis;Kernel;Computational modeling;Hardware;Runtime;Graphics processing units","gas industry;graphics processing units;multiprocessing systems;parallel processing;scheduling;shared memory systems;storage management","asynchronous task-based execution;oil and gas industry;distributed-memory systems;multiple GPUs;StarPU dynamic runtime system;asynchronous scheduling;RTM computational tasks;workload characteristics;hardware system;memory hierarchy;compute kernels;memory system;GPU main memory;large-scale RTM simulations;hardware occupancy;memory bandwidth;memory subsystem;data solutions;fast storage system;targeted hardware architectures;massively parallel GPU-based systems;RTM framework;hardware heterogeneity;reverse time migration simulation","","2","","49","","7 Nov 2019","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Efficient integral image computation on the GPU","B. Bilgic; B. K. P. Horn; I. Masaki","Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA 02139, USA; Department of Electrical Engineering and Computer Science and CSAIL, MIT, Cambridge, MA 02139, USA; Department of Electrical Engineering and Computer Science and MTL, MIT, Cambridge, MA 02139, USA","2010 IEEE Intelligent Vehicles Symposium","16 Aug 2010","2010","","","528","533","We present an integral image algorithm that can run in real-time on a Graphics Processing Unit (GPU). Our system exploits the parallelisms in computation via the NIVIDA CUDA programming model, which is a software platform for solving non-graphics problems in a massively parallel high-performance fashion. This implementation makes use of the work-efficient scan algorithm that is explicated in. Treating the rows and the columns of the target image as independent input arrays for the scan algorithm, our method manages to expose a second level of parallelism in the problem. We compare the performance of the parallel approach running on the GPU with the sequential CPU implementation across a range of image sizes and report a speed up by a factor of 8 for a 4 megapixel input. We further investigate the impact of using packed vector type data on the performance, as well as the effect of double precision arithmetic on the GPU.","1931-0587","978-1-4244-7868-2","10.1109/IVS.2010.5548142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5548142","","Signal processing algorithms;Graphics processing unit;Parallel processing;Concurrent computing;Parallel programming;Central Processing Unit;Detectors","computer graphic equipment;coprocessors;image processing","integral image computation;graphics processing unit;NIVIDA CUDA programming model;nongraphics problems;scan algorithm;feature evaluation","","51","2","12","","16 Aug 2010","","","IEEE","IEEE Conferences"
notebooks/data/ieee_3.csv:"Database processing by Linear Regression on GPU using CUDA","J. B. Kulkarni; A. A. Sawant; V. S. Inamdar","Department of Computer Engineering and Information Technology, College of Engineering, Pune - 411001, India; Department of Computer Engineering and Information Technology, College of Engineering, Pune - 411001, India; Department of Computer Engineering and Information Technology, College of Engineering, Pune - 411001, India","2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies","22 Sep 2011","2011","","","20","23","In today's era, there is a great importance to parallel programming to gain high performance in terms of time required for data computation. There are some constraints to achieve parallelism on CPU (Central Processing Unit). It is possible to achieve data parallelism by SIMD (Single Instruction Multiple Data) on General Purpose Graphics Processing Unit (GPGPU) integrated with Central Processing Unit (CPU). In Database processing, most of the research is going on. In this implementation, Linear Regression Algorithm is used to achieve parallelism in database processing on images using a programming model, Compute Unified Device Architecture (CUDA) which uses multithreading technique. Most of the time is required to perform various operations on huge content-based database e.g. to read big images, datasets, etc. Linear Regression is one of the algorithm to predict, forecast, mine huge amount of data. Linear Regression using CUDA can achieve high performance. Here, Linear Regression is implemented on Graphics Processing Unit (GPU) and on CPU to process image database for prediction of data by finding Covariance matrix, Eigen values and Eigen vectors. The strongest Eigen vector is the best fit line. The time spent for computation is compared in both the implementations.","","978-1-61284-653-8","10.1109/ICSCCN.2011.6024507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6024507","Central Processing Unit;Graphics Processing Unit;CUDA;LTI;DirectX;Residual error;Sum of square;etc","Graphics processing unit;Linear regression;Central Processing Unit;Databases;Computer architecture;Covariance matrix;Programming","computer graphic equipment;coprocessors;covariance matrices;eigenvalues and eigenfunctions;multi-threading;regression analysis;visual databases","database processing;linear regression;CUDA;Compute Unified Device Architecture;parallel programming;central processing unit;CPU;data parallelism;SIMD;single instruction multiple data;GPGPU;general purpose graphics processing unit;image database;covariance matrix;eigenvalues;eigenvectors;multithreading technique","","3","","12","","22 Sep 2011","","","IEEE","IEEE Conferences"

```
