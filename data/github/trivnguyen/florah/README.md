# https://github.com/trivnguyen/florah

```console
src/florah/models/attention_model/att_generator.py:                x, x, x, attn_mask=attn_mask.cuda(), need_weights=False)[0])
src/florah/utils/sampling.py:            'cuda' if torch.cuda.is_available() else 'cpu')
src/florah/utils/sampling.py:        device = torch.device('cpu' if torch.cuda.is_available() else 'cuda')

```
